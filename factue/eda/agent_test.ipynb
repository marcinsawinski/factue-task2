{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import BaseOutputParser\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "import json\n",
    "\n",
    "\n",
    "# --- Custom Output Parser for JSON ---\n",
    "\n",
    "\n",
    "class GuardedJSONParser(BaseOutputParser):\n",
    "    \"\"\"Parses LLM output by looking for a guard token and parsing JSON safely.\"\"\"\n",
    "\n",
    "    def parse(self, text: str) -> dict:\n",
    "        if \"JSON_OUTPUT_START\" in text:\n",
    "            text = text.split(\"JSON_OUTPUT_START\")[-1].strip()\n",
    "\n",
    "        if not text.endswith(\"}\"):\n",
    "            text += \"}\"\n",
    "\n",
    "        try:\n",
    "            return json.loads(text)\n",
    "        except json.JSONDecodeError as e:\n",
    "            raise ValueError(f\"Failed to parse JSON: {e}\\nRaw output: {text}\")\n",
    "\n",
    "\n",
    "# --- Build the prompt ---\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "You are an expert journalist and fact-checker.\n",
    "\n",
    "Compare the extracted claim with the original post and answer five fact-checking questions.\n",
    "\n",
    "For each question:\n",
    "- Answer `true` or `false`.\n",
    "- If `false`, list specific errors.\n",
    "- If `true`, leave the errors list empty.\n",
    "\n",
    "Respond ONLY in valid JSON format. End after the JSON. Do not explain anything.\n",
    "\n",
    "Here is the required output format:\n",
    "\n",
    "{{\n",
    "  \"questions\": [\n",
    "    {{\n",
    "      \"id\": \"meaning_preserved\",\n",
    "      \"answer\": true,\n",
    "      \"errors\": []\n",
    "    }},\n",
    "    {{\n",
    "      \"id\": \"correct_named_entities\",\n",
    "      \"answer\": true,\n",
    "      \"errors\": []\n",
    "    }},\n",
    "    {{\n",
    "      \"id\": \"correct_numbers\",\n",
    "      \"answer\": true,\n",
    "      \"errors\": []\n",
    "    }},\n",
    "    {{\n",
    "      \"id\": \"no_added_data\",\n",
    "      \"answer\": true,\n",
    "      \"errors\": []\n",
    "    }},\n",
    "    {{\n",
    "      \"id\": \"no_missing_data\",\n",
    "      \"answer\": true,\n",
    "      \"errors\": []\n",
    "    }}\n",
    "  ]\n",
    "}}\n",
    "\n",
    "---\n",
    "\n",
    "CLAIM:\n",
    "\\\"\\\"\\\"{claim}\\\"\\\"\\\"\n",
    "\n",
    "POST:\n",
    "\\\"\\\"\\\"{post}\\\"\\\"\\\"\n",
    "\n",
    "JSON_OUTPUT_START\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "# --- Create the LLM ---\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"your-local-model-name\",  # replace with your model name\n",
    "    openai_api_base=\"http://localhost:1234/v1\",\n",
    "    openai_api_key=\"lm-studio\",  # dummy key\n",
    "    temperature=0.0,\n",
    "    stop=[\"}\"],  # stop at end of JSON\n",
    ")\n",
    "\n",
    "# --- Build the Chain ---\n",
    "\n",
    "factcheck_chain = LLMChain(\n",
    "    llm=llm, prompt=prompt_template, output_parser=GuardedJSONParser()\n",
    ")\n",
    "\n",
    "# --- Function to call ---\n",
    "\n",
    "\n",
    "def factcheck_claim_against_post(claim: str, post: str) -> dict:\n",
    "    result = factcheck_chain.run(claim=claim, post=post)\n",
    "    return result\n",
    "\n",
    "\n",
    "# --- Example usage ---\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    claim = \"The president of Denmark pledged 3 billion euros to Norway in 2025.\"\n",
    "    post = \"In 2025, the prime minister of Sweden pledged 1.5 billion euros to Finland.\"\n",
    "\n",
    "    output = factcheck_claim_against_post(claim, post)\n",
    "    print(json.dumps(output, indent=2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

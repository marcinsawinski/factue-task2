{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5bb4b26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc303d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wd = '/mnt/openfact/users/msawinski/factue-task2'\n",
    "wd = '/Users/marcinsawinski/Documents/GitHub/factue-task2'\n",
    "import sys, os\n",
    "os.chdir(wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "baa931db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Name_Calling-Labeling\"\n",
      "\"Guilt_by_Association\"\n",
      "\"Doubt\"\n",
      "\"Appeal_to_Hypocrisy\"\n",
      "\"Questioning_the_Reputation\"\n",
      "\"Flag_Waving\"\n",
      "\"Appeal_to_Authority\"\n",
      "\"Appeal_to_Popularity\"\n",
      "\"Appeal_to_Values\"\n",
      "\"Appeal_to_Fear-Prejudice\"\n",
      "\"Straw_Man\"\n",
      "\"Red_Herring\"\n",
      "\"Whataboutism\"\n",
      "\"Appeal_to_Pity\"\n",
      "\"Causal_Oversimplification\"\n",
      "\"False_Dilemma-No_Choice\"\n",
      "\"Consequential_Oversimplification\"\n",
      "\"False_Equivalence\"\n",
      "\"Slogans\"\n",
      "\"Conversation_Killer\"\n",
      "\"Appeal_to_Time\"\n",
      "\"Loaded_Language\"\n",
      "\"Obfuscation-Vagueness-Confusion\"\n",
      "\"Exaggeration-Minimisation\"\n",
      "\"Repetition\"\n"
     ]
    }
   ],
   "source": [
    "from factue.methods.llm_calls import load_template_list, load_template_parts\n",
    "for x in load_template_list(job='persuasion', step=\"explain\", prompt_version='v001').keys():\n",
    "    print(f'\"{x}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "babd803f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "filename",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "start",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "end",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "text_lang",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "text",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "label_bin",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "label_multi",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "base_split",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Questioning_the_Reputation",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Name_Calling-Labeling",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Appeal_to_Hypocrisy",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Conversation_Killer",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Loaded_Language",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Repetition",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Appeal_to_Popularity",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Doubt",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Red_Herring",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Flag_Waving",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Exaggeration-Minimisation",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Consequential_Oversimplification",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Appeal_to_Pity",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Appeal_to_Time",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Appeal_to_Values",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Obfuscation-Vagueness-Confusion",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Straw_Man",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Slogans",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Appeal_to_Fear-Prejudice",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Causal_Oversimplification",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Appeal_to_Authority",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "False_Dilemma-No_Choice",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Whataboutism",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "False_Equivalence",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Guilt_by_Association",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "alt_split",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "output_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "prompt_name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "prompt_version",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "job",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "step",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "max_iterations",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "temperature",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "model_provider",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "model_name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "model_mode",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "gold",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "gold_text",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "spans",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "extra_properties",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "is_valid",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "raw",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "updated_definition",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "think_content",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "illegal_value",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "explanation",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "extra_content",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "source_file",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "error",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "status",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "split",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "expected_output",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "02cd936c-c3a0-422f-aacb-6f49bbf4e4d3",
       "rows": [
        [
         "0",
         "pl_eu_12_06_2024_n01.txt",
         "0",
         "135",
         "PL",
         "Wicemarszałek Włodzimierz Czarzasty:\nBardzo proszę panią poseł Danutę Jazłowiecką\no przedstawienie sprawozdania komisji.\nBardzo proszę.",
         "False",
         "[]",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/Exaggeration-Minimisation",
         "Exaggeration-Minimisation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "0",
         "No, the Exaggeration-Minimisation technique is not used in the input.",
         "\"\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The input text does not contain any elements of exaggeration or minimisation. The statements made are straightforward and do not attempt to amplify or downplay any issues.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "['The input text does not contain any elements of exaggeration or minimisation. The statements made are straightforward and do not attempt to amplify or downplay any issues.']",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/Exaggeration-Minimisation/train/pl/train-pl-part_0005.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text does not contain any elements of exaggeration or minimisation. The statements made are straightforward and do not attempt to amplify or downplay any issues.\", \"verdict\": false}"
        ],
        [
         "1",
         "pl_defence_22_05_2024_n01.txt",
         "3608",
         "3857",
         "PL",
         "Pan wspominał o ABCS – Integrated Battle Command System. Ten program ja miałem zaszczyt nabyć w marcu 2018 r. (Oklaski) razem z umową dotyczącą dwóch baterii Patriot. A tę umowę przygotowywał mój poprzednik pan minister Antoni Macierewicz. (Oklaski)",
         "False",
         "[]",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/Exaggeration-Minimisation",
         "Exaggeration-Minimisation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "0",
         "No, the Exaggeration-Minimisation technique is not used in the input.",
         "\"\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The input text does not contain any instances of exaggeration or minimisation. It presents information about the Integrated Battle Command System and a contract for Patriot batteries without making any claims that are excessively positive or negative, nor does it downplay any significance.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "['The input text does not contain any instances of exaggeration or minimisation. It presents information about the Integrated Battle Command System and a contract for Patriot batteries without making any claims that are excessively positive or negative, nor does it downplay any significance.']",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/Exaggeration-Minimisation/train/pl/train-pl-part_0005.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text does not contain any instances of exaggeration or minimisation. It presents information about the Integrated Battle Command System and a contract for Patriot batteries without making any claims that are excessively positive or negative, nor does it downplay any significance.\", \"verdict\": false}"
        ],
        [
         "2",
         "pl_current_affairs_09_01_2025_n03.txt",
         "1808",
         "1984",
         "PL",
         "(Poseł Anna Gembicka: Decyzja została zmieniona. Proszę słuchać uważnie.)\nTo jest nieprawda, ten raport nie został poprawiony.\n(Poseł Anna Gembicka: Decyzja została zmieniona.)",
         "True",
         "['Repetition']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Decyzja została zmieniona' 'Decyzja została zmieniona.)']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/Exaggeration-Minimisation",
         "Exaggeration-Minimisation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "0",
         "No, the Exaggeration-Minimisation technique is not used in the input.",
         "\"\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The Exaggeration - Minimisation technique was not used in the input text as there are no instances of representing something in an excessive manner or downplaying its importance. The statements made are straightforward and do not exaggerate or minimize any claims.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "['The Exaggeration - Minimisation technique was not used in the input text as there are no instances of representing something in an excessive manner or downplaying its importance. The statements made are straightforward and do not exaggerate or minimize any claims.']",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/Exaggeration-Minimisation/train/pl/train-pl-part_0005.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The Exaggeration - Minimisation technique was not used in the input text as there are no instances of representing something in an excessive manner or downplaying its importance. The statements made are straightforward and do not exaggerate or minimize any claims.\", \"verdict\": false}"
        ],
        [
         "3",
         "pl_abortion_11_04_2024_n08.txt",
         "2952",
         "3136",
         "PL",
         "Czy czas najwyższy, by w końcu dopuścić\ndekryminalizację kradzieży i pomocnictwa w kradzieżach\nz włamaniem? Dlaczego tak nie lubicie dzieci?\nDlaczego chcecie pozwolić na ich zabijanie?",
         "True",
         "['False_Equivalence' 'Loaded_Language' 'Whataboutism' 'Straw_Man']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "['zabijanie?']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Czy czas najwyższy, by w końcu dopuścić dekryminalizację kradzieży i pomocnictwa w kradzieżach z włamaniem?']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Dlaczego tak nie lubicie dzieci?']",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/Exaggeration-Minimisation",
         "Exaggeration-Minimisation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "0",
         "No, the Exaggeration-Minimisation technique is not used in the input.",
         "\"\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The input text does not employ the Exaggeration - Minimisation technique, as it does not exaggerate or downplay any statements or arguments. The questions posed are direct and do not distort the importance of the issues discussed.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "['The input text does not employ the Exaggeration - Minimisation technique, as it does not exaggerate or downplay any statements or arguments. The questions posed are direct and do not distort the importance of the issues discussed.']",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/Exaggeration-Minimisation/train/pl/train-pl-part_0005.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text does not employ the Exaggeration - Minimisation technique, as it does not exaggerate or downplay any statements or arguments. The questions posed are direct and do not distort the importance of the issues discussed.\", \"verdict\": false}"
        ],
        [
         "4",
         "pl_eu_12_06_2024_n01.txt",
         "1277",
         "2304",
         "PL",
         "Prezentowany na posiedzeniu projekt ustawy, opracowany w celu wzmocnienia bezpieczeństwa podczas\nprzebiegu najważniejszych wydarzeń, które odbędą\nsię w Polsce w czasie trwania polskiej prezydencji,\nwyznacza zadania i ich realizację przez poszczególne\nsłużby i organy administracji publicznej. Spośród\nrozwiązań szczegółowych wyszczególnione zostały\nm.in.: koordynacja działań podejmowanych w zakresie zapewnienia bezpieczeństwa, plan zapewnienia\nbezpieczeństwa i porządku publicznego, przetwarzanie informacji, w tym danych osobowych, przez Policję, sprawdzenie przez służby osób lub podmiotów\nwspółpracujących przy organizacji wydarzeń, zawieranie porozumień z instytucjami unijnymi, wzmacnianie personelu Stałego Przedstawicielstwa Rzeczypospolitej Polskiej przy Unii Europejskiej, zasady\nudzielania i realizacji zamówień, zasady przedłużania czasu pracy służb, funkcjonariuszy. Minister\nzwrócił uwagę na czasowy charakter ustawy, obejmujący okres przygotowania, przeprowadzenia i rozliczenia prezydencji w Unii Europejskiej.",
         "False",
         "[]",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/Exaggeration-Minimisation",
         "Exaggeration-Minimisation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "0",
         "No, the Exaggeration-Minimisation technique is not used in the input.",
         "\"\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The input text does not employ the Exaggeration - Minimisation technique, as it presents information about a legislative project in a straightforward manner without exaggerating its importance or minimising any potential issues. The content is factual and does not include any statements that inflate or downplay the significance of the discussed measures.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "['The input text does not employ the Exaggeration - Minimisation technique, as it presents information about a legislative project in a straightforward manner without exaggerating its importance or minimising any potential issues. The content is factual and does not include any statements that inflate or downplay the significance of the discussed measures.']",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/Exaggeration-Minimisation/train/pl/train-pl-part_0005.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text does not employ the Exaggeration - Minimisation technique, as it presents information about a legislative project in a straightforward manner without exaggerating its importance or minimising any potential issues. The content is factual and does not include any statements that inflate or downplay the significance of the discussed measures.\", \"verdict\": false}"
        ],
        [
         "5",
         "pl_abortion_11_04_2024_n06.txt",
         "1965",
         "2258",
         "PL",
         "Wicemarszałek Włodzimierz Czarzasty:\nPrzepraszam, pani posłanko, przepraszam bardzo.\n(Poseł Krystyna Skowrońska: Proszę zwrócić uwagę.)\nAle zaraz, proszę państwa, proszę państwa…\n(Wypowiedź poza mikrofonem)\n(Poseł Krystyna Skowrońska: Ale nie zagłusza…)\n(Poseł Mariusz Krystian: A wy możecie?)",
         "False",
         "[]",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/Exaggeration-Minimisation",
         "Exaggeration-Minimisation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "0",
         "No, the Exaggeration-Minimisation technique is not used in the input.",
         "\"\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The input text does not contain any instances of exaggeration or minimisation. The statements made by Wicemarszałek Włodzimierz Czarzasty are straightforward and do not attempt to amplify or downplay any situation or argument.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "['The input text does not contain any instances of exaggeration or minimisation. The statements made by Wicemarszałek Włodzimierz Czarzasty are straightforward and do not attempt to amplify or downplay any situation or argument.']",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/Exaggeration-Minimisation/train/pl/train-pl-part_0005.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text does not contain any instances of exaggeration or minimisation. The statements made by Wicemarsza\\u0142ek W\\u0142odzimierz Czarzasty are straightforward and do not attempt to amplify or downplay any situation or argument.\", \"verdict\": false}"
        ],
        [
         "6",
         "pl_defence_22_05_2024_n02.txt",
         "1907",
         "2635",
         "PL",
         "...do walki, musi on przejść długie szkolenie.\nRosjanie, zanim puszczą żołnierza na front, ćwiczą go\n12 miesięcy, a u nas można przejść do rezerwy po\nzaledwie miesięcznym szkoleniu w ramach\ndobrowolnej zasadniczej służby wojskowej. Nawet Niemcy na\npoczątku 1945 r., kiedy front całkowicie im się\nposypał, wydali rozkaz zabraniający puszczania do walki\nżołnierzy poniżej 8 tygodni szkolenia, ponieważ jest\nto bezsensowne marnowanie ich życia bez istotnej\nkorzyści dla wojska. Kiedy my wreszcie zaczniemy\nmasowo szkolić rezerwy? Czy jak Rosja nas już zaatakuje,\nładnie poprosimy Putina, żeby zaczekali jeszcze\nrok, bo musimy się przygotować do tej wojny, czy też\nwyślemy na pewną śmierć nieprzygotowanych,\nnieprzeszkolonych ludzi?",
         "True",
         "['Doubt' 'Appeal_to_Fear-Prejudice']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Rosjanie, zanim puszczą żołnierza na front, ćwiczą go 12 miesięcy, a u nas można przejść do rezerwy po zaledwie miesięcznym szkoleniu w ramach dobrowolnej zasadniczej służby wojskowej'\n 'u nas można przejść do rezerwy po zaledwie miesięcznym szkoleniu w ramach dobrowolnej zasadniczej służby wojskowej. Nawet Niemcy na początku 1945 r., kiedy front całkowicie im się posypał, wydali rozkaz zabraniający puszczania do walki żołnierzy poniżej 8 tygodni szkolenia, ponieważ jest to bezsensowne marnowanie ich życia bez istotnej korzyści dla wojska']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Czy jak Rosja nas już zaatakuje, ładnie poprosimy Putina, żeby zaczekali jeszcze rok, bo musimy się przygotować do tej wojny, czy też wyślemy na pewną śmierć nieprzygotowanych, nieprzeszkolonych ludzi?']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/Exaggeration-Minimisation",
         "Exaggeration-Minimisation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "0",
         "No, the Exaggeration-Minimisation technique is not used in the input.",
         "\"\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The input text does not employ the Exaggeration - Minimisation technique, as it does not exaggerate or downplay any statements. Instead, it presents a comparison of military training durations without making any claims that are excessively positive or negative.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "['The input text does not employ the Exaggeration - Minimisation technique, as it does not exaggerate or downplay any statements. Instead, it presents a comparison of military training durations without making any claims that are excessively positive or negative.']",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/Exaggeration-Minimisation/train/pl/train-pl-part_0005.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text does not employ the Exaggeration - Minimisation technique, as it does not exaggerate or downplay any statements. Instead, it presents a comparison of military training durations without making any claims that are excessively positive or negative.\", \"verdict\": false}"
        ],
        [
         "7",
         "pl_abortion_11_04_2024_n03.txt",
         "10068",
         "10611",
         "PL",
         "Państwo polskie zaoszczędziło na zdrowiu i życiu\nPolek 49 mln przez ostatnie 8 lat. Na aborcje\nwykonywane u kobiet z Polski składają się wszystkie inne\npaństwa, takie jak Holandia, Francja czy Belgia, ale\nteż prywatni darczyńcy. Każdego dnia dzięki pieniądzom\notrzymanym z organizacji kobiecych około\nsiedmiu kobiet wyjeżdża do Holandii na zabieg\naborcji w drugim trymestrze ciąży. Wiele z nich\npotrzebuje wsparcia finansowego. To są często ciąże chciane,\nto są często ciąże wyczekane, ale te kobiety nie\nmogą otrzymać pomocy w swoim państwie.",
         "True",
         "['Flag_Waving' 'Questioning_the_Reputation' 'Appeal_to_Popularity']",
         "train",
         "['Państwo polskie zaoszczędziło na zdrowiu i życiu Polek 49 mln przez ostatnie 8 lat']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Na aborcje wykonywane u kobiet z Polski składają się wszystkie inne państwa, takie jak Holandia, Francja czy Belgia, ale też prywatni darczyńcy. Każdego dnia dzięki pieniądzom otrzymanym z organizacji kobiecych około siedmiu kobiet wyjeżdża do Holandii na zabieg aborcji w drugim trymestrze ciąży']",
         "[]",
         "[]",
         "['te kobiety nie mogą otrzymać pomocy w swoim państwie']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/Exaggeration-Minimisation",
         "Exaggeration-Minimisation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "0",
         "No, the Exaggeration-Minimisation technique is not used in the input.",
         "\"\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The input text does not employ the Exaggeration - Minimisation technique, as it does not exaggerate or downplay any statements. It presents information about the financial impact on women\\'s health and the need for abortion services without making excessive claims or minimizing the importance of the issue.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "[\"The input text does not employ the Exaggeration - Minimisation technique, as it does not exaggerate or downplay any statements. It presents information about the financial impact on women's health and the need for abortion services without making excessive claims or minimizing the importance of the issue.\"]",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/Exaggeration-Minimisation/train/pl/train-pl-part_0005.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text does not employ the Exaggeration - Minimisation technique, as it does not exaggerate or downplay any statements. It presents information about the financial impact on women's health and the need for abortion services without making excessive claims or minimizing the importance of the issue.\", \"verdict\": false}"
        ],
        [
         "8",
         "pl_defence_22_05_2024_n01.txt",
         "3494",
         "3606",
         "PL",
         "A więc trzeba za to wszystko przeprosić i potem\nrealizować program Prawa i Sprawiedliwości, bo to\ndobry program.",
         "True",
         "['Slogans' 'False_Dilemma-No_Choice']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['bo to dobry program']",
         "[]",
         "[]",
         "[]",
         "['A więc trzeba za to wszystko przeprosić i potem realizować program Prawa i Sprawiedliwości, bo to dobry program']",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/Exaggeration-Minimisation",
         "Exaggeration-Minimisation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "0",
         "No, the Exaggeration-Minimisation technique is not used in the input.",
         "\"\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The input text does not contain any instances of exaggeration or minimisation. It simply states the need to apologize and implement a program without making any claims that are excessive or downplaying any issues.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "['The input text does not contain any instances of exaggeration or minimisation. It simply states the need to apologize and implement a program without making any claims that are excessive or downplaying any issues.']",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/Exaggeration-Minimisation/train/pl/train-pl-part_0005.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text does not contain any instances of exaggeration or minimisation. It simply states the need to apologize and implement a program without making any claims that are excessive or downplaying any issues.\", \"verdict\": false}"
        ],
        [
         "9",
         "pl_abortion_11_04_2024_n03.txt",
         "6145",
         "6687",
         "PL",
         "W szpitalach na Podlasiu i Podkarpaciu nawet ten\npseudokompromis nie działał, bo żadna, ale to żadna,\nkobieta od lat, nawet w przypadku zagrożenia\nzdrowia i życia, nie mogła tam otrzymać pomocy i była\nodsyłana z kwitkiem, chociaż w zasadzie raczej bez\nkwitka, bo lekarze odmawiali aborcji, zasłaniając się\nklauzulą sumienia. I chociaż łamali w ten sposób prawo,\nnie wyznaczali podmiotu leczniczego, w którym\nkobieta mogłaby przerwać ciążę, i nie dokumentowali\ntej odmowy na piśmie. Łamanie praw pacjentek?\nKto by tam się przejmował kobietami.",
         "True",
         "['Loaded_Language' 'Appeal_to_Hypocrisy' 'Questioning_the_Reputation'\n 'Appeal_to_Values' 'Repetition']",
         "train",
         "['I chociaż łamali w ten sposób prawo, nie wyznaczali podmiotu leczniczego, w którym kobieta mogłaby przerwać ciążę, i nie dokumentowali tej odmowy na piśmie']",
         "[]",
         "['lekarze odmawiali aborcji, zasłaniając się klauzulą sumienia']",
         "[]",
         "['pseudokompromis' 'była odsyłana z kwitkiem' 'Kto by tam się przejmował']",
         "['żadna' 'żadna']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['bo lekarze odmawiali aborcji, zasłaniając się klauzulą sumienia'\n 'Łamanie praw pacjentek? Kto by tam się przejmował kobietami']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/Exaggeration-Minimisation",
         "Exaggeration-Minimisation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "0",
         "No, the Exaggeration-Minimisation technique is not used in the input.",
         "\"\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The input text does not employ the Exaggeration - Minimisation technique, as it does not exaggerate or downplay any statements. Instead, it presents a serious issue regarding women\\'s access to healthcare without embellishment or minimization.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "[\"The input text does not employ the Exaggeration - Minimisation technique, as it does not exaggerate or downplay any statements. Instead, it presents a serious issue regarding women's access to healthcare without embellishment or minimization.\"]",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/Exaggeration-Minimisation/train/pl/train-pl-part_0005.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text does not employ the Exaggeration - Minimisation technique, as it does not exaggerate or downplay any statements. Instead, it presents a serious issue regarding women's access to healthcare without embellishment or minimization.\", \"verdict\": false}"
        ],
        [
         "10",
         "pl_abortion_11_04_2024_n06.txt",
         "7182",
         "7570",
         "PL",
         "Nie chcemy więcej, aby Ogólnopolski Strajk\nKobiet organizował strajki na ulicach. Nie chcemy tych\nsetek tysięcy kobiet, które będą wychodziły w obronie\nnaszego zdrowia i naszego życia. To parlament jest\nmiejscem, z którego ma wyjść dobre prawo, które da\nkobietom poczucie bezpieczeństwa. Bo ile jeszcze\nrazy będziemy powtarzać numer telefonu, pod\nktórym można szukać pomocy: 22 29 22 597?",
         "True",
         "['Obfuscation-Vagueness-Confusion' 'Appeal_to_Values']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Nie chcemy tych setek tysięcy kobiet, które będą wychodziły w obronie naszego zdrowia i naszego życia'\n 'dobre prawo, które da kobietom poczucie bezpieczeństwa']",
         "['dobre prawo']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/Exaggeration-Minimisation",
         "Exaggeration-Minimisation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "0",
         "No, the Exaggeration-Minimisation technique is not used in the input.",
         "\"\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The input text does not employ the Exaggeration - Minimisation technique, as it does not exaggerate or downplay any statements or arguments. The content expresses a clear stance without employing hyperbole or minimization.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "['The input text does not employ the Exaggeration - Minimisation technique, as it does not exaggerate or downplay any statements or arguments. The content expresses a clear stance without employing hyperbole or minimization.']",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/Exaggeration-Minimisation/train/pl/train-pl-part_0015.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text does not employ the Exaggeration - Minimisation technique, as it does not exaggerate or downplay any statements or arguments. The content expresses a clear stance without employing hyperbole or minimization.\", \"verdict\": false}"
        ],
        [
         "11",
         "pl_defence_22_05_2024_n01.txt",
         "4288",
         "4362",
         "PL",
         "(Poseł Barbara Bartuś: Skandal.)\nCzy to nie jest skandal? To jest skandal.",
         "True",
         "['Loaded_Language' 'Repetition']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Skandal']",
         "['Czy to nie jest skandal?' 'To jest skandal']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/Exaggeration-Minimisation",
         "Exaggeration-Minimisation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "0",
         "No, the Exaggeration-Minimisation technique is not used in the input.",
         "\"\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The input text does not employ the Exaggeration - Minimisation technique, as it does not exaggerate or downplay any statements. The phrase \\'To jest skandal\\' simply asserts that something is a scandal without embellishment or minimization.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "[\"The input text does not employ the Exaggeration - Minimisation technique, as it does not exaggerate or downplay any statements. The phrase 'To jest skandal' simply asserts that something is a scandal without embellishment or minimization.\"]",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/Exaggeration-Minimisation/train/pl/train-pl-part_0015.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text does not employ the Exaggeration - Minimisation technique, as it does not exaggerate or downplay any statements. The phrase 'To jest skandal' simply asserts that something is a scandal without embellishment or minimization.\", \"verdict\": false}"
        ],
        [
         "12",
         "pl_defence_22_05_2024_n01.txt",
         "7013",
         "8337",
         "PL",
         "(Głos z sali: Hełmy zardzewiałe.)\n5 tys. hełmów. To jest kwintesencja. Obraz mówi\nwięcej niż tysiąc słów. Z kim prowadziliśmy dialog? Ze\nStanami Zjednoczonymi. Dlaczego ze Stanami Zjednoczonymi? Dlatego że Stany Zjednoczone posiadają\nnajsilniejszą armię na świecie. Ruscy boją się Amerykanów. Powinniśmy – i tak je tworzyliśmy – tworzyć\nWojsko Polskie właśnie na wzór jednostek amerykańskich. Nie dalej jak wczoraj byłem w Poznaniu. Byłem\nobok Camp Kościuszko, czyli miejsca, w którym na\nstałe stacjonują wojska amerykańskie. To jest V Korpus sił lądowych Stanów Zjednoczonych, dowództwo\ntego korpusu, które z Polski dowodzi wojskami amerykańskimi na całej wschodniej flance NATO. (Oklaski) I to jest nasz sukces, to jest sukces rządu Prawa\ni Sprawiedliwości, bo umieliśmy rozmawiać zarówno\nz administracją prezydenta Obamy, jak i z administracją prezydenta Trumpa; z administracją prezydenta\nBidena także potrafiliśmy rozmawiać. A wy co robicie?\nCo robi Donald Tusk? Atakuje republikanów. Niszczycie relacje polsko-amerykańskie, angażując się po jednej stronie sporu politycznego w Ameryce. (Oklaski)\nDo czego to może (Dzwonek) doprowadzić? Jeżeli jesienią tego roku wygra prezydent Donald Trump, może\ndoprowadzić to do tego, że Polska będzie zagrożona,\nco by było fatalne, co by było konsekwencją waszych\nfatalnych rządów.",
         "True",
         "['Consequential_Oversimplification' 'Exaggeration-Minimisation'\n 'Loaded_Language' 'Flag_Waving' 'Questioning_the_Reputation'\n 'Appeal_to_Authority' 'Name_Calling-Labeling' 'Repetition' 'Doubt'\n 'Appeal_to_Fear-Prejudice']",
         "train",
         "['bo umieliśmy rozmawiać zarówno z administracją prezydenta Obamy, jak i z administracją prezydenta Trumpa; z administracją prezydenta Bidena także potrafiliśmy rozmawiać. A wy co robicie? Co robi Donald Tusk? Atakuje republikanów'\n 'konsekwencją waszych fatalnych rządów']",
         "['fatalnych rządów']",
         "[]",
         "[]",
         "['Hełmy zardzewiałe.)' 'To jest kwintesencja' 'Ruscy' 'fatalne']",
         "['I to jest nasz sukces' 'to jest sukces rządu Prawa i Sprawiedliwości']",
         "[]",
         "['Niszczycie relacje polsko-amerykańskie, angażując się po jednej stronie sporu politycznego w Ameryce']",
         "[]",
         "['Polska będzie zagrożona']",
         "['Obraz mówi więcej niż tysiąc słów']",
         "['Jeżeli jesienią tego roku wygra prezydent Donald Trump, może doprowadzić to do tego, że Polska będzie zagrożona, co by było fatalne, co by było konsekwencją waszych fatalnych rządów']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Do czego to może (Dzwonek) doprowadzić?']",
         "[]",
         "['Ruscy boją się Amerykanów. Powinniśmy – i tak je tworzyliśmy – tworzyć Wojsko Polskie właśnie na wzór jednostek amerykańskich']",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/Exaggeration-Minimisation",
         "Exaggeration-Minimisation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "1",
         "Yes, the Exaggeration-Minimisation technique is used in the input.",
         "\"Obraz mówi więcej niż tysiąc słów\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The Exaggeration - Minimisation technique is used in the input text through the phrase \\'Obraz mówi więcej niż tysiąc słów\\', which exaggerates the impact of an image by suggesting it conveys more meaning than a thousand words. This aligns with the definition of exaggeration by making something seem larger or more significant than it is.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[\"The Exaggeration - Minimisation technique is used in the input text through the phrase 'Obraz mówi więcej niż tysiąc słów', which exaggerates the impact of an image by suggesting it conveys more meaning than a thousand words. This aligns with the definition of exaggeration by making something seem larger or more significant than it is.\"]",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/Exaggeration-Minimisation/train/pl/train-pl-part_0015.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The Exaggeration - Minimisation technique is used in the input text through the phrase 'Obraz m\\u00f3wi wi\\u0119cej ni\\u017c tysi\\u0105c s\\u0142\\u00f3w', which exaggerates the impact of an image by suggesting it conveys more meaning than a thousand words. This aligns with the definition of exaggeration by making something seem larger or more significant than it is.\", \"verdict\": true}"
        ],
        [
         "13",
         "pl_abortion_11_04_2024_n02.txt",
         "5985",
         "6157",
         "PL",
         "Skończmy z okrutnym, bezdusznym prawem.\nApeluję o przyjęcie dekryminalizacji aborcji,\nto jest prawdziwy kompromis, proszę państwa.\nDziękuję. (Oklaski)\n(Głos z sali: Brawo!)",
         "True",
         "['Loaded_Language' 'Appeal_to_Values']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "['okrutnym, bezdusznym']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Apeluję o przyjęcie dekryminalizacji aborcji, to jest prawdziwy kompromis']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/Exaggeration-Minimisation",
         "Exaggeration-Minimisation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "0",
         "No, the Exaggeration-Minimisation technique is not used in the input.",
         "\"\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The input text does not contain any instances of exaggeration or minimisation. The speaker is making a straightforward appeal for the decriminalization of abortion without inflating or downplaying the issue.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "['The input text does not contain any instances of exaggeration or minimisation. The speaker is making a straightforward appeal for the decriminalization of abortion without inflating or downplaying the issue.']",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/Exaggeration-Minimisation/train/pl/train-pl-part_0015.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text does not contain any instances of exaggeration or minimisation. The speaker is making a straightforward appeal for the decriminalization of abortion without inflating or downplaying the issue.\", \"verdict\": false}"
        ],
        [
         "14",
         "pl_current_affairs_09_01_2025_n03.txt",
         "2672",
         "3168",
         "PL",
         "A ponieważ mamy jeszcze chwilę, to wrócę do tej\nlisty, którą należy państwu przypomnieć. To było\nbardzo niedawno, więc jeszcze raz podkreślę i przypomnę. Mówicie o bezpieczeństwie przeciwpowodziowym, o zbiornikach suchych, retencyjnych, które\nbyły potrzebne w Kotlinie Kłodzkiej, a to właśnie\nwasz minister odmówił ich budowy. Mówił: Po co te\nzbiorniki? Chyba psu na budę. Już wyszedł, bo nie\nchce się z tego tutaj wytłumaczyć.\n(Poseł Anna Gembicka: Marszałek Wielichowska\norganizowała protesty…)",
         "True",
         "['Appeal_to_Hypocrisy' 'Loaded_Language' 'Questioning_the_Reputation']",
         "train",
         "['Już wyszedł, bo nie chce się z tego tutaj wytłumaczyć']",
         "[]",
         "['Mówicie o bezpieczeństwie przeciwpowodziowym, o zbiornikach suchych, retencyjnych, które były potrzebne w Kotlinie Kłodzkiej, a to właśnie wasz minister odmówił ich budowy']",
         "[]",
         "['psu na budę']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/Exaggeration-Minimisation",
         "Exaggeration-Minimisation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "0",
         "No, the Exaggeration-Minimisation technique is not used in the input.",
         "\"\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The input text does not employ the Exaggeration - Minimisation technique, as it does not exaggerate or downplay any statements or arguments. The speaker is directly addressing the issue of flood safety and the refusal to build necessary reservoirs without embellishment or minimization.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "['The input text does not employ the Exaggeration - Minimisation technique, as it does not exaggerate or downplay any statements or arguments. The speaker is directly addressing the issue of flood safety and the refusal to build necessary reservoirs without embellishment or minimization.']",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/Exaggeration-Minimisation/train/pl/train-pl-part_0015.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text does not employ the Exaggeration - Minimisation technique, as it does not exaggerate or downplay any statements or arguments. The speaker is directly addressing the issue of flood safety and the refusal to build necessary reservoirs without embellishment or minimization.\", \"verdict\": false}"
        ],
        [
         "15",
         "pl_current_affairs_09_01_2025_n03.txt",
         "5308",
         "5539",
         "PL",
         "(Poseł Kazimierz Gwiazdowski: Kiedy to było?)\nTo były czarne czasy. To wtedy było.\nPytanie zadadzą ministrowi obrony narodowej,\nw imieniu którego odpowie sekretarz stanu w Ministerstwie Obrony Narodowej pan minister Cezary\nTomczyk.",
         "True",
         "['Loaded_Language']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "['czarne czasy']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/Exaggeration-Minimisation",
         "Exaggeration-Minimisation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "0",
         "No, the Exaggeration-Minimisation technique is not used in the input.",
         "\"\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The input text does not contain any instances of exaggeration or minimisation. The statements made do not amplify or downplay any issues or events, thus aligning with the expert\\'s verdict that the technique was not used.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[\"The input text does not contain any instances of exaggeration or minimisation. The statements made do not amplify or downplay any issues or events, thus aligning with the expert's verdict that the technique was not used.\"]",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/Exaggeration-Minimisation/train/pl/train-pl-part_0015.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text does not contain any instances of exaggeration or minimisation. The statements made do not amplify or downplay any issues or events, thus aligning with the expert's verdict that the technique was not used.\", \"verdict\": false}"
        ],
        [
         "16",
         "pl_abortion_11_04_2024_n07.txt",
         "7421",
         "7841",
         "PL",
         "W omawianym projekcie, podobnie jak w\nprojektach KO i Trzeciej Drogi, znalazły się przepisy\nbezprawnie ograniczające konstytucyjną wolność\nsumienia i nakładające na ordynatora oddziału lub\nkierownika podmiotu leczniczego obowiązek zapewnienia\nwykonania aborcji w podmiocie leczniczym, co jest\nniezgodne z wyrokiem Trybunału Konstytucyjnego\nz 7 października 2015 r. obradującego pod\nprzewodnictwem Andrzeja Rzeplińskiego.",
         "True",
         "['Appeal_to_Authority']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['W omawianym projekcie, podobnie jak w projektach KO i Trzeciej Drogi, znalazły się przepisy bezprawnie ograniczające konstytucyjną wolność sumienia i nakładające na ordynatora oddziału lub kierownika podmiotu leczniczego obowiązek zapewnienia wykonania aborcji w podmiocie leczniczym, co jest niezgodne z wyrokiem Trybunału Konstytucyjnego z 7 października 2015 r. obradującego pod przewodnictwem Andrzeja Rzeplińskiego']",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/Exaggeration-Minimisation",
         "Exaggeration-Minimisation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "0",
         "No, the Exaggeration-Minimisation technique is not used in the input.",
         "\"\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The input text does not employ the Exaggeration - Minimisation technique, as it does not exaggerate or downplay any statements. It presents a clear argument regarding the legal implications of the project without embellishment or minimization.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "['The input text does not employ the Exaggeration - Minimisation technique, as it does not exaggerate or downplay any statements. It presents a clear argument regarding the legal implications of the project without embellishment or minimization.']",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/Exaggeration-Minimisation/train/pl/train-pl-part_0015.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text does not employ the Exaggeration - Minimisation technique, as it does not exaggerate or downplay any statements. It presents a clear argument regarding the legal implications of the project without embellishment or minimization.\", \"verdict\": false}"
        ],
        [
         "17",
         "pl_defence_22_05_2024_n01.txt",
         "3110",
         "3492",
         "PL",
         "(Głos z sali: Hańba.)\nNie miał kto Polski bronić. Rzeczywiście to jest\nhańba. Zlikwidowaliście całą dywizję, 1. Dywizję\nZmechanizowaną im. Tadeusza Kościuszki, której\nzadaniem była obrona bramy brzeskiej. To my odtworzyliśmy jednostkę, odtworzyliśmy dywizję. To jest\n18. Dywizja Zmechanizowana, która broni właśnie\nbramy brzeskiej, odstraszając agresora, przed atakiem na nasz kraj.",
         "True",
         "['Exaggeration-Minimisation' 'Loaded_Language' 'Appeal_to_Fear-Prejudice']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Hańba' 'hańba']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Nie miał kto Polski bronić. Rzeczywiście to jest hańba']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['odstraszając agresora, przed atakiem na nasz kraj']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/Exaggeration-Minimisation",
         "Exaggeration-Minimisation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "1",
         "Yes, the Exaggeration-Minimisation technique is used in the input.",
         "\"Nie miał kto Polski bronić. Rzeczywiście to jest hańba\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The Exaggeration - Minimisation technique is used in the input text by emphasizing the severity of the situation with the phrase \\'Rzeczywiście to jest hańba\\', which exaggerates the disgrace of not having anyone to defend Poland. This statement amplifies the perceived importance of the issue, making it seem more critical than it may be, thus fitting the definition of exaggeration.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "[\"The Exaggeration - Minimisation technique is used in the input text by emphasizing the severity of the situation with the phrase 'Rzeczywiście to jest hańba', which exaggerates the disgrace of not having anyone to defend Poland. This statement amplifies the perceived importance of the issue, making it seem more critical than it may be, thus fitting the definition of exaggeration.\"]",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/Exaggeration-Minimisation/train/pl/train-pl-part_0015.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The Exaggeration - Minimisation technique is used in the input text by emphasizing the severity of the situation with the phrase 'Rzeczywi\\u015bcie to jest ha\\u0144ba', which exaggerates the disgrace of not having anyone to defend Poland. This statement amplifies the perceived importance of the issue, making it seem more critical than it may be, thus fitting the definition of exaggeration.\", \"verdict\": true}"
        ],
        [
         "18",
         "pl_abortion_11_04_2024_n08.txt",
         "6182",
         "6827",
         "PL",
         "Chcecie odesłać te projekty do jakiejś dziwnej\nspeckomisji, żeby się mroziły, leżały, z nadzieją, że\nwygracie wybory prezydenckie i mając swojego\nprezydenta, wprowadzicie niezgodne z konstytucją prawo,\ntak jak niezgodnie z prawem przejęliście\nprokuraturę, tak jak niezgodnie z prawem odwołujecie sędziów\nsądów apelacyjnych, jak pozwalacie sobie na\nbezprawie, korzystając z tego, jak beznadziejną mamy\nkonstytucję. W wielu sprawach mamy beznadziejną, ale\nnie w kwestii dotyczącej ochrony życia, zwłaszcza po\ntym, jak została ona zdefiniowana tymi dwoma\nwyrokami. I to są wyroki, które obowiązują, czy wam\nsię to podoba, czy wam się to nie podoba.",
         "True",
         "['Conversation_Killer' 'Loaded_Language' 'Questioning_the_Reputation'\n 'Whataboutism' 'Repetition']",
         "train",
         "['wprowadzicie niezgodne z konstytucją prawo, tak jak niezgodnie z prawem przejęliście prokuraturę, tak jak niezgodnie z prawem odwołujecie sędziów sądów apelacyjnych, jak pozwalacie sobie na bezprawie']",
         "[]",
         "[]",
         "['I to są wyroki, które obowiązują, czy wam się to podoba, czy wam się to nie podoba']",
         "['dziwnej' 'beznadziejną' 'beznadziejną']",
         "['tak jak niezgodnie z prawem' 'beznadziejną']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['niezgodnie z prawem przejęliście prokuraturę'\n 'tak jak niezgodnie z prawem odwołujecie sędziów sądów apelacyjnych, jak pozwalacie sobie na bezprawie, korzystając z tego, jak beznadziejną mamy konstytucję']",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/Exaggeration-Minimisation",
         "Exaggeration-Minimisation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "0",
         "No, the Exaggeration-Minimisation technique is not used in the input.",
         "\"\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The input text does not employ the Exaggeration - Minimisation technique, as it does not exaggerate or downplay any statements or arguments. Instead, it presents a critical perspective on legal and constitutional issues without resorting to hyperbole or minimization.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "['The input text does not employ the Exaggeration - Minimisation technique, as it does not exaggerate or downplay any statements or arguments. Instead, it presents a critical perspective on legal and constitutional issues without resorting to hyperbole or minimization.']",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/Exaggeration-Minimisation/train/pl/train-pl-part_0015.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text does not employ the Exaggeration - Minimisation technique, as it does not exaggerate or downplay any statements or arguments. Instead, it presents a critical perspective on legal and constitutional issues without resorting to hyperbole or minimization.\", \"verdict\": false}"
        ],
        [
         "19",
         "pl_abortion_11_04_2024_n04.txt",
         "1703",
         "2045",
         "PL",
         "A przecież to u tych aktywistek, u tych\ndziałaczek, u tych organizacji państwo polskie zaciągnęło\nogromny dług. Ogromny dług, który czas spłacić.\nI nie mówię teraz o tych 50 mln zł, spłaćcie wreszcie\ndług wobec nas, kobiet. Spłaćcie ten dług, byśmy\nmogły wreszcie decydować o swoim zdrowiu, życiu i\nciele zgodnie z prawem. Bo i tak to robimy.",
         "True",
         "['Conversation_Killer' 'Flag_Waving' 'Appeal_to_Time' 'Appeal_to_Pity'\n 'Appeal_to_Values' 'Repetition']",
         "train",
         "[]",
         "[]",
         "[]",
         "['Bo i tak to robimy']",
         "[]",
         "['ogromny dług' 'Ogromny dług' 'spłaćcie wreszcie dług'\n 'Spłaćcie ten dług']",
         "[]",
         "[]",
         "[]",
         "['A przecież to u tych aktywistek, u tych działaczek, u tych organizacji państwo polskie zaciągnęło ogromny dług. Ogromny dług, który czas spłacić']",
         "[]",
         "[]",
         "['A przecież to u tych aktywistek, u tych działaczek, u tych organizacji państwo polskie zaciągnęło ogromny dług']",
         "['Ogromny dług, który czas spłacić']",
         "['spłaćcie wreszcie dług wobec nas, kobiet. Spłaćcie ten dług, byśmy mogły wreszcie decydować o swoim zdrowiu, życiu i ciele zgodnie z prawem']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/Exaggeration-Minimisation",
         "Exaggeration-Minimisation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "0",
         "No, the Exaggeration-Minimisation technique is not used in the input.",
         "\"\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The input text does not employ the Exaggeration - Minimisation technique, as it does not exaggerate or downplay any statements. The speaker emphasizes the importance of repaying a debt to women without making excessive claims or minimizing the significance of the issue.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "['The input text does not employ the Exaggeration - Minimisation technique, as it does not exaggerate or downplay any statements. The speaker emphasizes the importance of repaying a debt to women without making excessive claims or minimizing the significance of the issue.']",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/Exaggeration-Minimisation/train/pl/train-pl-part_0015.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text does not employ the Exaggeration - Minimisation technique, as it does not exaggerate or downplay any statements. The speaker emphasizes the importance of repaying a debt to women without making excessive claims or minimizing the significance of the issue.\", \"verdict\": false}"
        ],
        [
         "20",
         "pl_abortion_11_04_2024_n08.txt",
         "6992",
         "7754",
         "PL",
         "Jesteśmy ideową prawicą, jesteśmy za życiem,\njesteśmy za tym, żeby chronić najbardziej podstawowe\nprawa człowieka: życie, wolność, własność (Oklaski),\nby chronić przyrodzoną godność człowieka, także\nmaleńkiego człowieka, który nie może tutaj wystąpić,\nnie może sam się bronić. Jesteśmy za tym, żeby\ndzieci się rodziły, żeby pomagać kobietom, które są w\ntrudnej sytuacji, parom, które są w trudnej sytuacji,\nwspierać je, by wspierać pomoc prenatalną. Znam osoby,\nmam przyjaciół, których dzieci urodziły się pomimo\ntego, że miały się nie urodzić, pomimo tego, że miały\npoważne wady kręgosłupa, rozszczepienia i były\noperowane jeszcze przed narodzinami. Te dzieci żyją, są\nkochane i kochają. I o to będziemy walczyć. Dziękuję\nbardzo. (Oklaski)\n(Głos z sali: Brawo!)",
         "True",
         "['Loaded_Language' 'Slogans' 'Appeal_to_Values']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "['maleńkiego']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Jesteśmy ideową prawicą, jesteśmy za życiem, jesteśmy za tym, żeby chronić najbardziej podstawowe prawa człowieka: życie, wolność, własność (Oklaski), by chronić przyrodzoną godność człowieka, także maleńkiego człowieka, który nie może tutaj wystąpić, nie może sam się bronić'\n 'Jesteśmy za tym, żeby dzieci się rodziły, żeby pomagać kobietom, które są w trudnej sytuacji, parom, które są w trudnej sytuacji, wspierać je, by wspierać pomoc prenatalną']",
         "[]",
         "[]",
         "['I o to będziemy walczyć']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/Exaggeration-Minimisation",
         "Exaggeration-Minimisation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "0",
         "No, the Exaggeration-Minimisation technique is not used in the input.",
         "\"\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The input text does not employ the Exaggeration - Minimisation technique, as it does not exaggerate or downplay any statements. The speaker presents their views on life and support for children without making excessive claims or minimizing the importance of any issues.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "['The input text does not employ the Exaggeration - Minimisation technique, as it does not exaggerate or downplay any statements. The speaker presents their views on life and support for children without making excessive claims or minimizing the importance of any issues.']",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/Exaggeration-Minimisation/train/pl/train-pl-part_0014.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text does not employ the Exaggeration - Minimisation technique, as it does not exaggerate or downplay any statements. The speaker presents their views on life and support for children without making excessive claims or minimizing the importance of any issues.\", \"verdict\": false}"
        ],
        [
         "21",
         "pl_defence_22_05_2024_n01.txt",
         "6514",
         "6714",
         "PL",
         "(Głos z sali: Właśnie. Hańba!)\n80. rocznica zwycięskiej bitwy pod Monte Cassino.\nDlaczego pana tam nie było? To bardzo ważne, żeby\nkształtować postawy Polaków w duchu patriotyzmu.\nWy tego nie robicie.",
         "True",
         "['Loaded_Language' 'Flag_Waving' 'Whataboutism'\n 'Questioning_the_Reputation']",
         "train",
         "['Wy tego nie robicie']",
         "[]",
         "[]",
         "[]",
         "['Hańba!']",
         "[]",
         "[]",
         "[]",
         "[]",
         "['To bardzo ważne, żeby kształtować postawy Polaków w duchu patriotyzmu']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['80. rocznica zwycięskiej bitwy pod Monte Cassino. Dlaczego pana tam nie było?']",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/Exaggeration-Minimisation",
         "Exaggeration-Minimisation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "0",
         "No, the Exaggeration-Minimisation technique is not used in the input.",
         "\"\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The input text does not contain any instances of exaggeration or minimisation. It discusses the importance of shaping Polish patriotism without making excessive claims or downplaying any issues.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "['The input text does not contain any instances of exaggeration or minimisation. It discusses the importance of shaping Polish patriotism without making excessive claims or downplaying any issues.']",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/Exaggeration-Minimisation/train/pl/train-pl-part_0014.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text does not contain any instances of exaggeration or minimisation. It discusses the importance of shaping Polish patriotism without making excessive claims or downplaying any issues.\", \"verdict\": false}"
        ],
        [
         "22",
         "pl_current_affairs_09_01_2025_n02.txt",
         "4561",
         "5517",
         "PL",
         "Poseł Joanna Borowiak:\nDziękuję.\nPanie Marszałku! Wysoki Sejmie! Bezpieczeństwo\nma różne wymiary. Tego, jak ważne jest bezpieczeństwo przeciwpowodziowe, boleśnie doświadczyli mieszkańcy Dolnego Śląska i Opolszczyzny we wrześniu\nub.r. Aby taka sama sytuacja nie spotkała mieszkańców terenów nadwiślańskich Kujaw, rząd Prawa\ni Sprawiedliwości podjął kluczową dla regionu decyzję o budowie stopnia wodnego w Siarzewie. Ta inwestycja miała gwarancję realizacji i została wpisana\ndo programu wieloletniego „Zagospodarowanie Dolnej Wisły”. Stopień wodny w Siarzewie to gwarancja\nbezpieczeństwa zapory we Włocławku, która jest\nmocno wysłużona i co roku wymaga poważnego doinwestowania finansowego, by nie zagrozić katastrofą powodziową i ekologiczną. Stopień wodny w Siarzewie to nie tylko bezpieczeństwo przeciwpowodziowe, ale także bezpieczeństwo przeciwsuszowe dla\nlicznych terenów rolnych. Z całą pewnością jako nowoczesna inwestycja stopień chroniłby naturę.",
         "True",
         "['Conversation_Killer' 'Appeal_to_Values']",
         "train",
         "[]",
         "[]",
         "[]",
         "['Z całą pewnością jako nowoczesna inwestycja stopień chroniłby naturę']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Z całą pewnością jako nowoczesna inwestycja stopień chroniłby naturę']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/Exaggeration-Minimisation",
         "Exaggeration-Minimisation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "0",
         "No, the Exaggeration-Minimisation technique is not used in the input.",
         "\"\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The input text does not employ the Exaggeration - Minimisation technique, as it does not exaggerate the importance of the flood control measures or downplay any potential risks. The statements made are factual and do not distort the significance of the issues discussed.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "['The input text does not employ the Exaggeration - Minimisation technique, as it does not exaggerate the importance of the flood control measures or downplay any potential risks. The statements made are factual and do not distort the significance of the issues discussed.']",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/Exaggeration-Minimisation/train/pl/train-pl-part_0014.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text does not employ the Exaggeration - Minimisation technique, as it does not exaggerate the importance of the flood control measures or downplay any potential risks. The statements made are factual and do not distort the significance of the issues discussed.\", \"verdict\": false}"
        ],
        [
         "23",
         "pl_defence_22_05_2024_n01.txt",
         "10655",
         "11075",
         "PL",
         "…ale posłowie Prawa i Sprawiedliwości będą o tym\nmówili. Proszę państwa, powiedzmy sobie wprost:\nobrona cywilna nie istniała. To my najpierw przygotowaliśmy projekt ustawy w rządzie, a teraz ten projekt został złożony jako projekt poselski, projekt Prawa i Sprawiedliwości. A wy tylko zapowiadacie i projektu rządowego wciąż nie widać. Proszę bardzo, jest\nprojekt Prawa i Sprawiedliwości. (Oklaski)\n(Głos z sali: 8 lat…)",
         "True",
         "['Conversation_Killer' 'Questioning_the_Reputation']",
         "train",
         "['A wy tylko zapowiadacie i projektu rządowego wciąż nie widać']",
         "[]",
         "[]",
         "['obrona cywilna nie istniała']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/Exaggeration-Minimisation",
         "Exaggeration-Minimisation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "0",
         "No, the Exaggeration-Minimisation technique is not used in the input.",
         "\"\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The input text does not employ the Exaggeration - Minimisation technique, as it does not exaggerate or downplay any statements or arguments. The speaker presents facts about the legislative process without embellishment or minimization.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "['The input text does not employ the Exaggeration - Minimisation technique, as it does not exaggerate or downplay any statements or arguments. The speaker presents facts about the legislative process without embellishment or minimization.']",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/Exaggeration-Minimisation/train/pl/train-pl-part_0014.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text does not employ the Exaggeration - Minimisation technique, as it does not exaggerate or downplay any statements or arguments. The speaker presents facts about the legislative process without embellishment or minimization.\", \"verdict\": false}"
        ],
        [
         "24",
         "pl_abortion_11_04_2024_n07.txt",
         "2698",
         "3273",
         "PL",
         "Okoliczności zajścia w ciążę są naprawdę bardzo\nróżne. Jest wiele kobiet, które gdy widzą dwie kreski\nna teście ciążowym, mogą czuć w sobie jakiś rodzaj\nniepokoju: Czy ja sobie poradzę? Jestem za młoda na\ndziecko. Jestem za stara. Nie mam jeszcze dzieci albo\nmam ich za dużo. Miałam iść na studia, miałam iść\ndo pracy. Dlaczego ja? Dlaczego teraz? Co dalej? Taka\nkobieta potrzebuje usłyszeć jedno: nie bój się, nie\njesteś sama, pomogę ci. Zamiast: twoje ciało, twój\nwybór, zasługuje na to, żeby usłyszeć: nasze dziecko,\nnasza odpowiedzialność. (Oklaski)\n(Głos z sali: Brawo!)",
         "True",
         "['Slogans' 'Appeal_to_Values']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['nasze dziecko, nasza odpowiedzialność']",
         "[]",
         "[]",
         "['nie bój się, nie jesteś sama, pomogę ci']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/Exaggeration-Minimisation",
         "Exaggeration-Minimisation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "0",
         "No, the Exaggeration-Minimisation technique is not used in the input.",
         "\"\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The input text does not employ the Exaggeration - Minimisation technique, as it does not exaggerate or downplay any statements or situations. Instead, it expresses a range of emotions and concerns related to pregnancy without making them seem more significant or less significant than they are.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "['The input text does not employ the Exaggeration - Minimisation technique, as it does not exaggerate or downplay any statements or situations. Instead, it expresses a range of emotions and concerns related to pregnancy without making them seem more significant or less significant than they are.']",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/Exaggeration-Minimisation/train/pl/train-pl-part_0014.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text does not employ the Exaggeration - Minimisation technique, as it does not exaggerate or downplay any statements or situations. Instead, it expresses a range of emotions and concerns related to pregnancy without making them seem more significant or less significant than they are.\", \"verdict\": false}"
        ],
        [
         "25",
         "pl_abortion_11_04_2024_n06.txt",
         "3710",
         "3885",
         "PL",
         "Każdy z nas będzie mógł zabrać głos w tej debacie,\nale pan nigdy nie będzie wiedział, co to znaczy bać\nsię być w ciąży w Polsce. A więc proszę mi tutaj\nniczego nie insynuować.",
         "True",
         "['Questioning_the_Reputation' 'Straw_Man']",
         "train",
         "['pan nigdy nie będzie wiedział, co to znaczy bać się być w ciąży w Polsce']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Każdy z nas będzie mógł zabrać głos w tej debacie, ale pan nigdy nie będzie wiedział, co to znaczy bać się być w ciąży w Polsce. A więc proszę mi tutaj niczego nie insynuować']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/Exaggeration-Minimisation",
         "Exaggeration-Minimisation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "0",
         "No, the Exaggeration-Minimisation technique is not used in the input.",
         "\"\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The input text does not contain any instances of exaggeration or minimisation. The speaker does not make any excessive claims or downplay any issues; rather, they assert their perspective without employing the technique.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "['The input text does not contain any instances of exaggeration or minimisation. The speaker does not make any excessive claims or downplay any issues; rather, they assert their perspective without employing the technique.']",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/Exaggeration-Minimisation/train/pl/train-pl-part_0014.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text does not contain any instances of exaggeration or minimisation. The speaker does not make any excessive claims or downplay any issues; rather, they assert their perspective without employing the technique.\", \"verdict\": false}"
        ],
        [
         "26",
         "pl_eu_12_06_2024_n02.txt",
         "1035",
         "1849",
         "PL",
         "Natomiast odniosę się bezpośrednio do tych rozwiązań ustawowych. 7 miesięcy. Mieliście państwo\n7 miesięcy, żeby przygotować się do tego, do tej przyszłej prezydencji. Nie zrobiliście właściwie nic. Bo\njeżeli dzisiaj chcecie rezygnować z Prawa zamówień\npublicznych, a macie jeszcze blisko pół roku, to zasadne jest pytanie, czy faktycznie nie jesteście w stanie tego zrobić, tak jak wielu innych rzeczy, czy chcecie coś ukryć. (Dzwonek) I gdyby były wyłączone\nkwestie związane z bezpieczeństwem, to można by\nbyło się na to zgodzić. Natomiast jeżeli chcecie wyłączyć procesy inwestycyjne, a nie chcieliście się zgodzić, np. w czasie COVID-u mieliście wiele zastrzeżeń, w czasie budowy zapory na granicy nie chcieliście się zgodzić, jeżeli chodzi o Prawo zamówień publicznych, to był jeden z argumentów, dlaczego nie…",
         "True",
         "['Questioning_the_Reputation']",
         "train",
         "['Nie zrobiliście właściwie nic'\n 'Bo jeżeli dzisiaj chcecie rezygnować z Prawa zamówień publicznych, a macie jeszcze blisko pół roku, to zasadne jest pytanie, czy faktycznie nie jesteście w stanie tego zrobić, tak jak wielu innych rzeczy, czy chcecie coś ukryć'\n 'Natomiast jeżeli chcecie wyłączyć procesy inwestycyjne, a nie chcieliście się zgodzić, np. w czasie COVID-u mieliście wiele zastrzeżeń, w czasie budowy zapory na granicy nie chcieliście się zgodzić, jeżeli chodzi o Prawo zamówień publicznych, to był jeden z argumentów, dlaczego nie…']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/Exaggeration-Minimisation",
         "Exaggeration-Minimisation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "0",
         "No, the Exaggeration-Minimisation technique is not used in the input.",
         "\"\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The input text does not employ the Exaggeration - Minimisation technique, as it does not exaggerate or downplay any statements or arguments. The speaker is directly addressing the actions and inactions of the audience without embellishing or minimizing the significance of those actions.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "['The input text does not employ the Exaggeration - Minimisation technique, as it does not exaggerate or downplay any statements or arguments. The speaker is directly addressing the actions and inactions of the audience without embellishing or minimizing the significance of those actions.']",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/Exaggeration-Minimisation/train/pl/train-pl-part_0014.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text does not employ the Exaggeration - Minimisation technique, as it does not exaggerate or downplay any statements or arguments. The speaker is directly addressing the actions and inactions of the audience without embellishing or minimizing the significance of those actions.\", \"verdict\": false}"
        ],
        [
         "27",
         "pl_current_affairs_09_01_2025_n03.txt",
         "2439",
         "2670",
         "PL",
         "Po drugie, zapora we Włocławku została zrewitalizowana. Według wszelkich posiadanych danych nie\nma już ryzyka, które wymagałoby dobudowywania\nkolejnych zbiorników w celu wzmocnienia tej zapory,\nponieważ ona została zrewitalizowana.",
         "False",
         "[]",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/Exaggeration-Minimisation",
         "Exaggeration-Minimisation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "0",
         "No, the Exaggeration-Minimisation technique is not used in the input.",
         "\"\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The input text does not employ the Exaggeration - Minimisation technique, as it does not exaggerate the significance of the revitalization of the dam or downplay any associated risks. It simply states that the dam has been revitalized and that there is no longer a risk requiring additional reservoirs.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "['The input text does not employ the Exaggeration - Minimisation technique, as it does not exaggerate the significance of the revitalization of the dam or downplay any associated risks. It simply states that the dam has been revitalized and that there is no longer a risk requiring additional reservoirs.']",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/Exaggeration-Minimisation/train/pl/train-pl-part_0014.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text does not employ the Exaggeration - Minimisation technique, as it does not exaggerate the significance of the revitalization of the dam or downplay any associated risks. It simply states that the dam has been revitalized and that there is no longer a risk requiring additional reservoirs.\", \"verdict\": false}"
        ],
        [
         "28",
         "pl_abortion_11_04_2024_n05.txt",
         "7269",
         "7982",
         "PL",
         "Dziś rozmawiamy o prawach kobiet, ale praw kobiet\nprzecież się nie negocjuje, praw kobiet nie zapisuje się\nteż w żadnej umowie koalicyjnej, praw kobiet\nnie poddaje się pod referendum. Prawa człowieka są\nzapisane w konstytucji. (Oklaski) Prawo do\ndecydowania o sobie, o swoim ciele jest fundamentalne.\nKażda osoba powinna mieć prawo do podejmowania\ndecyzji dotyczących swojego zdrowia i swojej przyszłości.\nOgraniczanie tego prawa jest wyrazem braku\nposzanowania godności i autonomii każdego człowieka.\nI nikt nikomu nie może narzucać swoich poglądów.\nNikt nie może narzucać konsekwencji swoich\npoglądów innym, bo ludzie są różni, mają różne\nświatopoglądy i chcą o sobie decydować.\nNikt z nas nie ma do tego prawa.",
         "True",
         "['Conversation_Killer' 'Appeal_to_Values' 'Repetition']",
         "train",
         "[]",
         "[]",
         "[]",
         "['praw kobiet przecież się nie negocjuje'\n 'praw kobiet nie zapisuje się też w żadnej umowie koalicyjnej'\n 'praw kobiet nie poddaje się pod referendum']",
         "[]",
         "['prawach kobiet' 'praw kobiet' 'praw kobiet' 'praw kobiet'\n 'I nikt nikomu nie może narzucać swoich poglądów'\n 'Nikt nie może narzucać konsekwencji swoich poglądów innym'\n 'Nikt z nas nie ma do tego prawa']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Dziś rozmawiamy o prawach kobiet, ale praw kobiet przecież się nie negocjuje, praw kobiet nie zapisuje się też w żadnej umowie koalicyjnej, praw kobiet nie poddaje się pod referendum'\n 'Prawa człowieka są zapisane w konstytucji'\n 'Prawo do decydowania o sobie, o swoim ciele jest fundamentalne'\n 'Każda osoba powinna mieć prawo do podejmowania decyzji dotyczących swojego zdrowia i swojej przyszłości'\n 'Ograniczanie tego prawa jest wyrazem braku poszanowania godności i autonomii każdego człowieka']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/Exaggeration-Minimisation",
         "Exaggeration-Minimisation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "0",
         "No, the Exaggeration-Minimisation technique is not used in the input.",
         "\"\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The input text does not employ the Exaggeration - Minimisation technique, as it does not exaggerate or downplay any statements. Instead, it firmly asserts the importance of women\\'s rights and autonomy without minimizing or exaggerating the issues discussed.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "[\"The input text does not employ the Exaggeration - Minimisation technique, as it does not exaggerate or downplay any statements. Instead, it firmly asserts the importance of women's rights and autonomy without minimizing or exaggerating the issues discussed.\"]",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/Exaggeration-Minimisation/train/pl/train-pl-part_0014.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text does not employ the Exaggeration - Minimisation technique, as it does not exaggerate or downplay any statements. Instead, it firmly asserts the importance of women's rights and autonomy without minimizing or exaggerating the issues discussed.\", \"verdict\": false}"
        ],
        [
         "29",
         "pl_abortion_11_04_2024_n03.txt",
         "177",
         "1021",
         "PL",
         "Poseł Katarzyna Kotula:\nDziękuję bardzo.\nPanie Marszałku! Wysoka Izbo! Drogie,\nSzanowne Działaczki Ruchów Kobiecych i Działaczki\nAborcyjne! Dokładnie miesiąc temu, kiedy marszałek\nSzymon Hołownia przesuwał debatę o aborcji, w\nwarszawskim szpitalu Paulina starała się o przerwanie\nciąży. Miała wszelką niezbędną dokumentację\nmedyczną, która uprawniała ją do legalnej aborcji na\npodstawie obowiązującego prawa. Paulina miała\nzaświadczenie od specjalisty, które zapewniało, że jej\nzdrowie jest zagrożone. Ginekolodzy w warszawskim\nszpitalu nie chcieli niestety uznać tego zaświadczenia\ni rozpoczęła się gra na czas. Kto dłużej wytrzyma tę\npróbę sił? Kobieta w stanie zagrażającym zdrowiu czy\nszpital, instytucja, która powinna jej pomóc, a nie\nkłaść kłody pod nogi? To była gra życiem kobiety.\nNie pierwsza, ale mam nadzieję, że jedna z ostatnich.",
         "True",
         "['Flag_Waving' 'Loaded_Language' 'Appeal_to_Time'\n 'Questioning_the_Reputation' 'Appeal_to_Values' 'Red_Herring' 'Doubt'\n 'Appeal_to_Fear-Prejudice']",
         "train",
         "['instytucja, która powinna jej pomóc, a nie kłaść kłody pod nogi?']",
         "[]",
         "[]",
         "[]",
         "['kłaść kłody pod nogi?']",
         "[]",
         "[]",
         "['Paulina miała zaświadczenie od specjalisty, które zapewniało, że jej zdrowie jest zagrożone. Ginekolodzy w warszawskim szpitalu nie chcieli niestety uznać tego zaświadczenia']",
         "['kiedy marszałek Szymon Hołownia przesuwał debatę o aborcji']",
         "['Działaczki Ruchów Kobiecych i Działaczki Aborcyjne!']",
         "[]",
         "[]",
         "[]",
         "['Nie pierwsza, ale mam nadzieję, że jedna z ostatnich']",
         "['Kobieta w stanie zagrażającym zdrowiu czy szpital, instytucja, która powinna jej pomóc'\n 'To była gra życiem kobiety']",
         "[]",
         "[]",
         "[]",
         "['Paulina miała zaświadczenie od specjalisty, które zapewniało, że jej zdrowie jest zagrożone'\n 'To była gra życiem kobiety']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/Exaggeration-Minimisation",
         "Exaggeration-Minimisation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "0",
         "No, the Exaggeration-Minimisation technique is not used in the input.",
         "\"\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The input text does not employ the Exaggeration - Minimisation technique, as it does not exaggerate or downplay any statements or situations. The speaker presents the facts regarding Paulina\\'s situation without embellishment or minimization.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[\"The input text does not employ the Exaggeration - Minimisation technique, as it does not exaggerate or downplay any statements or situations. The speaker presents the facts regarding Paulina's situation without embellishment or minimization.\"]",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/Exaggeration-Minimisation/train/pl/train-pl-part_0014.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text does not employ the Exaggeration - Minimisation technique, as it does not exaggerate or downplay any statements or situations. The speaker presents the facts regarding Paulina's situation without embellishment or minimization.\", \"verdict\": false}"
        ],
        [
         "30",
         "pl_abortion_11_04_2024_n06.txt",
         "3465",
         "3708",
         "PL",
         "Poseł Monika Rosa:\nPanie Pośle! Pan nigdy nie był w ciąży i pan nie\nwie, co to znaczy nosić dziecko i się bać. A więc proszę\nnie wychodzić mi z jakimiś moralnymi według pana\ni etycznymi komentarzami. (Oklaski)\n(Poseł Piotr Kaleta: Ojej, ojej…)",
         "True",
         "['Loaded_Language' 'Questioning_the_Reputation' 'Straw_Man']",
         "train",
         "['Pan nigdy nie był w ciąży i pan nie wie, co to znaczy nosić dziecko i się bać. A więc proszę nie wychodzić mi z jakimiś moralnymi według pana i etycznymi komentarzami']",
         "[]",
         "[]",
         "[]",
         "['nie wychodzić mi']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Pan nigdy nie był w ciąży i pan nie wie, co to znaczy nosić dziecko i się bać. A więc proszę nie wychodzić mi z jakimiś moralnymi według pana i etycznymi komentarzami']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/Exaggeration-Minimisation",
         "Exaggeration-Minimisation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "0",
         "No, the Exaggeration-Minimisation technique is not used in the input.",
         "\"\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The Exaggeration - Minimisation technique is not used in the input text as there are no instances of representing something in an excessive manner or downplaying the importance of a statement. The speaker is expressing a personal experience and does not exaggerate or minimize any claims.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "['The Exaggeration - Minimisation technique is not used in the input text as there are no instances of representing something in an excessive manner or downplaying the importance of a statement. The speaker is expressing a personal experience and does not exaggerate or minimize any claims.']",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/Exaggeration-Minimisation/train/pl/train-pl-part_0004.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The Exaggeration - Minimisation technique is not used in the input text as there are no instances of representing something in an excessive manner or downplaying the importance of a statement. The speaker is expressing a personal experience and does not exaggerate or minimize any claims.\", \"verdict\": false}"
        ],
        [
         "31",
         "pl_abortion_11_04_2024_n01.txt",
         "4660",
         "5608",
         "PL",
         "Musimy się zgodzić na to, żeby ta pomoc nie groziła\ntym, że rozdziela się rodziny, rozdziela się ojców i\ndzieci, rozdziela się babcie oraz ciocie czy też przyjaciółki\nrodziny. Ogólnodostępne dane zawierające informacje\no treści wyroków polskich sądów pokazują, że w\nostatnich latach za pomoc kobiecie w aborcji zostali skazani\nm.in.: ojciec, który przekazał córce pieniądze na\npokrycie kosztów jej zabiegu aborcji w klinice w Holandii;\nmatka, która pomogła córce wyjechać na zabieg aborcji\ndo kliniki w Holandii i która opłaciła córce koszty\nprzejazdu i samego zabiegu; kolejna matka, matka kobiety,\nżyjącej kobiety, która zorganizowała swojej córce\nwyjazd na zabieg aborcji i również opłaciła jej środek\ntransportu; następna matka – to samo, dokładnie taki\nsam przypadek. Tych wyroków jest w Polsce dużo.\nPaństwo może sobie nie zdają z tego sprawy, bo być może\nto jest takie podejście: nie interesujemy się, niech sobie\nkobiety to załatwiają same.",
         "True",
         "['Appeal_to_Pity' 'Appeal_to_Values' 'False_Dilemma-No_Choice' 'Doubt']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['bo być może to jest takie podejście: nie interesujemy się, niech sobie kobiety to załatwiają same']",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Ogólnodostępne dane zawierające informacje o treści wyroków polskich sądów pokazują, że w ostatnich latach za pomoc kobiecie w aborcji zostali skazani m.in.: ojciec, który przekazał córce pieniądze na pokrycie kosztów jej zabiegu aborcji w klinice w Holandii; matka, która pomogła córce wyjechać na zabieg aborcji do kliniki w Holandii i która opłaciła córce koszty przejazdu i samego zabiegu; kolejna matka, matka kobiety, żyjącej kobiety, która zorganizowała swojej córce wyjazd na zabieg aborcji i również opłaciła jej środek transportu; następna matka – to samo, dokładnie taki sam przypadek']",
         "[]",
         "['Musimy się zgodzić na to, żeby ta pomoc nie groziła tym, że rozdziela się rodziny, rozdziela się ojców i dzieci, rozdziela się babcie oraz ciocie czy też przyjaciółki rodziny']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Musimy się zgodzić na to, żeby ta pomoc nie groziła tym, że rozdziela się rodziny, rozdziela się ojców i dzieci, rozdziela się babcie oraz ciocie czy też przyjaciółki rodziny']",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/Exaggeration-Minimisation",
         "Exaggeration-Minimisation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "0",
         "No, the Exaggeration-Minimisation technique is not used in the input.",
         "\"\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The input text does not employ the Exaggeration - Minimisation technique, as it does not exaggerate or downplay any statements or situations. It presents factual information about legal cases without embellishment or minimization.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "['The input text does not employ the Exaggeration - Minimisation technique, as it does not exaggerate or downplay any statements or situations. It presents factual information about legal cases without embellishment or minimization.']",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/Exaggeration-Minimisation/train/pl/train-pl-part_0004.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text does not employ the Exaggeration - Minimisation technique, as it does not exaggerate or downplay any statements or situations. It presents factual information about legal cases without embellishment or minimization.\", \"verdict\": false}"
        ],
        [
         "32",
         "pl_eu_12_06_2024_n02.txt",
         "2901",
         "3285",
         "PL",
         "Niewątpliwie priorytetem będzie kwestia poprawy obronności. Cieszę się, że rząd Donalda Tuska po\nzmianie, po 15 października przejął stery naszej dyplomacji, bo to jest gwarancja tego, że wykorzystamy\nten czas jak najlepiej (Dzwonek) dla zapewnienia i realizacji interesów Polski, m.in. poprzez poprawę bezpieczeństwa i zaangażowania w tę kwestię członków\nUnii Europejskiej. Dziękuję.",
         "True",
         "['Consequential_Oversimplification' 'Flag_Waving']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['dla zapewnienia i realizacji interesów Polski']",
         "[]",
         "['rząd Donalda Tuska po zmianie, po 15 października przejął stery naszej dyplomacji, bo to jest gwarancja tego, że wykorzystamy ten czas jak najlepiej']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/Exaggeration-Minimisation",
         "Exaggeration-Minimisation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "0",
         "No, the Exaggeration-Minimisation technique is not used in the input.",
         "\"\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The input text does not contain any instances of exaggeration or minimisation. It discusses the importance of improving defense and expresses confidence in the government\\'s actions without overstating or downplaying any issues.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "[\"The input text does not contain any instances of exaggeration or minimisation. It discusses the importance of improving defense and expresses confidence in the government's actions without overstating or downplaying any issues.\"]",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/Exaggeration-Minimisation/train/pl/train-pl-part_0004.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text does not contain any instances of exaggeration or minimisation. It discusses the importance of improving defense and expresses confidence in the government's actions without overstating or downplaying any issues.\", \"verdict\": false}"
        ],
        [
         "33",
         "pl_abortion_11_04_2024_n04.txt",
         "4214",
         "4856",
         "PL",
         "Poseł Agnieszka Buczyńska:\nPanie Marszałku! Wysoka Izbo! Czy polskie\nkobiety oczekują od nas, polityczek i polityków, kłótni\ni krzyków z mównicy, wewnętrznych wojen i obrażania?\nA może raczej umiejętności dyskusji i szukania\nwspólnego rozwiązania? Uspokojenia, empatii,\nwrażliwości, bo i tak w samym społeczeństwie ten temat\nwywołuje potężne emocje. Jesienią 2020 r. tysiące\nkobiet i nierzadko mężczyzn wyszło na ulice\nprotestować przeciwko skandalicznej decyzji Trybunału\nKonstytucyjnego Przyłębskiej, który w swoim\nbezpodstawnym orzeczeniu zmusił kobiety do heroizmu,\ndo rodzenia dzieci z ciężkimi wadami płodu,\ndo narażania własnego życia.",
         "True",
         "['Exaggeration-Minimisation' 'Appeal_to_Values' 'Name_Calling-Labeling'\n 'Straw_Man' 'Repetition']",
         "train",
         "[]",
         "['skandalicznej decyzji Trybunału Konstytucyjnego'\n 'bezpodstawnym orzeczeniu']",
         "[]",
         "[]",
         "[]",
         "['zmusił kobiety do heroizmu']",
         "[]",
         "[]",
         "[]",
         "[]",
         "['zmusił kobiety do heroizmu']",
         "[]",
         "[]",
         "[]",
         "['Czy polskie kobiety oczekują od nas, polityczek i polityków, kłótni i krzyków z mównicy, wewnętrznych wojen i obrażania?'\n 'A może raczej umiejętności dyskusji i szukania wspólnego rozwiązania?'\n 'Uspokojenia, empatii, wrażliwości, bo i tak w samym społeczeństwie ten temat wywołuje potężne emocje'\n 'narażania własnego życia']",
         "[]",
         "['Czy polskie kobiety oczekują od nas, polityczek i polityków, kłótni i krzyków z mównicy, wewnętrznych wojen i obrażania?']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/Exaggeration-Minimisation",
         "Exaggeration-Minimisation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "1",
         "Yes, the Exaggeration-Minimisation technique is used in the input.",
         "\"zmusił kobiety do heroizmu\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The Exaggeration - Minimisation technique is used in the input text by stating that the court\\'s decision \\'zmusił kobiety do heroizmu\\' (forced women into heroism). This exaggerates the situation by implying that women are being compelled to perform an extraordinary act of bravery, thus making the issue seem more severe and dramatic than it may be perceived in a more neutral context.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "[\"The Exaggeration - Minimisation technique is used in the input text by stating that the court's decision 'zmusił kobiety do heroizmu' (forced women into heroism). This exaggerates the situation by implying that women are being compelled to perform an extraordinary act of bravery, thus making the issue seem more severe and dramatic than it may be perceived in a more neutral context.\"]",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/Exaggeration-Minimisation/train/pl/train-pl-part_0004.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The Exaggeration - Minimisation technique is used in the input text by stating that the court's decision 'zmusi\\u0142 kobiety do heroizmu' (forced women into heroism). This exaggerates the situation by implying that women are being compelled to perform an extraordinary act of bravery, thus making the issue seem more severe and dramatic than it may be perceived in a more neutral context.\", \"verdict\": true}"
        ],
        [
         "34",
         "pl_eu_12_06_2024_n01.txt",
         "6832",
         "7189",
         "PL",
         "Projektodawca jest również niekonsekwentny.\nZ jednej strony ogłasza plan likwidacji CBA, z drugiej, w art. 9 nakazuje zamawiającym zgłaszać zamówienia realizowane poza reżimem Prawa zamówień\npublicznych właśnie dokąd? Do CBA. Zasadny jest\nwięc wniosek mniejszości, by wykreślić art. 8 i powiązany z nim art. 9 projektu ustawy. Będziemy popierać ten wniosek.",
         "True",
         "['Appeal_to_Hypocrisy' 'Doubt']",
         "train",
         "[]",
         "[]",
         "['Z jednej strony ogłasza plan likwidacji CBA, z drugiej, w art. 9 nakazuje zamawiającym zgłaszać zamówienia realizowane poza reżimem Prawa zamówień publicznych właśnie dokąd? Do CBA']",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Projektodawca jest również niekonsekwentny']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/Exaggeration-Minimisation",
         "Exaggeration-Minimisation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "0",
         "No, the Exaggeration-Minimisation technique is not used in the input.",
         "\"\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The input text does not employ the Exaggeration - Minimisation technique, as it does not exaggerate or downplay any statements or arguments. It presents a critique of the project in a straightforward manner without embellishment or minimization.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "['The input text does not employ the Exaggeration - Minimisation technique, as it does not exaggerate or downplay any statements or arguments. It presents a critique of the project in a straightforward manner without embellishment or minimization.']",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/Exaggeration-Minimisation/train/pl/train-pl-part_0004.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text does not employ the Exaggeration - Minimisation technique, as it does not exaggerate or downplay any statements or arguments. It presents a critique of the project in a straightforward manner without embellishment or minimization.\", \"verdict\": false}"
        ],
        [
         "35",
         "pl_abortion_11_04_2024_n01.txt",
         "3417",
         "3907",
         "PL",
         "Rozmawiamy o życiu. Rozmawiajmy o życiu\nkobiet, jak to życie jest niszczone przez to, że mąż\nkobiety, która przerwała ciążę – podkreślam, miała\nprawo to zrobić – idzie do więzienia. Czy to jest\nnormalne? Czy to nie jest niszczenie życia rodzin?\nWiększość kobiet, które przerywają ciążę, już ma dzieci,\njedno lub więcej, i w tym momencie członek rodziny\n– czasem tata tych dzieci, czasem babcia, czasem\nciocia – ryzykuje tym, że trafi na 3 lata do więzienia.\nTo się musi zmienić natychmiast.",
         "True",
         "['Appeal_to_Time' 'Appeal_to_Pity' 'Appeal_to_Values' 'Repetition' 'Doubt']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Rozmawiamy o życiu' 'Rozmawiajmy o życiu kobiet']",
         "[]",
         "['Czy to jest normalne?']",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Rozmawiajmy o życiu kobiet, jak to życie jest niszczone przez to, że mąż kobiety, która przerwała ciążę – podkreślam, miała prawo to zrobić – idzie do więzienia. Czy to jest normalne? Czy to nie jest niszczenie życia rodzin?'\n 'Większość kobiet, które przerywają ciążę, już ma dzieci, jedno lub więcej, i w tym momencie członek rodziny – czasem tata tych dzieci, czasem babcia, czasem ciocia – ryzykuje tym, że trafi na 3 lata do więzienia']",
         "['To się musi zmienić natychmiast']",
         "['Rozmawiamy o życiu'\n 'Rozmawiajmy o życiu kobiet, jak to życie jest niszczone przez to, że mąż kobiety, która przerwała ciążę – podkreślam, miała prawo to zrobić – idzie do więzienia'\n 'Czy to nie jest niszczenie życia rodzin?']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/Exaggeration-Minimisation",
         "Exaggeration-Minimisation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "0",
         "No, the Exaggeration-Minimisation technique is not used in the input.",
         "\"\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The input text discusses the impact of imprisonment on families due to abortion laws, emphasizing the seriousness of the situation without exaggerating or minimizing the facts. The expert\\'s verdict is supported as there are no instances of exaggeration or minimization present.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "[\"The input text discusses the impact of imprisonment on families due to abortion laws, emphasizing the seriousness of the situation without exaggerating or minimizing the facts. The expert's verdict is supported as there are no instances of exaggeration or minimization present.\"]",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/Exaggeration-Minimisation/train/pl/train-pl-part_0004.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text discusses the impact of imprisonment on families due to abortion laws, emphasizing the seriousness of the situation without exaggerating or minimizing the facts. The expert's verdict is supported as there are no instances of exaggeration or minimization present.\", \"verdict\": false}"
        ],
        [
         "36",
         "pl_abortion_11_04_2024_n04.txt",
         "7452",
         "7724",
         "PL",
         "Wicemarszałek Włodzimierz Czarzasty:\nDziękuję bardzo.\nZanim poproszę panią poseł, chcę przeprosić, bo\nnie wiem, czy jeszcze jest grupa młodzieży z Jędrzejowa.\nJesteście jeszcze państwo? Są, jesteście.\nWitam was serdecznie. (Oklaski)\n(Poseł Urszula Pasławska: Pozdrawiamy.)",
         "False",
         "[]",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/Exaggeration-Minimisation",
         "Exaggeration-Minimisation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "0",
         "No, the Exaggeration-Minimisation technique is not used in the input.",
         "\"\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The input text does not contain any instances of exaggeration or minimisation. The speaker expresses gratitude and acknowledges the presence of a group without making any statements that inflate or downplay the situation.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "['The input text does not contain any instances of exaggeration or minimisation. The speaker expresses gratitude and acknowledges the presence of a group without making any statements that inflate or downplay the situation.']",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/Exaggeration-Minimisation/train/pl/train-pl-part_0004.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text does not contain any instances of exaggeration or minimisation. The speaker expresses gratitude and acknowledges the presence of a group without making any statements that inflate or downplay the situation.\", \"verdict\": false}"
        ],
        [
         "37",
         "pl_abortion_11_04_2024_n04.txt",
         "2549",
         "2890",
         "PL",
         "Dziś z tego miejsca chciałabym, by jeszcze raz\nwybrzmiało, że aborcja to prawa człowieka, to\npodstawowe prawo kobiety do podjęcia decyzji o swoim\nciele, zdrowiu i życiu. Aborcje były, są i będą tak długo,\njak będą potrzebne. Aborcja jest jednym z najczęściej\nstosowanych zabiegów medycznych na świecie i\nnajczęstszym zabiegiem w ginekologii.",
         "True",
         "['Conversation_Killer' 'Appeal_to_Values' 'Appeal_to_Popularity']",
         "train",
         "[]",
         "[]",
         "[]",
         "['Aborcje były, są i będą']",
         "[]",
         "[]",
         "['Aborcja jest jednym z najczęściej stosowanych zabiegów medycznych na świecie i najczęstszym zabiegiem w ginekologii']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Dziś z tego miejsca chciałabym, by jeszcze raz wybrzmiało, że aborcja to prawa człowieka, to podstawowe prawo kobiety do podjęcia decyzji o swoim ciele, zdrowiu i życiu']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/Exaggeration-Minimisation",
         "Exaggeration-Minimisation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "0",
         "No, the Exaggeration-Minimisation technique is not used in the input.",
         "\"\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The input text does not employ the Exaggeration - Minimisation technique, as it does not exaggerate or downplay any statements regarding abortion. It presents facts about abortion as a human right and a common medical procedure without embellishment or minimization.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "['The input text does not employ the Exaggeration - Minimisation technique, as it does not exaggerate or downplay any statements regarding abortion. It presents facts about abortion as a human right and a common medical procedure without embellishment or minimization.']",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/Exaggeration-Minimisation/train/pl/train-pl-part_0004.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text does not employ the Exaggeration - Minimisation technique, as it does not exaggerate or downplay any statements regarding abortion. It presents facts about abortion as a human right and a common medical procedure without embellishment or minimization.\", \"verdict\": false}"
        ],
        [
         "38",
         "pl_defence_22_05_2024_n02.txt",
         "3985",
         "4869",
         "PL",
         "Trzeba zwiększyć polskie zdolności produkcyjne,\nzamawiać dużo sprzętu w polskich firmach, zarówno\nprywatnych, jak i publicznych, trzeba też im płacić\nza utrzymanie zdolności produkcyjnych na czas\nwojny oraz wycofać się z konwencji ottawskiej o zakazie\nużywania min przeciwpiechotnych. Nie są stroną tej\nkonwencji Rosja, Stany Zjednoczone, Chiny, Indie,\nIzrael, Egipt. Ukraina, gdyby nie miny\nprzeciwpiechotne, nie broniłaby się skutecznie przed Rosją.\nMusimy jak najszybciej wypowiedzieć tę konwencję.\nNie jesteśmy w tym momencie gotowi do wojny.\nJedni i drudzy rządziliście Polską od 20 lat i nie\nprzygotowaliście nas do obrony na czas wojny. PiS\nprzygotowywał się tylko do wojny z Platformą, Platforma\nprzygotowywała się do wojny z PiS-em, a Polska nie\njest gotowa. Nasze Siły Zbrojne pod kątem liczby\nrezerw, liczby czołgów czy też liczby\nsprzętu są najsłabsze od 80 lat. (Oklaski)",
         "True",
         "['Causal_Oversimplification' 'Exaggeration-Minimisation' 'Appeal_to_Time'\n 'Questioning_the_Reputation' 'Whataboutism' 'Doubt'\n 'Appeal_to_Fear-Prejudice']",
         "train",
         "['Jedni i drudzy rządziliście Polską od 20 lat i nie przygotowaliście nas do obrony na czas wojny']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Nasze Siły Zbrojne pod kątem liczby rezerw, liczby czołgów czy też liczby sprzętu są najsłabsze od 80 lat']",
         "[]",
         "[]",
         "['PiS przygotowywał się tylko do wojny z Platformą, Platforma przygotowywała się do wojny z PiS-em, a Polska nie jest gotowa']",
         "[]",
         "[]",
         "['Musimy jak najszybciej wypowiedzieć tę konwencję']",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Nie jesteśmy w tym momencie gotowi do wojny'\n 'Jedni i drudzy rządziliście Polską od 20 lat i nie przygotowaliście nas do obrony na czas wojny']",
         "['Ukraina, gdyby nie miny przeciwpiechotne, nie broniłaby się skutecznie przed Rosją']",
         "[]",
         "[]",
         "['PiS przygotowywał się tylko do wojny z Platformą, Platforma przygotowywała się do wojny z PiS-em, a Polska nie jest gotowa']",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/Exaggeration-Minimisation",
         "Exaggeration-Minimisation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "1",
         "Yes, the Exaggeration-Minimisation technique is used in the input.",
         "\"PiS przygotowywał się tylko do wojny z Platformą, Platforma przygotowywała się do wojny z PiS-em, a Polska nie jest gotowa\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The Exaggeration - Minimisation technique is used in the input text by downplaying the readiness of Poland for war. The statement \\'Polska nie jest gotowa\\' minimizes the country\\'s preparedness, suggesting a severe lack of readiness without acknowledging any potential strengths or preparations that may exist. This aligns with the technique\\'s definition of making something seem less important or smaller than it really is.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "[\"The Exaggeration - Minimisation technique is used in the input text by downplaying the readiness of Poland for war. The statement 'Polska nie jest gotowa' minimizes the country's preparedness, suggesting a severe lack of readiness without acknowledging any potential strengths or preparations that may exist. This aligns with the technique's definition of making something seem less important or smaller than it really is.\"]",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/Exaggeration-Minimisation/train/pl/train-pl-part_0004.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The Exaggeration - Minimisation technique is used in the input text by downplaying the readiness of Poland for war. The statement 'Polska nie jest gotowa' minimizes the country's preparedness, suggesting a severe lack of readiness without acknowledging any potential strengths or preparations that may exist. This aligns with the technique's definition of making something seem less important or smaller than it really is.\", \"verdict\": true}"
        ],
        [
         "39",
         "pl_abortion_11_04_2024_n02.txt",
         "2916",
         "3709",
         "PL",
         "Ale to nie koniec. Art. 152, jak wiemy, jest\nprzyczyną tragedii także w polskich szpitalach, bo od\n30 lat aborcja jest traktowana nie jak zabieg\nmedyczny, tylko jak przestępstwo. To sprawia, że lekarze nie\nuczą się o tym, jak przeprowadzać aborcję, nie mają\npraktyki, nie wiedzą, jak to się robi, i kiedy stają\nwobec takiej sytuacji, że mają przerwać ciążę, to się\nboją, próbują tego uniknąć. Nawet wtedy, kiedy ta\ndecyzja zagraża życiu i zdrowiu pacjentki.\nBo brakuje im kompetencji, bo boją się o swoją karierę.\nI właśnie to spychanie aborcji do sfery świata\nkryminalnego doprowadziło do śmierci Izy z Pszczyny,\ndoprowadziło do śmierci Doroty z Nowego Targu i innych\nmłodych kobiet, które miały przed sobą całe życie,\nktóre miały małe dzieci, które mogły dalej\nżyć i wychowywać swoje dzieci.",
         "True",
         "['Causal_Oversimplification' 'Loaded_Language'\n 'Questioning_the_Reputation' 'Appeal_to_Values' 'Doubt']",
         "train",
         "['bo boją się o swoją karierę']",
         "[]",
         "[]",
         "[]",
         "['spychanie aborcji do sfery świata kryminalnego']",
         "[]",
         "[]",
         "['Art. 152, jak wiemy, jest przyczyną tragedii także w polskich szpitalach, bo od 30 lat aborcja jest traktowana nie jak zabieg medyczny, tylko jak przestępstwo'\n 'Bo brakuje im kompetencji']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Nawet wtedy, kiedy ta decyzja zagraża życiu i zdrowiu pacjentki'\n 'które miały przed sobą całe życie, które miały małe dzieci, które mogły dalej żyć i wychowywać swoje dzieci']",
         "[]",
         "[]",
         "[]",
         "[]",
         "['To sprawia, że lekarze nie uczą się o tym, jak przeprowadzać aborcję, nie mają praktyki, nie wiedzą, jak to się robi, i kiedy stają wobec takiej sytuacji, że mają przerwać ciążę, to się boją, próbują tego uniknąć'\n 'I właśnie to spychanie aborcji do sfery świata kryminalnego doprowadziło do śmierci Izy z Pszczyny, doprowadziło do śmierci Doroty z Nowego Targu i innych młodych kobiet, które miały przed sobą całe życie, które miały małe dzieci, które mogły dalej żyć i wychowywać swoje dzieci']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/Exaggeration-Minimisation",
         "Exaggeration-Minimisation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "0",
         "No, the Exaggeration-Minimisation technique is not used in the input.",
         "\"\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The input text does not employ the Exaggeration - Minimisation technique, as it does not exaggerate or downplay any statements. Instead, it presents a serious issue regarding abortion in Poland without making excessive claims or minimizing the gravity of the situation.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "['The input text does not employ the Exaggeration - Minimisation technique, as it does not exaggerate or downplay any statements. Instead, it presents a serious issue regarding abortion in Poland without making excessive claims or minimizing the gravity of the situation.']",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/Exaggeration-Minimisation/train/pl/train-pl-part_0004.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text does not employ the Exaggeration - Minimisation technique, as it does not exaggerate or downplay any statements. Instead, it presents a serious issue regarding abortion in Poland without making excessive claims or minimizing the gravity of the situation.\", \"verdict\": false}"
        ],
        [
         "40",
         "pl_defence_22_05_2024_n01.txt",
         "4364",
         "4657",
         "PL",
         "(Głos z sali: Hańba.)\nAle przejdźmy dalej do tych zakupów. Przychodzi\nrok 2019. Zamówiony został dywizjon HIMARS. Już\nsą te rakiety o zasięgu do 300 km na wyposażeniu\nWojska Polskiego. Proszę państwa, po 18 latach odtworzyliśmy jednostki rakietowe w siłach lądowych\npolskiego wojska. (Oklaski)",
         "True",
         "['Loaded_Language']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Hańba']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/Exaggeration-Minimisation",
         "Exaggeration-Minimisation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "0",
         "No, the Exaggeration-Minimisation technique is not used in the input.",
         "\"\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The input text does not employ the Exaggeration - Minimisation technique, as it does not present any statements in an excessive manner or downplay any significance. The information provided is straightforward and factual without embellishment or minimization.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "['The input text does not employ the Exaggeration - Minimisation technique, as it does not present any statements in an excessive manner or downplay any significance. The information provided is straightforward and factual without embellishment or minimization.']",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/Exaggeration-Minimisation/train/pl/train-pl-part_0020.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text does not employ the Exaggeration - Minimisation technique, as it does not present any statements in an excessive manner or downplay any significance. The information provided is straightforward and factual without embellishment or minimization.\", \"verdict\": false}"
        ],
        [
         "41",
         "pl_abortion_11_04_2024_n05.txt",
         "1362",
         "1720",
         "PL",
         "Ale wracając do projektu ustawy: nasz projekt ustawy\nprzywraca rozwiązanie sprzed wyroku pseudotrybunału\ndo tzw. ustawień fabrycznych. Ale idziemy dalej,\nbo idziemy w stronę edukacji seksualnej, antykoncepcji.\nSwoją drogą, nie wiem, czy państwo wiecie, ale dostęp\ndo antykoncepcji w Polsce jest najsłabszy, najgorszy\nw całej Europie. I to jest pierwszy krok.",
         "True",
         "['Name_Calling-Labeling' 'Appeal_to_Popularity']",
         "train",
         "[]",
         "['pseudotrybunału']",
         "[]",
         "[]",
         "[]",
         "[]",
         "['dostęp do antykoncepcji w Polsce jest najsłabszy, najgorszy w całej Europie']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/Exaggeration-Minimisation",
         "Exaggeration-Minimisation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "0",
         "No, the Exaggeration-Minimisation technique is not used in the input.",
         "\"\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The input text does not employ the Exaggeration - Minimisation technique, as it does not exaggerate or downplay any statements. The claims made about the state of contraception in Poland are presented as factual without embellishment or minimization.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "['The input text does not employ the Exaggeration - Minimisation technique, as it does not exaggerate or downplay any statements. The claims made about the state of contraception in Poland are presented as factual without embellishment or minimization.']",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/Exaggeration-Minimisation/train/pl/train-pl-part_0020.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text does not employ the Exaggeration - Minimisation technique, as it does not exaggerate or downplay any statements. The claims made about the state of contraception in Poland are presented as factual without embellishment or minimization.\", \"verdict\": false}"
        ],
        [
         "42",
         "pl_defence_22_05_2024_n01.txt",
         "1828",
         "2081",
         "PL",
         "Wicemarszałek Piotr Zgorzelski:\nPanie pośle, proszę zachować powagę, bo jest\ndebata.\n(Głos z sali: No właśnie to jest powaga.)\n(Głos z sali: Dokumentujemy powagę, panie marszałku.)\nJest debata, proszę zachować powagę.\n(Głos z sali: Gdzie jest Hołownia?)",
         "False",
         "[]",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/Exaggeration-Minimisation",
         "Exaggeration-Minimisation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "0",
         "No, the Exaggeration-Minimisation technique is not used in the input.",
         "\"\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The Exaggeration - Minimisation technique is not used in the input text as there are no instances of exaggerating or downplaying statements. The dialogue focuses on maintaining seriousness during a debate without any excessive or minimized representations.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "['The Exaggeration - Minimisation technique is not used in the input text as there are no instances of exaggerating or downplaying statements. The dialogue focuses on maintaining seriousness during a debate without any excessive or minimized representations.']",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/Exaggeration-Minimisation/train/pl/train-pl-part_0006.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The Exaggeration - Minimisation technique is not used in the input text as there are no instances of exaggerating or downplaying statements. The dialogue focuses on maintaining seriousness during a debate without any excessive or minimized representations.\", \"verdict\": false}"
        ],
        [
         "43",
         "pl_abortion_11_04_2024_n03.txt",
         "9280",
         "9741",
         "PL",
         "Zakaz aborcji zabija i nie likwiduje aborcji. Zakaz\naborcji powoduje, że w polskich szpitalach nie ma\ndzisiaj bezpiecznej aborcji. Ale od 30 lat te aborcje się\ndzieją tylko dlatego, że poszczególne osoby znajdują\nsposób na to, żeby je zrobić. Ostatnie lata to zasługa\ngrup nieformalnych i aktywistek działających\nw Polsce – to Aborcyjny Dream Team czy Aborcja bez Granic.\nWiem, że jesteście, pozdrawiam was bardzo serdecznie\ni dziękuję za waszą pracę. (Oklaski)",
         "True",
         "['Consequential_Oversimplification' 'Causal_Oversimplification'\n 'Loaded_Language' 'Flag_Waving' 'Appeal_to_Popularity' 'Doubt'\n 'Appeal_to_Fear-Prejudice']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "['zabija']",
         "[]",
         "['Ostatnie lata to zasługa grup nieformalnych i aktywistek działających w Polsce – to Aborcyjny Dream Team czy Aborcja bez Granic']",
         "['Zakaz aborcji zabija i nie likwiduje aborcji']",
         "[]",
         "['Wiem, że jesteście, pozdrawiam']",
         "[]",
         "['Zakaz aborcji zabija i nie likwiduje aborcji']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Zakaz aborcji zabija']",
         "['Zakaz aborcji powoduje, że w polskich szpitalach nie ma dzisiaj bezpiecznej aborcji']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/Exaggeration-Minimisation",
         "Exaggeration-Minimisation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "0",
         "No, the Exaggeration-Minimisation technique is not used in the input.",
         "\"\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The input text does not employ the Exaggeration - Minimisation technique, as it does not exaggerate or downplay any statements. It presents a clear argument regarding the impact of abortion bans without making excessive claims or minimizing the importance of the issue.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "['The input text does not employ the Exaggeration - Minimisation technique, as it does not exaggerate or downplay any statements. It presents a clear argument regarding the impact of abortion bans without making excessive claims or minimizing the importance of the issue.']",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/Exaggeration-Minimisation/train/pl/train-pl-part_0006.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text does not employ the Exaggeration - Minimisation technique, as it does not exaggerate or downplay any statements. It presents a clear argument regarding the impact of abortion bans without making excessive claims or minimizing the importance of the issue.\", \"verdict\": false}"
        ],
        [
         "44",
         "pl_abortion_11_04_2024_n04.txt",
         "7809",
         "7883",
         "PL",
         "Bardzo proszę panią poseł Urszulę Pasławską o zabranie głosu.\nProszę, Ula.",
         "False",
         "[]",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/Exaggeration-Minimisation",
         "Exaggeration-Minimisation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "0",
         "No, the Exaggeration-Minimisation technique is not used in the input.",
         "\"\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The input text does not contain any elements of exaggeration or minimisation, as it simply requests a person to speak without embellishing or downplaying any statements.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "['The input text does not contain any elements of exaggeration or minimisation, as it simply requests a person to speak without embellishing or downplaying any statements.']",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/Exaggeration-Minimisation/train/pl/train-pl-part_0006.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text does not contain any elements of exaggeration or minimisation, as it simply requests a person to speak without embellishing or downplaying any statements.\", \"verdict\": false}"
        ],
        [
         "45",
         "pl_current_affairs_09_01_2025_n03.txt",
         "4738",
         "4973",
         "PL",
         "…a za rządów Jarosława Kaczyńskiego, Mateusza\nMorawieckiego i ministra Gróbarczyka odpowiedzialnego za zabezpieczenie przeciwpowodziowe – 303 km.\n1732 km versus 303 km. Myślę, że na podsumowanie\nto wystarczy. Dziękuję bardzo. (Oklaski)",
         "True",
         "['Conversation_Killer' 'Doubt']",
         "train",
         "[]",
         "[]",
         "[]",
         "['Myślę, że na podsumowanie to wystarczy']",
         "[]",
         "[]",
         "[]",
         "['…a za rządów Jarosława Kaczyńskiego, Mateusza Morawieckiego i ministra Gróbarczyka odpowiedzialnego za zabezpieczenie przeciwpowodziowe – 303 km. 1732 km versus 303 km']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/Exaggeration-Minimisation",
         "Exaggeration-Minimisation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "0",
         "No, the Exaggeration-Minimisation technique is not used in the input.",
         "\"\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The input text does not employ the Exaggeration - Minimisation technique, as it does not present any statements in an excessive manner or downplay any arguments. The comparison of 1732 km versus 303 km is a straightforward presentation of facts without exaggeration or minimisation.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "['The input text does not employ the Exaggeration - Minimisation technique, as it does not present any statements in an excessive manner or downplay any arguments. The comparison of 1732 km versus 303 km is a straightforward presentation of facts without exaggeration or minimisation.']",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/Exaggeration-Minimisation/train/pl/train-pl-part_0006.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text does not employ the Exaggeration - Minimisation technique, as it does not present any statements in an excessive manner or downplay any arguments. The comparison of 1732 km versus 303 km is a straightforward presentation of facts without exaggeration or minimisation.\", \"verdict\": false}"
        ],
        [
         "46",
         "pl_eu_12_06_2024_n02.txt",
         "1851",
         "1921",
         "PL",
         "Wicemarszałek Włodzimierz Czarzasty:\nDziękuję serdecznie, panie pośle.",
         "False",
         "[]",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/Exaggeration-Minimisation",
         "Exaggeration-Minimisation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "0",
         "No, the Exaggeration-Minimisation technique is not used in the input.",
         "\"\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The input text does not contain any elements of exaggeration or minimisation, as it is a simple expression of gratitude without any embellishment or downplaying of significance.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "['The input text does not contain any elements of exaggeration or minimisation, as it is a simple expression of gratitude without any embellishment or downplaying of significance.']",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/Exaggeration-Minimisation/train/pl/train-pl-part_0006.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text does not contain any elements of exaggeration or minimisation, as it is a simple expression of gratitude without any embellishment or downplaying of significance.\", \"verdict\": false}"
        ],
        [
         "47",
         "pl_eu_12_06_2024_n01.txt",
         "3163",
         "3547",
         "PL",
         "Po rozpatrzeniu całości projektu ustawy członkowie obu komisji, 51 posłanek i posłów, 32 głosami za,\n2 przeciw i 17 wstrzymującymi przyjęli projekt ustawy o szczególnych rozwiązaniach w związku z przygotowywaniem i sprawowaniem przez Rzeczpospolitą Polską przewodnictwa w Radzie Unii Europejskiej\nw I połowie 2025 roku, druk nr 347, rekomendując\ngo Wysokiej Izbie. Dziękuję. (Oklaski)",
         "False",
         "[]",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/Exaggeration-Minimisation",
         "Exaggeration-Minimisation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "0",
         "No, the Exaggeration-Minimisation technique is not used in the input.",
         "\"\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The input text presents factual information regarding the approval of a legislative project without any exaggeration or minimisation of its significance. It simply states the voting results and the context of the project, which aligns with the expert\\'s verdict that the technique was not used.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "[\"The input text presents factual information regarding the approval of a legislative project without any exaggeration or minimisation of its significance. It simply states the voting results and the context of the project, which aligns with the expert's verdict that the technique was not used.\"]",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/Exaggeration-Minimisation/train/pl/train-pl-part_0006.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text presents factual information regarding the approval of a legislative project without any exaggeration or minimisation of its significance. It simply states the voting results and the context of the project, which aligns with the expert's verdict that the technique was not used.\", \"verdict\": false}"
        ],
        [
         "48",
         "pl_eu_12_06_2024_n02.txt",
         "5845",
         "5961",
         "PL",
         "Wicemarszałek Włodzimierz Czarzasty:\nDziękuję.\nPan poseł Janusz Kowalski, Klub Parlamentarny\nPrawo i Sprawiedliwość.",
         "False",
         "[]",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/Exaggeration-Minimisation",
         "Exaggeration-Minimisation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "0",
         "No, the Exaggeration-Minimisation technique is not used in the input.",
         "\"\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The input text does not contain any elements of exaggeration or minimisation, as it is a straightforward acknowledgment without any embellishment or downplaying of statements.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "['The input text does not contain any elements of exaggeration or minimisation, as it is a straightforward acknowledgment without any embellishment or downplaying of statements.']",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/Exaggeration-Minimisation/train/pl/train-pl-part_0006.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text does not contain any elements of exaggeration or minimisation, as it is a straightforward acknowledgment without any embellishment or downplaying of statements.\", \"verdict\": false}"
        ],
        [
         "49",
         "pl_abortion_11_04_2024_n01.txt",
         "268",
         "371",
         "PL",
         "Panowie, halo, szanujmy wszystkich gości.\nDziękujemy wam bardzo za przybycie.\nSuper, bardzo dziękujemy.",
         "False",
         "[]",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/Exaggeration-Minimisation",
         "Exaggeration-Minimisation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "0",
         "No, the Exaggeration-Minimisation technique is not used in the input.",
         "\"\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The input text does not contain any instances of exaggeration or minimisation. It expresses gratitude and respect without inflating or downplaying any statements.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "['The input text does not contain any instances of exaggeration or minimisation. It expresses gratitude and respect without inflating or downplaying any statements.']",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/Exaggeration-Minimisation/train/pl/train-pl-part_0006.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text does not contain any instances of exaggeration or minimisation. It expresses gratitude and respect without inflating or downplaying any statements.\", \"verdict\": false}"
        ]
       ],
       "shape": {
        "columns": 60,
        "rows": 15491
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>text_lang</th>\n",
       "      <th>text</th>\n",
       "      <th>label_bin</th>\n",
       "      <th>label_multi</th>\n",
       "      <th>base_split</th>\n",
       "      <th>Questioning_the_Reputation</th>\n",
       "      <th>Name_Calling-Labeling</th>\n",
       "      <th>...</th>\n",
       "      <th>updated_definition</th>\n",
       "      <th>think_content</th>\n",
       "      <th>illegal_value</th>\n",
       "      <th>explanation</th>\n",
       "      <th>extra_content</th>\n",
       "      <th>source_file</th>\n",
       "      <th>error</th>\n",
       "      <th>status</th>\n",
       "      <th>split</th>\n",
       "      <th>expected_output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pl_eu_12_06_2024_n01.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>135</td>\n",
       "      <td>PL</td>\n",
       "      <td>Wicemarszałek Włodzimierz Czarzasty:\\nBardzo p...</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>train</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[The input text does not contain any elements ...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41_MINI...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "      <td>{\"description\": \"The input text does not conta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pl_defence_22_05_2024_n01.txt</td>\n",
       "      <td>3608</td>\n",
       "      <td>3857</td>\n",
       "      <td>PL</td>\n",
       "      <td>Pan wspominał o ABCS – Integrated Battle Comma...</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>train</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[The input text does not contain any instances...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41_MINI...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "      <td>{\"description\": \"The input text does not conta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pl_current_affairs_09_01_2025_n03.txt</td>\n",
       "      <td>1808</td>\n",
       "      <td>1984</td>\n",
       "      <td>PL</td>\n",
       "      <td>(Poseł Anna Gembicka: Decyzja została zmienion...</td>\n",
       "      <td>True</td>\n",
       "      <td>[Repetition]</td>\n",
       "      <td>train</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[The Exaggeration - Minimisation technique was...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41_MINI...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "      <td>{\"description\": \"The Exaggeration - Minimisati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pl_abortion_11_04_2024_n08.txt</td>\n",
       "      <td>2952</td>\n",
       "      <td>3136</td>\n",
       "      <td>PL</td>\n",
       "      <td>Czy czas najwyższy, by w końcu dopuścić\\ndekry...</td>\n",
       "      <td>True</td>\n",
       "      <td>[False_Equivalence, Loaded_Language, Whatabout...</td>\n",
       "      <td>train</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[The input text does not employ the Exaggerati...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41_MINI...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "      <td>{\"description\": \"The input text does not emplo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pl_eu_12_06_2024_n01.txt</td>\n",
       "      <td>1277</td>\n",
       "      <td>2304</td>\n",
       "      <td>PL</td>\n",
       "      <td>Prezentowany na posiedzeniu projekt ustawy, op...</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>train</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[The input text does not employ the Exaggerati...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41_MINI...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "      <td>{\"description\": \"The input text does not emplo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15486</th>\n",
       "      <td>20231208_URW_BG_71.txt</td>\n",
       "      <td>3950</td>\n",
       "      <td>3965</td>\n",
       "      <td>BG</td>\n",
       "      <td>Има ли реплика?</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>train</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[The input text does not contain any arguments...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41/v001...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "      <td>{\"description\": \"The input text does not conta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15487</th>\n",
       "      <td>20231208_URW_BG_76.txt</td>\n",
       "      <td>1541</td>\n",
       "      <td>1938</td>\n",
       "      <td>BG</td>\n",
       "      <td>Най-интересното е, че в т. 7 пише, цитирам, че...</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>train</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[The input text does not employ the Strawman t...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41/v001...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "      <td>{\"description\": \"The input text does not emplo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15488</th>\n",
       "      <td>20240704_URW_BG_25.txt</td>\n",
       "      <td>4841</td>\n",
       "      <td>5237</td>\n",
       "      <td>BG</td>\n",
       "      <td>и, предлагам това заседание, госпожо Председат...</td>\n",
       "      <td>True</td>\n",
       "      <td>[Appeal_to_Hypocrisy, Loaded_Language]</td>\n",
       "      <td>train</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[The input text does not demonstrate the Straw...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41/v001...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "      <td>{\"description\": \"The input text does not demon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15489</th>\n",
       "      <td>20240704_URW_BG_25.txt</td>\n",
       "      <td>1179</td>\n",
       "      <td>1237</td>\n",
       "      <td>BG</td>\n",
       "      <td>АВ РИБАРСКИ (ПП-ДБ): Благодаря, госпожо Предсе...</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>train</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[The input text does not contain any elements ...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41/v001...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "      <td>{\"description\": \"The input text does not conta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15490</th>\n",
       "      <td>trail_raw_BG_7.txt</td>\n",
       "      <td>51</td>\n",
       "      <td>113</td>\n",
       "      <td>BG</td>\n",
       "      <td>АНИСЛАВ БАЛАБАНОВ (ИТН): Господин Председател,...</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>train</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[The input text does not contain any arguments...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41/v001...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "      <td>{\"description\": \"The input text does not conta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15491 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    filename  start   end text_lang  \\\n",
       "0                   pl_eu_12_06_2024_n01.txt      0   135        PL   \n",
       "1              pl_defence_22_05_2024_n01.txt   3608  3857        PL   \n",
       "2      pl_current_affairs_09_01_2025_n03.txt   1808  1984        PL   \n",
       "3             pl_abortion_11_04_2024_n08.txt   2952  3136        PL   \n",
       "4                   pl_eu_12_06_2024_n01.txt   1277  2304        PL   \n",
       "...                                      ...    ...   ...       ...   \n",
       "15486                 20231208_URW_BG_71.txt   3950  3965        BG   \n",
       "15487                 20231208_URW_BG_76.txt   1541  1938        BG   \n",
       "15488                 20240704_URW_BG_25.txt   4841  5237        BG   \n",
       "15489                 20240704_URW_BG_25.txt   1179  1237        BG   \n",
       "15490                     trail_raw_BG_7.txt     51   113        BG   \n",
       "\n",
       "                                                    text  label_bin  \\\n",
       "0      Wicemarszałek Włodzimierz Czarzasty:\\nBardzo p...      False   \n",
       "1      Pan wspominał o ABCS – Integrated Battle Comma...      False   \n",
       "2      (Poseł Anna Gembicka: Decyzja została zmienion...       True   \n",
       "3      Czy czas najwyższy, by w końcu dopuścić\\ndekry...       True   \n",
       "4      Prezentowany na posiedzeniu projekt ustawy, op...      False   \n",
       "...                                                  ...        ...   \n",
       "15486                                    Има ли реплика?      False   \n",
       "15487  Най-интересното е, че в т. 7 пише, цитирам, че...      False   \n",
       "15488  и, предлагам това заседание, госпожо Председат...       True   \n",
       "15489  АВ РИБАРСКИ (ПП-ДБ): Благодаря, госпожо Предсе...      False   \n",
       "15490  АНИСЛАВ БАЛАБАНОВ (ИТН): Господин Председател,...      False   \n",
       "\n",
       "                                             label_multi base_split  \\\n",
       "0                                                     []      train   \n",
       "1                                                     []      train   \n",
       "2                                           [Repetition]      train   \n",
       "3      [False_Equivalence, Loaded_Language, Whatabout...      train   \n",
       "4                                                     []      train   \n",
       "...                                                  ...        ...   \n",
       "15486                                                 []      train   \n",
       "15487                                                 []      train   \n",
       "15488             [Appeal_to_Hypocrisy, Loaded_Language]      train   \n",
       "15489                                                 []      train   \n",
       "15490                                                 []      train   \n",
       "\n",
       "      Questioning_the_Reputation Name_Calling-Labeling  ...  \\\n",
       "0                             []                    []  ...   \n",
       "1                             []                    []  ...   \n",
       "2                             []                    []  ...   \n",
       "3                             []                    []  ...   \n",
       "4                             []                    []  ...   \n",
       "...                          ...                   ...  ...   \n",
       "15486                         []                    []  ...   \n",
       "15487                         []                    []  ...   \n",
       "15488                         []                    []  ...   \n",
       "15489                         []                    []  ...   \n",
       "15490                         []                    []  ...   \n",
       "\n",
       "      updated_definition think_content illegal_value  \\\n",
       "0                 [None]        [None]        [None]   \n",
       "1                     []        [None]        [None]   \n",
       "2                     []        [None]        [None]   \n",
       "3                     []        [None]        [None]   \n",
       "4                     []        [None]        [None]   \n",
       "...                  ...           ...           ...   \n",
       "15486                 []        [None]        [None]   \n",
       "15487             [None]        [None]        [None]   \n",
       "15488                 []        [None]        [None]   \n",
       "15489                 []        [None]        [None]   \n",
       "15490                 []        [None]        [None]   \n",
       "\n",
       "                                             explanation extra_content  \\\n",
       "0      [The input text does not contain any elements ...        [None]   \n",
       "1      [The input text does not contain any instances...        [None]   \n",
       "2      [The Exaggeration - Minimisation technique was...        [None]   \n",
       "3      [The input text does not employ the Exaggerati...        [None]   \n",
       "4      [The input text does not employ the Exaggerati...        [None]   \n",
       "...                                                  ...           ...   \n",
       "15486  [The input text does not contain any arguments...        [None]   \n",
       "15487  [The input text does not employ the Strawman t...        [None]   \n",
       "15488  [The input text does not demonstrate the Straw...        [None]   \n",
       "15489  [The input text does not contain any elements ...        [None]   \n",
       "15490  [The input text does not contain any arguments...        [None]   \n",
       "\n",
       "                                             source_file error status  split  \\\n",
       "0      data/llm_output/persuasion/explain/GPT_41_MINI...   NaN    NaN  train   \n",
       "1      data/llm_output/persuasion/explain/GPT_41_MINI...   NaN    NaN  train   \n",
       "2      data/llm_output/persuasion/explain/GPT_41_MINI...   NaN    NaN  train   \n",
       "3      data/llm_output/persuasion/explain/GPT_41_MINI...   NaN    NaN  train   \n",
       "4      data/llm_output/persuasion/explain/GPT_41_MINI...   NaN    NaN  train   \n",
       "...                                                  ...   ...    ...    ...   \n",
       "15486  data/llm_output/persuasion/explain/GPT_41/v001...   NaN    NaN  train   \n",
       "15487  data/llm_output/persuasion/explain/GPT_41/v001...   NaN    NaN  train   \n",
       "15488  data/llm_output/persuasion/explain/GPT_41/v001...   NaN    NaN  train   \n",
       "15489  data/llm_output/persuasion/explain/GPT_41/v001...   NaN    NaN  train   \n",
       "15490  data/llm_output/persuasion/explain/GPT_41/v001...   NaN    NaN  train   \n",
       "\n",
       "                                         expected_output  \n",
       "0      {\"description\": \"The input text does not conta...  \n",
       "1      {\"description\": \"The input text does not conta...  \n",
       "2      {\"description\": \"The Exaggeration - Minimisati...  \n",
       "3      {\"description\": \"The input text does not emplo...  \n",
       "4      {\"description\": \"The input text does not emplo...  \n",
       "...                                                  ...  \n",
       "15486  {\"description\": \"The input text does not conta...  \n",
       "15487  {\"description\": \"The input text does not emplo...  \n",
       "15488  {\"description\": \"The input text does not demon...  \n",
       "15489  {\"description\": \"The input text does not conta...  \n",
       "15490  {\"description\": \"The input text does not conta...  \n",
       "\n",
       "[15491 rows x 60 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os\n",
    "import json \n",
    "import numpy as np\n",
    "\n",
    "root = Path(\"data/llm_output/persuasion/explain\")\n",
    "# Example path template\n",
    "files = root.rglob(\"*/*.parquet\")\n",
    "\n",
    "# Read all files and add file path as a column\n",
    "df_list = []\n",
    "for f in files:\n",
    "    df_part = pd.read_parquet(f)\n",
    "    df_part['source_file'] = f  # add the file path\n",
    "    df_list.append(df_part)\n",
    "\n",
    "# Combine into one DataFrame\n",
    "df = pd.concat(df_list, ignore_index=True)\n",
    "df['split'] = df.source_file.astype(str).str.split('/',expand=True)[7]\n",
    "\n",
    "def safe_description(data):\n",
    "    if isinstance(data, (list,np.ndarray)):\n",
    "        return data[-1]\n",
    "    else:\n",
    "        return None  # or \"\", depending on what you prefer\n",
    "    \n",
    "df['expected_output'] = df.apply(lambda row: json.dumps({\n",
    "    'description': safe_description(row['explanation']),\n",
    "    'verdict': bool(row['gold'])\n",
    "}), axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3668470",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "filename",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "start",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "end",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "text_lang",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "text",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "label_bin",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "label_multi",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "base_split",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Questioning_the_Reputation",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Name_Calling-Labeling",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Appeal_to_Hypocrisy",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Conversation_Killer",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Loaded_Language",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Repetition",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Appeal_to_Popularity",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Doubt",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Red_Herring",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Flag_Waving",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Exaggeration-Minimisation",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Consequential_Oversimplification",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Appeal_to_Pity",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Appeal_to_Time",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Appeal_to_Values",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Obfuscation-Vagueness-Confusion",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Straw_Man",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Slogans",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Appeal_to_Fear-Prejudice",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Causal_Oversimplification",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Appeal_to_Authority",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "False_Dilemma-No_Choice",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Whataboutism",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "False_Equivalence",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Guilt_by_Association",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "alt_split",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "output_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "prompt_name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "prompt_version",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "job",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "step",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "max_iterations",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "temperature",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "model_provider",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "model_name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "model_mode",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "gold",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "gold_text",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "spans",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "extra_properties",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "is_valid",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "raw",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "updated_definition",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "think_content",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "illegal_value",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "explanation",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "extra_content",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "source_file",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "error",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "status",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "split",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "expected_output",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "b4d0b630-afa8-4532-a63f-be9b8b23e773",
       "rows": [
        [
         "11106",
         "pl_abortion_11_04_2024_n03.txt",
         "4168",
         "5204",
         "PL",
         "W latach 90., które już bardzo dobrze pamiętam,\nmiały miejsce kolejne próby zaostrzenia prawa\naborcyjnego. Najpierw efektem tego było prawo aborcyjne\noparte na czterech przesłankach, w tym przesłance\nekonomiczno-społecznej, a finalnie, po wyroku\nTrybunału Konstytucyjnego w 1997 r. zakończyło się to\nwprowadzeniem zakazu aborcji opartego na trzech\nwąskich przesłankach, dla niepoznaki i czystych\nsumień konserwatywnych polityków i duchownych\nKościoła katolickiego zwanego kompromisem aborcyjnym.\nNikt nie pytał wtedy kobiet o zdanie w sprawie\nplanowania rodziny, ochrony płodu ludzkiego i\nwarunków dopuszczalności przerywania ciąży – tak\nnazywała się ta ustawa. Nie pytano kobiet, bo ta ustawa\nbyła początkiem wymazywania kobiet z debaty o aborcji.\nCzęść polityków miała czyste ręce i czyste sumienia.\nPrawo zabraniało kobiecie przerywania ciąży,\nlekarze przestali wykonywać aborcję, ale tylko w\npublicznych szpitalach. Według rządowych statystyk\nciążę przerywało 600–1000 kobiet rocznie, a w rze-\nczywistości miała ją co trzecia Polka.",
         "True",
         "['Appeal_to_Hypocrisy' 'Loaded_Language' 'Questioning_the_Reputation'\n 'Appeal_to_Popularity' 'Repetition']",
         "train",
         "['ustawa była początkiem wymazywania kobiet z debaty o aborcji'\n 'Część polityków miała czyste ręce i czyste sumienia']",
         "[]",
         "['zakazu aborcji opartego na trzech wąskich przesłankach, dla niepoznaki i czystych sumień konserwatywnych polityków i duchownych Kościoła katolickiego zwanego kompromisem aborcyjnym']",
         "[]",
         "['wymazywania kobiet' 'wymazywania']",
         "['Nikt nie pytał wtedy kobiet' 'Nie pytano kobiet']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Hypocrisy",
         "Appeal_to_Hypocrisy",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "1",
         "Yes, the Appeal to Hypocrisy technique is used in the input.",
         "\"zakazu aborcji opartego na trzech wąskich przesłankach, dla niepoznaki i czystych sumień konserwatywnych polityków i duchownych Kościoła katolickiego zwanego kompromisem aborcyjnym\"",
         "[None]",
         "[False]",
         "['{\\n  \"explanation\": \"The Appeal to Hypocrisy technique is used in the input text by highlighting the inconsistency of conservative politicians and Catholic clergy who, while advocating for strict abortion laws, are described as having \\'czyste sumienia\\' (clean consciences). This implies that they are hypocritical for imposing restrictions on women\\'s rights while not considering their opinions, thus attacking their reputation by pointing out this hypocrisy.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/pl/train-pl-part_0000.parquet",
         null,
         null,
         "train",
         "{\"description\": null, \"verdict\": true}"
        ],
        [
         "11284",
         "SI_interpelation_interior_12.txt",
         "4448",
         "7979",
         "SI",
         "Najlepša hvala za besedo. Najprej hvala gospod minister za odgovor. Vi in vaši sodelavci ste se potrudili. Je pa res, da niste postregli s številkami, ki bi demantirale številke, ki smo jih predstavili poslanke in poslanci, ki smo se podpisali pod interpelacijo. V tem delu imate problem. Ampak pojdimo k številkam, kot sem rekla, ki ne lažejo. Brez patetike, brez in sumi insinuacij, kot je bilo danes rečeno, ampak prva trditev, gospod minister, policija dela dobro. Da, strinjam se z vami. Policistke in policisti na terenu delajo dobro, človek bi rekel, presenetljivo dobro glede na vodstvo policije, ki že dve leti to policijo razkraja. Hvaležna sem jim kot Novomeščanka, kajti ko je kjerkoli kaj narobe, posebno seveda v romskem naselju, o katerem bom govorila kasneje, so prvi na kraju policistke in policisti. Vendar, se opravičujem, še enkrat, bom prebrala najbolj pomembne številke, ki kažejo, gospod minister, da statistika, ki je popolnoma sveža letošnja in zajema tudi lansko obdobje kaže, da je v vašem obdobju se je zmanjšalo število odkritih kaznivih dejanj za 43,5 procentov. Torej vi ne morete vplivati verjetno ne na število kriminalcev, ki hodijo po naši državi, lahko pa vplivate na število odkritih kaznivih dejanj, torej z dobrim, učinkovitim vodenjem in s preventivnim delovanjem policije. Povečalo se je število kaznivih dejanj gospodarske kriminalitete za 18 procentov in mladoletniške za. 9,4, in tisto kar nas res boli in so nekateri, ki so ime, ki so pisali odzive poslanskih skupin slabo prebrali, našo interpelacijo, je porast kriminalitete v družinah, na področju nasilja v družini se je ta povečala za 18 procentov in pri odvzetih mladoletniških osebah, kar spet mislim na moje dolenjske mladoletne Rome, se je povečala za 65,7 procenta, ta kriminaliteta. Torej Slovenija je varna država, vendar je delo policije neučinkovito in če bo to delo trajalo še dolgo, hvala bogu, da ta Vlada ne bo zelo dolgo, bomo prišli res na zaskrbljujoče številke in nekaj o mladoletnikih, kar nas dejansko tudi skrbi, posebno v Novi Sloveniji in na kar smo dejansko opozarjali, da se je povečalo število nasilništva med mladoletniki. In ko smo vas prosili, spoštovana in draga koalicija, da ukrepate v zvezi z romsko problematiko, ste samo obljubljali, nekateri z gnusom zavrnili naše zakone in številke so vas vzele, izdale. Niste učinkoviti in nikoli ne boste vedeli kako učinkoviti bi bili, če bi pred enim letom in pol sprejeli zakone, ki so jih napisali župani. Takrat ste rekli, prav ena poslanka iz Svobode, da Vida Čadonič Špelič, njen župan in tudi ostali župani Dolenjske lažejo in zavajajo, številke govorijo drugače. Torej, spoštovani gospod minister, tisti, ki vam je pisal odgovore na našo interpelacijo je spregledal te številke. Drugo, rekli ste, da policija dela dobro, vendar ste v isti sapi povedali, da niste zadovoljni z delom CVZ. Spoštovani minister, saj vi ja dobro veste, da je CVZ del policije. In zdaj, ko se pogovarjamo o CVZ je prav, da povemo nekaj, česar se verjetno poslanke in poslanci ne zavedamo. Tudi policistke in policisti, ki so del naše službe, našega varovanja tukaj, ki nas tako prijetno pozdravijo, ko vstopimo v ta Državni zbor in najbolj prijetno je, ko zvečer pozno odhajajo, nam pomahajo v slovo in zaželijo srečno pot. Tudi oni so del CVZ, ne, oni ne delajo slabo, vsi ne delajo slabo. Dela pa slabo očitno vodstvo CVZ, ki ga vaš direktor, zdaj že bivši, ki je častno odstopil, ni uspel urediti. Šele danes ali včeraj, kdaj je to bilo, je tudi CVZ dobila novo vodstvo.",
         "True",
         "['Consequential_Oversimplification' 'Exaggeration-Minimisation'\n 'Loaded_Language' 'Appeal_to_Hypocrisy' 'Appeal_to_Pity'\n 'Appeal_to_Authority' 'Questioning_the_Reputation'\n 'False_Dilemma-No_Choice' 'Red_Herring' 'Repetition' 'Doubt'\n 'Appeal_to_Fear-Prejudice']",
         "train",
         "['tisti, ki vam je pisal odgovore na našo interpelacijo je spregledal te številke']",
         "[]",
         "['Drugo, rekli ste, da policija dela dobro, vendar ste v isti sapi povedali, da niste zadovoljni z delom CVZ']",
         "[]",
         "['posebno seveda v romskem naselju'\n 'kriminalcev, ki hodijo po naši državi' 'moje dolenjske mladoletne Rome'\n 'gnusom']",
         "['k številkam, kot sem rekla, ki ne lažejo' 'številke' 'številke'\n 'vsi ne delajo slabo']",
         "[]",
         "['Policistke in policisti na terenu delajo dobro, človek bi rekel, presenetljivo dobro glede na vodstvo policije, ki že dve leti to policijo razkraja'\n 'Niste učinkoviti in nikoli ne boste vedeli kako učinkoviti bi bili, če bi pred enim letom in pol sprejeli zakone, ki so jih napisali župani']",
         "['kot Novomeščanka'\n 'Tudi policistke in policisti, ki so del naše službe, našega varovanja tukaj, ki nas tako prijetno pozdravijo, ko vstopimo v ta Državni zbor in najbolj prijetno je, ko zvečer pozno odhajajo, nam pomahajo v slovo in zaželijo srečno pot']",
         "[]",
         "['Niste učinkoviti in nikoli ne boste vedeli kako učinkoviti bi bili']",
         "['vendar je delo policije neučinkovito in če bo to delo trajalo še dolgo, hvala bogu, da ta Vlada ne bo zelo dolgo, bomo prišli res na zaskrbljujoče številke']",
         "['Hvaležna sem jim kot Novomeščanka'\n 'Tudi policistke in policisti, ki so del naše službe, našega varovanja tukaj, ki nas tako prijetno pozdravijo, ko vstopimo v ta Državni zbor in najbolj prijetno je, ko zvečer pozno odhajajo, nam pomahajo v slovo in zaželijo srečno pot']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Povečalo se je število kaznivih dejanj gospodarske kriminalitete za 18 procentov in mladoletniške za. 9,4, in tisto kar nas res boli in so nekateri, ki so ime, ki so pisali odzive poslanskih skupin slabo prebrali, našo interpelacijo, je porast kriminalitete v družinah, na področju nasilja v družini se je ta povečala za 18 procentov in pri odvzetih mladoletniških osebah, kar spet mislim na moje dolenjske mladoletne Rome, se je povečala za 65,7 procenta, ta kriminaliteta'\n 'Torej Slovenija je varna država, vendar je delo policije neučinkovito in če bo to delo trajalo še dolgo, hvala bogu, da ta Vlada ne bo zelo dolgo, bomo prišli res na zaskrbljujoče številke in nekaj o mladoletnikih, kar nas dejansko tudi skrbi, posebno v Novi Sloveniji in na kar smo dejansko opozarjali, da se je povečalo število nasilništva med mladoletniki']",
         "[]",
         "['k številkam, kot sem rekla, ki ne lažejo'\n 'Hvaležna sem jim kot Novomeščanka, kajti ko je kjerkoli kaj narobe, posebno seveda v romskem naselju, o katerem bom govorila kasneje, so prvi na kraju policistke in policisti'\n 'številke so vas vzele, izdale']",
         "['Niste učinkoviti in nikoli ne boste vedeli kako učinkoviti bi bili, če bi pred enim letom in pol sprejeli zakone, ki so jih napisali župani']",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Hypocrisy",
         "Appeal_to_Hypocrisy",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "1",
         "Yes, the Appeal to Hypocrisy technique is used in the input.",
         "\"Drugo, rekli ste, da policija dela dobro, vendar ste v isti sapi povedali, da niste zadovoljni z delom CVZ\"",
         "[None]",
         "[False]",
         "['{\\n  \"explanation\": \"The Appeal to Hypocrisy technique is used in the input text when the speaker points out the contradiction in the minister\\'s statements. The minister claims that the police are doing well, yet simultaneously expresses dissatisfaction with the work of CVZ, which is part of the police. This highlights the inconsistency in the minister\\'s position, effectively attacking his credibility by showing hypocrisy.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/si/train-si-part_0004.parquet",
         null,
         null,
         "train",
         "{\"description\": null, \"verdict\": true}"
        ],
        [
         "11292",
         "SI_interpelation_interior_7.txt",
         "2598",
         "5288",
         "SI",
         "Policisti prav tako dobijo navodila, naj ne spoštujejo zakonov, kajti policisti, ko primejo osebo, ki je ilegalno vstopila v Slovenijo, so dolžni preveriti vse okoliščine takega dejanja in morajo osebi zavrniti vstop v državo, če za to obstajajo zakoniti razlogi. Če je dejansko nesporno, da je oseba ilegalno vstopila v Slovenijo iz Hrvaške, ki je varna država, mora policist tako osebo vrniti v državo iz katere je prišla, torej s sosednjo Hrvaško. Tega policisti več ne preverjajo, kot so to prej, ampak postanejo le še zgolj taksisti, ki na državne stroške ilegalne migrante prevažajo v azilni dom v Ljubljano. Ti po nekaj dnevih azilni dom zapustijo, in če jih policisti na poti proti Avstriji ali Italiji ustavijo, imajo nalogo, da jim ponudijo ponovno možnost podajo vloge za azil ali mednarodno zaščito in ponovno nastanitev v azilnem domu, česar pa prej ni bilo. Taka navodila policistom seveda preprečujejo ostalo zakonodajo, delati ostalo zakonodajo, kar prav tako doprinaša k razpadanju sistema delovanja policije. V času bivanja v Sloveniji, se nekateri ilegalni migranti prosto gibajo po glavnem mestu in povzročajo številna kazniva dejanja, kradejo, napadajo policiste in paznike, ki jih pri tem zalotijo, posiljujejo, prekupčujejo z drogo in se pretepajo. Včasih katerega najdejo tudi utopljenega v Ljubljanici, med tem policija zadevo prikriva. Namesto ustreznega ukrepanja policija na podhodu železniške postaje v Ljubljani namesti nalepke z napisom: Če ste sami žrtev spolnega napada ali veste za ta primer, ga takoj prijavite policiji in ljudem svetuje, seveda mora biti žrtev posilstva, naj poskušajo s storilcem, naj se poskušajo s storilcem pogovoriti in vzbuditi občutek razumevanja ter sočutja. Zelo zanimivo. Ljudi, predvsem pa žensk, je ponoči strah hoditi po Ljubljani. Prodaja solzivcev se v Ljubljani poveča za kar 1000 odstotkov. Katastrofalne postanejo razmere tudi v centru za varnost in zaščito. Na to javnost opozori tožilka Mateja Gončin, ki se izpove o številnih nepravilnostih, zlorabah in celo naklepnih kaznivih dejanjih varnostnikov, zlasti pa vodstva omenjenega centra pri njenem varovanju. Prav tako naj bi varnostniki celo zbirali podatke o naši predsednici Državnega zbora zaradi morebitne kasnejše diskreditacije, iz Civilne centra za varstvo in zaščito naj bi informacije tudi odtekale kriminalcem. Čeprav je z nepravilnostmi večkrat seznanila tako nezakonitega generalnega direktorja policije Jušića, kot notranjega ministra Poklukarja, se na tem področju ni zgodilo nič. V CVZ se tudi nadpovprečno obremenjuje varnostnike, ki tudi več dni zaporedoma nimajo zagotovljenega minimalnega dnevnega počitka, nepravilno se obračunavajo delovne ure.",
         "True",
         "['Consequential_Oversimplification' 'Exaggeration-Minimisation'\n 'Loaded_Language' 'Appeal_to_Hypocrisy' 'Appeal_to_Pity'\n 'Questioning_the_Reputation' 'Appeal_to_Authority' 'Red_Herring' 'Doubt'\n 'Appeal_to_Fear-Prejudice']",
         "train",
         "['Taka navodila policistom seveda preprečujejo ostalo zakonodajo, delati ostalo zakonodajo, kar prav tako doprinaša k razpadanju sistema delovanja policije']",
         "[]",
         "['Čeprav je z nepravilnostmi večkrat seznanila tako nezakonitega generalnega direktorja policije Jušića, kot notranjega ministra Poklukarja, se na tem področju ni zgodilo nič']",
         "[]",
         "['le še zgolj taksisti' 'državne stroške']",
         "[]",
         "[]",
         "['Policisti prav tako dobijo navodila, naj ne spoštujejo zakonov'\n 'Včasih katerega najdejo tudi utopljenega v Ljubljanici, med tem policija zadevo prikriva']",
         "['V CVZ se tudi nadpovprečno obremenjuje varnostnike, ki tudi več dni zaporedoma nimajo zagotovljenega minimalnega dnevnega počitka, nepravilno se obračunavajo delovne ure']",
         "[]",
         "['številna kazniva dejanja'\n 'Katastrofalne postanejo razmere tudi v centru za varnost in zaščito']",
         "['Namesto ustreznega ukrepanja policija na podhodu železniške postaje v Ljubljani namesti nalepke z napisom: Če ste sami žrtev spolnega napada ali veste za ta primer, ga takoj prijavite policiji in ljudem svetuje, seveda mora biti žrtev posilstva, naj poskušajo s storilcem, naj se poskušajo s storilcem pogovoriti in vzbuditi občutek razumevanja ter sočutja'\n 'Prodaja solzivcev se v Ljubljani poveča za kar 1000 odstotkov']",
         "['nadpovprečno obremenjuje varnostnike, ki tudi več dni zaporedoma nimajo zagotovljenega minimalnega dnevnega počitka']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['V času bivanja v Sloveniji, se nekateri ilegalni migranti prosto gibajo po glavnem mestu in povzročajo številna kazniva dejanja, kradejo, napadajo policiste in paznike, ki jih pri tem zalotijo, posiljujejo, prekupčujejo z drogo in se pretepajo'\n 'Ljudi, predvsem pa žensk, je ponoči strah hoditi po Ljubljani'\n 'Prav tako naj bi varnostniki celo zbirali podatke o naši predsednici Državnega zbora zaradi morebitne kasnejše diskreditacije, iz Civilne centra za varstvo in zaščito naj bi informacije tudi odtekale kriminalcem']",
         "[]",
         "['tožilka Mateja Gončin']",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Hypocrisy",
         "Appeal_to_Hypocrisy",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "1",
         "Yes, the Appeal to Hypocrisy technique is used in the input.",
         "\"Čeprav je z nepravilnostmi večkrat seznanila tako nezakonitega generalnega direktorja policije Jušića, kot notranjega ministra Poklukarja, se na tem področju ni zgodilo nič\"",
         "[None]",
         "[False]",
         "['{\\n  \"explanation\": \"The Appeal to Hypocrisy technique is used in the input text by highlighting the inaction of the general director of police and the interior minister despite being informed of irregularities. This implies hypocrisy, as they are expected to uphold the law and address issues but fail to do so, thus attacking their reputation for inconsistency.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/si/train-si-part_0004.parquet",
         null,
         null,
         "train",
         "{\"description\": null, \"verdict\": true}"
        ],
        [
         "11310",
         "SI_interpelation_interior_7.txt",
         "839",
         "2596",
         "SI",
         "Naslednji primer: žena pomočnika generalnega direktorja policije, ki na policiji opravlja piar službo, se prevaža s protokolarnim vozilom, ki je namenjeno za prevoze varovanih oseb in ne uslužbencev policije. Ko policijska voznica v poročilu navede, koga je prevažala, mora po navodilu pomočnika generalnega direktorja policije, ki je mož te osebe, poročilo popraviti. Prav tako je kasneje s strani vodstva šikanirana. Namestnik generalnega direktorja policije, torej mož piarovke, si za službeno vozilo prilasti novo toyoto, ostalim pa v uporabo nameni stara vozila. Zoper svetovalca generalnega direktorja, zdaj že bivšega generalnega direktorja za področje gospodarske in korupcijske kriminalitete, bi pa naj bilo podanih kar več kaznivih ovadb. Da je stanje v policiji slabo, dokazuje tudi poročilo iz prvega polletja leta 2023, iz katerega je razvidno, da se je število kaznivih dejanj znatno povečalo, število preiskanosti in odkritosti z lastno dejavnostjo pa znatno zmanjšalo. Povečala se je uporaba prisilnih sredstev in izdanih plačilnih nalogov, število opozoril se je zmanjšalo, prav tako se v deželici z imenom Slovenija v časih golobistov prične na meji odstranjevati ograja. S tem se ilegalnim migrantom sporoči, da je prehod preko Slovenije lažji, zato se prične znatno povečevati število ilegalnih prehodov meje. Migranti se tako množično gibajo po naseljih ob hrvaški meji, kar povzročajo, povzroča strah in nelagodje tamkajšnjim prebivalcem. Število je že tako veliko, da kapacitete v azilnih domovih več ne zadoščajo, zato vlada sklene, da bo v Obrežju in v Središču ob Dravi uredila izpostave azilnega doma, ne da bi se o tem predhodno posvetovala z lokalno skupnostjo. To seveda povzroči nestrinjanje in upor tamkajšnjega prebivalstva.",
         "True",
         "['Causal_Oversimplification' 'Exaggeration-Minimisation'\n 'Appeal_to_Hypocrisy' 'Loaded_Language' 'Appeal_to_Pity'\n 'Obfuscation-Vagueness-Confusion' 'Questioning_the_Reputation'\n 'Name_Calling-Labeling' 'Doubt' 'Repetition' 'Appeal_to_Fear-Prejudice']",
         "train",
         "['mora po navodilu pomočnika generalnega direktorja policije, ki je mož te osebe, poročilo popraviti']",
         "['golobistov']",
         "['žena pomočnika generalnega direktorja policije, ki na policiji opravlja piar službo, se prevaža s protokolarnim vozilom, ki je namenjeno za prevoze varovanih oseb in ne uslužbencev policije'\n 'Namestnik generalnega direktorja policije, torej mož piarovke, si za službeno vozilo prilasti novo toyoto, ostalim pa v uporabo nameni stara vozila'\n 'Zoper svetovalca generalnega direktorja, zdaj že bivšega generalnega direktorja za področje gospodarske in korupcijske kriminalitete, bi pa naj bilo podanih kar več kaznivih ovadb']",
         "[]",
         "['šikanirana' 'ilegalnim migrantom']",
         "['golobistov']",
         "[]",
         "['s strani vodstva šikanirana']",
         "[]",
         "[]",
         "['stara vozila' 'množično gibajo po naseljih ob hrvaški meji']",
         "[]",
         "['s strani vodstva šikanirana']",
         "[]",
         "[]",
         "['prisilnih sredstev']",
         "[]",
         "[]",
         "['zato se prične znatno povečevati število ilegalnih prehodov meje'\n 'Migranti se tako množično gibajo po naseljih ob hrvaški meji, kar povzročajo, povzroča strah in nelagodje tamkajšnjim prebivalcem']",
         "['S tem se ilegalnim migrantom sporoči, da je prehod preko Slovenije lažji, zato se prične znatno povečevati število ilegalnih prehodov meje']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Hypocrisy",
         "Appeal_to_Hypocrisy",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "1",
         "Yes, the Appeal to Hypocrisy technique is used in the input.",
         "\"žena pomočnika generalnega direktorja policije, ki na policiji opravlja piar službo, se prevaža s protokolarnim vozilom, ki je namenjeno za prevoze varovanih oseb in ne uslužbencev policije Namestnik generalnega direktorja policije, torej mož piarovke, si za službeno vozilo prilasti novo toyoto, ostalim pa v uporabo nameni stara vozila Zoper svetovalca generalnega direktorja, zdaj že bivšega generalnega direktorja za področje gospodarske in korupcijske kriminalitete, bi pa naj bilo podanih kar več kaznivih ovadb\"",
         "[None]",
         "[False]",
         "['{\\n  \"explanation\": \"The Appeal to Hypocrisy technique is used in the input text by highlighting the inconsistency in the actions of the deputy director of the police and his wife, who is in a public relations role. The text points out that while she uses a vehicle meant for protected individuals, her husband, the deputy director, appropriates a new vehicle for himself while providing older vehicles to others. This contradiction illustrates hypocrisy in their actions, as they are in positions of authority yet act in self-serving ways, which undermines their credibility.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/si/train-si-part_0006.parquet",
         null,
         null,
         "train",
         "{\"description\": null, \"verdict\": true}"
        ],
        [
         "11317",
         "SI_interpelation_interior_6.txt",
         "270",
         "7305",
         "SI",
         "Na eni izmed sej Odbora za notranje zadeve mi je predsednica odbora dejala, da sem pravljičar, zato mi spoštovani kolegi in kolegice dovolite, da vam v imenu Poslanske skupine Slovenske demokratske stranke povem zgodbo, ki morda ni pravljica in se glasi takole. Tam, na sončni strani Alp, so v deželici z imenom Slovenija nedolgo nazaj vladali janšisti. Prišel je čas volitev in oblast so prevzeli golobisti. Tik pred prevzemom oblasti njihov vodja k sebi pokliče novo ministrico za notranje zadeve in novega vršilca dolžnosti generalnega direktorja policije in jima naroči: Imata eno samo nalogo in to je, da policijo očistita janšistov. Oba vestno pričneta z opravljanjem ukazane naloge in na vodilnih položajih policije zamenjujeta osebe, ki naj bi bili janšisti. Še posebej direktorja, tam na mojem koncu, kot je dejal njihov vodja, in direktor Nacionalnega preiskovalnega urada, kajti prav ta urad preiskuje vodjo golobistov, zaradi ukradene identitete v Romuniji in kup denarja na tamkajšnjem računu, nakazila novinarki Vesni Vuković za neznane usluge in balkanskim poslovanjem denarja. Pri svojem delu pa naletita na težavo, kdo je janšist in kdo ne, saj so določene osebe, menita, da zamenjava ni potrebna. To povzroči nezadovoljstvo pri vodji in zato vršilca dolžnosti generalnega direktorja policije vrže čez ramo in ga noče imenovati za generalnega direktorja policije. Temu se ministrica upre in odstopi. Praznino v vodenju notranjega ministrstva izkoristi človek iz ozadja, ki sicer deluje na drugem ministrstvu in vodji predlaga osebo, ki bo pa poslušna. In tako minister za notranje zadeve postane Boštjan Poklukar. No, in novi minister Boštjan Poklukar prične z delom, seveda s poslušnim delom. Najprej o tem, kako naj bi delovalo policija in ministrstvo sicer ne posvetuje z ustreznimi strokovnjaki, ampak pogovor opravi z Jašo Jenulom, torej osebo, ki je bila v času vodenja janšistov večkrat kaznovana, ker je pozival k neprijavljenim protestom. Nato kljub temu, da je znotraj policije na desetine visoko izobraženih ter usposobljenih kadrov, na željo vodje golobistov za vršilca dolžnosti generalnega direktorja policije imenuje Senada Jušića, ki seveda nima vodstvenih izkušenj, saj je v preteklosti deloval zgolj kot pomočnik vodje na lokalnem nivoju. Imenovanje za vršilca dolžnosti generalnega direktorja policije pa naj bi bilo celo nezakonito, saj se ob njegovi premestitvi ne bi opravilo varnostno preverjanje, kar je sicer vedno obvezno o premestitvi na višje delovno mesto. Senad Jušić je tako nezakonito imenovan kasneje za generalnega direktorja Policije, saj Uradniški svet pri sklepu o izpolnitvi pogojev upošteva neke interne akte policije in za to poda tudi pomanjkljivo obrazložitev, ker seveda nimajo kaj obrazložiti. Ker bivši vršilec dolžnosti generalnega direktorja policije to ve, poda tožbo na Upravno sodišče, ki seveda razsodi, da je sklep natečajne komisije nezakonit, tako da je tudi imenovanje Senada Jušića za generalnega direktorja Policije nezakonito. Vodja golobistov, generalni direktor Policije, kakor tudi minister Poklukar se sprenevedajo, zanemarjajo sistem pravne države in ne spoštujejo sodbe. Jušića varujejo pred očitki, tako daleč, da se mora v to dogajanje vključiti sam striček iz ozadja in po 83 dneh Senad Jušić odstopi. Seveda v času vodenja policije s strani Senada Jušića postajajo razmere na policiji iz dneva v dan bolj kritične in dosežejo najnižjo točko v sistem delovanja policije v zgodovini Slovenije. Nestrokovni vodje svojo nestrokovnost prenašajo na policiste in policiste. Na njih izvajajo pritiske. Policisti in policistke več ne vedo kako naj delajo, kako naj postopajo, da bo prav in da zoper njih ne bodo uvedene sankcije. Strah jih je, delajo več nadur in tako dalje. Tako se policisti raje umaknejo, kot bi posredovali v eni izmed garažnih hiš v Ljubljani, kjer so policijsko patruljo ob posredovanju obkrožili zbrani mladostniki in preprečevali vožnjo. Policista se z vozilom umakneta. Prav tako se v Ljubljani zbere množica ljudi, ki z avtomobili hupa, drifta s strelnim orožjem strelja v zrak in na eno izmed policijskih vozil celo namesti albansko zastavo. Na jugovzhodnem delu te deželice se pojavijo težave, saj policija ni več kos kaznivim dejanjem, tamkajšnjim živečim Romom, ki kršijo prometne predpise, izvajajo tatvine, ustrahujejo, pretepajo, uporabljajo strelno orožje in tako dalje. Slovenija postane tudi raj za hudodelske združbe, ki med sabo obračunavajo kar sredi dneva, izvajajo likvidacije, umore, in to kar pred očmi otrok. Prav tako umorijo skesanca, ki ga policija ne zaščiti kljub opozorilom o njegovi likvidaciji. V priljubljenem velenjskem lokalu ob pretepu poseduje lastnik tega lokala, ki pa je med najbolj iskanimi osebami v Evropi na Interpolovi tiralici, zaradi sodelovanja v kriminalni združbi v Bosni in Hercegovini. Kljub obsodbi na leto in pol zapora brez težav torej opravlja ta lokal, se svobodno giba po Sloveniji, saj ga policija ne aretira. Varnost v državi se iz leta v leto slabša, kar dokazuje podatek globalnega indeksa miru, ker je Slovenija iz četrtega mesta v letu 2020 v lanskem letu 2024 zdrsnila na deveto mesto. Policisti in policistke tako množično zapuščajo policijske vrste: bodisi se upokojijo ali pa si poiščejo boljšo zaposlitev in podajo odpoved. Novih zaposlitev ni. Zdesetkana, policija ne zmore več opravljati nalog, ki jih je dolžna izvajati. V času janšistov, torej v letu 2020 in 2021 je bilo kar 164 odstotkov več prihodov kot odhodov. V času golobistov, v letu 2022 in vaju 24 je pa bilo 60 odstotkov več. Torej, manj prihodov kot odhodov. Od tega v času ministrovanja Boštjana Poklukarja, torej v letu 23 in 24 za 51 odstotkov manj prihodov kot odhodov. Kljub temu, da je denarja v davčni blagajni rekordno veliko se za promocijo poklica policist, policijska ne namenjajo namenska finančna sredstva, ki bi imela v proračunu svojo postavko, kot jo ima to na primer vojska. Poslabšanje organizacijske klime v policiji dokazuje tudi raziskava odbora za integriteto in etiko v policiji, saj so se rezultati pod vodstvom Boštjana Poklukarja znatno poslabšali. Medtem se v vodstvenih vrstah izvajajo različne mahinacije, kot so naslednji; minister Poklukar podpiše novo sistemizacijo delovnih mest na Policijski upravi Maribor, kjer se omogoči zaposlitev izbrane osebe za pomočnika direktorja Policijske uprave. Njihovo namero na žalost tik pred iztekom roka razpise prekine poslanec iz naše poslanske skupine, ki na to temo poda pisno poslansko vprašanje. Tako v istem dnevu razpis prekličejo, zamenjajo priloge te sistemizacije in razpišejo novo delovno mesto, in sicer za policijskega svetnika na Policijski upravi. Ta oseba se na ta razpis prijavi in se tudi zaposli. V odgovoru na pisno poslansko vprašanje poslanca naše poslanske skupine se pa minister zlaže, da je zaposlitev policijskega svetnika na PU Maribor potrebna zaradi povečanega števila kaznivih dejanj Romov iz Hrvaške na območju Policijske postaje Ormož in Gorišnica in zaradi povečanega števila migracij na tem območju.",
         "True",
         "['Loaded_Language' 'Obfuscation-Vagueness-Confusion'\n 'Name_Calling-Labeling' 'Red_Herring' 'Guilt_by_Association' 'Doubt'\n 'Causal_Oversimplification' 'Exaggeration-Minimisation'\n 'Questioning_the_Reputation' 'Appeal_to_Authority' 'Appeal_to_Values'\n 'False_Dilemma-No_Choice' 'Repetition' 'Appeal_to_Fear-Prejudice']",
         "train",
         "['Še posebej direktorja, tam na mojem koncu, kot je dejal njihov vodja, in direktor Nacionalnega preiskovalnega urada, kajti prav ta urad preiskuje vodjo golobistov, zaradi ukradene identitete v Romuniji in kup denarja na tamkajšnjem računu, nakazila novinarki Vesni Vuković za neznane usluge in balkanskim poslovanjem denarja'\n 'Praznino v vodenju notranjega ministrstva izkoristi človek iz ozadja, ki sicer deluje na drugem ministrstvu in vodji predlaga osebo, ki bo pa poslušna'\n 'minister zlaže']",
         "['golobisti' 'janšistov' 'janšisti' 'janšistov' 'golobistov' 'golobistov'\n 'janšistov' 'golobistov']",
         "[]",
         "[]",
         "['janšisti' 'golobisti' 'janšist' 'vrže čez ramo' 'striček iz ozadja'\n 'deželice' 'hudodelske združbe' 'Zdesetkana' 'mahinacije']",
         "['janšisti' 'janšist' 'janšistov' 'golobistov' 'nezakonito' 'golobistov'\n 'janšistov' 'golobistov']",
         "[]",
         "['seveda s poslušnim delom'\n 'Nato kljub temu, da je znotraj policije na desetine visoko izobraženih ter usposobljenih kadrov, na željo vodje golobistov za vršilca dolžnosti generalnega direktorja policije imenuje Senada Jušića, ki seveda nima vodstvenih izkušenj, saj je v preteklosti deloval zgolj kot pomočnik vodje na lokalnem nivoju'\n 'Senad Jušić je tako nezakonito imenovan kasneje za generalnega direktorja Policije']",
         "['Na eni izmed sej Odbora za notranje zadeve mi je predsednica odbora dejala, da sem pravljičar, zato mi spoštovani kolegi in kolegice dovolite, da vam v imenu Poslanske skupine Slovenske demokratske stranke povem zgodbo, ki morda ni pravljica in se glasi takole'\n 'Tam, na sončni strani Alp, so v deželici z imenom Slovenija nedolgo nazaj vladali janšisti. Prišel je čas volitev in oblast so prevzeli golobisti. Tik pred prevzemom oblasti njihov vodja k sebi pokliče novo ministrico za notranje zadeve in novega vršilca dolžnosti generalnega direktorja policije in jima naroči: Imata eno samo nalogo in to je, da policijo očistita janšistov'\n 'Oba vestno pričneta z opravljanjem ukazane naloge in na vodilnih položajih policije zamenjujeta osebe, ki naj bi bili janšisti. Še posebej direktorja, tam na mojem koncu, kot je dejal njihov vodja, in direktor Nacionalnega preiskovalnega urada, kajti prav ta urad preiskuje vodjo golobistov, zaradi ukradene identitete v Romuniji in kup denarja na tamkajšnjem računu, nakazila novinarki Vesni Vuković za neznane usluge in balkanskim poslovanjem denarja. Pri svojem delu pa naletita na težavo, kdo je janšist in kdo ne, saj so določene osebe, menita, da zamenjava ni potrebna. To povzroči nezadovoljstvo pri vodji in zato vršilca dolžnosti generalnega direktorja policije vrže čez ramo in ga noče imenovati za generalnega direktorja policije. Temu se ministrica upre in odstopi. Praznino v vodenju notranjega ministrstva izkoristi človek iz ozadja, ki sicer deluje na drugem ministrstvu in vodji predlaga osebo, ki bo pa poslušna']",
         "[]",
         "['eno samo nalogo' 'zgolj kot pomočnik vodje na lokalnem nivoju'\n 'iz dneva v dan bolj kritične in dosežejo najnižjo točko v sistem delovanja policije v zgodovini Slovenije'\n 'Slovenija postane tudi raj za hudodelske združbe, ki med sabo obračunavajo kar sredi dneva, izvajajo likvidacije, umore, in to kar pred očmi otrok'\n 'najbolj iskanimi osebami v Evropi na Interpolovi tiralici' 'množično'\n 'V času janšistov, torej v letu 2020 in 2021 je bilo kar 164 odstotkov več prihodov kot odhodov'\n 'rekordno veliko' 'znatno poslabšali']",
         "[]",
         "[]",
         "[]",
         "['nezakonito' 'nezakonito'\n 'Vodja golobistov, generalni direktor Policije, kakor tudi minister Poklukar se sprenevedajo, zanemarjajo sistem pravne države in ne spoštujejo sodbe'\n 'Nestrokovni vodje svojo nestrokovnost prenašajo na policiste in policiste']",
         "['človek iz ozadja' 'neke interne akte policije' 'uvedene sankcije']",
         "[]",
         "[]",
         "['očistita janšistov'\n 'Nestrokovni vodje svojo nestrokovnost prenašajo na policiste in policiste. Na njih izvajajo pritiske'\n 'Policisti in policistke več ne vedo kako naj delajo, kako naj postopajo, da bo prav in da zoper njih ne bodo uvedene sankcije. Strah jih je, delajo več nadur in tako dalje'\n 'Prav tako se v Ljubljani zbere množica ljudi, ki z avtomobili hupa, drifta s strelnim orožjem strelja v zrak in na eno izmed policijskih vozil celo namesti albansko zastavo'\n 'Na jugovzhodnem delu te deželice se pojavijo težave, saj policija ni več kos kaznivim dejanjem, tamkajšnjim živečim Romom, ki kršijo prometne predpise, izvajajo tatvine, ustrahujejo, pretepajo, uporabljajo strelno orožje in tako dalje'\n 'Slovenija postane tudi raj za hudodelske združbe, ki med sabo obračunavajo kar sredi dneva, izvajajo likvidacije, umore, in to kar pred očmi otrok'\n 'Prav tako umorijo skesanca, ki ga policija ne zaščiti kljub opozorilom o njegovi likvidaciji'\n 'V priljubljenem velenjskem lokalu ob pretepu poseduje lastnik tega lokala, ki pa je med najbolj iskanimi osebami v Evropi na Interpolovi tiralici, zaradi sodelovanja v kriminalni združbi v Bosni in Hercegovini'\n 'Kljub obsodbi na leto in pol zapora brez težav torej opravlja ta lokal, se svobodno giba po Sloveniji, saj ga policija ne aretira'\n 'povečanega števila kaznivih dejanj Romov']",
         "['Varnost v državi se iz leta v leto slabša, kar dokazuje podatek globalnega indeksa miru, ker je Slovenija iz četrtega mesta v letu 2020 v lanskem letu 2024 zdrsnila na deveto mesto'\n 'Od tega v času ministrovanja Boštjana Poklukarja, torej v letu 23 in 24 za 51 odstotkov manj prihodov kot odhodov']",
         "['Nato kljub temu, da je znotraj policije na desetine visoko izobraženih ter usposobljenih kadrov'\n 'odbora za integriteto in etiko v policiji']",
         "['bodisi se upokojijo ali pa si poiščejo boljšo zaposlitev in podajo odpoved']",
         "[]",
         "[]",
         "['sicer ne posvetuje z ustreznimi strokovnjaki, ampak pogovor opravi z Jašo Jenulom, torej osebo, ki je bila v času vodenja janšistov večkrat kaznovana, ker je pozival k neprijavljenim protestom']",
         "train",
         "GPT_41/v001/Appeal_to_Hypocrisy",
         "Appeal_to_Hypocrisy",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Appeal to Hypocrisy technique is not used in the input.",
         "\"\"",
         "[None]",
         "[False]",
         "['{\\n  \"explanation\": \"The input text does not contain any explicit or implicit attacks on the reputation of a target by charging them with hypocrisy or inconsistency. There are no instances where the speaker calls out hypocrisy directly or highlights contradictions between different positions or actions. Therefore, the Appeal to Hypocrisy technique is not used.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/si/train-si-part_0006.parquet",
         null,
         null,
         "train",
         "{\"description\": null, \"verdict\": false}"
        ],
        [
         "11339",
         "SI_interpelation_interior_11.txt",
         "2427",
         "2780",
         "SI",
         "Vse te stvari bomo uredili s sprejetjem novele Zakona o nalogah in pooblastilih policije, ki bo bolje urejala ukrep prepovedi približevanja. To so in bi morale biti družbene prioritete, ki bi si zaslužile obravnavo na sejah teles parlamenta, ne pa razne tendencioznosti, temelječe na napihovanju bojda slabe varnostne situacije, kot sem opisala uvodoma.",
         "True",
         "['Consequential_Oversimplification' 'Loaded_Language' 'Appeal_to_Values'\n 'Red_Herring']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "['tendencioznosti, temelječe na napihovanju bojda slabe varnostne situacije']",
         "[]",
         "[]",
         "[]",
         "['Vse te stvari bomo uredili s sprejetjem novele Zakona o nalogah in pooblastilih policije, ki bo bolje urejala ukrep prepovedi približevanja']",
         "[]",
         "[]",
         "['Vse te stvari bomo uredili s sprejetjem novele Zakona o nalogah in pooblastilih policije, ki bo bolje urejala ukrep prepovedi približevanja']",
         "[]",
         "[]",
         "['To so in bi morale biti družbene prioritete']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Hypocrisy",
         "Appeal_to_Hypocrisy",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Appeal to Hypocrisy technique is not used in the input.",
         "\"\"",
         "[None]",
         "[False]",
         "['{\\n  \"explanation\": \"The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. There are no explicit or implicit references to contradictions between positions or actions, which is essential for the Appeal to Hypocrisy technique.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/si/train-si-part_0000.parquet",
         null,
         null,
         "train",
         "{\"description\": null, \"verdict\": false}"
        ],
        [
         "11342",
         "SI_interpelation_interior_1.txt",
         "0",
         "1089",
         "SI",
         "Tožilka se je zaradi nezaupanja v policijo varovanju odpovedala, saj je posumila, da je prišlo do nezakonitega vpogleda v nadzorno kamero, nameščeno na njeni hiši. Naj spomnim na znameniti stavek predsednika Vlade: \"Namesto, da bi bila varovana, je bila nadzorovana.\" Javno je priznal napake generalnega direktorja policije in ministra Poklukarja, toda ni ukrepal. In pri odstopu gospoda Jušića sta oba, tako predsednik vlade kot minister Poklukar, rekla, da je Jušić delal dobro in da je njegov odstop časten. Kaj je častnega v takšnem delu, kot sem ga zdaj predstavila? Na SVZ so razmere še zdaj nerešene in pred kratkim smo slišali, da mnenje, ali je potrebno ali ni potrebno varovanje tožilke in ostalih, ki delajo v pravnem sistemu, menjajo na SVZ hitreje kot mnenja, mnenje predsednik Vlade oziroma stališče o recimo omrežninah. Saj veste, v parih urah so rekli, da, potem pa ne. In kaj smo danes slišali? Da je bila v obdobju, ko SVZ ni varoval tožilke Gončinove, velika verjetnost, da je bil v Sloveniji morilec Satka Zovka, tako imenovani Cezar. In hvala bogu, tožilka je še živa.",
         "True",
         "['Appeal_to_Hypocrisy' 'Questioning_the_Reputation'\n 'Appeal_to_Fear-Prejudice']",
         "train",
         "['Kaj je častnega v takšnem delu, kot sem ga zdaj predstavila?']",
         "[]",
         "['Javno je priznal napake generalnega direktorja policije in ministra Poklukarja, toda ni ukrepal']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Da je bila v obdobju, ko SVZ ni varoval tožilke Gončinove, velika verjetnost, da je bil v Sloveniji morilec Satka Zovka, tako imenovani Cezar']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Hypocrisy",
         "Appeal_to_Hypocrisy",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "1",
         "Yes, the Appeal to Hypocrisy technique is used in the input.",
         "\"Javno je priznal napake generalnega direktorja policije in ministra Poklukarja, toda ni ukrepal\"",
         "[None]",
         "[False]",
         "['{\\n  \"explanation\": \"The Appeal to Hypocrisy technique is used in the input text by highlighting the inconsistency of the Prime Minister\\'s public acknowledgment of mistakes made by the police leadership while failing to take any action. This contradiction points to hypocrisy, as the Prime Minister criticizes the situation but does not follow through with necessary measures, thus undermining his credibility.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/si/train-si-part_0000.parquet",
         null,
         null,
         "train",
         "{\"description\": null, \"verdict\": true}"
        ],
        [
         "11343",
         "SI_interpelation_interior_0.txt",
         "1825",
         "2018",
         "SI",
         "Glasujemo. Ravno sem bila obveščena, da je očitno prišlo do tehničnih težav s sistemom in da bi bilo treba za 15 minut prekiniti sejo, da bomo te tehnične težave rešili. Se iskreno opravičujem.",
         "False",
         "[]",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Hypocrisy",
         "Appeal_to_Hypocrisy",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Appeal to Hypocrisy technique is not used in the input.",
         "\"\"",
         "[None]",
         "[False]",
         "['{\\n  \"explanation\": \"The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. There are no explicit or implicit references to contradictions or past actions that would qualify as an Appeal to Hypocrisy.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/si/train-si-part_0000.parquet",
         null,
         null,
         "train",
         "{\"description\": null, \"verdict\": false}"
        ],
        [
         "11346",
         "SI_interpelation_interior_0.txt",
         "3170",
         "3956",
         "SI",
         "Danes bomo govorili o delu ministra za notranje zadeve in o razlogih za njegovo razrešitev, v resnici pa bomo predstavljali tudi bistvo zgrešenih potez predsednika Vlade. On je namreč obljubljal eno, delal je popolnoma drugače. In kaj je pravzaprav največja napaka predsednika vlade? Da napak ne priznava. Dela in odloča se po navdihu. Kljub temu, da tako predsednik vlade kot v Svobodi ne priznavajo napak, sem prepričana, da globoko v sebi vedo, da je bila odstranitev Tatjane Bobnar in Boštjana Lindava napaka. Zaradi te napake je posledično prišlo do politizacije policije, krize vodenja razkroja institucij in zaradi velike ubogljivosti in želje ugajati šefu je stanje na področju varnosti slabo. Tako čutijo ljudje, tako govorijo ankete in tako vam bom zdaj dokazala s številkami.",
         "True",
         "['Consequential_Oversimplification' 'Appeal_to_Hypocrisy'\n 'Appeal_to_Popularity']",
         "train",
         "[]",
         "[]",
         "['Danes bomo govorili o delu ministra za notranje zadeve in o razlogih za njegovo razrešitev, v resnici pa bomo predstavljali tudi bistvo zgrešenih potez predsednika Vlade'\n 'On je namreč obljubljal eno, delal je popolnoma drugače'\n 'Kljub temu, da tako predsednik vlade kot v Svobodi ne priznavajo napak, sem prepričana, da globoko v sebi vedo, da je bila odstranitev Tatjane Bobnar in Boštjana Lindava napaka']",
         "[]",
         "[]",
         "[]",
         "['Tako čutijo ljudje, tako govorijo ankete']",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Zaradi te napake je posledično prišlo do politizacije policije, krize vodenja razkroja institucij in zaradi velike ubogljivosti in želje ugajati šefu je stanje na področju varnosti slabo']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Hypocrisy",
         "Appeal_to_Hypocrisy",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "1",
         "Yes, the Appeal to Hypocrisy technique is used in the input.",
         "\"Danes bomo govorili o delu ministra za notranje zadeve in o razlogih za njegovo razrešitev, v resnici pa bomo predstavljali tudi bistvo zgrešenih potez predsednika Vlade On je namreč obljubljal eno, delal je popolnoma drugače Kljub temu, da tako predsednik vlade kot v Svobodi ne priznavajo napak, sem prepričana, da globoko v sebi vedo, da je bila odstranitev Tatjane Bobnar in Boštjana Lindava napaka\"",
         "[None]",
         "[False]",
         "['{\\n  \"explanation\": \"The Appeal to Hypocrisy technique is used in the input text by highlighting the inconsistency between the Prime Minister\\'s promises and his actions. The speaker points out that the Prime Minister promised one thing but acted in a completely different manner, which directly attacks his credibility and reputation. This aligns with the definition of the technique, as it calls out the hypocrisy of the Prime Minister not acknowledging his mistakes while implying that he is aware of them.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/si/train-si-part_0000.parquet",
         null,
         null,
         "train",
         "{\"description\": null, \"verdict\": true}"
        ],
        [
         "11348",
         "SI_interpelation_interior_2.txt",
         "3786",
         "5640",
         "SI",
         "Dovolite, da se referiram še na eno vašo značajsko lastnost, ki jo izpostavljate v odgovoru na interpelacijo. Zapišete: Visoka stopnja politične kulture bo vedno eno izmed mojih temeljnih vodil pri opravljanju funkcije. Pa se zato za zaključek dotaknimo še nezakonitega imenovanja direktorja policije. V odgovoru na interpelacijo zapišete: Nezakonitosti imenovanja magistra senata Jušića za generalnega direktorja policije. Posledično Upravno sodišče torej sploh ni moglo ugotoviti in je tudi ni ugotovilo. O nezakonitem imenovanju zato ne moremo in ne smemo govoriti. Spoštovani minister, pravnik doktor Pirnat, si je vendarle drznil govoriti. Rekel je: Če je akt posebne natečajne komisije uradniškega sveta nezakonit, potem je gotovo nezakonito tudi imenovanje generalnega direktorja. Tako nazadnje veleva tudi zdrav razum. Na dan sodbe Upravnega sodišča je potekel rok za odstop generalnega direktorja policije. Kajti, gospod Poklukar, če ste res pošten in iskren politik, potem se morava strinjati, da za nezakonito imenovan direktor ne more opravljati svoje funkcije niti en dan. Kakšen vtis v javnosti pa daje policija, če jo vodi nezakonito imenovan direktor, medtem ko v vseh ostalih zahteva zakonitost delovanja? In naprej, z vsakim dnem, ko je po odločitvi sodišča generalni direktor Policije vztrajal na svojem mestu, vi, gospod Poklukar, pa ga niste pozvali k odstopu, je minil dan strmoglavljenja politične kulture te vlade. In vi ste več kot dva meseca branili to stanje. Če ste torej pošten in iskren politik, katerega, kot sami pravite, visoka stopnja politične kulture bo vedno eno izmed temeljnih vodil pri opravljanju funkcije ministra, potem preprosto morate odstopiti, ker ste predolgo tolerirali nekaj, kar ni moč tolerirati, sploh ne na vrhu represivnega organa, ki bi moral biti vsem državljankam in državljanom za vzgled. Hvala.",
         "True",
         "['Exaggeration-Minimisation' 'Loaded_Language' 'Appeal_to_Hypocrisy'\n 'Appeal_to_Authority' 'Appeal_to_Values' 'Repetition']",
         "train",
         "[]",
         "[]",
         "['Kakšen vtis v javnosti pa daje policija, če jo vodi nezakonito imenovan direktor, medtem ko v vseh ostalih zahteva zakonitost delovanja?']",
         "[]",
         "['drznil govoriti']",
         "['pošten in iskren politik' 'pošten in iskren politik']",
         "[]",
         "[]",
         "[]",
         "[]",
         "['je minil dan strmoglavljenja politične kulture te vlade']",
         "[]",
         "[]",
         "[]",
         "['Če ste torej pošten in iskren politik, katerega, kot sami pravite, visoka stopnja politične kulture bo vedno eno izmed temeljnih vodil pri opravljanju funkcije ministra, potem preprosto morate odstopiti, ker ste predolgo tolerirali nekaj, kar ni moč tolerirati, sploh ne na vrhu represivnega organa, ki bi moral biti vsem državljankam in državljanom za vzgled']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['pravnik doktor Pirnat']",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Hypocrisy",
         "Appeal_to_Hypocrisy",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "1",
         "Yes, the Appeal to Hypocrisy technique is used in the input.",
         "\"Kakšen vtis v javnosti pa daje policija, če jo vodi nezakonito imenovan direktor, medtem ko v vseh ostalih zahteva zakonitost delovanja?\"",
         "[None]",
         "[False]",
         "['{\\n  \"explanation\": \"The Appeal to Hypocrisy technique is used in the input text by highlighting the inconsistency in the minister\\'s stance on legality. The speaker points out that while the minister demands legality in other areas, he tolerates an illegally appointed police director, thus attacking the minister\\'s reputation for being a principled politician. This aligns with the definition, as it calls out the hypocrisy of the minister\\'s actions compared to his stated values.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/si/train-si-part_0000.parquet",
         null,
         null,
         "train",
         "{\"description\": null, \"verdict\": true}"
        ],
        [
         "11349",
         "SI_interpelation_interior_9.txt",
         "3480",
         "4437",
         "SI",
         "Spoštovani minister Poklukar! Državljanov ne zanimajo obljube o reorganizaciji, zanima jih, kdo in zakaj se je spravil na tožilko v zadevi Kavaški klan, kdaj bodo spisane in vložene ovadbe, kdaj se bodo začeli kazenski in predkazenski postopki glede tega, to nas zanima. Že 15 mesecev je minilo, odkar je tožilka vse odgovorne seznanila z nepravilnostmi, ko je šlo za varovanje predsednika vlade Goloba, se je zadeva rešila v treh mesecih. ko je šlo za varovanje predsednika vlade Goloba, se je zadeva rešila v treh mesecih. Ali vam je, minister Poklukar, pomembno samo varovanje predsednika vlade, za druge se pa ne sekirate, tudi za tiste, ki preganjajo mafijone, za predsednika vlade posebno varnostno službo, za ostale pa, kaj? Ne varnostno službo? Še veliko tega imam za povedati, ampak tudi kolegice in kolegi iz Poslanske skupine Nove Slovenije bodo kasneje v razpravi, kot tudi predlagateljica, ki je odlično uvedla zadevo, bodo kasneje še povedali.",
         "True",
         "['Appeal_to_Hypocrisy' 'Questioning_the_Reputation'\n 'Name_Calling-Labeling' 'Appeal_to_Popularity' 'Repetition']",
         "train",
         "['Ali vam je, minister Poklukar, pomembno samo varovanje predsednika vlade, za druge se pa ne sekirate, tudi za tiste, ki preganjajo mafijone, za predsednika vlade posebno varnostno službo, za ostale pa, kaj? Ne varnostno službo?']",
         "['mafijone']",
         "['Že 15 mesecev je minilo, odkar je tožilka vse odgovorne seznanila z nepravilnostmi, ko je šlo za varovanje predsednika vlade Goloba, se je zadeva rešila v treh mesecih. ko je šlo za varovanje predsednika vlade Goloba, se je zadeva rešila v treh mesecih']",
         "[]",
         "[]",
         "['to nas zanima'\n 'ko je šlo za varovanje predsednika vlade Goloba, se je zadeva rešila v treh mesecih']",
         "['Državljanov ne zanimajo obljube o reorganizaciji, zanima jih, kdo in zakaj se je spravil na tožilko v zadevi Kavaški klan, kdaj bodo spisane in vložene ovadbe, kdaj se bodo začeli kazenski in predkazenski postopki glede tega, to nas zanima']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Hypocrisy",
         "Appeal_to_Hypocrisy",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "1",
         "Yes, the Appeal to Hypocrisy technique is used in the input.",
         "\"Že 15 mesecev je minilo, odkar je tožilka vse odgovorne seznanila z nepravilnostmi, ko je šlo za varovanje predsednika vlade Goloba, se je zadeva rešila v treh mesecih. ko je šlo za varovanje predsednika vlade Goloba, se je zadeva rešila v treh mesecih\"",
         "[None]",
         "[False]",
         "['{\\n  \"explanation\": \"The Appeal to Hypocrisy technique is used in the input text by highlighting the inconsistency in the minister\\'s actions regarding the protection of the Prime Minister compared to the lack of action for others. The speaker points out that while issues concerning the Prime Minister were resolved quickly, similar issues affecting others have not been addressed, thus calling out the hypocrisy in prioritizing one over the other.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/si/train-si-part_0001.parquet",
         null,
         null,
         "train",
         "{\"description\": null, \"verdict\": true}"
        ],
        [
         "11354",
         "SI_interpelation_interior_2.txt",
         "5869",
         "5947",
         "SI",
         "Spoštovana gospa predsednica Državnega zbora! Spoštovane poslanke in poslanci!",
         "False",
         "[]",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Hypocrisy",
         "Appeal_to_Hypocrisy",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Appeal to Hypocrisy technique is not used in the input.",
         "\"\"",
         "[None]",
         "[False]",
         "['{\\n  \"explanation\": \"The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. There are no explicit or implicit references to contradictions or past actions that would qualify as an Appeal to Hypocrisy.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/si/train-si-part_0001.parquet",
         null,
         null,
         "train",
         "{\"description\": null, \"verdict\": false}"
        ],
        [
         "11355",
         "SI_interpelation_interior_4.txt",
         "3163",
         "7586",
         "SI",
         "V javnosti najodmevnejši očitek, ki so ga seveda prevzeli tudi predlagatelji, je očitek glede delovanja Centra za varovanje in zaščito. Situacija v zvezi z delovanjem in organizacijo Centra za varovanje in zaščito je bistveno bolj kompleksna, kot jo sicer nekateri radi prikazujejo in je trenutno v fazi preiskave morebitnih sumov storitve kaznivih dejanj pripadnikov te enote, ki jo vodi specializirano državno tožilstvo. Naj povem, da je Center za varovanje in zaščito vseeno zelo profesionalna enota policije z dolgoletno tradicijo in je sposobna brezhibno izvesti tudi najzahtevnejša varovanja, vključno z zagotavljanjem najvišje stopnje varovanja svetovnim voditeljem, ki so izpostavljeni visokim varnostnim tveganjem in grožnjam. Pri osebnem varovanju je ključno vzpostaviti zaupanje med varnostniki in varovano osebo. Iz lastnih izkušenj že drugič kot varovana oseba lahko potrdim, da policisti varnostniki svoje naloge opravljajo profesionalno in dosledno. Naj pa jasno povem, da je bil zadnji izredni nadzor nad Centrom za varovanje in zaščito uveden leta 2010 s strani takratne ministrice za notranje zadeve, zaradi tako imenovane afere katarske ure, in ponovni nadzor nad enoto leta 2012 s strani takratnega notranjega ministra. Dejstvo je tudi, da v vsem tem času direktorat za policijo in druge varnostne naloge ministrstva v obravnavo ni prejel nobene pritožbe zoper dela policistov varnostnikov centra za varovanje in zaščito. Nekdanji generalni direktor Policije magister Senad Jušić je takoj po nastopu funkcije leta 2023 aktivno pričel z različnimi aktivnostmi in ukrepi za izboljšanje stanja v Centru za varovanje in zaščito. Zaradi določenih nepravilnosti in napak v enoti je večkrat odredil notranje varnostne postopke, ki pa so v izključni pristojnosti generalnega direktorja policije in ne ministra za notranje zadeve. Kot minister za notranje zadeve sem na podlagi nekaterih medijskih objav o nepravilnostih v Centru za varovanje in zaščito 28. februarja lani v skladu s svojo zakonsko pristojnostjo direktoratu za policijo in druge varnostne naloge Ministrstva za notranje zadeve odredil izredni strokovni nadzor nad izvajanjem policijskih nalog in pooblastil v Centru za varovanje in zaščito, ki sta ga izvedla nadzornika direktorata. Po zaključnem nadzoru sta nadzornika direktorata konec avgusta leta 2024 zaključila poročilo o izrednem nadzoru v centru za varovanje in zaščito, ki je pod oznako stopnje zaupnosti interno. V samem izrednem strokovnem nadzoru so bile ugotovljene nepravilnosti in napake, ki so zapisane v poročilu izrednega nadzora. Na podlagi teh ugotovitev sem generalnemu direktorju policije z usmeritvami in obveznimi navodili ministra naložil ukrepe za izboljšanje stanja v Centru za varovanje in zaščito. Policija je takoj pristopila k odpravljanju nepravilnosti in pripravila načrt za odpravo ugotovljenih nepravilnosti in pomanjkljivosti na podlagi mojih usmeritev in obveznih navodil in ga začela tudi izvajati. V oddaji TV Slovenija Tarča lani decembra, so bile razkrite operativne informacije o varovanju varovanih oseb, izpostavljene so bile nepravilnosti in podani morebitni sumi storitve kaznivih dejanj v Centru za varovanje in zaščito na podlagi razkritih odklonov sem naslednji dan generalnemu direktorju policije izdal usmeritev in obvezno navodilo za reorganizacijo centra za varovanje in zaščito do 1. aprila letos. Prav tako sem zaradi javnega dvoma v zakonitost in transparentnost postopka javnega naročanja izdal sklep o izvedbi notranje revizije uporabe nastanitvenih kapacitet za potrebe Centra za varovanje in zaščito. Na podlagi medijskih očitkov in nekaterih neresničnih informacij ter predvsem zaradi velikega interesa javnosti, je bila delno umaknjena stopnja zaupnosti sporočila izrednega nadzora, ki ga je na tiskovni konferenci predstavil direktor direktorata za policijo in druge varnostne naloge, prav tako pa so ga prejeli nekateri mediji po dostopu do informacij javnega značaja in ga tudi javno objavili. Prav tako sem z elektronskim sporočilom zaprosil generalno državno tožilko, da v skladu s svojimi pristojnostmi naredi vse, da se čim prej preiščejo sumi morebitnih kaznivih dejanj v Centru za varovanje in zaščito. Njen odgovor je bil, da je preiskava že uvedena po uradni dolžnosti. Naj še dodam, da je Specializirano državno tožilstvo zahtevalo celotno poročilo o izrednem nadzoru, ki ga je Ministrstvo za notranje zadeve tudi predal.",
         "True",
         "['Exaggeration-Minimisation' 'Loaded_Language'\n 'Obfuscation-Vagueness-Confusion' 'Appeal_to_Authority'\n 'Appeal_to_Values' 'Appeal_to_Popularity' 'Doubt']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "['seveda'\n 'vseeno zelo profesionalna enota policije z dolgoletno tradicijo'\n 'brezhibno izvesti tudi najzahtevnejša varovanja, vključno z zagotavljanjem najvišje stopnje varovanja'\n 'operativne informacije']",
         "[]",
         "['ni prejel nobene pritožbe']",
         "['nekaterih neresničnih informacij']",
         "[]",
         "[]",
         "['V javnosti najodmevnejši očitek' 'aktivno pričel']",
         "[]",
         "[]",
         "[]",
         "['javnega dvoma v zakonitost in transparentnost postopka javnega naročanja']",
         "['bolj kompleksna, kot jo sicer nekateri radi prikazujejo'\n 'različnimi aktivnostmi in ukrepi' 'določenih nepravilnosti in napak'\n 'operativne informacije' 'nepravilnosti'\n 'morebitni sumi storitve kaznivih dejanj' 'javnega dvoma']",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Naj povem, da je Center za varovanje in zaščito vseeno zelo profesionalna enota policije z dolgoletno tradicijo in je sposobna brezhibno izvesti tudi najzahtevnejša varovanja, vključno z zagotavljanjem najvišje stopnje varovanja svetovnim voditeljem, ki so izpostavljeni visokim varnostnim tveganjem in grožnjam'\n 'kot varovana oseba lahko potrdim' 'Kot minister za notranje zadeve'\n 'v skladu s svojo zakonsko pristojnostjo' 'nadzornika direktorata'\n 'izrednem strokovnem nadzoru']",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Hypocrisy",
         "Appeal_to_Hypocrisy",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Appeal to Hypocrisy technique is not used in the input.",
         "\"\"",
         "[None]",
         "[False]",
         "['{\\n  \"explanation\": \"The input text does not contain any instances of the Appeal to Hypocrisy technique, as it does not attack the reputation of any individual by charging them with hypocrisy or inconsistency. The text focuses on the operations and oversight of the Center for Protection and Security without making any comparisons to past actions or positions that would indicate hypocrisy.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/si/train-si-part_0001.parquet",
         null,
         null,
         "train",
         "{\"description\": null, \"verdict\": false}"
        ],
        [
         "11358",
         "SI_interpelation_interior_10.txt",
         "554",
         "2314",
         "SI",
         "Na tem mestu Socialni demokrati opozarjamo, da se je v razmerju do vodstvenih kadrov v policiji doslej že bistveno prevečkrat pozabljalo na potrebo po ohranjanju zakonskih določb, gospod Jušić je položaj obdržal kljub ugotovitvam upravnega sodišča in po zaslugi intervenciji politike, zato zahtevamo, da minister in koalicija opravita nujen razmislek o spremembi načina imenovanja generalnega direktorja policije na način, ki v največji možni meri politično izključi iz postopkov imenovanja in izbire. Pred navedenim pa so se odprli tudi očitki zoper strokovnost ministra, ki izhaja iz katastrofalnega stanja v Centru za varovanje in zaščito. Specializirana tožilka, gospa Gončin, je pričala o napakah v okviru njenega varovanja in CVZ očita, da naj bi nepooblaščeno zbirali njene zasebne podatke. Sama je celo izjavila, da je izgubila zaupanje v policijo. Sporne okoliščine se pojavljajo tudi v razmerju zaposlitve člana osebnega varovanja tožilke. Specializirana tožilka Gončin je proti zaposlenemu v centru spisala tudi kazensko ovadbo, in sicer zaradi nepooblaščenega vstopa v videonadzorni sistem, ki je namenjen njenemu varovanju. Članu njenega varovanja očitno kaznivo dejanje zlorabe pooblastil. Kljub navedenemu pa je pod ministrom in nekdanjim generalnim direktorjem v okviru CVZ celo napredoval. Dejstvo je, da je stanje na CVZ odgovornost ministra za notranje zadeve, saj ima na podlagi določb Zakona o organiziranosti in delu v policiji vsa pooblastila, ki mu preko podajanja usmeritev omogočajo, da stanje posredno z intervencijo v vodstvo policije odpravi. Zato je nesprejemljivo, da takšno stanje na CVZ vlada že kar 14 mesecev. Navsezadnje pa gre za odgovornost ministra tudi zato, ker je na vodilno mesto v policiji imenovan neprimeren kader.",
         "True",
         "['Loaded_Language' 'Appeal_to_Hypocrisy' 'Questioning_the_Reputation'\n 'Appeal_to_Authority' 'Doubt' 'Appeal_to_Fear-Prejudice']",
         "train",
         "['opozarjamo, da se je v razmerju do vodstvenih kadrov v policiji doslej že bistveno prevečkrat pozabljalo na potrebo po ohranjanju zakonskih določb, gospod Jušić je položaj obdržal kljub ugotovitvam upravnega sodišča in po zaslugi intervenciji politike'\n 'očitki zoper strokovnost ministra'\n 'Kljub navedenemu pa je pod ministrom in nekdanjim generalnim direktorjem v okviru CVZ celo napredoval']",
         "[]",
         "['Kljub navedenemu pa je pod ministrom in nekdanjim generalnim direktorjem v okviru CVZ celo napredoval']",
         "[]",
         "['katastrofalnega stanja']",
         "[]",
         "[]",
         "['Navsezadnje pa gre za odgovornost ministra tudi zato, ker je na vodilno mesto v policiji imenovan neprimeren kader']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['zaradi nepooblaščenega vstopa v videonadzorni sistem, ki je namenjen njenemu varovanju']",
         "[]",
         "['Sama je celo izjavila, da je izgubila zaupanje v policijo']",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Hypocrisy",
         "Appeal_to_Hypocrisy",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "1",
         "Yes, the Appeal to Hypocrisy technique is used in the input.",
         "\"Kljub navedenemu pa je pod ministrom in nekdanjim generalnim direktorjem v okviru CVZ celo napredoval\"",
         "[None]",
         "[False]",
         "['{\\n  \"explanation\": \"The Appeal to Hypocrisy technique is used in the input text by highlighting the inconsistency in the minister\\'s actions. The excerpt points out that despite the problematic situation in the CVZ, a member of the security team has advanced under the minister\\'s leadership, suggesting hypocrisy in the minister\\'s ability to manage the situation while allowing such advancements.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/si/train-si-part_0001.parquet",
         null,
         null,
         "train",
         "{\"description\": null, \"verdict\": true}"
        ],
        [
         "11389",
         "20231208_URW_BG_72.txt",
         "3279",
         "3627",
         "BG",
         "Аз обаче не взех репликата за това, а взех репликата, господин Гуцанов, за да Ви кажа, че не само лъжете в това Ваше изказване, но и от 29 септември, когато излязохте на тази трибуна да ни кажете, че бензинът става 4 лв., измина доста време, а вече той е със 17 стотинки надолу от деня, в който Вие го казахте, и нямат нищо общо с 4 лв. Благодаря. ",
         "True",
         "['Appeal_to_Hypocrisy' 'Red_Herring']",
         "train",
         "[]",
         "[]",
         "['Аз обаче не взех репликата за това, а взех репликата, господин Гуцанов, за да Ви кажа, че не само лъжете в това Ваше изказване, но и от 29 септември, когато излязохте на тази трибуна да ни кажете, че бензинът става 4 лв., измина доста време, а вече той е със 17 стотинки надолу от деня, в който Вие го казахте, и нямат нищо общо с 4 лв']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Аз обаче не взех репликата за това, а взех репликата, господин Гуцанов, за да Ви кажа, че не само лъжете в това Ваше изказване, но и от 29 септември, когато излязохте на тази трибуна да ни кажете, че бензинът става 4 лв., измина доста време, а вече той е със 17 стотинки надолу от деня, в който Вие го казахте, и нямат нищо общо с 4 лв']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Hypocrisy",
         "Appeal_to_Hypocrisy",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "1",
         "Yes, the Appeal to Hypocrisy technique is used in the input.",
         "\"Аз обаче не взех репликата за това, а взех репликата, господин Гуцанов, за да Ви кажа, че не само лъжете в това Ваше изказване, но и от 29 септември, когато излязохте на тази трибуна да ни кажете, че бензинът става 4 лв., измина доста време, а вече той е със 17 стотинки надолу от деня, в който Вие го казахте, и нямат нищо общо с 4 лв\"",
         "[None]",
         "[False]",
         "['{\\n  \"explanation\": \"The Appeal to Hypocrisy technique is used in the input text as the speaker accuses Mr. Gutsanov of lying about the price of gasoline, highlighting the inconsistency between his previous statement and the current price. This directly attacks Gutsanov\\'s credibility by pointing out his past claim that gasoline would rise to 4 BGN, which is now proven false.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/bg/train-bg-part_0009.parquet",
         "[None]",
         "[None]",
         "train",
         "{\"description\": null, \"verdict\": true}"
        ],
        [
         "11479",
         "20231208_URW_BG_73.txt",
         "5323",
         "5459",
         "BG",
         "КОСТАДИН КОСТАДИНОВ (ВЪЗРАЖДАНЕ, от място): А докато беше в БСП до миналата година, дали беше проруска партия?! (Реплики от ВЪЗРАЖДАНЕ.)",
         "True",
         "['Appeal_to_Hypocrisy']",
         "train",
         "[]",
         "[]",
         "['А докато беше в БСП до миналата година, дали беше проруска партия?!']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Hypocrisy",
         "Appeal_to_Hypocrisy",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "1",
         "Yes, the Appeal to Hypocrisy technique is used in the input.",
         "\"А докато беше в БСП до миналата година, дали беше проруска партия?!\"",
         "[None]",
         "[False]",
         "['{\\n  \"explanation\": \"The Appeal to Hypocrisy technique is used in the input text as it directly calls out the hypocrisy of the target by questioning their past affiliation with the BСП (Bulgarian Socialist Party) and implying that they were a pro-Russian party at that time. This highlights a contradiction between their past actions and their current stance.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/bg/train-bg-part_0002.parquet",
         null,
         null,
         "train",
         "{\"description\": null, \"verdict\": true}"
        ],
        [
         "11644",
         "pl_abortion_11_04_2024_n08.txt",
         "3138",
         "3188",
         "PL",
         "(Poseł Joanna Scheuring-Wielgus: Zejdź z mównicy.)",
         "True",
         "['Loaded_Language']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Zejdź z mównicy']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Questioning_the_Reputation",
         "Questioning_the_Reputation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Questioning the Reputation technique is not used in the input.",
         "\"\"",
         "[None]",
         "[False]",
         "['{\\n  \"explanation\": \"The input text does not contain any elements that attack the reputation of a target or make negative claims about their character or moral stature. Therefore, the Questioning the Reputation technique is not used.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/pl/train-pl-part_0007.parquet",
         null,
         null,
         "train",
         "{\"description\": null, \"verdict\": false}"
        ],
        [
         "11646",
         "pl_eu_12_06_2024_n02.txt",
         "5000",
         "5586",
         "PL",
         "Poseł Marcin Porzucek:\nPanie Marszałku! Wysoka Izbo! Szanowni Państwo! W okresie COVID-u, gdy sytuacje pandemiczne\npojawiały się w ciągu nie roku, nie miesięcy, nie tygodnia, ale wręcz dni, i podejmowaliśmy stosowne\ndziałania, państwo nas krytykowaliście. Gdy Rosja\nnapadała pełnoskalowo na Ukrainę, było podobnie.\nSytuacja wojny hybrydowej na granicy polsko-białoruskiej, podobnie. A dzisiaj państwo macie jeszcze\ntyle czasu, chociaż zmarnowaliście ostatnie pół roku,\nproponujecie rozwiązania ekstraordynaryjne, choć\nmożna to w wielu aspektach zrobić tradycyjnie. To\njest jedna sprawa.",
         "True",
         "['Questioning_the_Reputation']",
         "train",
         "['podejmowaliśmy stosowne działania, państwo nas krytykowaliście'\n 'Gdy Rosja napadała pełnoskalowo na Ukrainę, było podobnie. Sytuacja wojny hybrydowej na granicy polsko-białoruskiej, podobnie'\n 'zmarnowaliście ostatnie pół roku']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Questioning_the_Reputation",
         "Questioning_the_Reputation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "1",
         "Yes, the Questioning the Reputation technique is used in the input.",
         "\"podejmowaliśmy stosowne działania, państwo nas krytykowaliście Gdy Rosja napadała pełnoskalowo na Ukrainę, było podobnie. Sytuacja wojny hybrydowej na granicy polsko-białoruskiej, podobnie zmarnowaliście ostatnie pół roku\"",
         "[None]",
         "[False]",
         "['{\\n  \"explanation\": \"The input text uses the Questioning the Reputation technique by criticizing the actions of the opposing party during critical situations, such as the COVID pandemic and the war in Ukraine. The speaker implies that the opposition has failed to act appropriately (\\'państwo nas krytykowaliście\\' and \\'zmarnowaliście ostatnie pół roku\\'), which attacks their reputation and moral standing rather than addressing the topic directly.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/pl/train-pl-part_0007.parquet",
         null,
         null,
         "train",
         "{\"description\": null, \"verdict\": true}"
        ],
        [
         "11648",
         "pl_abortion_11_04_2024_n05.txt",
         "9681",
         "10556",
         "PL",
         "Dziś jesteśmy w demograficznym kryzysie. Polki\nnie chcą rodzić dzieci w Polsce, która nie jest dla nich\nbezpieczna pod żadnym względem. Mówią: boję się\nbyć w ciąży, bo dziewczyny w moim wieku umierają.\nUmarły pan Iza, pani Agnieszka, pani Marta, pani\nDorota. Dlatego Koalicja Obywatelska przygotowała\ni przedstawia projekt ustawy o świadomym rodzicielstwie.\nZakaz aborcji w Polsce to restrykcyjne prawo,\nktóre zagraża zdrowiu, życiu i bezpieczeństwu kobiet,\na nasz projekt, projekt Koalicji Obywatelskiej,\nprzywraca kobietom wolność wyboru, przywraca kobietom\ngodność, przywraca kobietom podmiotowość. Zakłada\nmożliwość bezpiecznego i bezpłatnego przerywania\nciąży do 12 tygodnia jej trwania oraz po 12 tygodniu\nw określonych okolicznościach. Aborcja musi być\nbezpieczna, aborcja musi być legalna. Aborcja musi być\ndostępna, a kobieta musi być bezpieczna.\nDziękuję. (Oklaski)",
         "True",
         "['Conversation_Killer' 'Causal_Oversimplification' 'Slogans'\n 'Whataboutism' 'Appeal_to_Values' 'Repetition' 'Appeal_to_Fear-Prejudice']",
         "train",
         "[]",
         "[]",
         "[]",
         "['aborcja musi być legalna' 'Aborcja musi być dostępna']",
         "[]",
         "['przywraca kobietom wolność wyboru' 'przywraca kobietom godność'\n 'przywraca kobietom podmiotowość']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['zagraża zdrowiu, życiu i bezpieczeństwu kobiet']",
         "[]",
         "[]",
         "['Aborcja musi być bezpieczna, aborcja musi być legalna'\n 'Aborcja musi być dostępna, a kobieta musi być bezpieczna']",
         "['Mówią: boję się być w ciąży, bo dziewczyny w moim wieku umierają. Umarły pan Iza, pani Agnieszka, pani Marta, pani Dorota'\n 'Zakaz aborcji w Polsce to restrykcyjne prawo, które zagraża zdrowiu, życiu i bezpieczeństwu kobiet']",
         "['Polki nie chcą rodzić dzieci w Polsce, która nie jest dla nich bezpieczna pod żadnym względem']",
         "[]",
         "[]",
         "['Dziś jesteśmy w demograficznym kryzysie']",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Questioning_the_Reputation",
         "Questioning_the_Reputation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Questioning the Reputation technique is not used in the input.",
         "\"\"",
         "[None]",
         "[False]",
         "['{\\n  \"explanation\": \"The input text does not contain any elements that attack the reputation of a target or make strong negative claims about it. It focuses on discussing the issue of abortion and women\\'s rights without undermining the character or moral stature of any individual or group. Therefore, the Questioning the Reputation technique is not used.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/pl/train-pl-part_0007.parquet",
         null,
         null,
         "train",
         "{\"description\": null, \"verdict\": false}"
        ],
        [
         "11675",
         "pl_current_affairs_09_01_2025_n02.txt",
         "10564",
         "11076",
         "PL",
         "Przypomnę tylko, że 23 czerwca 2017 r. na pochylni Wulkan Nowy w Szczecińskim Parku Przemysłowym odbyło się położenie stępki pod budowę promu\npasażersko-samochodowego. Obecny na tej ceremonii pan minister Marek Gróbarczyk podkreślił znaczenie projektu w procesie odbudowy pozycji polskich\nstoczni. W 2023 r., kilka lat później, okazało się, że\njeśli chodzi o dokapitalizowanie spółek zaangażowanych w ten projekt, w projekt „Batory”, zainwestowano 1 mld zł z publicznych pieniędzy – 1 mld zł strat\ni zero promów.",
         "True",
         "['Questioning_the_Reputation']",
         "train",
         "['W 2023 r., kilka lat później, okazało się, że jeśli chodzi o dokapitalizowanie spółek zaangażowanych w ten projekt, w projekt „Batory”, zainwestowano 1 mld zł z publicznych pieniędzy – 1 mld zł strat i zero promów']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Questioning_the_Reputation",
         "Questioning_the_Reputation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "1",
         "Yes, the Questioning the Reputation technique is used in the input.",
         "\"W 2023 r., kilka lat później, okazało się, że jeśli chodzi o dokapitalizowanie spółek zaangażowanych w ten projekt, w projekt „Batory”, zainwestowano 1 mld zł z publicznych pieniędzy – 1 mld zł strat i zero promów\"",
         "[None]",
         "[False]",
         "['{\\n  \"explanation\": \"The input text uses the Questioning the Reputation technique by highlighting the financial losses and lack of results from the project \\'Batory\\', which undermines the credibility and moral standing of those involved, particularly the minister who previously supported the project. This aligns with the technique\\'s definition of attacking reputation through negative claims.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/pl/train-pl-part_0001.parquet",
         null,
         null,
         "train",
         "{\"description\": null, \"verdict\": true}"
        ],
        [
         "11676",
         "pl_abortion_11_04_2024_n06.txt",
         "3223",
         "3463",
         "PL",
         "Panie pośle, na podstawie art. 175 ust. 3 regulaminu\nSejmu przywołuję pana do porządku.\nRozumiem, że pan wyłączył urządzenie. Rozumiem, że pan zrozumiał.\n(Poseł Dariusz Matecki: Wyłączyłem bicie serca dziecka.)\nPani posłanko, bardzo proszę.",
         "True",
         "['Obfuscation-Vagueness-Confusion']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Wyłączyłem bicie serca dziecka']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Questioning_the_Reputation",
         "Questioning_the_Reputation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Questioning the Reputation technique is not used in the input.",
         "\"\"",
         "[None]",
         "[False]",
         "['{\\n  \"explanation\": \"The input text does not contain any elements that attack the reputation of a target or make strong negative claims about it. There are no attempts to undermine character or moral stature, which are key aspects of the Questioning the Reputation technique. Therefore, the expert\\'s verdict that this technique was not used is accurate.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/pl/train-pl-part_0001.parquet",
         null,
         null,
         "train",
         "{\"description\": null, \"verdict\": false}"
        ],
        [
         "11680",
         "pl_current_affairs_09_01_2025_n02.txt",
         "1271",
         "1380",
         "PL",
         "(Poseł Joanna Borowiak: A kto to?)\nNie wiem, ale to mili ludzie, uśmiechnięci, z otwartymi sercami. (Oklaski)",
         "False",
         "[]",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Questioning_the_Reputation",
         "Questioning_the_Reputation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Questioning the Reputation technique is not used in the input.",
         "\"\"",
         "[None]",
         "[False]",
         "['{\\n  \"explanation\": \"The input text does not contain any elements that attack or undermine the reputation of a target. It instead describes people in a positive light, which does not align with the definition of the Questioning the Reputation technique.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/pl/train-pl-part_0001.parquet",
         null,
         null,
         "train",
         "{\"description\": null, \"verdict\": false}"
        ],
        [
         "11686",
         "pl_defence_22_05_2024_n01.txt",
         "11403",
         "11488",
         "PL",
         "(Głos z sali: Dla ojczyzny ratowania…)\n…dla ojczyzny ratowania rzucił się przez most.",
         "True",
         "['Flag_Waving' 'Red_Herring']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['dla ojczyzny ratowania']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Questioning_the_Reputation",
         "Questioning_the_Reputation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Questioning the Reputation technique is not used in the input.",
         "\"\"",
         "[None]",
         "[False]",
         "['{\\n  \"explanation\": \"The input text does not contain any elements that attack the reputation of a target or make strong negative claims about it. There are no indications of undermining character or moral stature, which are essential for the use of the Questioning the Reputation technique.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/pl/train-pl-part_0008.parquet",
         null,
         null,
         "train",
         "{\"description\": null, \"verdict\": false}"
        ],
        [
         "11689",
         "pl_defence_22_05_2024_n02.txt",
         "0",
         "110",
         "PL",
         "Wicemarszałek Włodzimierz Czarzasty:\nDziękuję serdecznie.\nPan poseł Sławomir Mentzen, Konfederacja.\nZapraszam.",
         "False",
         "[]",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Questioning_the_Reputation",
         "Questioning_the_Reputation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Questioning the Reputation technique is not used in the input.",
         "\"\"",
         "[None]",
         "[False]",
         "['{\\n  \"explanation\": \"The input text does not contain any elements that attack the reputation of an individual or make negative claims about their character or moral stature. Therefore, the Questioning the Reputation technique is not used.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/pl/train-pl-part_0008.parquet",
         null,
         null,
         "train",
         "{\"description\": null, \"verdict\": false}"
        ],
        [
         "11691",
         "pl_abortion_11_04_2024_n01.txt",
         "373",
         "911",
         "PL",
         "Przystępujemy do rozpatrzenia punktów 10.,\n11., 12. i 13. porządku dziennego:\n10. Pierwsze czytanie poselskiego projektu\nustawy o zmianie ustawy – Kodeks karny (druk nr 176).\n11. Pierwsze czytanie poselskiego projektu\nustawy o bezpiecznym przerywaniu ciąży (druk nr 177).\n12. Pierwsze czytanie poselskiego projektu\nustawy o zmianie ustawy o planowaniu rodziny,\nochronie płodu ludzkiego i warunkach\ndopuszczalności przerywania ciąży (druk nr 223).\n13. Pierwsze czytanie poselskiego projektu\nustawy o świadomym rodzicielstwie (druk nr 224).",
         "False",
         "[]",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Questioning_the_Reputation",
         "Questioning_the_Reputation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Questioning the Reputation technique is not used in the input.",
         "\"\"",
         "[None]",
         "[False]",
         "['{\\n  \"explanation\": \"The input text does not contain any elements that attack the reputation of a target or make negative claims about it. It simply lists legislative proposals without any commentary on the character or moral stature of individuals or groups involved.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/pl/train-pl-part_0008.parquet",
         null,
         null,
         "train",
         "{\"description\": null, \"verdict\": false}"
        ],
        [
         "11692",
         "pl_abortion_11_04_2024_n07.txt",
         "8356",
         "8651",
         "PL",
         "Projekt referendum Trzeciej Drogi. Pytanie\nreferendalne. Jak będzie brzmiało? Czy jesteś za zabijaniem\ndzieci w łonach matek? A dlaczego nie dać pytania: Czy\njesteś za legalizacją zabijania określonych grup\netnicznych lub osób posiadających nieprawidłowe poglądy?\n(Głos z sali: Co pan opowiada?)",
         "True",
         "['Loaded_Language' 'Obfuscation-Vagueness-Confusion'\n 'Questioning_the_Reputation' 'Red_Herring']",
         "train",
         "['Projekt referendum Trzeciej Drogi. Pytanie referendalne. Jak będzie brzmiało? Czy jesteś za zabijaniem dzieci w łonach matek? A dlaczego nie dać pytania: Czy jesteś za legalizacją zabijania określonych grup etnicznych lub osób posiadających nieprawidłowe poglądy?']",
         "[]",
         "[]",
         "[]",
         "['zabijaniem dzieci w łonach matek?']",
         "[]",
         "[]",
         "[]",
         "['Czy jesteś za legalizacją zabijania określonych grup etnicznych lub osób posiadających nieprawidłowe poglądy?']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Czy jesteś za legalizacją zabijania określonych grup etnicznych lub osób posiadających nieprawidłowe poglądy?']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Questioning_the_Reputation",
         "Questioning_the_Reputation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "1",
         "Yes, the Questioning the Reputation technique is used in the input.",
         "\"Projekt referendum Trzeciej Drogi. Pytanie referendalne. Jak będzie brzmiało? Czy jesteś za zabijaniem dzieci w łonach matek? A dlaczego nie dać pytania: Czy jesteś za legalizacją zabijania określonych grup etnicznych lub osób posiadających nieprawidłowe poglądy?\"",
         "[None]",
         "[False]",
         "['{\\n  \"explanation\": \"The input text employs the Questioning the Reputation technique by framing the referendum question in a highly inflammatory manner, suggesting that supporting the referendum equates to supporting heinous acts such as killing children and specific ethnic groups. This approach attacks the moral character of those who might support the referendum, thereby undermining their reputation without engaging in a substantive argument about the referendum itself.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/pl/train-pl-part_0008.parquet",
         null,
         null,
         "train",
         "{\"description\": null, \"verdict\": true}"
        ],
        [
         "11725",
         "RU_URW_2.txt",
         "2035",
         "2295",
         "RU",
         "Наша партия в конце февраля проводит Всероссийский форум «Плечом к плечу. За Русскую Победу!». Мы приглашаем всех присоединиться к этому мероприятию и поддержать бойцов специальной военной операции и членов их семей во имя мира на русской земле и во всём мире.",
         "False",
         "[]",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Questioning_the_Reputation",
         "Questioning_the_Reputation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Questioning the Reputation technique is not used in the input.",
         "\"\"",
         "[None]",
         "[False]",
         "['{\\n  \"explanation\": \"The input text does not contain any elements that attack the reputation of a target or make negative claims about it. It focuses on promoting a forum and supporting military personnel, which does not align with the definition of Questioning the Reputation.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/ru/train-ru-part_0003.parquet",
         null,
         null,
         "train",
         "{\"description\": null, \"verdict\": false}"
        ],
        [
         "11726",
         "RU_migrants_5.txt",
         "2013",
         "2271",
         "RU",
         "ия города, да и системы в том, что следователь спокойно вменяет за похищение и издевательства «хулиганку». Как верно сказал Михаил Маваши, не инкриминируется «по предварительному сговору», «совершенное группой лиц», а также «с особым цинизмом».\n\nНе нужно уже",
         "True",
         "['Loaded_Language' 'Appeal_to_Authority']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "['И тут деградация города, да и системы в том']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Как верно сказал Михаил Маваши, не инкриминируется «по предварительному сговору», «совершенное группой лиц», а также «с особым цинизмом»']",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Questioning_the_Reputation",
         "Questioning_the_Reputation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Questioning the Reputation technique is not used in the input.",
         "\"\"",
         "[None]",
         "[False]",
         "['{\\n  \"explanation\": \"The input text does not contain any elements that attack the reputation of a target or make strong negative claims about it. There are no attempts to undermine character or moral stature, which are key aspects of the Questioning the Reputation technique. Therefore, the expert\\'s verdict that this technique is not used is accurate.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/ru/train-ru-part_0003.parquet",
         null,
         null,
         "train",
         "{\"description\": null, \"verdict\": false}"
        ],
        [
         "11743",
         "RU_discrediting_the_west_10.txt",
         "2217",
         "2286",
         "RU",
         "ивации воевать за Родину… Так не должно быть.",
         "True",
         "['Conversation_Killer']",
         "train",
         "[]",
         "[]",
         "[]",
         "['Так не должно быть']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Questioning_the_Reputation",
         "Questioning_the_Reputation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Questioning the Reputation technique is not used in the input.",
         "\"\"",
         "[None]",
         "[False]",
         "['{\\n  \"explanation\": \"The input text does not contain any elements that attack the reputation of a target or make strong negative claims about it. Therefore, the Questioning the Reputation technique is not used.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/ru/train-ru-part_0008.parquet",
         null,
         null,
         "train",
         "{\"description\": null, \"verdict\": false}"
        ],
        [
         "11744",
         "RU_discrediting_the_west_19.txt",
         "0",
         "26",
         "RU",
         "Объединённая Европа в шоке",
         "True",
         "['Exaggeration-Minimisation']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Объединённая Европа в шоке']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Questioning_the_Reputation",
         "Questioning_the_Reputation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Questioning the Reputation technique is not used in the input.",
         "\"\"",
         "[None]",
         "[False]",
         "['{\\n  \"explanation\": \"The input text does not contain any elements that attack the reputation of a target or make strong negative claims about it. Therefore, the Questioning the Reputation technique is not used.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/ru/train-ru-part_0008.parquet",
         null,
         null,
         "train",
         "{\"description\": null, \"verdict\": false}"
        ],
        [
         "11747",
         "RU_discrediting_the_west_2.txt",
         "1959",
         "2185",
         "RU",
         "Такая истерика вокруг закона об иноагентах может говорить только о том, что есть решения Вашингтона и Брюсселя по свержению действующей грузинской власти и деньги на это уже выделены, а принятие закона может эти планы сорвать.",
         "False",
         "[]",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Questioning_the_Reputation",
         "Questioning_the_Reputation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Questioning the Reputation technique is not used in the input.",
         "\"\"",
         "[None]",
         "[False]",
         "['{\\n  \"explanation\": \"The input text does not contain any explicit attacks on the reputation or moral character of a target. It discusses political implications without undermining anyone\\'s reputation, which aligns with the expert\\'s verdict that the technique was not used.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/ru/train-ru-part_0008.parquet",
         null,
         null,
         "train",
         "{\"description\": null, \"verdict\": false}"
        ],
        [
         "11749",
         "RU_discrediting_the_west_1.txt",
         "1468",
         "1612",
         "RU",
         "Подобные проявления только сначала выглядят игрой и шуткой.\nЗа этим скрывается серьезная программа отказа от человечности и всего человеческого.",
         "False",
         "[]",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Questioning_the_Reputation",
         "Questioning_the_Reputation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Questioning the Reputation technique is not used in the input.",
         "\"\"",
         "[None]",
         "[False]",
         "['{\\n  \"explanation\": \"The input text does not contain any explicit negative claims about a target\\'s reputation or character. It discusses a serious program but does not attack or undermine the reputation of any specific individual or group, which is necessary for the Questioning the Reputation technique to be applicable.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/ru/train-ru-part_0008.parquet",
         null,
         null,
         "train",
         "{\"description\": null, \"verdict\": false}"
        ],
        [
         "11833",
         "SI_interpelation_interior_10.txt",
         "3284",
         "3366",
         "SI",
         "Hvala. Besedo ima Poslanska skupina Levica, zanjo kolegica Nataša Sukič. Izvolite.",
         "False",
         "[]",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Questioning_the_Reputation",
         "Questioning_the_Reputation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Questioning the Reputation technique is not used in the input.",
         "\"\"",
         "[None]",
         "[False]",
         "['{\\n  \"explanation\": \"The input text does not contain any elements that attack the reputation of a target or make negative claims about it. There are no indications of undermining character or moral stature, which are essential for the use of the Questioning the Reputation technique.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/si/train-si-part_0007.parquet",
         null,
         null,
         "train",
         "{\"description\": null, \"verdict\": false}"
        ],
        [
         "11834",
         "SI_interpelation_interior_6.txt",
         "177",
         "268",
         "SI",
         "Hvala spoštovana predsednica za besedo. Lep pozdrav predstavniki Vlade, kolegi in kolegice.",
         "False",
         "[]",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Questioning_the_Reputation",
         "Questioning_the_Reputation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Questioning the Reputation technique is not used in the input.",
         "\"\"",
         "[None]",
         "[False]",
         "['{\\n  \"explanation\": \"The input text does not contain any elements that attack the reputation of a target or make negative claims about it. It is a neutral greeting without any indication of undermining character or moral stature.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/si/train-si-part_0007.parquet",
         null,
         null,
         "train",
         "{\"description\": null, \"verdict\": false}"
        ],
        [
         "11837",
         "SI_interpelation_interior_8.txt",
         "955",
         "966",
         "SI",
         "Hvala lepa.",
         "False",
         "[]",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Questioning_the_Reputation",
         "Questioning_the_Reputation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Questioning the Reputation technique is not used in the input.",
         "\"\"",
         "[None]",
         "[False]",
         "['{\\n  \"explanation\": \"The input text does not contain any elements that attack or undermine the reputation of a target. It is a simple expression of gratitude and does not engage in any negative claims about anyone\\'s character or moral stature.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/si/train-si-part_0007.parquet",
         null,
         null,
         "train",
         "{\"description\": null, \"verdict\": false}"
        ],
        [
         "11838",
         "SI_interpelation_interior_0.txt",
         "2778",
         "2896",
         "SI",
         "Interpelacijo je v obravnavo zboru predložila skupina poslank in poslancev s prvopodpisanim Janezom Ciglerjem Kraljem.",
         "False",
         "[]",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Questioning_the_Reputation",
         "Questioning_the_Reputation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Questioning the Reputation technique is not used in the input.",
         "\"\"",
         "[None]",
         "[False]",
         "['{\\n  \"explanation\": \"The input text does not contain any elements that attack the reputation of an individual or group. It simply states that a group of representatives, led by Janez Cigler Kralj, has submitted an interpellation. There are no negative claims or attempts to undermine character present in the text.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/si/train-si-part_0007.parquet",
         null,
         null,
         "train",
         "{\"description\": null, \"verdict\": false}"
        ],
        [
         "11949",
         "20240112_SHG_BG_60.txt",
         "6122",
         "6481",
         "BG",
         "Стриктното прилагане означава точно това и Вие много добре го знаете. Самите европейски държави не го прилагат. Да Ви кажа ли каква е грубата бройка, защото сега нямах време да ги сметна, на лицата по Дъблинския регламент за 2022 г., защото за 2023 г. още няма тази информация? Малко над 600 хиляди души. Че те само през България минават 300 хиляди на година.",
         "True",
         "['Appeal_to_Popularity']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Самите европейски държави не го прилагат']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Questioning_the_Reputation",
         "Questioning_the_Reputation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Questioning the Reputation technique is not used in the input.",
         "\"\"",
         "[None]",
         "[False]",
         "['{\\n  \"explanation\": \"The input text does not contain any elements that attack the reputation of a target or make strong negative claims about it. It focuses on presenting factual information regarding the application of a regulation and statistics, without undermining anyone\\'s character or moral stature.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/bg/train-bg-part_0007.parquet",
         null,
         null,
         "train",
         "{\"description\": null, \"verdict\": false}"
        ],
        [
         "11951",
         "20240704_URW_BG_25.txt",
         "5302",
         "5341",
         "BG",
         "ава ще подложа на гласуване процедурата",
         "False",
         "[]",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Questioning_the_Reputation",
         "Questioning_the_Reputation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Questioning the Reputation technique is not used in the input.",
         "\"\"",
         "[None]",
         "[False]",
         "['{\\n  \"explanation\": \"The input text does not contain any elements that attack or undermine the reputation of a target. There are no strong negative claims made about any individual or group, nor is there an attempt to bias the audience\\'s perception regarding someone\\'s character or moral stature. Therefore, the Questioning the Reputation technique is not used.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/bg/train-bg-part_0007.parquet",
         null,
         null,
         "train",
         "{\"description\": null, \"verdict\": false}"
        ],
        [
         "11952",
         "20231208_URW_BG_76.txt",
         "4199",
         "4532",
         "BG",
         "Така че тук в залата еничари, господин Професоре, няма. Вие не сте историк, затова няма как да го знаете. Тук има спахии-християни – хора, които доброволно се продали на чужди държави; хора, които доброволно, обслужвайки чужди национални интереси, доброволно продават и предават своята национална чест и достойнство. (Шум и реплики.)",
         "True",
         "['Questioning_the_Reputation' 'Name_Calling-Labeling']",
         "train",
         "['Тук има спахии-християни – хора, които доброволно се продали на чужди държави; хора, които доброволно, обслужвайки чужди национални интереси, доброволно продават и предават своята национална чест и достойнство']",
         "['еничари' 'спахии-християни']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Questioning_the_Reputation",
         "Questioning_the_Reputation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "1",
         "Yes, the Questioning the Reputation technique is used in the input.",
         "\"Тук има спахии-християни – хора, които доброволно се продали на чужди държави; хора, които доброволно, обслужвайки чужди национални интереси, доброволно продават и предават своята национална чест и достойнство\"",
         "[None]",
         "[False]",
         "['{\\n  \"explanation\": \"The Questioning the Reputation technique is explicitly used in the input text by labeling individuals as \\'спахии-християни\\' (Christian spahis) and accusing them of selling out to foreign states and betraying their national honor and dignity. This strong negative characterization undermines their moral stature and reputation, aligning with the technique\\'s definition of attacking the target\\'s character rather than engaging in a substantive argument.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/bg/train-bg-part_0007.parquet",
         null,
         null,
         "train",
         "{\"description\": null, \"verdict\": true}"
        ],
        [
         "11953",
         "20231208_URW_BG_76.txt",
         "6506",
         "6670",
         "BG",
         "На 14 декември 1941 г. от трибуната на Народното събрание Богдан Филов чете декларация за обявяване на война на правителството на Съединените щати и Великобритания.",
         "True",
         "['Red_Herring']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Questioning_the_Reputation",
         "Questioning_the_Reputation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Questioning the Reputation technique is not used in the input.",
         "\"\"",
         "[None]",
         "[False]",
         "['{\\n  \"explanation\": \"The input text does not contain any elements that attack the reputation of a target or make negative claims about it. It simply states a historical fact without undermining anyone\\'s character or moral stature.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/bg/train-bg-part_0007.parquet",
         null,
         null,
         "train",
         "{\"description\": null, \"verdict\": false}"
        ],
        [
         "13460",
         "SI_interpelation_interior_7.txt",
         "839",
         "2596",
         "SI",
         "Naslednji primer: žena pomočnika generalnega direktorja policije, ki na policiji opravlja piar službo, se prevaža s protokolarnim vozilom, ki je namenjeno za prevoze varovanih oseb in ne uslužbencev policije. Ko policijska voznica v poročilu navede, koga je prevažala, mora po navodilu pomočnika generalnega direktorja policije, ki je mož te osebe, poročilo popraviti. Prav tako je kasneje s strani vodstva šikanirana. Namestnik generalnega direktorja policije, torej mož piarovke, si za službeno vozilo prilasti novo toyoto, ostalim pa v uporabo nameni stara vozila. Zoper svetovalca generalnega direktorja, zdaj že bivšega generalnega direktorja za področje gospodarske in korupcijske kriminalitete, bi pa naj bilo podanih kar več kaznivih ovadb. Da je stanje v policiji slabo, dokazuje tudi poročilo iz prvega polletja leta 2023, iz katerega je razvidno, da se je število kaznivih dejanj znatno povečalo, število preiskanosti in odkritosti z lastno dejavnostjo pa znatno zmanjšalo. Povečala se je uporaba prisilnih sredstev in izdanih plačilnih nalogov, število opozoril se je zmanjšalo, prav tako se v deželici z imenom Slovenija v časih golobistov prične na meji odstranjevati ograja. S tem se ilegalnim migrantom sporoči, da je prehod preko Slovenije lažji, zato se prične znatno povečevati število ilegalnih prehodov meje. Migranti se tako množično gibajo po naseljih ob hrvaški meji, kar povzročajo, povzroča strah in nelagodje tamkajšnjim prebivalcem. Število je že tako veliko, da kapacitete v azilnih domovih več ne zadoščajo, zato vlada sklene, da bo v Obrežju in v Središču ob Dravi uredila izpostave azilnega doma, ne da bi se o tem predhodno posvetovala z lokalno skupnostjo. To seveda povzroči nestrinjanje in upor tamkajšnjega prebivalstva.",
         "True",
         "['Causal_Oversimplification' 'Exaggeration-Minimisation'\n 'Appeal_to_Hypocrisy' 'Loaded_Language' 'Appeal_to_Pity'\n 'Obfuscation-Vagueness-Confusion' 'Questioning_the_Reputation'\n 'Name_Calling-Labeling' 'Doubt' 'Repetition' 'Appeal_to_Fear-Prejudice']",
         "train",
         "['mora po navodilu pomočnika generalnega direktorja policije, ki je mož te osebe, poročilo popraviti']",
         "['golobistov']",
         "['žena pomočnika generalnega direktorja policije, ki na policiji opravlja piar službo, se prevaža s protokolarnim vozilom, ki je namenjeno za prevoze varovanih oseb in ne uslužbencev policije'\n 'Namestnik generalnega direktorja policije, torej mož piarovke, si za službeno vozilo prilasti novo toyoto, ostalim pa v uporabo nameni stara vozila'\n 'Zoper svetovalca generalnega direktorja, zdaj že bivšega generalnega direktorja za področje gospodarske in korupcijske kriminalitete, bi pa naj bilo podanih kar več kaznivih ovadb']",
         "[]",
         "['šikanirana' 'ilegalnim migrantom']",
         "['golobistov']",
         "[]",
         "['s strani vodstva šikanirana']",
         "[]",
         "[]",
         "['stara vozila' 'množično gibajo po naseljih ob hrvaški meji']",
         "[]",
         "['s strani vodstva šikanirana']",
         "[]",
         "[]",
         "['prisilnih sredstev']",
         "[]",
         "[]",
         "['zato se prične znatno povečevati število ilegalnih prehodov meje'\n 'Migranti se tako množično gibajo po naseljih ob hrvaški meji, kar povzročajo, povzroča strah in nelagodje tamkajšnjim prebivalcem']",
         "['S tem se ilegalnim migrantom sporoči, da je prehod preko Slovenije lažji, zato se prične znatno povečevati število ilegalnih prehodov meje']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Guilt_by_Association",
         "Guilt_by_Association",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Guilt by Association technique is not used in the input.",
         "\"\"",
         "[None]",
         "[False]",
         "['{\\n  \"explanation\": \"The input text does not employ the Guilt by Association technique, as it does not attempt to link any individual, group, or activity to another with negative connotations. The narrative focuses on specific incidents and issues within the police and migration context without making associative attacks.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Guilt_by_Association/train/si/train-si-part_0006.parquet",
         null,
         null,
         "train",
         "{\"description\": null, \"verdict\": false}"
        ],
        [
         "13467",
         "SI_interpelation_interior_6.txt",
         "270",
         "7305",
         "SI",
         "Na eni izmed sej Odbora za notranje zadeve mi je predsednica odbora dejala, da sem pravljičar, zato mi spoštovani kolegi in kolegice dovolite, da vam v imenu Poslanske skupine Slovenske demokratske stranke povem zgodbo, ki morda ni pravljica in se glasi takole. Tam, na sončni strani Alp, so v deželici z imenom Slovenija nedolgo nazaj vladali janšisti. Prišel je čas volitev in oblast so prevzeli golobisti. Tik pred prevzemom oblasti njihov vodja k sebi pokliče novo ministrico za notranje zadeve in novega vršilca dolžnosti generalnega direktorja policije in jima naroči: Imata eno samo nalogo in to je, da policijo očistita janšistov. Oba vestno pričneta z opravljanjem ukazane naloge in na vodilnih položajih policije zamenjujeta osebe, ki naj bi bili janšisti. Še posebej direktorja, tam na mojem koncu, kot je dejal njihov vodja, in direktor Nacionalnega preiskovalnega urada, kajti prav ta urad preiskuje vodjo golobistov, zaradi ukradene identitete v Romuniji in kup denarja na tamkajšnjem računu, nakazila novinarki Vesni Vuković za neznane usluge in balkanskim poslovanjem denarja. Pri svojem delu pa naletita na težavo, kdo je janšist in kdo ne, saj so določene osebe, menita, da zamenjava ni potrebna. To povzroči nezadovoljstvo pri vodji in zato vršilca dolžnosti generalnega direktorja policije vrže čez ramo in ga noče imenovati za generalnega direktorja policije. Temu se ministrica upre in odstopi. Praznino v vodenju notranjega ministrstva izkoristi človek iz ozadja, ki sicer deluje na drugem ministrstvu in vodji predlaga osebo, ki bo pa poslušna. In tako minister za notranje zadeve postane Boštjan Poklukar. No, in novi minister Boštjan Poklukar prične z delom, seveda s poslušnim delom. Najprej o tem, kako naj bi delovalo policija in ministrstvo sicer ne posvetuje z ustreznimi strokovnjaki, ampak pogovor opravi z Jašo Jenulom, torej osebo, ki je bila v času vodenja janšistov večkrat kaznovana, ker je pozival k neprijavljenim protestom. Nato kljub temu, da je znotraj policije na desetine visoko izobraženih ter usposobljenih kadrov, na željo vodje golobistov za vršilca dolžnosti generalnega direktorja policije imenuje Senada Jušića, ki seveda nima vodstvenih izkušenj, saj je v preteklosti deloval zgolj kot pomočnik vodje na lokalnem nivoju. Imenovanje za vršilca dolžnosti generalnega direktorja policije pa naj bi bilo celo nezakonito, saj se ob njegovi premestitvi ne bi opravilo varnostno preverjanje, kar je sicer vedno obvezno o premestitvi na višje delovno mesto. Senad Jušić je tako nezakonito imenovan kasneje za generalnega direktorja Policije, saj Uradniški svet pri sklepu o izpolnitvi pogojev upošteva neke interne akte policije in za to poda tudi pomanjkljivo obrazložitev, ker seveda nimajo kaj obrazložiti. Ker bivši vršilec dolžnosti generalnega direktorja policije to ve, poda tožbo na Upravno sodišče, ki seveda razsodi, da je sklep natečajne komisije nezakonit, tako da je tudi imenovanje Senada Jušića za generalnega direktorja Policije nezakonito. Vodja golobistov, generalni direktor Policije, kakor tudi minister Poklukar se sprenevedajo, zanemarjajo sistem pravne države in ne spoštujejo sodbe. Jušića varujejo pred očitki, tako daleč, da se mora v to dogajanje vključiti sam striček iz ozadja in po 83 dneh Senad Jušić odstopi. Seveda v času vodenja policije s strani Senada Jušića postajajo razmere na policiji iz dneva v dan bolj kritične in dosežejo najnižjo točko v sistem delovanja policije v zgodovini Slovenije. Nestrokovni vodje svojo nestrokovnost prenašajo na policiste in policiste. Na njih izvajajo pritiske. Policisti in policistke več ne vedo kako naj delajo, kako naj postopajo, da bo prav in da zoper njih ne bodo uvedene sankcije. Strah jih je, delajo več nadur in tako dalje. Tako se policisti raje umaknejo, kot bi posredovali v eni izmed garažnih hiš v Ljubljani, kjer so policijsko patruljo ob posredovanju obkrožili zbrani mladostniki in preprečevali vožnjo. Policista se z vozilom umakneta. Prav tako se v Ljubljani zbere množica ljudi, ki z avtomobili hupa, drifta s strelnim orožjem strelja v zrak in na eno izmed policijskih vozil celo namesti albansko zastavo. Na jugovzhodnem delu te deželice se pojavijo težave, saj policija ni več kos kaznivim dejanjem, tamkajšnjim živečim Romom, ki kršijo prometne predpise, izvajajo tatvine, ustrahujejo, pretepajo, uporabljajo strelno orožje in tako dalje. Slovenija postane tudi raj za hudodelske združbe, ki med sabo obračunavajo kar sredi dneva, izvajajo likvidacije, umore, in to kar pred očmi otrok. Prav tako umorijo skesanca, ki ga policija ne zaščiti kljub opozorilom o njegovi likvidaciji. V priljubljenem velenjskem lokalu ob pretepu poseduje lastnik tega lokala, ki pa je med najbolj iskanimi osebami v Evropi na Interpolovi tiralici, zaradi sodelovanja v kriminalni združbi v Bosni in Hercegovini. Kljub obsodbi na leto in pol zapora brez težav torej opravlja ta lokal, se svobodno giba po Sloveniji, saj ga policija ne aretira. Varnost v državi se iz leta v leto slabša, kar dokazuje podatek globalnega indeksa miru, ker je Slovenija iz četrtega mesta v letu 2020 v lanskem letu 2024 zdrsnila na deveto mesto. Policisti in policistke tako množično zapuščajo policijske vrste: bodisi se upokojijo ali pa si poiščejo boljšo zaposlitev in podajo odpoved. Novih zaposlitev ni. Zdesetkana, policija ne zmore več opravljati nalog, ki jih je dolžna izvajati. V času janšistov, torej v letu 2020 in 2021 je bilo kar 164 odstotkov več prihodov kot odhodov. V času golobistov, v letu 2022 in vaju 24 je pa bilo 60 odstotkov več. Torej, manj prihodov kot odhodov. Od tega v času ministrovanja Boštjana Poklukarja, torej v letu 23 in 24 za 51 odstotkov manj prihodov kot odhodov. Kljub temu, da je denarja v davčni blagajni rekordno veliko se za promocijo poklica policist, policijska ne namenjajo namenska finančna sredstva, ki bi imela v proračunu svojo postavko, kot jo ima to na primer vojska. Poslabšanje organizacijske klime v policiji dokazuje tudi raziskava odbora za integriteto in etiko v policiji, saj so se rezultati pod vodstvom Boštjana Poklukarja znatno poslabšali. Medtem se v vodstvenih vrstah izvajajo različne mahinacije, kot so naslednji; minister Poklukar podpiše novo sistemizacijo delovnih mest na Policijski upravi Maribor, kjer se omogoči zaposlitev izbrane osebe za pomočnika direktorja Policijske uprave. Njihovo namero na žalost tik pred iztekom roka razpise prekine poslanec iz naše poslanske skupine, ki na to temo poda pisno poslansko vprašanje. Tako v istem dnevu razpis prekličejo, zamenjajo priloge te sistemizacije in razpišejo novo delovno mesto, in sicer za policijskega svetnika na Policijski upravi. Ta oseba se na ta razpis prijavi in se tudi zaposli. V odgovoru na pisno poslansko vprašanje poslanca naše poslanske skupine se pa minister zlaže, da je zaposlitev policijskega svetnika na PU Maribor potrebna zaradi povečanega števila kaznivih dejanj Romov iz Hrvaške na območju Policijske postaje Ormož in Gorišnica in zaradi povečanega števila migracij na tem območju.",
         "True",
         "['Loaded_Language' 'Obfuscation-Vagueness-Confusion'\n 'Name_Calling-Labeling' 'Red_Herring' 'Guilt_by_Association' 'Doubt'\n 'Causal_Oversimplification' 'Exaggeration-Minimisation'\n 'Questioning_the_Reputation' 'Appeal_to_Authority' 'Appeal_to_Values'\n 'False_Dilemma-No_Choice' 'Repetition' 'Appeal_to_Fear-Prejudice']",
         "train",
         "['Še posebej direktorja, tam na mojem koncu, kot je dejal njihov vodja, in direktor Nacionalnega preiskovalnega urada, kajti prav ta urad preiskuje vodjo golobistov, zaradi ukradene identitete v Romuniji in kup denarja na tamkajšnjem računu, nakazila novinarki Vesni Vuković za neznane usluge in balkanskim poslovanjem denarja'\n 'Praznino v vodenju notranjega ministrstva izkoristi človek iz ozadja, ki sicer deluje na drugem ministrstvu in vodji predlaga osebo, ki bo pa poslušna'\n 'minister zlaže']",
         "['golobisti' 'janšistov' 'janšisti' 'janšistov' 'golobistov' 'golobistov'\n 'janšistov' 'golobistov']",
         "[]",
         "[]",
         "['janšisti' 'golobisti' 'janšist' 'vrže čez ramo' 'striček iz ozadja'\n 'deželice' 'hudodelske združbe' 'Zdesetkana' 'mahinacije']",
         "['janšisti' 'janšist' 'janšistov' 'golobistov' 'nezakonito' 'golobistov'\n 'janšistov' 'golobistov']",
         "[]",
         "['seveda s poslušnim delom'\n 'Nato kljub temu, da je znotraj policije na desetine visoko izobraženih ter usposobljenih kadrov, na željo vodje golobistov za vršilca dolžnosti generalnega direktorja policije imenuje Senada Jušića, ki seveda nima vodstvenih izkušenj, saj je v preteklosti deloval zgolj kot pomočnik vodje na lokalnem nivoju'\n 'Senad Jušić je tako nezakonito imenovan kasneje za generalnega direktorja Policije']",
         "['Na eni izmed sej Odbora za notranje zadeve mi je predsednica odbora dejala, da sem pravljičar, zato mi spoštovani kolegi in kolegice dovolite, da vam v imenu Poslanske skupine Slovenske demokratske stranke povem zgodbo, ki morda ni pravljica in se glasi takole'\n 'Tam, na sončni strani Alp, so v deželici z imenom Slovenija nedolgo nazaj vladali janšisti. Prišel je čas volitev in oblast so prevzeli golobisti. Tik pred prevzemom oblasti njihov vodja k sebi pokliče novo ministrico za notranje zadeve in novega vršilca dolžnosti generalnega direktorja policije in jima naroči: Imata eno samo nalogo in to je, da policijo očistita janšistov'\n 'Oba vestno pričneta z opravljanjem ukazane naloge in na vodilnih položajih policije zamenjujeta osebe, ki naj bi bili janšisti. Še posebej direktorja, tam na mojem koncu, kot je dejal njihov vodja, in direktor Nacionalnega preiskovalnega urada, kajti prav ta urad preiskuje vodjo golobistov, zaradi ukradene identitete v Romuniji in kup denarja na tamkajšnjem računu, nakazila novinarki Vesni Vuković za neznane usluge in balkanskim poslovanjem denarja. Pri svojem delu pa naletita na težavo, kdo je janšist in kdo ne, saj so določene osebe, menita, da zamenjava ni potrebna. To povzroči nezadovoljstvo pri vodji in zato vršilca dolžnosti generalnega direktorja policije vrže čez ramo in ga noče imenovati za generalnega direktorja policije. Temu se ministrica upre in odstopi. Praznino v vodenju notranjega ministrstva izkoristi človek iz ozadja, ki sicer deluje na drugem ministrstvu in vodji predlaga osebo, ki bo pa poslušna']",
         "[]",
         "['eno samo nalogo' 'zgolj kot pomočnik vodje na lokalnem nivoju'\n 'iz dneva v dan bolj kritične in dosežejo najnižjo točko v sistem delovanja policije v zgodovini Slovenije'\n 'Slovenija postane tudi raj za hudodelske združbe, ki med sabo obračunavajo kar sredi dneva, izvajajo likvidacije, umore, in to kar pred očmi otrok'\n 'najbolj iskanimi osebami v Evropi na Interpolovi tiralici' 'množično'\n 'V času janšistov, torej v letu 2020 in 2021 je bilo kar 164 odstotkov več prihodov kot odhodov'\n 'rekordno veliko' 'znatno poslabšali']",
         "[]",
         "[]",
         "[]",
         "['nezakonito' 'nezakonito'\n 'Vodja golobistov, generalni direktor Policije, kakor tudi minister Poklukar se sprenevedajo, zanemarjajo sistem pravne države in ne spoštujejo sodbe'\n 'Nestrokovni vodje svojo nestrokovnost prenašajo na policiste in policiste']",
         "['človek iz ozadja' 'neke interne akte policije' 'uvedene sankcije']",
         "[]",
         "[]",
         "['očistita janšistov'\n 'Nestrokovni vodje svojo nestrokovnost prenašajo na policiste in policiste. Na njih izvajajo pritiske'\n 'Policisti in policistke več ne vedo kako naj delajo, kako naj postopajo, da bo prav in da zoper njih ne bodo uvedene sankcije. Strah jih je, delajo več nadur in tako dalje'\n 'Prav tako se v Ljubljani zbere množica ljudi, ki z avtomobili hupa, drifta s strelnim orožjem strelja v zrak in na eno izmed policijskih vozil celo namesti albansko zastavo'\n 'Na jugovzhodnem delu te deželice se pojavijo težave, saj policija ni več kos kaznivim dejanjem, tamkajšnjim živečim Romom, ki kršijo prometne predpise, izvajajo tatvine, ustrahujejo, pretepajo, uporabljajo strelno orožje in tako dalje'\n 'Slovenija postane tudi raj za hudodelske združbe, ki med sabo obračunavajo kar sredi dneva, izvajajo likvidacije, umore, in to kar pred očmi otrok'\n 'Prav tako umorijo skesanca, ki ga policija ne zaščiti kljub opozorilom o njegovi likvidaciji'\n 'V priljubljenem velenjskem lokalu ob pretepu poseduje lastnik tega lokala, ki pa je med najbolj iskanimi osebami v Evropi na Interpolovi tiralici, zaradi sodelovanja v kriminalni združbi v Bosni in Hercegovini'\n 'Kljub obsodbi na leto in pol zapora brez težav torej opravlja ta lokal, se svobodno giba po Sloveniji, saj ga policija ne aretira'\n 'povečanega števila kaznivih dejanj Romov']",
         "['Varnost v državi se iz leta v leto slabša, kar dokazuje podatek globalnega indeksa miru, ker je Slovenija iz četrtega mesta v letu 2020 v lanskem letu 2024 zdrsnila na deveto mesto'\n 'Od tega v času ministrovanja Boštjana Poklukarja, torej v letu 23 in 24 za 51 odstotkov manj prihodov kot odhodov']",
         "['Nato kljub temu, da je znotraj policije na desetine visoko izobraženih ter usposobljenih kadrov'\n 'odbora za integriteto in etiko v policiji']",
         "['bodisi se upokojijo ali pa si poiščejo boljšo zaposlitev in podajo odpoved']",
         "[]",
         "[]",
         "['sicer ne posvetuje z ustreznimi strokovnjaki, ampak pogovor opravi z Jašo Jenulom, torej osebo, ki je bila v času vodenja janšistov večkrat kaznovana, ker je pozival k neprijavljenim protestom']",
         "train",
         "GPT_41/v001/Guilt_by_Association",
         "Guilt_by_Association",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "1",
         "Yes, the Guilt by Association technique is used in the input.",
         "\"sicer ne posvetuje z ustreznimi strokovnjaki, ampak pogovor opravi z Jašo Jenulom, torej osebo, ki je bila v času vodenja janšistov večkrat kaznovana, ker je pozival k neprijavljenim protestom\"",
         "[None]",
         "[False]",
         "['{\\n  \"explanation\": \"The Guilt by Association technique is used in the input text by linking Jaša Jenul, who has a negative history of being punished for calling for unauthorized protests, to the current minister\\'s actions. This association implies that the current minister\\'s decisions are similarly questionable or problematic due to his connection with Jenul, who is associated with the previous \\'janšist\\' regime, which carries negative connotations for the audience.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Guilt_by_Association/train/si/train-si-part_0006.parquet",
         null,
         null,
         "train",
         "{\"description\": null, \"verdict\": true}"
        ],
        [
         "13506",
         "SI_interpelation_interior_11.txt",
         "3647",
         "7212",
         "SI",
         "Zamislite si, NSi problema z uporabo nacističnih in fašističnih simbolov nima, kajne, danes pa bi rušila ministra. Narobe svet. Pravzaprav dobrodošli v strašljivi novi krasni svet, ki ga vse bolj poosebljajo novi fašizmi, ki v Evropi in po svetu dvigajo glavo in ki predlagatelje današnje interpelacije očitno niti malo ne motijo. Kot jih ni motil Poklukarjev predhodnik, nekdanji minister Hojs, človek, ki je bil zdaleč najbolj brutalni notranji minister v zgodovini te države. Minister, ki je označil rumene jopiče, malikovalce Hitlerja, za bisere. Minister, ki je s svojimi zakoni in s svojim obnašanjem omogočal in demonstriral politično vmešavanje v delo policije in še več političnega kadrovanja, ki je podrejal in ustrahoval tako policijo kot državljane, ki je policijo instrumentaliziral za represijo nad državljankami in državljani, ki so si kakorkoli drznili kritizirati Janševo oblast, v kateri je veselo kolaborirala tudi NSi. Oblast, ki je, kot vemo, povsem izgubila kompas, ko se je nad ljudstvo spravila z vodnim topom s solzivcem in pendreki, in je zaplinila širši center prestolnice. Niti to jih ni zmotilo, da je Hojs sam podal odstopno izjavo, Janša pa kuverte z odstopom ni nikdar odprl. Je NSi takrat reagirala, kot bi se spodobilo od neke državotvorne in kredibilne politične stranke? So oni kadarkoli kogarkoli kot Janševi koalicijski partnerji pozvali k sprejetju odgovornosti? So po škandaloznem zaplinjanju Ljubljane k odstopu pozvali takratnega generalnega direktorja policije? Seveda ne. Bili so tiho kot miške, danes pa s polnimi jadri in pljuči uprizarjajo politični cirkus v optimističnem, čeprav Sizifovem poskusu destabilizirati vladajočo koalicijo in v žep pospraviti nekaj cenenih političnih točk. Zato je današnja interpelacija zoper ministra dobesedno patetična. Mar res mislite v NSi, da imamo državljanke in državljani spomin zlate ribice, da je nastopila vsesplošna in množična amnezija in se nihče več ne spomni vašega pridnega asistiranja pri najbolj brutalnem obračunavanju z ljudstvom po taktirko Hojsa, kar ga pomnimo v tej državi. Toliko o vaši kredibilnosti. Zato o ostalih navedbah interpelacije in strokovnjaških ocenah iz nje, kot so razne preplačane stražarske hiške ali prepočasno delovanje NPU in podobno, ne mislim tratiti besed. Glede na dvojna merila predlagateljev in njihove več kot očitno bizarne kriterije o tem kaj varnost je in kaj ni, res ne. V Levici nismo skrivali zaskrbljenosti ob razkritjih situacije na CVZ ob aferi Gončin in tudi ne glede dvomov pri imenovanju nekdanjega generalnega direktorja Jušića. Bili smo kritični in jasni, povedali smo, da je v primeru CVZ potrebno sprejeti politično odgovornost in povedali smo, da bi v imenu politične higiene in transparentnosti nekdanji direktor moral že takoj, ko je sodišče presodilo, da je sklep o njegovem izpolnjevanju pogojev za generalnega direktorja policije nezakonit, odstopiti in s tem omogočiti ponovitev razpisa. Ko se je k temu pritaknila še afera v zvezi s škandaloznim stanjem na CVZ, smo izrazili pričakovanje, da Jušić kot neposredno odgovorna oseba za stanje stvari na CVZ odstopi. Kar se je potem dejansko tudi zgodilo in s čimer je, kot rečeno, nekdanji generalni direktor razbremenil policijo, pa konec koncev tudi ministra Poklukarja. Skratka, razkritja glede CVZ so zaenkrat dobila ustrezen epilog in s tem je za nas trenutno ta zgodba zaključena. Higienski minimum je z odstopom generalnega direktorja dosežen, zaupanje v policijo pa ubranjeno. V Levici se bomo ob interpelaciji v luči vsega povedanega vzdržali. Hvala lepa.",
         "True",
         "['Causal_Oversimplification' 'Exaggeration-Minimisation'\n 'Appeal_to_Hypocrisy' 'Loaded_Language' 'Whataboutism'\n 'Questioning_the_Reputation' 'Appeal_to_Values' 'Guilt_by_Association'\n 'Appeal_to_Popularity' 'Appeal_to_Fear-Prejudice']",
         "train",
         "['Je NSi takrat reagirala, kot bi se spodobilo od neke državotvorne in kredibilne politične stranke?'\n 'So oni kadarkoli kogarkoli kot Janševi koalicijski partnerji pozvali k sprejetju odgovornosti?'\n 'So po škandaloznem zaplinjanju Ljubljane k odstopu pozvali takratnega generalnega direktorja policije?'\n 'Toliko o vaši kredibilnosti']",
         "[]",
         "['Zamislite si, NSi problema z uporabo nacističnih in fašističnih simbolov nima, kajne, danes pa bi rušila ministra'\n 'Kot jih ni motil Poklukarjev predhodnik, nekdanji minister Hojs, človek, ki je bil zdaleč najbolj brutalni notranji minister v zgodovini te države'\n 'Bili so tiho kot miške, danes pa s polnimi jadri in pljuči uprizarjajo politični cirkus v optimističnem, čeprav Sizifovem poskusu destabilizirati vladajočo koalicijo in v žep pospraviti nekaj cenenih političnih točk'\n 'Mar res mislite v NSi, da imamo državljanke in državljani spomin zlate ribice, da je nastopila vsesplošna in množična amnezija in se nihče več ne spomni vašega pridnega asistiranja pri najbolj brutalnem obračunavanju z ljudstvom po taktirko Hojsa, kar ga pomnimo v tej državi'\n 'Glede na dvojna merila predlagateljev in njihove več kot očitno bizarne kriterije o tem kaj varnost je in kaj ni, res ne']",
         "[]",
         "['strašljivi novi krasni svet' 'brutalni'\n 'rumene jopiče, malikovalce Hitlerja' 'politični cirkus'\n 'Sizifovem poskusu' 'pridnega asistiranja' 'strokovnjaških ocenah']",
         "[]",
         "['kot vemo']",
         "[]",
         "[]",
         "[]",
         "['Oblast, ki je, kot vemo, povsem izgubila kompas, ko se je nad ljudstvo spravila z vodnim topom s solzivcem in pendreki, in je zaplinila širši center prestolnice'\n 'spomin zlate ribice, da je nastopila vsesplošna in množična amnezija'\n 'pridnega asistiranja pri najbolj brutalnem obračunavanju z ljudstvom po taktirko Hojsa, kar ga pomnimo v tej državi'\n 'Skratka, razkritja glede CVZ so zaenkrat dobila ustrezen epilog in s tem je za nas trenutno ta zgodba zaključena']",
         "[]",
         "[]",
         "[]",
         "['Bili smo kritični in jasni'\n 'v imenu politične higiene in transparentnosti']",
         "[]",
         "[]",
         "[]",
         "['dobrodošli v strašljivi novi krasni svet, ki ga vse bolj poosebljajo novi fašizmi'\n 'ko se je nad ljudstvo spravila z vodnim topom s solzivcem in pendreki, in je zaplinila širši center prestolnice']",
         "['Higienski minimum je z odstopom generalnega direktorja dosežen, zaupanje v policijo pa ubranjeno']",
         "[]",
         "[]",
         "['Niti to jih ni zmotilo, da je Hojs sam podal odstopno izjavo, Janša pa kuverte z odstopom ni nikdar odprl. Je NSi takrat reagirala, kot bi se spodobilo od neke državotvorne in kredibilne politične stranke? So oni kadarkoli kogarkoli kot Janševi koalicijski partnerji pozvali k sprejetju odgovornosti? So po škandaloznem zaplinjanju Ljubljane k odstopu pozvali takratnega generalnega direktorja policije?']",
         "[]",
         "['Zamislite si, NSi problema z uporabo nacističnih in fašističnih simbolov nima, kajne, danes pa bi rušila ministra'\n 'Minister, ki je s svojimi zakoni in s svojim obnašanjem omogočal in demonstriral politično vmešavanje v delo policije in še več političnega kadrovanja, ki je podrejal in ustrahoval tako policijo kot državljane, ki je policijo instrumentaliziral za represijo nad državljankami in državljani, ki so si kakorkoli drznili kritizirati Janševo oblast, v kateri je veselo kolaborirala tudi NSi']",
         "train",
         "GPT_41/v001/Guilt_by_Association",
         "Guilt_by_Association",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "1",
         "Yes, the Guilt by Association technique is used in the input.",
         "\"Zamislite si, NSi problema z uporabo nacističnih in fašističnih simbolov nima, kajne, danes pa bi rušila ministra Minister, ki je s svojimi zakoni in s svojim obnašanjem omogočal in demonstriral politično vmešavanje v delo policije in še več političnega kadrovanja, ki je podrejal in ustrahoval tako policijo kot državljane, ki je policijo instrumentaliziral za represijo nad državljankami in državljani, ki so si kakorkoli drznili kritizirati Janševo oblast, v kateri je veselo kolaborirala tudi NSi\"",
         "[None]",
         "[False]",
         "['{\\n  \"explanation\": \"The Guilt by Association technique is explicitly used in the input text by linking the NSi party to negative connotations associated with Nazi and fascist symbols. The speaker suggests that NSi\\'s lack of concern about these symbols implies complicity in the oppressive actions of the government, particularly under Minister Hojs, who is described as brutal and repressive. This association creates a negative perception of NSi by connecting it to historically condemned ideologies and actions.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Guilt_by_Association/train/si/train-si-part_0001.parquet",
         null,
         null,
         "train",
         "{\"description\": null, \"verdict\": true}"
        ],
        [
         "13553",
         "20240704_URW_BG_29.txt",
         "7408",
         "7453",
         "BG",
         "",
         "False",
         "[]",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Guilt_by_Association",
         "Guilt_by_Association",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Guilt by Association technique is not used in the input.",
         "\"\"",
         "[None]",
         "[False]",
         "['{\\n  \"explanation\": \"The input text does not contain any instances of Guilt by Association, as there are no excerpts provided that link the opponent or activity to any negatively perceived group, individual, or event.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Guilt_by_Association/train/bg/train-bg-part_0008.parquet",
         null,
         null,
         "train",
         "{\"description\": null, \"verdict\": false}"
        ],
        [
         "13710",
         "trail_raw_BG_7.txt",
         "2225",
         "2773",
         "BG",
         "итат от Мария Захарова, която е директно представител на руската държава. Това не е просто проруска партия, това са директно думите на Кремъл, изречени от тази трибуна. Това правят ВЪЗРАЖДАНЕ, господин Божанков. Така че, когато кажете проруска партия, това не е достатъчно ясно. Това са буквално представители – явно платени или по някакъв начин накарани да идват и да изразяват позицията на руската държава и на Кремъл от трибуната, така че, моля Ви се, когато ги адресирате, адресирайте ги правилно. (Реплики от ВЪЗРАЖДАНЕ.)\n\nПРЕДСЕДАТЕЛ РОСЕН ЖЕ",
         "True",
         "['Exaggeration-Minimisation' 'Name_Calling-Labeling'\n 'Guilt_by_Association']",
         "train",
         "[]",
         "['проруска партия' 'проруска партия']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['това са директно думите на Кремъл, изречени от тази трибуна'\n 'буквално представители – явно платени или по някакъв начин накарани да идват и да изразяват позицията на руската държава и на Кремъл от трибуната']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Това не е просто проруска партия, това са директно думите на Кремъл, изречени от тази трибуна'\n 'буквално представители – явно платени или по някакъв начин накарани да идват и да изразяват позицията на руската държава и на Кремъл от трибуната']",
         "train",
         "GPT_41/v001/Guilt_by_Association",
         "Guilt_by_Association",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "1",
         "Yes, the Guilt by Association technique is used in the input.",
         "\"Това не е просто проруска партия, това са директно думите на Кремъл, изречени от тази трибуна буквално представители – явно платени или по някакъв начин накарани да идват и да изразяват позицията на руската държава и на Кремъл от трибуната\"",
         "[None]",
         "[False]",
         "['{\\n  \"explanation\": \"The Guilt by Association technique is explicitly used in the input text by linking the political party to the Kremlin, which has a negative connotation for the audience. The speaker asserts that the party is not merely pro-Russian but is directly representing the Kremlin\\'s words and interests, implying that they are complicit or controlled by a negative entity (the Kremlin). This association aims to discredit the party by connecting it to a source viewed unfavorably.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Guilt_by_Association/train/bg/train-bg-part_0004.parquet",
         "[None]",
         "[None]",
         "train",
         "{\"description\": null, \"verdict\": true}"
        ],
        [
         "13879",
         "pl_defence_22_05_2024_n02.txt",
         "520",
         "805",
         "PL",
         "Przede wszystkim mamy olbrzymi bałagan w dowodzeniu.\nSystem kierowania i dowodzenia Siłami\nZbrojnymi był kilkanaście razy zmieniany od czasu\nupadku PRL-u. Jest skomplikowany, jest niejasny,\na generalny dowódca rodzajów Sił Zbrojnych do tej\npory dowodził co najwyżej pułkiem specjalnym.",
         "True",
         "['Doubt']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['System kierowania i dowodzenia Siłami Zbrojnymi był kilkanaście razy zmieniany od czasu upadku PRL-u. Jest skomplikowany, jest niejasny, a generalny dowódca rodzajów Sił Zbrojnych do tej pory dowodził co najwyżej pułkiem specjalnym']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Name_Calling-Labeling",
         "Name_Calling-Labeling",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Name Calling-Labeling technique is not used in the input.",
         "\"\"",
         "[None]",
         "[False]",
         "['{\\n  \"explanation\": \"The input text does not contain any loaded labels directed at individuals or groups in an insulting or demeaning way. It discusses the complexity and issues within the command system of the armed forces without resorting to name-calling or labeling.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Name_Calling-Labeling/train/pl/train-pl-part_0003.parquet",
         null,
         null,
         "train",
         "{\"description\": null, \"verdict\": false}"
        ],
        [
         "14019",
         "RU_discrediting_the_west_8.txt",
         "2034",
         "2466",
         "RU",
         "ии с законами Российской Федерации они являются террористами. Так их действия квалифицирует Генеральная прокуратура России, и именно по этим статьям — терроризм — возбуждено против них уголовное дело Следственным комитетом Российской Федерации. Вот сейчас только что упоминали о пленных, но вот к этим людям мы, безусловно, прежде всего должны относиться как к террористам в соответствии с законами Российской Федерации.\n\nМы ко всем",
         "True",
         "['Appeal_to_Authority' 'Name_Calling-Labeling']",
         "train",
         "[]",
         "['они являются террористами']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Так их действия квалифицирует Генеральная прокуратура России']",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Name_Calling-Labeling",
         "Name_Calling-Labeling",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "1",
         "Yes, the Name Calling-Labeling technique is used in the input.",
         "\"они являются террористами\"",
         "[None]",
         "[False]",
         "['{\\n  \"explanation\": \"The Name Calling - Labeling technique is explicitly used in the input text as the phrase \\'они являются террористами\\' directly labels a group of individuals as \\'terrorists\\'. This label is loaded and demeaning, aligning with the definition that describes the use of insulting or negative labels directed at individuals or groups, disregarding factual arguments.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Name_Calling-Labeling/train/ru/train-ru-part_0001.parquet",
         null,
         null,
         "train",
         "{\"description\": null, \"verdict\": true}"
        ],
        [
         "14115",
         "RU_URW_4.txt",
         "1717",
         "1991",
         "RU",
         "Чтобы было еще понятней, нарушать взятые на себя обязанности, как часто любит говорить экстремист и бывший сотрудник аппарата Зеленского – Арестович, для киевских считается не плохим и позорным, а \"политической хитростью\" и \"проявлением воли\", где они \"легко кидают Путина\".",
         "True",
         "['Name_Calling-Labeling']",
         "train",
         "[]",
         "['экстремист']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Name_Calling-Labeling",
         "Name_Calling-Labeling",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "1",
         "Yes, the Name Calling-Labeling technique is used in the input.",
         "\"экстремист\"",
         "[None]",
         "[False]",
         "['{\\n  \"explanation\": \"The Name Calling - Labeling technique is explicitly used in the input text through the term \\'экстремист\\' (extremist), which is a loaded label directed at an individual (Арестович). This label carries a negative connotation and serves to demean the subject, aligning with the definition of the technique that focuses on qualitative judgment rather than factual argumentation.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Name_Calling-Labeling/train/ru/train-ru-part_0006.parquet",
         null,
         null,
         "train",
         "{\"description\": null, \"verdict\": true}"
        ],
        [
         "14157",
         "SI_interpelation_interior_7.txt",
         "839",
         "2596",
         "SI",
         "Naslednji primer: žena pomočnika generalnega direktorja policije, ki na policiji opravlja piar službo, se prevaža s protokolarnim vozilom, ki je namenjeno za prevoze varovanih oseb in ne uslužbencev policije. Ko policijska voznica v poročilu navede, koga je prevažala, mora po navodilu pomočnika generalnega direktorja policije, ki je mož te osebe, poročilo popraviti. Prav tako je kasneje s strani vodstva šikanirana. Namestnik generalnega direktorja policije, torej mož piarovke, si za službeno vozilo prilasti novo toyoto, ostalim pa v uporabo nameni stara vozila. Zoper svetovalca generalnega direktorja, zdaj že bivšega generalnega direktorja za področje gospodarske in korupcijske kriminalitete, bi pa naj bilo podanih kar več kaznivih ovadb. Da je stanje v policiji slabo, dokazuje tudi poročilo iz prvega polletja leta 2023, iz katerega je razvidno, da se je število kaznivih dejanj znatno povečalo, število preiskanosti in odkritosti z lastno dejavnostjo pa znatno zmanjšalo. Povečala se je uporaba prisilnih sredstev in izdanih plačilnih nalogov, število opozoril se je zmanjšalo, prav tako se v deželici z imenom Slovenija v časih golobistov prične na meji odstranjevati ograja. S tem se ilegalnim migrantom sporoči, da je prehod preko Slovenije lažji, zato se prične znatno povečevati število ilegalnih prehodov meje. Migranti se tako množično gibajo po naseljih ob hrvaški meji, kar povzročajo, povzroča strah in nelagodje tamkajšnjim prebivalcem. Število je že tako veliko, da kapacitete v azilnih domovih več ne zadoščajo, zato vlada sklene, da bo v Obrežju in v Središču ob Dravi uredila izpostave azilnega doma, ne da bi se o tem predhodno posvetovala z lokalno skupnostjo. To seveda povzroči nestrinjanje in upor tamkajšnjega prebivalstva.",
         "True",
         "['Causal_Oversimplification' 'Exaggeration-Minimisation'\n 'Appeal_to_Hypocrisy' 'Loaded_Language' 'Appeal_to_Pity'\n 'Obfuscation-Vagueness-Confusion' 'Questioning_the_Reputation'\n 'Name_Calling-Labeling' 'Doubt' 'Repetition' 'Appeal_to_Fear-Prejudice']",
         "train",
         "['mora po navodilu pomočnika generalnega direktorja policije, ki je mož te osebe, poročilo popraviti']",
         "['golobistov']",
         "['žena pomočnika generalnega direktorja policije, ki na policiji opravlja piar službo, se prevaža s protokolarnim vozilom, ki je namenjeno za prevoze varovanih oseb in ne uslužbencev policije'\n 'Namestnik generalnega direktorja policije, torej mož piarovke, si za službeno vozilo prilasti novo toyoto, ostalim pa v uporabo nameni stara vozila'\n 'Zoper svetovalca generalnega direktorja, zdaj že bivšega generalnega direktorja za področje gospodarske in korupcijske kriminalitete, bi pa naj bilo podanih kar več kaznivih ovadb']",
         "[]",
         "['šikanirana' 'ilegalnim migrantom']",
         "['golobistov']",
         "[]",
         "['s strani vodstva šikanirana']",
         "[]",
         "[]",
         "['stara vozila' 'množično gibajo po naseljih ob hrvaški meji']",
         "[]",
         "['s strani vodstva šikanirana']",
         "[]",
         "[]",
         "['prisilnih sredstev']",
         "[]",
         "[]",
         "['zato se prične znatno povečevati število ilegalnih prehodov meje'\n 'Migranti se tako množično gibajo po naseljih ob hrvaški meji, kar povzročajo, povzroča strah in nelagodje tamkajšnjim prebivalcem']",
         "['S tem se ilegalnim migrantom sporoči, da je prehod preko Slovenije lažji, zato se prične znatno povečevati število ilegalnih prehodov meje']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Name_Calling-Labeling",
         "Name_Calling-Labeling",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "1",
         "Yes, the Name Calling-Labeling technique is used in the input.",
         "\"golobistov\"",
         "[None]",
         "[False]",
         "['{\\n  \"explanation\": \"The Name Calling - Labeling technique is explicitly used in the input text through the term \\'golobistov\\', which serves as a loaded label directed at a group associated with a specific political orientation. This term is derogatory and implies a negative judgment about the individuals it describes, aligning with the definition of the technique that focuses on characterizing subjects in a demeaning way.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Name_Calling-Labeling/train/si/train-si-part_0006.parquet",
         null,
         null,
         "train",
         "{\"description\": null, \"verdict\": true}"
        ],
        [
         "14164",
         "SI_interpelation_interior_6.txt",
         "270",
         "7305",
         "SI",
         "Na eni izmed sej Odbora za notranje zadeve mi je predsednica odbora dejala, da sem pravljičar, zato mi spoštovani kolegi in kolegice dovolite, da vam v imenu Poslanske skupine Slovenske demokratske stranke povem zgodbo, ki morda ni pravljica in se glasi takole. Tam, na sončni strani Alp, so v deželici z imenom Slovenija nedolgo nazaj vladali janšisti. Prišel je čas volitev in oblast so prevzeli golobisti. Tik pred prevzemom oblasti njihov vodja k sebi pokliče novo ministrico za notranje zadeve in novega vršilca dolžnosti generalnega direktorja policije in jima naroči: Imata eno samo nalogo in to je, da policijo očistita janšistov. Oba vestno pričneta z opravljanjem ukazane naloge in na vodilnih položajih policije zamenjujeta osebe, ki naj bi bili janšisti. Še posebej direktorja, tam na mojem koncu, kot je dejal njihov vodja, in direktor Nacionalnega preiskovalnega urada, kajti prav ta urad preiskuje vodjo golobistov, zaradi ukradene identitete v Romuniji in kup denarja na tamkajšnjem računu, nakazila novinarki Vesni Vuković za neznane usluge in balkanskim poslovanjem denarja. Pri svojem delu pa naletita na težavo, kdo je janšist in kdo ne, saj so določene osebe, menita, da zamenjava ni potrebna. To povzroči nezadovoljstvo pri vodji in zato vršilca dolžnosti generalnega direktorja policije vrže čez ramo in ga noče imenovati za generalnega direktorja policije. Temu se ministrica upre in odstopi. Praznino v vodenju notranjega ministrstva izkoristi človek iz ozadja, ki sicer deluje na drugem ministrstvu in vodji predlaga osebo, ki bo pa poslušna. In tako minister za notranje zadeve postane Boštjan Poklukar. No, in novi minister Boštjan Poklukar prične z delom, seveda s poslušnim delom. Najprej o tem, kako naj bi delovalo policija in ministrstvo sicer ne posvetuje z ustreznimi strokovnjaki, ampak pogovor opravi z Jašo Jenulom, torej osebo, ki je bila v času vodenja janšistov večkrat kaznovana, ker je pozival k neprijavljenim protestom. Nato kljub temu, da je znotraj policije na desetine visoko izobraženih ter usposobljenih kadrov, na željo vodje golobistov za vršilca dolžnosti generalnega direktorja policije imenuje Senada Jušića, ki seveda nima vodstvenih izkušenj, saj je v preteklosti deloval zgolj kot pomočnik vodje na lokalnem nivoju. Imenovanje za vršilca dolžnosti generalnega direktorja policije pa naj bi bilo celo nezakonito, saj se ob njegovi premestitvi ne bi opravilo varnostno preverjanje, kar je sicer vedno obvezno o premestitvi na višje delovno mesto. Senad Jušić je tako nezakonito imenovan kasneje za generalnega direktorja Policije, saj Uradniški svet pri sklepu o izpolnitvi pogojev upošteva neke interne akte policije in za to poda tudi pomanjkljivo obrazložitev, ker seveda nimajo kaj obrazložiti. Ker bivši vršilec dolžnosti generalnega direktorja policije to ve, poda tožbo na Upravno sodišče, ki seveda razsodi, da je sklep natečajne komisije nezakonit, tako da je tudi imenovanje Senada Jušića za generalnega direktorja Policije nezakonito. Vodja golobistov, generalni direktor Policije, kakor tudi minister Poklukar se sprenevedajo, zanemarjajo sistem pravne države in ne spoštujejo sodbe. Jušića varujejo pred očitki, tako daleč, da se mora v to dogajanje vključiti sam striček iz ozadja in po 83 dneh Senad Jušić odstopi. Seveda v času vodenja policije s strani Senada Jušića postajajo razmere na policiji iz dneva v dan bolj kritične in dosežejo najnižjo točko v sistem delovanja policije v zgodovini Slovenije. Nestrokovni vodje svojo nestrokovnost prenašajo na policiste in policiste. Na njih izvajajo pritiske. Policisti in policistke več ne vedo kako naj delajo, kako naj postopajo, da bo prav in da zoper njih ne bodo uvedene sankcije. Strah jih je, delajo več nadur in tako dalje. Tako se policisti raje umaknejo, kot bi posredovali v eni izmed garažnih hiš v Ljubljani, kjer so policijsko patruljo ob posredovanju obkrožili zbrani mladostniki in preprečevali vožnjo. Policista se z vozilom umakneta. Prav tako se v Ljubljani zbere množica ljudi, ki z avtomobili hupa, drifta s strelnim orožjem strelja v zrak in na eno izmed policijskih vozil celo namesti albansko zastavo. Na jugovzhodnem delu te deželice se pojavijo težave, saj policija ni več kos kaznivim dejanjem, tamkajšnjim živečim Romom, ki kršijo prometne predpise, izvajajo tatvine, ustrahujejo, pretepajo, uporabljajo strelno orožje in tako dalje. Slovenija postane tudi raj za hudodelske združbe, ki med sabo obračunavajo kar sredi dneva, izvajajo likvidacije, umore, in to kar pred očmi otrok. Prav tako umorijo skesanca, ki ga policija ne zaščiti kljub opozorilom o njegovi likvidaciji. V priljubljenem velenjskem lokalu ob pretepu poseduje lastnik tega lokala, ki pa je med najbolj iskanimi osebami v Evropi na Interpolovi tiralici, zaradi sodelovanja v kriminalni združbi v Bosni in Hercegovini. Kljub obsodbi na leto in pol zapora brez težav torej opravlja ta lokal, se svobodno giba po Sloveniji, saj ga policija ne aretira. Varnost v državi se iz leta v leto slabša, kar dokazuje podatek globalnega indeksa miru, ker je Slovenija iz četrtega mesta v letu 2020 v lanskem letu 2024 zdrsnila na deveto mesto. Policisti in policistke tako množično zapuščajo policijske vrste: bodisi se upokojijo ali pa si poiščejo boljšo zaposlitev in podajo odpoved. Novih zaposlitev ni. Zdesetkana, policija ne zmore več opravljati nalog, ki jih je dolžna izvajati. V času janšistov, torej v letu 2020 in 2021 je bilo kar 164 odstotkov več prihodov kot odhodov. V času golobistov, v letu 2022 in vaju 24 je pa bilo 60 odstotkov več. Torej, manj prihodov kot odhodov. Od tega v času ministrovanja Boštjana Poklukarja, torej v letu 23 in 24 za 51 odstotkov manj prihodov kot odhodov. Kljub temu, da je denarja v davčni blagajni rekordno veliko se za promocijo poklica policist, policijska ne namenjajo namenska finančna sredstva, ki bi imela v proračunu svojo postavko, kot jo ima to na primer vojska. Poslabšanje organizacijske klime v policiji dokazuje tudi raziskava odbora za integriteto in etiko v policiji, saj so se rezultati pod vodstvom Boštjana Poklukarja znatno poslabšali. Medtem se v vodstvenih vrstah izvajajo različne mahinacije, kot so naslednji; minister Poklukar podpiše novo sistemizacijo delovnih mest na Policijski upravi Maribor, kjer se omogoči zaposlitev izbrane osebe za pomočnika direktorja Policijske uprave. Njihovo namero na žalost tik pred iztekom roka razpise prekine poslanec iz naše poslanske skupine, ki na to temo poda pisno poslansko vprašanje. Tako v istem dnevu razpis prekličejo, zamenjajo priloge te sistemizacije in razpišejo novo delovno mesto, in sicer za policijskega svetnika na Policijski upravi. Ta oseba se na ta razpis prijavi in se tudi zaposli. V odgovoru na pisno poslansko vprašanje poslanca naše poslanske skupine se pa minister zlaže, da je zaposlitev policijskega svetnika na PU Maribor potrebna zaradi povečanega števila kaznivih dejanj Romov iz Hrvaške na območju Policijske postaje Ormož in Gorišnica in zaradi povečanega števila migracij na tem območju.",
         "True",
         "['Loaded_Language' 'Obfuscation-Vagueness-Confusion'\n 'Name_Calling-Labeling' 'Red_Herring' 'Guilt_by_Association' 'Doubt'\n 'Causal_Oversimplification' 'Exaggeration-Minimisation'\n 'Questioning_the_Reputation' 'Appeal_to_Authority' 'Appeal_to_Values'\n 'False_Dilemma-No_Choice' 'Repetition' 'Appeal_to_Fear-Prejudice']",
         "train",
         "['Še posebej direktorja, tam na mojem koncu, kot je dejal njihov vodja, in direktor Nacionalnega preiskovalnega urada, kajti prav ta urad preiskuje vodjo golobistov, zaradi ukradene identitete v Romuniji in kup denarja na tamkajšnjem računu, nakazila novinarki Vesni Vuković za neznane usluge in balkanskim poslovanjem denarja'\n 'Praznino v vodenju notranjega ministrstva izkoristi človek iz ozadja, ki sicer deluje na drugem ministrstvu in vodji predlaga osebo, ki bo pa poslušna'\n 'minister zlaže']",
         "['golobisti' 'janšistov' 'janšisti' 'janšistov' 'golobistov' 'golobistov'\n 'janšistov' 'golobistov']",
         "[]",
         "[]",
         "['janšisti' 'golobisti' 'janšist' 'vrže čez ramo' 'striček iz ozadja'\n 'deželice' 'hudodelske združbe' 'Zdesetkana' 'mahinacije']",
         "['janšisti' 'janšist' 'janšistov' 'golobistov' 'nezakonito' 'golobistov'\n 'janšistov' 'golobistov']",
         "[]",
         "['seveda s poslušnim delom'\n 'Nato kljub temu, da je znotraj policije na desetine visoko izobraženih ter usposobljenih kadrov, na željo vodje golobistov za vršilca dolžnosti generalnega direktorja policije imenuje Senada Jušića, ki seveda nima vodstvenih izkušenj, saj je v preteklosti deloval zgolj kot pomočnik vodje na lokalnem nivoju'\n 'Senad Jušić je tako nezakonito imenovan kasneje za generalnega direktorja Policije']",
         "['Na eni izmed sej Odbora za notranje zadeve mi je predsednica odbora dejala, da sem pravljičar, zato mi spoštovani kolegi in kolegice dovolite, da vam v imenu Poslanske skupine Slovenske demokratske stranke povem zgodbo, ki morda ni pravljica in se glasi takole'\n 'Tam, na sončni strani Alp, so v deželici z imenom Slovenija nedolgo nazaj vladali janšisti. Prišel je čas volitev in oblast so prevzeli golobisti. Tik pred prevzemom oblasti njihov vodja k sebi pokliče novo ministrico za notranje zadeve in novega vršilca dolžnosti generalnega direktorja policije in jima naroči: Imata eno samo nalogo in to je, da policijo očistita janšistov'\n 'Oba vestno pričneta z opravljanjem ukazane naloge in na vodilnih položajih policije zamenjujeta osebe, ki naj bi bili janšisti. Še posebej direktorja, tam na mojem koncu, kot je dejal njihov vodja, in direktor Nacionalnega preiskovalnega urada, kajti prav ta urad preiskuje vodjo golobistov, zaradi ukradene identitete v Romuniji in kup denarja na tamkajšnjem računu, nakazila novinarki Vesni Vuković za neznane usluge in balkanskim poslovanjem denarja. Pri svojem delu pa naletita na težavo, kdo je janšist in kdo ne, saj so določene osebe, menita, da zamenjava ni potrebna. To povzroči nezadovoljstvo pri vodji in zato vršilca dolžnosti generalnega direktorja policije vrže čez ramo in ga noče imenovati za generalnega direktorja policije. Temu se ministrica upre in odstopi. Praznino v vodenju notranjega ministrstva izkoristi človek iz ozadja, ki sicer deluje na drugem ministrstvu in vodji predlaga osebo, ki bo pa poslušna']",
         "[]",
         "['eno samo nalogo' 'zgolj kot pomočnik vodje na lokalnem nivoju'\n 'iz dneva v dan bolj kritične in dosežejo najnižjo točko v sistem delovanja policije v zgodovini Slovenije'\n 'Slovenija postane tudi raj za hudodelske združbe, ki med sabo obračunavajo kar sredi dneva, izvajajo likvidacije, umore, in to kar pred očmi otrok'\n 'najbolj iskanimi osebami v Evropi na Interpolovi tiralici' 'množično'\n 'V času janšistov, torej v letu 2020 in 2021 je bilo kar 164 odstotkov več prihodov kot odhodov'\n 'rekordno veliko' 'znatno poslabšali']",
         "[]",
         "[]",
         "[]",
         "['nezakonito' 'nezakonito'\n 'Vodja golobistov, generalni direktor Policije, kakor tudi minister Poklukar se sprenevedajo, zanemarjajo sistem pravne države in ne spoštujejo sodbe'\n 'Nestrokovni vodje svojo nestrokovnost prenašajo na policiste in policiste']",
         "['človek iz ozadja' 'neke interne akte policije' 'uvedene sankcije']",
         "[]",
         "[]",
         "['očistita janšistov'\n 'Nestrokovni vodje svojo nestrokovnost prenašajo na policiste in policiste. Na njih izvajajo pritiske'\n 'Policisti in policistke več ne vedo kako naj delajo, kako naj postopajo, da bo prav in da zoper njih ne bodo uvedene sankcije. Strah jih je, delajo več nadur in tako dalje'\n 'Prav tako se v Ljubljani zbere množica ljudi, ki z avtomobili hupa, drifta s strelnim orožjem strelja v zrak in na eno izmed policijskih vozil celo namesti albansko zastavo'\n 'Na jugovzhodnem delu te deželice se pojavijo težave, saj policija ni več kos kaznivim dejanjem, tamkajšnjim živečim Romom, ki kršijo prometne predpise, izvajajo tatvine, ustrahujejo, pretepajo, uporabljajo strelno orožje in tako dalje'\n 'Slovenija postane tudi raj za hudodelske združbe, ki med sabo obračunavajo kar sredi dneva, izvajajo likvidacije, umore, in to kar pred očmi otrok'\n 'Prav tako umorijo skesanca, ki ga policija ne zaščiti kljub opozorilom o njegovi likvidaciji'\n 'V priljubljenem velenjskem lokalu ob pretepu poseduje lastnik tega lokala, ki pa je med najbolj iskanimi osebami v Evropi na Interpolovi tiralici, zaradi sodelovanja v kriminalni združbi v Bosni in Hercegovini'\n 'Kljub obsodbi na leto in pol zapora brez težav torej opravlja ta lokal, se svobodno giba po Sloveniji, saj ga policija ne aretira'\n 'povečanega števila kaznivih dejanj Romov']",
         "['Varnost v državi se iz leta v leto slabša, kar dokazuje podatek globalnega indeksa miru, ker je Slovenija iz četrtega mesta v letu 2020 v lanskem letu 2024 zdrsnila na deveto mesto'\n 'Od tega v času ministrovanja Boštjana Poklukarja, torej v letu 23 in 24 za 51 odstotkov manj prihodov kot odhodov']",
         "['Nato kljub temu, da je znotraj policije na desetine visoko izobraženih ter usposobljenih kadrov'\n 'odbora za integriteto in etiko v policiji']",
         "['bodisi se upokojijo ali pa si poiščejo boljšo zaposlitev in podajo odpoved']",
         "[]",
         "[]",
         "['sicer ne posvetuje z ustreznimi strokovnjaki, ampak pogovor opravi z Jašo Jenulom, torej osebo, ki je bila v času vodenja janšistov večkrat kaznovana, ker je pozival k neprijavljenim protestom']",
         "train",
         "GPT_41/v001/Name_Calling-Labeling",
         "Name_Calling-Labeling",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "1",
         "Yes, the Name Calling-Labeling technique is used in the input.",
         "\"golobisti janšistov janšisti janšistov golobistov golobistov janšistov golobistov\"",
         "[None]",
         "[False]",
         "['{\\n  \"explanation\": \"The Name Calling - Labeling technique is explicitly used in the input text through the repeated use of derogatory labels such as \\'golobisti\\' and \\'janšisti\\'. These terms are directed at specific groups, implying negative connotations and creating a divisive narrative. This aligns with the definition, as the labels are loaded and serve to characterize the groups in a demeaning way, disregarding factual arguments.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Name_Calling-Labeling/train/si/train-si-part_0006.parquet",
         null,
         null,
         "train",
         "{\"description\": null, \"verdict\": true}"
        ]
       ],
       "shape": {
        "columns": 60,
        "rows": 69
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>text_lang</th>\n",
       "      <th>text</th>\n",
       "      <th>label_bin</th>\n",
       "      <th>label_multi</th>\n",
       "      <th>base_split</th>\n",
       "      <th>Questioning_the_Reputation</th>\n",
       "      <th>Name_Calling-Labeling</th>\n",
       "      <th>...</th>\n",
       "      <th>updated_definition</th>\n",
       "      <th>think_content</th>\n",
       "      <th>illegal_value</th>\n",
       "      <th>explanation</th>\n",
       "      <th>extra_content</th>\n",
       "      <th>source_file</th>\n",
       "      <th>error</th>\n",
       "      <th>status</th>\n",
       "      <th>split</th>\n",
       "      <th>expected_output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11106</th>\n",
       "      <td>pl_abortion_11_04_2024_n03.txt</td>\n",
       "      <td>4168</td>\n",
       "      <td>5204</td>\n",
       "      <td>PL</td>\n",
       "      <td>W latach 90., które już bardzo dobrze pamiętam...</td>\n",
       "      <td>True</td>\n",
       "      <td>[Appeal_to_Hypocrisy, Loaded_Language, Questio...</td>\n",
       "      <td>train</td>\n",
       "      <td>[ustawa była początkiem wymazywania kobiet z d...</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41/v001...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "      <td>{\"description\": null, \"verdict\": true}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11284</th>\n",
       "      <td>SI_interpelation_interior_12.txt</td>\n",
       "      <td>4448</td>\n",
       "      <td>7979</td>\n",
       "      <td>SI</td>\n",
       "      <td>Najlepša hvala za besedo. Najprej hvala gospod...</td>\n",
       "      <td>True</td>\n",
       "      <td>[Consequential_Oversimplification, Exaggeratio...</td>\n",
       "      <td>train</td>\n",
       "      <td>[tisti, ki vam je pisal odgovore na našo inter...</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41/v001...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "      <td>{\"description\": null, \"verdict\": true}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11292</th>\n",
       "      <td>SI_interpelation_interior_7.txt</td>\n",
       "      <td>2598</td>\n",
       "      <td>5288</td>\n",
       "      <td>SI</td>\n",
       "      <td>Policisti prav tako dobijo navodila, naj ne sp...</td>\n",
       "      <td>True</td>\n",
       "      <td>[Consequential_Oversimplification, Exaggeratio...</td>\n",
       "      <td>train</td>\n",
       "      <td>[Taka navodila policistom seveda preprečujejo ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41/v001...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "      <td>{\"description\": null, \"verdict\": true}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11310</th>\n",
       "      <td>SI_interpelation_interior_7.txt</td>\n",
       "      <td>839</td>\n",
       "      <td>2596</td>\n",
       "      <td>SI</td>\n",
       "      <td>Naslednji primer: žena pomočnika generalnega d...</td>\n",
       "      <td>True</td>\n",
       "      <td>[Causal_Oversimplification, Exaggeration-Minim...</td>\n",
       "      <td>train</td>\n",
       "      <td>[mora po navodilu pomočnika generalnega direkt...</td>\n",
       "      <td>[golobistov]</td>\n",
       "      <td>...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41/v001...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "      <td>{\"description\": null, \"verdict\": true}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11317</th>\n",
       "      <td>SI_interpelation_interior_6.txt</td>\n",
       "      <td>270</td>\n",
       "      <td>7305</td>\n",
       "      <td>SI</td>\n",
       "      <td>Na eni izmed sej Odbora za notranje zadeve mi ...</td>\n",
       "      <td>True</td>\n",
       "      <td>[Loaded_Language, Obfuscation-Vagueness-Confus...</td>\n",
       "      <td>train</td>\n",
       "      <td>[Še posebej direktorja, tam na mojem koncu, ko...</td>\n",
       "      <td>[golobisti, janšistov, janšisti, janšistov, go...</td>\n",
       "      <td>...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41/v001...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "      <td>{\"description\": null, \"verdict\": false}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14693</th>\n",
       "      <td>20240704_URW_BG_30.txt</td>\n",
       "      <td>2946</td>\n",
       "      <td>2988</td>\n",
       "      <td>BG</td>\n",
       "      <td>Нинова, за процедура.\\n\\nИзчакайте, господи</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>train</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41/v001...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "      <td>{\"description\": null, \"verdict\": false}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14694</th>\n",
       "      <td>20231208_URW_BG_72.txt</td>\n",
       "      <td>1795</td>\n",
       "      <td>2118</td>\n",
       "      <td>BG</td>\n",
       "      <td>Говорите, че машините, които гласувахме – „Стр...</td>\n",
       "      <td>True</td>\n",
       "      <td>[Questioning_the_Reputation, Doubt]</td>\n",
       "      <td>train</td>\n",
       "      <td>[Ако за Вас 1956 г. е същата като 2001 г., за ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41/v001...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "      <td>{\"description\": null, \"verdict\": true}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14695</th>\n",
       "      <td>20240229_URW_BG_67.txt</td>\n",
       "      <td>2786</td>\n",
       "      <td>4165</td>\n",
       "      <td>BG</td>\n",
       "      <td>И да Ви кажа, уважаеми български граждани, че ...</td>\n",
       "      <td>True</td>\n",
       "      <td>[Appeal_to_Hypocrisy, Questioning_the_Reputati...</td>\n",
       "      <td>train</td>\n",
       "      <td>[И да Ви кажа, уважаеми български граждани, че...</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41/v001...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "      <td>{\"description\": null, \"verdict\": true}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14726</th>\n",
       "      <td>20240704_URW_BG_25.txt</td>\n",
       "      <td>4080</td>\n",
       "      <td>4133</td>\n",
       "      <td>BG</td>\n",
       "      <td>оспожо Председател.\\n\\nЩе направя процедурно п...</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>train</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41/v001...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "      <td>{\"description\": null, \"verdict\": false}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14733</th>\n",
       "      <td>trail_raw_BG_13.txt</td>\n",
       "      <td>3446</td>\n",
       "      <td>4689</td>\n",
       "      <td>BG</td>\n",
       "      <td>да се случи, когато се обърне колелото на ист...</td>\n",
       "      <td>True</td>\n",
       "      <td>[Conversation_Killer, Loaded_Language, Slogans...</td>\n",
       "      <td>train</td>\n",
       "      <td>[Вие не сте даже и такива, за които членувате ...</td>\n",
       "      <td>[руски агенти, руски агенти, гешефтари]</td>\n",
       "      <td>...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41/v001...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "      <td>{\"description\": null, \"verdict\": true}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>69 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               filename  start   end text_lang  \\\n",
       "11106    pl_abortion_11_04_2024_n03.txt   4168  5204        PL   \n",
       "11284  SI_interpelation_interior_12.txt   4448  7979        SI   \n",
       "11292   SI_interpelation_interior_7.txt   2598  5288        SI   \n",
       "11310   SI_interpelation_interior_7.txt    839  2596        SI   \n",
       "11317   SI_interpelation_interior_6.txt    270  7305        SI   \n",
       "...                                 ...    ...   ...       ...   \n",
       "14693            20240704_URW_BG_30.txt   2946  2988        BG   \n",
       "14694            20231208_URW_BG_72.txt   1795  2118        BG   \n",
       "14695            20240229_URW_BG_67.txt   2786  4165        BG   \n",
       "14726            20240704_URW_BG_25.txt   4080  4133        BG   \n",
       "14733               trail_raw_BG_13.txt   3446  4689        BG   \n",
       "\n",
       "                                                    text  label_bin  \\\n",
       "11106  W latach 90., które już bardzo dobrze pamiętam...       True   \n",
       "11284  Najlepša hvala za besedo. Najprej hvala gospod...       True   \n",
       "11292  Policisti prav tako dobijo navodila, naj ne sp...       True   \n",
       "11310  Naslednji primer: žena pomočnika generalnega d...       True   \n",
       "11317  Na eni izmed sej Odbora za notranje zadeve mi ...       True   \n",
       "...                                                  ...        ...   \n",
       "14693        Нинова, за процедура.\\n\\nИзчакайте, господи      False   \n",
       "14694  Говорите, че машините, които гласувахме – „Стр...       True   \n",
       "14695  И да Ви кажа, уважаеми български граждани, че ...       True   \n",
       "14726  оспожо Председател.\\n\\nЩе направя процедурно п...      False   \n",
       "14733   да се случи, когато се обърне колелото на ист...       True   \n",
       "\n",
       "                                             label_multi base_split  \\\n",
       "11106  [Appeal_to_Hypocrisy, Loaded_Language, Questio...      train   \n",
       "11284  [Consequential_Oversimplification, Exaggeratio...      train   \n",
       "11292  [Consequential_Oversimplification, Exaggeratio...      train   \n",
       "11310  [Causal_Oversimplification, Exaggeration-Minim...      train   \n",
       "11317  [Loaded_Language, Obfuscation-Vagueness-Confus...      train   \n",
       "...                                                  ...        ...   \n",
       "14693                                                 []      train   \n",
       "14694                [Questioning_the_Reputation, Doubt]      train   \n",
       "14695  [Appeal_to_Hypocrisy, Questioning_the_Reputati...      train   \n",
       "14726                                                 []      train   \n",
       "14733  [Conversation_Killer, Loaded_Language, Slogans...      train   \n",
       "\n",
       "                              Questioning_the_Reputation  \\\n",
       "11106  [ustawa była początkiem wymazywania kobiet z d...   \n",
       "11284  [tisti, ki vam je pisal odgovore na našo inter...   \n",
       "11292  [Taka navodila policistom seveda preprečujejo ...   \n",
       "11310  [mora po navodilu pomočnika generalnega direkt...   \n",
       "11317  [Še posebej direktorja, tam na mojem koncu, ko...   \n",
       "...                                                  ...   \n",
       "14693                                                 []   \n",
       "14694  [Ако за Вас 1956 г. е същата като 2001 г., за ...   \n",
       "14695  [И да Ви кажа, уважаеми български граждани, че...   \n",
       "14726                                                 []   \n",
       "14733  [Вие не сте даже и такива, за които членувате ...   \n",
       "\n",
       "                                   Name_Calling-Labeling  ...  \\\n",
       "11106                                                 []  ...   \n",
       "11284                                                 []  ...   \n",
       "11292                                                 []  ...   \n",
       "11310                                       [golobistov]  ...   \n",
       "11317  [golobisti, janšistov, janšisti, janšistov, go...  ...   \n",
       "...                                                  ...  ...   \n",
       "14693                                                 []  ...   \n",
       "14694                                                 []  ...   \n",
       "14695                                                 []  ...   \n",
       "14726                                                 []  ...   \n",
       "14733            [руски агенти, руски агенти, гешефтари]  ...   \n",
       "\n",
       "      updated_definition think_content illegal_value explanation  \\\n",
       "11106             [None]        [None]        [None]      [None]   \n",
       "11284             [None]        [None]        [None]      [None]   \n",
       "11292             [None]        [None]        [None]      [None]   \n",
       "11310             [None]        [None]        [None]      [None]   \n",
       "11317             [None]        [None]        [None]      [None]   \n",
       "...                  ...           ...           ...         ...   \n",
       "14693             [None]        [None]        [None]      [None]   \n",
       "14694             [None]        [None]        [None]      [None]   \n",
       "14695             [None]        [None]        [None]      [None]   \n",
       "14726             [None]        [None]        [None]      [None]   \n",
       "14733             [None]        [None]        [None]      [None]   \n",
       "\n",
       "      extra_content                                        source_file error  \\\n",
       "11106        [None]  data/llm_output/persuasion/explain/GPT_41/v001...   NaN   \n",
       "11284        [None]  data/llm_output/persuasion/explain/GPT_41/v001...   NaN   \n",
       "11292        [None]  data/llm_output/persuasion/explain/GPT_41/v001...   NaN   \n",
       "11310        [None]  data/llm_output/persuasion/explain/GPT_41/v001...   NaN   \n",
       "11317        [None]  data/llm_output/persuasion/explain/GPT_41/v001...   NaN   \n",
       "...             ...                                                ...   ...   \n",
       "14693        [None]  data/llm_output/persuasion/explain/GPT_41/v001...   NaN   \n",
       "14694        [None]  data/llm_output/persuasion/explain/GPT_41/v001...   NaN   \n",
       "14695        [None]  data/llm_output/persuasion/explain/GPT_41/v001...   NaN   \n",
       "14726        [None]  data/llm_output/persuasion/explain/GPT_41/v001...   NaN   \n",
       "14733        [None]  data/llm_output/persuasion/explain/GPT_41/v001...   NaN   \n",
       "\n",
       "      status  split                          expected_output  \n",
       "11106    NaN  train   {\"description\": null, \"verdict\": true}  \n",
       "11284    NaN  train   {\"description\": null, \"verdict\": true}  \n",
       "11292    NaN  train   {\"description\": null, \"verdict\": true}  \n",
       "11310    NaN  train   {\"description\": null, \"verdict\": true}  \n",
       "11317    NaN  train  {\"description\": null, \"verdict\": false}  \n",
       "...      ...    ...                                      ...  \n",
       "14693    NaN  train  {\"description\": null, \"verdict\": false}  \n",
       "14694    NaN  train   {\"description\": null, \"verdict\": true}  \n",
       "14695    NaN  train   {\"description\": null, \"verdict\": true}  \n",
       "14726    NaN  train  {\"description\": null, \"verdict\": false}  \n",
       "14733    NaN  train   {\"description\": null, \"verdict\": true}  \n",
       "\n",
       "[69 rows x 60 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"is_valid\"].apply(\n",
    "    lambda x: isinstance(x, (list, np.ndarray)) and list(x) == [False]\n",
    ")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee5b5a65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "prompt_name\n",
       "Exaggeration-Minimisation           692\n",
       "Appeal_to_Time                      692\n",
       "Whataboutism                        692\n",
       "Slogans                             691\n",
       "False_Equivalence                   691\n",
       "Flag_Waving                         691\n",
       "Obfuscation-Vagueness-Confusion     691\n",
       "Loaded_Language                     690\n",
       "Consequential_Oversimplification    690\n",
       "Repetition                          689\n",
       "False_Dilemma-No_Choice             689\n",
       "Appeal_to_Pity                      689\n",
       "Guilt_by_Association                688\n",
       "Straw_Man                           688\n",
       "Red_Herring                         687\n",
       "Causal_Oversimplification           687\n",
       "Conversation_Killer                 685\n",
       "Appeal_to_Hypocrisy                 677\n",
       "Name_Calling-Labeling               639\n",
       "Appeal_to_Fear-Prejudice            371\n",
       "Appeal_to_Authority                 370\n",
       "Appeal_to_Popularity                369\n",
       "Appeal_to_Values                    369\n",
       "Doubt                               350\n",
       "Questioning_the_Reputation          345\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean = df[~df[\"explanation\"].apply(\n",
    "    lambda x: isinstance(x, (list, np.ndarray)) and list(x) == [None]\n",
    ")]\n",
    "clean.prompt_name.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69ad669e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "prompt_name                       gold\n",
       "False_Equivalence                 0       681\n",
       "Guilt_by_Association              0       676\n",
       "Appeal_to_Time                    0       674\n",
       "Whataboutism                      0       673\n",
       "Straw_Man                         0       670\n",
       "Slogans                           0       670\n",
       "False_Dilemma-No_Choice           0       666\n",
       "Appeal_to_Pity                    0       663\n",
       "Obfuscation-Vagueness-Confusion   0       663\n",
       "Flag_Waving                       0       662\n",
       "Consequential_Oversimplification  0       660\n",
       "Red_Herring                       0       659\n",
       "Causal_Oversimplification         0       647\n",
       "Conversation_Killer               0       642\n",
       "Appeal_to_Hypocrisy               0       636\n",
       "Exaggeration-Minimisation         0       621\n",
       "Repetition                        0       620\n",
       "Name_Calling-Labeling             0       582\n",
       "Loaded_Language                   0       580\n",
       "Appeal_to_Popularity              0       344\n",
       "Appeal_to_Fear-Prejudice          0       332\n",
       "Appeal_to_Authority               0       331\n",
       "Appeal_to_Values                  0       323\n",
       "Doubt                             0       302\n",
       "Questioning_the_Reputation        0       300\n",
       "Loaded_Language                   1       110\n",
       "Exaggeration-Minimisation         1        71\n",
       "Repetition                        1        69\n",
       "Name_Calling-Labeling             1        57\n",
       "Doubt                             1        48\n",
       "Appeal_to_Values                  1        46\n",
       "Questioning_the_Reputation        1        45\n",
       "Conversation_Killer               1        43\n",
       "Appeal_to_Hypocrisy               1        41\n",
       "Causal_Oversimplification         1        40\n",
       "Appeal_to_Authority               1        39\n",
       "Appeal_to_Fear-Prejudice          1        39\n",
       "Consequential_Oversimplification  1        30\n",
       "Flag_Waving                       1        29\n",
       "Obfuscation-Vagueness-Confusion   1        28\n",
       "Red_Herring                       1        28\n",
       "Appeal_to_Pity                    1        26\n",
       "Appeal_to_Popularity              1        25\n",
       "False_Dilemma-No_Choice           1        23\n",
       "Slogans                           1        21\n",
       "Whataboutism                      1        19\n",
       "Straw_Man                         1        18\n",
       "Appeal_to_Time                    1        18\n",
       "Guilt_by_Association              1        12\n",
       "False_Equivalence                 1        10\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean.value_counts(['prompt_name','gold'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c589cac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lp/5z8ys0rj1q960h2656xp8c680000gn/T/ipykernel_49770/905121920.py:11: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda x: x.sample(n=3*counts.get(x.name, 0)))\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "filename",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "start",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "end",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "text_lang",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "text",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "label_bin",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "label_multi",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "base_split",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Questioning_the_Reputation",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Name_Calling-Labeling",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Appeal_to_Hypocrisy",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Conversation_Killer",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Loaded_Language",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Repetition",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Appeal_to_Popularity",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Doubt",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Red_Herring",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Flag_Waving",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Exaggeration-Minimisation",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Consequential_Oversimplification",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Appeal_to_Pity",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Appeal_to_Time",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Appeal_to_Values",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Obfuscation-Vagueness-Confusion",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Straw_Man",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Slogans",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Appeal_to_Fear-Prejudice",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Causal_Oversimplification",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Appeal_to_Authority",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "False_Dilemma-No_Choice",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Whataboutism",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "False_Equivalence",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Guilt_by_Association",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "alt_split",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "output_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "prompt_name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "prompt_version",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "job",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "step",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "max_iterations",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "temperature",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "model_provider",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "model_name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "model_mode",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "gold",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "gold_text",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "spans",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "extra_properties",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "is_valid",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "raw",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "updated_definition",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "think_content",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "illegal_value",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "explanation",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "extra_content",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "source_file",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "error",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "status",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "split",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "expected_output",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "54c11f35-3c50-4a2a-bbdb-239700295aa8",
       "rows": [
        [
         "0",
         "RU_demography_3.txt",
         "0",
         "108",
         "RU",
         "Вымирание ускоряется. Вышла статистика \"прорыва\" в год семьи и окончательного итога нацпроекта \"Демография\".",
         "True",
         "['Appeal_to_Time']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Вымирание ускоряется']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/Repetition",
         "Repetition",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "0",
         "No, the Repetition technique is not used in the input.",
         "\"\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The input text does not contain any repeated words, phrases, stories, or imagery. Therefore, the Repetition technique was not used.\",\\n  \"updated_definition\": \"The speaker uses the same word, phrase, story, or imagery repeatedly with the hope that the repetition will lead to persuade the audience; this includes instances where the same element is used multiple times within a text.\"\\n}']",
         "['The speaker uses the same word, phrase, story, or imagery repeatedly with the hope that the repetition will lead to persuade the audience; this includes instances where the same element is used multiple times within a text.']",
         "[None]",
         "[None]",
         "['The input text does not contain any repeated words, phrases, stories, or imagery. Therefore, the Repetition technique was not used.']",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/Repetition/train/ru/train-ru-part_0015.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text does not contain any repeated words, phrases, stories, or imagery. Therefore, the Repetition technique was not used.\", \"verdict\": false}"
        ],
        [
         "1",
         "pl_abortion_11_04_2024_n04.txt",
         "7726",
         "7807",
         "PL",
         "Przepraszam, że dopiero teraz, ale emocje,\nprzynajmniej u mnie, są dosyć wysokie.",
         "False",
         "[]",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Fear-Prejudice",
         "Appeal_to_Fear-Prejudice",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Appeal to Fear-Prejudice technique is not used in the input.",
         "\"\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The input text does not contain any elements that promote or reject an idea through fear or prejudice. It simply expresses a personal sentiment about high emotions without invoking fear or preconceived judgments.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "['The input text does not contain any elements that promote or reject an idea through fear or prejudice. It simply expresses a personal sentiment about high emotions without invoking fear or preconceived judgments.']",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Fear-Prejudice/train/pl/train-pl-part_0000.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text does not contain any elements that promote or reject an idea through fear or prejudice. It simply expresses a personal sentiment about high emotions without invoking fear or preconceived judgments.\", \"verdict\": false}"
        ],
        [
         "2",
         "RU_discrediting_the_west_11.txt",
         "129",
         "594",
         "RU",
         "евой генерал, результативный, не мясник - не нужен на СВО. А вот коррупционеры, которые отсиживаются в добровольческих формированиях, чтобы их не закрыли, нужны. Я знаю ряд лиц, в том числе, которые наворовались на строительстве фортификационных сооружений в Курской области, которые пытаются через якобы участия в СВО отмазаться от наказания. Отсиживаются в тылах, ну хоть пацанам что-то покупают на ворованные деньги - дроны, машины. Устроили из СВО отмывочную.\n\n",
         "True",
         "['Loaded_Language' 'Obfuscation-Vagueness-Confusion'\n 'False_Dilemma-No_Choice' 'Name_Calling-Labeling']",
         "train",
         "[]",
         "['коррупционеры, которые отсиживаются в добровольческих формированиях']",
         "[]",
         "[]",
         "['Устроили из СВО отмывочную']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Боевой генерал, результативный, не мясник - не нужен на СВО']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['А вот коррупционеры, которые отсиживаются в добровольческих формированиях, чтобы их не закрыли, нужны']",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/Loaded_Language",
         "Loaded_Language",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "1",
         "Yes, the Loaded Language technique is used in the input.",
         "\"Устроили из СВО отмывочную\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The input text employs Loaded Language through the phrase \\'Устроили из СВО отмывочную\\', which carries strong negative connotations. The term \\'отмывочную\\' implies that the situation is being used for illicit purposes, evoking a sense of corruption and deceit. This aligns with the definition of Loaded Language, as it uses emotionally charged words to influence the audience\\'s perception of the argument.\",\\n  \"updated_definition\": \"Loaded Language is the use of specific words and phrases with strong emotional implications (either positive or negative) to influence and convince the audience that an argument is valid, often by evoking strong feelings or reactions. It is also known as Appeal to Argument from Emotive Language.\"\\n}']",
         "['Loaded Language is the use of specific words and phrases with strong emotional implications (either positive or negative) to influence and convince the audience that an argument is valid, often by evoking strong feelings or reactions. It is also known as Appeal to Argument from Emotive Language.']",
         "[None]",
         "[None]",
         "[\"The input text employs Loaded Language through the phrase 'Устроили из СВО отмывочную', which carries strong negative connotations. The term 'отмывочную' implies that the situation is being used for illicit purposes, evoking a sense of corruption and deceit. This aligns with the definition of Loaded Language, as it uses emotionally charged words to influence the audience's perception of the argument.\"]",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/Loaded_Language/train/ru/train-ru-part_0014.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text employs Loaded Language through the phrase '\\u0423\\u0441\\u0442\\u0440\\u043e\\u0438\\u043b\\u0438 \\u0438\\u0437 \\u0421\\u0412\\u041e \\u043e\\u0442\\u043c\\u044b\\u0432\\u043e\\u0447\\u043d\\u0443\\u044e', which carries strong negative connotations. The term '\\u043e\\u0442\\u043c\\u044b\\u0432\\u043e\\u0447\\u043d\\u0443\\u044e' implies that the situation is being used for illicit purposes, evoking a sense of corruption and deceit. This aligns with the definition of Loaded Language, as it uses emotionally charged words to influence the audience's perception of the argument.\", \"verdict\": true}"
        ],
        [
         "3",
         "20240704_URW_BG_30.txt",
         "5823",
         "6119",
         "BG",
         "заседанието, което ще бъде абсолютно безсмислено, защото тази позиция трябва да се чуе от българския народ. Коментирайки я на закрито заседание, ще засилим подозрения, страхове, че нещо тук се прави, че ще вкарате България във война и така нататък.\n\nПравя цялото това изложение с абсолютната добр",
         "True",
         "['Consequential_Oversimplification' 'Exaggeration-Minimisation'\n 'Name_Calling-Labeling' 'Appeal_to_Fear-Prejudice']",
         "train",
         "[]",
         "['абсолютно безсмислено']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['абсолютно безсмислено']",
         "['Коментирайки я на закрито заседание, ще засилим подозрения, страхове, че нещо тук се прави, че ще вкарате България във война и така нататък']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['ще засилим подозрения, страхове, че нещо тук се прави, че ще вкарате България във война и така нататък']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Doubt",
         "Doubt",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Doubt technique is not used in the input.",
         "\"\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The input text does not contain any elements that cast doubt on the character or personal attributes of someone or something. It primarily expresses concerns about the implications of a closed meeting without discrediting any individual or their credibility. Therefore, the Casting Doubt technique is not used.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "['The input text does not contain any elements that cast doubt on the character or personal attributes of someone or something. It primarily expresses concerns about the implications of a closed meeting without discrediting any individual or their credibility. Therefore, the Casting Doubt technique is not used.']",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Doubt/train/bg/train-bg-part_0004.parquet",
         "[None]",
         "[None]",
         "train",
         "{\"description\": \"The input text does not contain any elements that cast doubt on the character or personal attributes of someone or something. It primarily expresses concerns about the implications of a closed meeting without discrediting any individual or their credibility. Therefore, the Casting Doubt technique is not used.\", \"verdict\": false}"
        ],
        [
         "4",
         "RU_migrants_4.txt",
         "836",
         "1171",
         "RU",
         "И еще один, тоже очень важный аспект. Родители-иностранцы, чьих несовершеннолетних детей признали нежелательно пребывающими в России, получат предписание покинуть страну в установленные сроки. Среди детей мигрантов, в том числе подростков, очень много преступности, неуважения российских традиций и наплевательское отношение к законам.",
         "True",
         "['Questioning_the_Reputation']",
         "train",
         "['Среди детей мигрантов, в том числе подростков, очень много преступности, неуважения российских традиций и наплевательское отношение к законам']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/Exaggeration-Minimisation",
         "Exaggeration-Minimisation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "0",
         "No, the Exaggeration-Minimisation technique is not used in the input.",
         "\"\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The input text does not employ the Exaggeration - Minimisation technique, as it does not exaggerate or downplay any statements. It presents information about foreign parents and their children in Russia without making excessive claims or minimizing the situation.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "['The input text does not employ the Exaggeration - Minimisation technique, as it does not exaggerate or downplay any statements. It presents information about foreign parents and their children in Russia without making excessive claims or minimizing the situation.']",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/Exaggeration-Minimisation/train/ru/train-ru-part_0002.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text does not employ the Exaggeration - Minimisation technique, as it does not exaggerate or downplay any statements. It presents information about foreign parents and their children in Russia without making excessive claims or minimizing the situation.\", \"verdict\": false}"
        ],
        [
         "5",
         "pl_eu_12_06_2024_n01.txt",
         "574",
         "1275",
         "PL",
         "Sekretarz stanu w Ministerstwie Spraw Wewnętrznych i Administracji Polski Czesław Mroczek przedstawił uzasadnienie projektu, podkreślając, że od\n1 stycznia 2025 r. Rzeczpospolita Polska przejmuje\npo raz kolejny przewodnictwo w Radzie Unii Europejskiej. Podkreślił, że z uwagi na zmieniający się\npoziom bezpieczeństwa związany z położeniem Polski w bliskiej strefie działań wojennych w Ukrainie,\nobowiązującymi na terenie Polski stopniami bezpieczeństwa, stopniami alarmowymi zobowiązani jesteśmy do wprowadzenia rozwiązań prawnych, które\njako mechanizmy prewencyjne stworzą warunki do\nskutecznego podniesienia poziomu bezpieczeństwa\nna czas przygotowania i sprawowania prezydencji\nw Unii Europejskiej.",
         "False",
         "[]",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/Exaggeration-Minimisation",
         "Exaggeration-Minimisation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "0",
         "No, the Exaggeration-Minimisation technique is not used in the input.",
         "\"\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The input text does not employ the Exaggeration - Minimisation technique, as it does not exaggerate or downplay any statements. The content is presented in a straightforward manner without any excessive claims or minimization of issues.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "['The input text does not employ the Exaggeration - Minimisation technique, as it does not exaggerate or downplay any statements. The content is presented in a straightforward manner without any excessive claims or minimization of issues.']",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/Exaggeration-Minimisation/train/pl/train-pl-part_0018.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text does not employ the Exaggeration - Minimisation technique, as it does not exaggerate or downplay any statements. The content is presented in a straightforward manner without any excessive claims or minimization of issues.\", \"verdict\": false}"
        ],
        [
         "6",
         "SI_interpelation_interior_13.txt",
         "0",
         "3791",
         "SI",
         "In, minister, prosim vas res za odgovor na dva vprašanja. Kaj je dejansko res v zvezi s poročanjem danes enega od medijev, da naj bi v času, ko je bilo varovanje gospe tožilki vzeto oziroma se ga je ona bolj natančno odpovedala iz znanih razlogov, o katerih smo danes govorili, najbrž se bi ga vsak ne, saj še celo sam premier, predsednik Vlade je povedal, da jo razume, da je bila nadzorovana namesto varovana. Torej res, gospod minister; ali je v tem času del policije, del kriminalistične policije, ki mu pravijo del, ki je zadolžen za ciljno iskanje, ne pozabimo, kriminalistično policijo je takrat vodil Damijan Petrič, on jo vodi od 18. 7. leta 2023, veste, to je tisti gospod, ki je zdaj postal v. d. direktorja, generalnega direktorja Policije, to se pravi, če imate kakršne koli podatke ali je res, da naj bi sumili ali celo vedeli, da je v tem času že maja lani Dino Muzaferović z, ki ga kličejo Cezar in naj bi bil, naj bi umoril gospoda Zovka, ali je res že bil v Sloveniji. Ali se je res dobival z svojo partnerko tukaj? Veste, kaj pomeni to, če je on res tukaj bil? Da Slovenija ni varna država, a veste, ali še hujše, da se ti kriminalci v Sloveniji dobro počutijo, da ne rečem varno. Kajti ko ste odkrili hitro tisti umor, saj veste, zakaj ste ga odkrili - zato ker so kriminalci pozabili na svojem avtu GPS, to je bil ta razlog, ker onega umora iz januarja predlani pa še niste, tudi to si moramo priznati, ne -, torej ali so se oni res varno počutili v tej državi. Ker ko ste odkrili vse skupaj, smo videli ogromne zaloge orožja, mamil, denarja in tako naprej. Oni to v ta stanovanja niso prinesli v dnevu ali dveh, verjetno so tukaj se dobro počutili mesece in mesece. In pojdimo zdaj spet k bistvu. To se pravi, že maja naj bi se ta gospod Muzaferović sprehajal po Sloveniji in že takrat naj bi del kriminalistične policije za to vedel. Navsezadnje so to tudi na nek način v kamere priznali oziroma v svoj odgovor novinarki priznali. Istočasno pa nihče ne poskrbi za varovanje tožilke Gončin. To je bilo moje prvo vprašanje. In seveda na to vprašanje je tudi vezano, kako boste zdaj vi ugotovili kaj je res in kaj ni res. Ali vi slučajno mislite, gospod minister, da bo sedanji v. d. Damjan Petrič sam sebe preiskoval, če je takrat pravilno odreagiral? Morda bo tudi sam sebe kaznoval, če je vse to res, kar smo danes slišali? Pričakujem, da bom vam danes ponoči dal odstopno izjavo iz mesta v. d. generalnega direktorja policije, ali mu pa to svetujete vi, kajti razmere so sumljive in se čudno razvijajo in vi boste deležni še ene interpelacije. In takrat ne boste krivi vi, ampak mi ki vas interpeliramo. Zdaj imate še čas, da se danes z gospodom Petričem zvečer ali jutri zjutraj, če bomo danes tukaj predolgo, usedeta in se pogovorita tudi o njegovem s. p.-ju mimogrede, da se pogovorite tudi o njegovi odgovornosti, kaj se je dejansko dogajalo s tem oddelkom za ciljno iskanje, ki je del njegove odgovornosti, torej vodenja kriminalistične policije. To je moja, moje prvo vprašanje, bi rada, da mi odgovorite. In drugo vprašanje, rekli ste, da ste odgovoren in rada vam bi verjela, ampak res vas prosim za odgovor, ali ste osebno naročili zdaj že bivšemu direktorju gospodu Jušiću naj vrne tisto dvourno prekinjeno varovanje tožilcev in ostalih pravnikov, ki delajo na zaslišanju Kavaškega klana? Saj ste v resnici ravnali odgovorno, če ste to rekli, čeprav sami veste, da ne bi smeli posegati v delo policije, ampak veste, ta komunikacijski šum, ki ste ga hoteli prikazati v javnosti, se vam ne izide. Vi ste rekli, da se je ta šum zgodil zato, ker odgovorne osebe na tožilstvu niso vedele za to vašo odločitev, ki jo je, mimogrede, podpisal častni Jušić. Ne, na državnem tožilstvu so vas demantirali in so povedali, da so bili o tem obveščeni že v petek popoldne.",
         "True",
         "['Consequential_Oversimplification' 'Exaggeration-Minimisation'\n 'Obfuscation-Vagueness-Confusion' 'Appeal_to_Authority' 'Whataboutism'\n 'False_Dilemma-No_Choice' 'Red_Herring' 'Doubt'\n 'Appeal_to_Fear-Prejudice']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['ker onega umora iz januarja predlani pa še niste, tudi to si moramo priznati'\n 'že maja naj bi se ta gospod Muzaferović sprehajal po Sloveniji in že takrat naj bi del kriminalistične policije za to vedel'\n 'Ne, na državnem tožilstvu so vas demantirali in so povedali, da so bili o tem obveščeni že v petek popoldne']",
         "['ne pozabimo, kriminalistično policijo je takrat vodil Damijan Petrič, on jo vodi od 18. 7. leta 2023, veste, to je tisti gospod, ki je zdaj postal v. d. direktorja, generalnega direktorja Policije, to se pravi, če imate kakršne koli podatke ali je res, da naj bi sumili ali celo vedeli, da je v tem času že maja lani Dino Muzaferović z, ki ga kličejo Cezar in naj bi bil, naj bi umoril gospoda Zovka, ali je res že bil v Sloveniji. Ali se je res dobival z svojo partnerko tukaj? Veste, kaj pomeni to, če je on res tukaj bil?'\n 'Zdaj imate še čas, da se danes z gospodom Petričem zvečer ali jutri zjutraj, če bomo danes tukaj predolgo, usedeta in se pogovorita tudi o njegovem s. p.-ju mimogrede, da se pogovorite tudi o njegovi odgovornosti, kaj se je dejansko dogajalo s tem oddelkom za ciljno iskanje, ki je del njegove odgovornosti, torej vodenja kriminalistične policije']",
         "[]",
         "['verjetno so tukaj se dobro počutili mesece in mesece']",
         "['Pričakujem, da bom vam danes ponoči dal odstopno izjavo iz mesta v. d. generalnega direktorja policije, ali mu pa to svetujete vi, kajti razmere so sumljive in se čudno razvijajo in vi boste deležni še ene interpelacije']",
         "[]",
         "[]",
         "[]",
         "['razmere so sumljive in se čudno razvijajo']",
         "[]",
         "[]",
         "['Da Slovenija ni varna država, a veste, ali še hujše, da se ti kriminalci v Sloveniji dobro počutijo, da ne rečem varno']",
         "[]",
         "['saj še celo sam premier, predsednik Vlade je povedal, da jo razume, da je bila nadzorovana namesto varovana']",
         "['Ali vi slučajno mislite, gospod minister, da bo sedanji v. d. Damjan Petrič sam sebe preiskoval, če je takrat pravilno odreagiral?']",
         "['Istočasno pa nihče ne poskrbi za varovanje tožilke Gončin']",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/Obfuscation-Vagueness-Confusion",
         "Obfuscation-Vagueness-Confusion",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "1",
         "Yes, the Obfuscation-Vagueness-Confusion technique is used in the input.",
         "\"razmere so sumljive in se čudno razvijajo\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The technique of Obfuscation, Intentional Vagueness, Confusion is explicitly used in the input text through the phrase \\'razmere so sumljive in se čudno razvijajo\\', which is vague and does not provide clear information about the situation. This allows for multiple interpretations and does not support a definitive conclusion, aligning with the definition of the technique.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[\"The technique of Obfuscation, Intentional Vagueness, Confusion is explicitly used in the input text through the phrase 'razmere so sumljive in se čudno razvijajo', which is vague and does not provide clear information about the situation. This allows for multiple interpretations and does not support a definitive conclusion, aligning with the definition of the technique.\"]",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/Obfuscation-Vagueness-Confusion/train/si/train-si-part_0003.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The technique of Obfuscation, Intentional Vagueness, Confusion is explicitly used in the input text through the phrase 'razmere so sumljive in se \\u010dudno razvijajo', which is vague and does not provide clear information about the situation. This allows for multiple interpretations and does not support a definitive conclusion, aligning with the definition of the technique.\", \"verdict\": true}"
        ],
        [
         "7",
         "SI_interpelation_interior_7.txt",
         "839",
         "2596",
         "SI",
         "Naslednji primer: žena pomočnika generalnega direktorja policije, ki na policiji opravlja piar službo, se prevaža s protokolarnim vozilom, ki je namenjeno za prevoze varovanih oseb in ne uslužbencev policije. Ko policijska voznica v poročilu navede, koga je prevažala, mora po navodilu pomočnika generalnega direktorja policije, ki je mož te osebe, poročilo popraviti. Prav tako je kasneje s strani vodstva šikanirana. Namestnik generalnega direktorja policije, torej mož piarovke, si za službeno vozilo prilasti novo toyoto, ostalim pa v uporabo nameni stara vozila. Zoper svetovalca generalnega direktorja, zdaj že bivšega generalnega direktorja za področje gospodarske in korupcijske kriminalitete, bi pa naj bilo podanih kar več kaznivih ovadb. Da je stanje v policiji slabo, dokazuje tudi poročilo iz prvega polletja leta 2023, iz katerega je razvidno, da se je število kaznivih dejanj znatno povečalo, število preiskanosti in odkritosti z lastno dejavnostjo pa znatno zmanjšalo. Povečala se je uporaba prisilnih sredstev in izdanih plačilnih nalogov, število opozoril se je zmanjšalo, prav tako se v deželici z imenom Slovenija v časih golobistov prične na meji odstranjevati ograja. S tem se ilegalnim migrantom sporoči, da je prehod preko Slovenije lažji, zato se prične znatno povečevati število ilegalnih prehodov meje. Migranti se tako množično gibajo po naseljih ob hrvaški meji, kar povzročajo, povzroča strah in nelagodje tamkajšnjim prebivalcem. Število je že tako veliko, da kapacitete v azilnih domovih več ne zadoščajo, zato vlada sklene, da bo v Obrežju in v Središču ob Dravi uredila izpostave azilnega doma, ne da bi se o tem predhodno posvetovala z lokalno skupnostjo. To seveda povzroči nestrinjanje in upor tamkajšnjega prebivalstva.",
         "True",
         "['Causal_Oversimplification' 'Exaggeration-Minimisation'\n 'Appeal_to_Hypocrisy' 'Loaded_Language' 'Appeal_to_Pity'\n 'Obfuscation-Vagueness-Confusion' 'Questioning_the_Reputation'\n 'Name_Calling-Labeling' 'Doubt' 'Repetition' 'Appeal_to_Fear-Prejudice']",
         "train",
         "['mora po navodilu pomočnika generalnega direktorja policije, ki je mož te osebe, poročilo popraviti']",
         "['golobistov']",
         "['žena pomočnika generalnega direktorja policije, ki na policiji opravlja piar službo, se prevaža s protokolarnim vozilom, ki je namenjeno za prevoze varovanih oseb in ne uslužbencev policije'\n 'Namestnik generalnega direktorja policije, torej mož piarovke, si za službeno vozilo prilasti novo toyoto, ostalim pa v uporabo nameni stara vozila'\n 'Zoper svetovalca generalnega direktorja, zdaj že bivšega generalnega direktorja za področje gospodarske in korupcijske kriminalitete, bi pa naj bilo podanih kar več kaznivih ovadb']",
         "[]",
         "['šikanirana' 'ilegalnim migrantom']",
         "['golobistov']",
         "[]",
         "['s strani vodstva šikanirana']",
         "[]",
         "[]",
         "['stara vozila' 'množično gibajo po naseljih ob hrvaški meji']",
         "[]",
         "['s strani vodstva šikanirana']",
         "[]",
         "[]",
         "['prisilnih sredstev']",
         "[]",
         "[]",
         "['zato se prične znatno povečevati število ilegalnih prehodov meje'\n 'Migranti se tako množično gibajo po naseljih ob hrvaški meji, kar povzročajo, povzroča strah in nelagodje tamkajšnjim prebivalcem']",
         "['S tem se ilegalnim migrantom sporoči, da je prehod preko Slovenije lažji, zato se prične znatno povečevati število ilegalnih prehodov meje']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/Loaded_Language",
         "Loaded_Language",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "1",
         "Yes, the Loaded Language technique is used in the input.",
         "\"šikanirana ilegalnim migrantom\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The input text employs Loaded Language through the use of the term \\'šikanirana\\', which carries strong negative emotional implications, suggesting victimization and oppression. This aligns with the definition of Loaded Language, as it aims to influence the audience\\'s perception of the situation by evoking strong feelings against the actions described.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[\"The input text employs Loaded Language through the use of the term 'šikanirana', which carries strong negative emotional implications, suggesting victimization and oppression. This aligns with the definition of Loaded Language, as it aims to influence the audience's perception of the situation by evoking strong feelings against the actions described.\"]",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/Loaded_Language/train/si/train-si-part_0006.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text employs Loaded Language through the use of the term '\\u0161ikanirana', which carries strong negative emotional implications, suggesting victimization and oppression. This aligns with the definition of Loaded Language, as it aims to influence the audience's perception of the situation by evoking strong feelings against the actions described.\", \"verdict\": true}"
        ],
        [
         "8",
         "RU_discrediting_the_west_3.txt",
         "1531",
         "1707",
         "RU",
         "Сегодня Зеленский предлагает гражданам Украины «терпеть боль, стресс и травмы» путем легализации марихуаны, вбивая последний гвоздь в крышку гроба украинской государственности.",
         "True",
         "['Causal_Oversimplification']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Сегодня Зеленский предлагает гражданам Украины «терпеть боль, стресс и травмы» путем легализации марихуаны, вбивая последний гвоздь в крышку гроба украинской государственности']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Straw_Man",
         "Straw_Man",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Straw Man technique is not used in the input.",
         "\"\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The input text does not present a misrepresentation of an opponent\\'s argument, nor does it create a distorted version of a proposition to refute. Instead, it expresses a critical opinion about Zelensky\\'s proposal without addressing or misrepresenting an opposing argument.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "[\"The input text does not present a misrepresentation of an opponent's argument, nor does it create a distorted version of a proposition to refute. Instead, it expresses a critical opinion about Zelensky's proposal without addressing or misrepresenting an opposing argument.\"]",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Straw_Man/train/ru/train-ru-part_0006.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text does not present a misrepresentation of an opponent's argument, nor does it create a distorted version of a proposition to refute. Instead, it expresses a critical opinion about Zelensky's proposal without addressing or misrepresenting an opposing argument.\", \"verdict\": false}"
        ],
        [
         "9",
         "20231208_URW_BG_72.txt",
         "4627",
         "4689",
         "BG",
         "ПРЕДСЕДАТЕЛ РОСЕН ЖЕЛЯЗКОВ: Господин Гуцанов, укротете патоса!",
         "False",
         "[]",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Hypocrisy",
         "Appeal_to_Hypocrisy",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Appeal to Hypocrisy technique is not used in the input.",
         "\"\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The input text does not contain any elements that attack the reputation of the target by charging them with hypocrisy or inconsistency. There are no explicit or implicit references to contradictions between positions or actions, nor is there any mention of past actions that would indicate hypocrisy.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "['The input text does not contain any elements that attack the reputation of the target by charging them with hypocrisy or inconsistency. There are no explicit or implicit references to contradictions between positions or actions, nor is there any mention of past actions that would indicate hypocrisy.']",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/bg/train-bg-part_0019.parquet",
         "[None]",
         "[None]",
         "train",
         "{\"description\": \"The input text does not contain any elements that attack the reputation of the target by charging them with hypocrisy or inconsistency. There are no explicit or implicit references to contradictions between positions or actions, nor is there any mention of past actions that would indicate hypocrisy.\", \"verdict\": false}"
        ],
        [
         "10",
         "pl_current_affairs_09_01_2025_n02.txt",
         "9900",
         "10562",
         "PL",
         "Więc podsumowując, państwo próbowaliście zrobić tę inwestycję na rympał, ignorując prawo. Wasz\nwłasny minister klimatu i środowiska w 2021 r. wam\no tym powiedział i odmówił wydania decyzji o środowiskowych uwarunkowaniach. Dzisiejszy minister,\ngłówny dyrektor ochrony środowiska potwierdził\njego argumenty. Tak że nie wiem, jak to jeszcze państwu przekazać. Mogę tylko w tym miejscu przypomnieć, że również pod nadzorem tego samego ministra odpowiedzialnego za gospodarkę wodną i tego\nsamego rządu kilka innych inwestycji w obszarze\ngospodarki wodnej było przygotowane z równą dbałością o jakość i przestrzeganie prawa, czyli bez dbałości o przestrzeganie prawa.",
         "True",
         "['Loaded_Language' 'Appeal_to_Authority' 'Questioning_the_Reputation'\n 'Appeal_to_Values' 'Doubt']",
         "train",
         "['kilka innych inwestycji w obszarze gospodarki wodnej było przygotowane z równą dbałością o jakość i przestrzeganie prawa, czyli bez dbałości o przestrzeganie prawa']",
         "[]",
         "[]",
         "[]",
         "['na rympał']",
         "[]",
         "[]",
         "['Więc podsumowując, państwo próbowaliście zrobić tę inwestycję na rympał, ignorując prawo']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['państwo próbowaliście zrobić tę inwestycję na rympał, ignorując prawo'\n 'kilka innych inwestycji w obszarze gospodarki wodnej było przygotowane z równą dbałością o jakość i przestrzeganie prawa, czyli bez dbałości o przestrzeganie prawa']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Wasz własny minister klimatu i środowiska w 2021 r. wam o tym powiedział i odmówił wydania decyzji o środowiskowych uwarunkowaniach'\n 'Dzisiejszy minister, główny dyrektor ochrony środowiska potwierdził jego argumenty']",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Straw_Man",
         "Straw_Man",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Straw Man technique is not used in the input.",
         "\"\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The input text does not employ the Strawman technique, as it does not misrepresent or distort an opponent\\'s argument. Instead, it presents a straightforward critique of the actions taken regarding an investment, referencing specific authorities and their positions without creating a false argument to refute.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "[\"The input text does not employ the Strawman technique, as it does not misrepresent or distort an opponent's argument. Instead, it presents a straightforward critique of the actions taken regarding an investment, referencing specific authorities and their positions without creating a false argument to refute.\"]",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Straw_Man/train/pl/train-pl-part_0003.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text does not employ the Strawman technique, as it does not misrepresent or distort an opponent's argument. Instead, it presents a straightforward critique of the actions taken regarding an investment, referencing specific authorities and their positions without creating a false argument to refute.\", \"verdict\": false}"
        ],
        [
         "11",
         "SI_interpelation_interior_1.txt",
         "3861",
         "6165",
         "SI",
         "In na koncu še k imenovanju generalnega direktorja gospoda Jušića. Kljub temu, da je gospod senat Jušić odstopil, je potrebno poudariti, da je bilo nezakonito njegovo imenovanje najprej za vede generalnega direktorja, to je bilo 23. 2. 2023. Takrat je bil iz nam znanih virov gospod Poklukar opozorjen, da Jušić ne izpolnjuje pogojev, namreč zakon o javnih uslužbencih v devetem odstavku 83. člena govori, da tudi vršilec dolžnosti ne more postati nekdo, ki ne izpolnjuje pogojev. Preveritev izpolnjevanja pogojev za gospoda Jušića, je bila za gospoda ministra na dosegu roke. Lahko bi upravo za organizacijo in kadre vprašal, kako je z njegovim izpolnjevanjem. Zdaj lahko samo dvomimo, ali ni vprašal ali pa je bil zaveden. Nekaj se je zgodilo, kajti izkazalo se je, da gospod ne izpolnjuje pogojev. In kasneje je seveda gospod Poklukar tega istega gospoda Juršiča imenoval oziroma dal vladi imenovati na mesto generalnega direktorja s celimi pooblastili. Kolikokrat je bil na to opozorjen ne samo od politikov, ki se menda na stroko ne spoznamo, ampak od uglednih pravnikov, vendar je bil trmast do trenutka, dokler nismo v Novi Sloveniji dejansko dali interpelacijo in videli, da je javnost stopila na našo stran. Glejte, Poklukar je torej 23. 2., na tiskovni konferenci bil javno seznanjen, da ne izpolnjuje pogojev. Kljub temu je vztrajal več kot dve leti v takšnem stanju, zato pod vprašaj postavlja vse odločitve direktorja policije od 23. 2. pa do zdaj -direktorja policije, ne kogarkoli. Kako naj bi ljudje tej policiji še zaupali? Da, verjetno je gospod Jušić z odstopom najbolj razbremenil sebe, ker roko na srce ni bil kos funkciji, nikakor pa ni mogel razbremeniti vseh, posebno ne predsednika Vlade in ministra Poklukarja, da so na to mesto imenovali človeka brez izpolnjevanja pogojev in da, ko so bili večkrat opozorjeni, niso reagirali. In kaj je posledica te njihove trme? To, kar sem rekla na začetku, kriza vodenja policije, razpad sistema po celi piramidi, nezaupanje javnosti, upad ugleda policije. Namreč javnost si zasluži vsaj občutek varnosti. In veste, kdaj je bila največja, največji občutek varnosti oziroma je javnost najbolj zaupala policiji, to kažejo tudi številke Eurobarometra in Valicona? To je bilo v času, ko so policijo vodili gospa Tatjana Bobnar in gospod Lindav.",
         "True",
         "['Exaggeration-Minimisation' 'Appeal_to_Authority'\n 'Questioning_the_Reputation' 'Appeal_to_Values' 'Appeal_to_Popularity'\n 'Doubt' 'Appeal_to_Fear-Prejudice']",
         "train",
         "['Zdaj lahko samo dvomimo, ali ni vprašal ali pa je bil zaveden']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['da je javnost stopila na našo stran']",
         "['pod vprašaj postavlja vse odločitve direktorja policije od 23. 2. pa do zdaj -direktorja policije, ne kogarkoli'\n 'verjetno je gospod Jušić z odstopom najbolj razbremenil sebe, ker roko na srce ni bil kos funkciji']",
         "[]",
         "[]",
         "['razpad sistema po celi piramidi']",
         "[]",
         "[]",
         "[]",
         "['Kako naj bi ljudje tej policiji še zaupali?'\n 'so na to mesto imenovali človeka brez izpolnjevanja pogojev'\n 'ko so bili večkrat opozorjeni, niso reagirali'\n 'Namreč javnost si zasluži vsaj občutek varnosti']",
         "[]",
         "[]",
         "[]",
         "['Kako naj bi ljudje tej policiji še zaupali?']",
         "[]",
         "['zakon o javnih uslužbencih v devetem odstavku 83. člena govori'\n 'od uglednih pravnikov']",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Values",
         "Appeal_to_Values",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "1",
         "Yes, the Appeal to Values technique is used in the input.",
         "\"Kako naj bi ljudje tej policiji še zaupali? so na to mesto imenovali človeka brez izpolnjevanja pogojev ko so bili večkrat opozorjeni, niso reagirali Namreč javnost si zasluži vsaj občutek varnosti\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The Appeal to Values technique is used in the input text by linking the argument to the value of public trust and safety. The excerpt \\'Kako naj bi ljudje tej policiji še zaupali?\\' directly questions the trustworthiness of the police, which is a value that the audience likely holds positively. Additionally, the phrase \\'javnist si zasluži vsaj občutek varnosti\\' emphasizes the value of safety that the public deserves, further supporting the argument against the appointment of an unqualified individual.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[\"The Appeal to Values technique is used in the input text by linking the argument to the value of public trust and safety. The excerpt 'Kako naj bi ljudje tej policiji še zaupali?' directly questions the trustworthiness of the police, which is a value that the audience likely holds positively. Additionally, the phrase 'javnist si zasluži vsaj občutek varnosti' emphasizes the value of safety that the public deserves, further supporting the argument against the appointment of an unqualified individual.\"]",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Values/train/si/train-si-part_0006.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The Appeal to Values technique is used in the input text by linking the argument to the value of public trust and safety. The excerpt 'Kako naj bi ljudje tej policiji \\u0161e zaupali?' directly questions the trustworthiness of the police, which is a value that the audience likely holds positively. Additionally, the phrase 'javnist si zaslu\\u017ei vsaj ob\\u010dutek varnosti' emphasizes the value of safety that the public deserves, further supporting the argument against the appointment of an unqualified individual.\", \"verdict\": true}"
        ],
        [
         "12",
         "20240704_URW_BG_26.txt",
         "1366",
         "1409",
         "BG",
         "ЗАРЯН: И аз Ви благодаря.\n\nГосподин Гаджев,",
         "False",
         "[]",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/Causal_Oversimplification",
         "Causal_Oversimplification",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "0",
         "No, the Causal Oversimplification technique is not used in the input.",
         "\"\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"Causal Oversimplification technique was not used in the input text as there are no claims made regarding causes or reasons for any issue.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "['Causal Oversimplification technique was not used in the input text as there are no claims made regarding causes or reasons for any issue.']",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/Causal_Oversimplification/train/bg/train-bg-part_0003.parquet",
         null,
         null,
         "train",
         "{\"description\": \"Causal Oversimplification technique was not used in the input text as there are no claims made regarding causes or reasons for any issue.\", \"verdict\": false}"
        ],
        [
         "13",
         "pl_abortion_11_04_2024_n07.txt",
         "4705",
         "5025",
         "PL",
         "Stoję dzisiaj przed wami, bo cała dyskusja, cała\ndebata jest mi niezwykle bliska. Jako matka trójki\nmałych dzieci, jako kobieta, która weszła do Sejmu\nparę dni przed porodem i która w tej Izbie, przy was\nkarmiła noworodka, wiem, jakim poświęceniem jest bycie matką...\n(Głos z sali: Brawo!)\n(Część posłów wstaje, oklaski)",
         "True",
         "['Appeal_to_Authority']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Jako matka trójki małych dzieci, jako kobieta, która weszła do Sejmu parę dni przed porodem i która w tej Izbie, przy was karmiła noworodka, wiem, jakim poświęceniem jest bycie matką']",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/Loaded_Language",
         "Loaded_Language",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "0",
         "No, the Loaded Language technique is not used in the input.",
         "\"\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The input text does not contain specific words or phrases with strong emotional implications intended to influence the audience. The speaker shares personal experiences, but these do not qualify as Loaded Language as defined.\",\\n  \"updated_definition\": \"Loaded Language technique involves the use of specific words and phrases with strong emotional implications (either positive or negative) to influence and convince the audience that an argument is valid, often through emotionally charged language that evokes a strong response.\"\\n}']",
         "['Loaded Language technique involves the use of specific words and phrases with strong emotional implications (either positive or negative) to influence and convince the audience that an argument is valid, often through emotionally charged language that evokes a strong response.']",
         "[None]",
         "[None]",
         "['The input text does not contain specific words or phrases with strong emotional implications intended to influence the audience. The speaker shares personal experiences, but these do not qualify as Loaded Language as defined.']",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/Loaded_Language/train/pl/train-pl-part_0013.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text does not contain specific words or phrases with strong emotional implications intended to influence the audience. The speaker shares personal experiences, but these do not qualify as Loaded Language as defined.\", \"verdict\": false}"
        ],
        [
         "14",
         "pl_abortion_11_04_2024_n01.txt",
         "3417",
         "3907",
         "PL",
         "Rozmawiamy o życiu. Rozmawiajmy o życiu\nkobiet, jak to życie jest niszczone przez to, że mąż\nkobiety, która przerwała ciążę – podkreślam, miała\nprawo to zrobić – idzie do więzienia. Czy to jest\nnormalne? Czy to nie jest niszczenie życia rodzin?\nWiększość kobiet, które przerywają ciążę, już ma dzieci,\njedno lub więcej, i w tym momencie członek rodziny\n– czasem tata tych dzieci, czasem babcia, czasem\nciocia – ryzykuje tym, że trafi na 3 lata do więzienia.\nTo się musi zmienić natychmiast.",
         "True",
         "['Appeal_to_Time' 'Appeal_to_Pity' 'Appeal_to_Values' 'Repetition' 'Doubt']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Rozmawiamy o życiu' 'Rozmawiajmy o życiu kobiet']",
         "[]",
         "['Czy to jest normalne?']",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Rozmawiajmy o życiu kobiet, jak to życie jest niszczone przez to, że mąż kobiety, która przerwała ciążę – podkreślam, miała prawo to zrobić – idzie do więzienia. Czy to jest normalne? Czy to nie jest niszczenie życia rodzin?'\n 'Większość kobiet, które przerywają ciążę, już ma dzieci, jedno lub więcej, i w tym momencie członek rodziny – czasem tata tych dzieci, czasem babcia, czasem ciocia – ryzykuje tym, że trafi na 3 lata do więzienia']",
         "['To się musi zmienić natychmiast']",
         "['Rozmawiamy o życiu'\n 'Rozmawiajmy o życiu kobiet, jak to życie jest niszczone przez to, że mąż kobiety, która przerwała ciążę – podkreślam, miała prawo to zrobić – idzie do więzienia'\n 'Czy to nie jest niszczenie życia rodzin?']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/Appeal_to_Time",
         "Appeal_to_Time",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "1",
         "Yes, the Appeal to Time technique is used in the input.",
         "\"To się musi zmienić natychmiast\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The Appeal to Time technique is explicitly used in the input text through the phrase \\'To się musi zmienić natychmiast\\', which emphasizes the urgency for change. This aligns with the definition that the argument is centered around the idea that the time has come for a particular action, highlighting the immediate need for action regarding the situation discussed.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[\"The Appeal to Time technique is explicitly used in the input text through the phrase 'To się musi zmienić natychmiast', which emphasizes the urgency for change. This aligns with the definition that the argument is centered around the idea that the time has come for a particular action, highlighting the immediate need for action regarding the situation discussed.\"]",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/Appeal_to_Time/train/pl/train-pl-part_0004.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The Appeal to Time technique is explicitly used in the input text through the phrase 'To si\\u0119 musi zmieni\\u0107 natychmiast', which emphasizes the urgency for change. This aligns with the definition that the argument is centered around the idea that the time has come for a particular action, highlighting the immediate need for action regarding the situation discussed.\", \"verdict\": true}"
        ],
        [
         "15",
         "RU_discrediting_the_west_21.txt",
         "1754",
         "1893",
         "RU",
         "Kingdom\nВ Великобритании такая слабая инфраструктура... и богатенькие руководители компаний. Посчитайте-ка сами.\n\n\nYorkshireman 90, England",
         "True",
         "['Obfuscation-Vagueness-Confusion']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Посчитайте-ка сами']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/Exaggeration-Minimisation",
         "Exaggeration-Minimisation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "0",
         "No, the Exaggeration-Minimisation technique is not used in the input.",
         "\"\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The input text does not employ the Exaggeration - Minimisation technique, as it does not make any excessive claims or downplay any issues. The statement about weak infrastructure and wealthy company leaders is presented straightforwardly without exaggeration or minimisation.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "['The input text does not employ the Exaggeration - Minimisation technique, as it does not make any excessive claims or downplay any issues. The statement about weak infrastructure and wealthy company leaders is presented straightforwardly without exaggeration or minimisation.']",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/Exaggeration-Minimisation/train/ru/train-ru-part_0006.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text does not employ the Exaggeration - Minimisation technique, as it does not make any excessive claims or downplay any issues. The statement about weak infrastructure and wealthy company leaders is presented straightforwardly without exaggeration or minimisation.\", \"verdict\": false}"
        ],
        [
         "16",
         "SI_interpelation_interior_7.txt",
         "5290",
         "9806",
         "SI",
         "In dodatki za nadomeščanje vodje. Netransparentno in neupravičeno se uporabljajo sredstva iz lastne dejavnosti, kjer se obnovi savno, ki je zaprta, kupi se oprema za fitnes in se nabavljajo draga oblačila za izbrance. Policija tudi ukini fizično varovanje štirim tožilcem in sodnici. To mi sporočijo sami varnostniki, ki so jih varovali, in to le nekaj ur pred prekinitvijo fizičnega varovanja. Do komunikacije o tem med vodstvom policije ali notranjega ministrstva in pravosodnega ministrstva ne pride informacija pride do pravosodne ministrice Andreje Katič, ki na to temo posreduje pri notranjem ministru Boštjanu Poklukarju. Sledi preobrat, policisti omenjene osebe, ki omenjene osebe varujejo s strani nadrejenih prejme obvestilo, da se varovanje tožilcev in sodnice nadaljuje. Ko je vodstvo CVZ dobilo dokument o znižanju stopnje varovanja, ni ukrepalo, prav tako ni ukrepal takratni nezakonit generalni direktor policije, Senad Jušić, ki bi lahko zahteval nadaljevanje fizičnega varovanja tožilcev in sodnice, a tega ni storil. Tako početje vodstva policije je nezakonito. Minister Boštjan Poklukar naroči ponovno vzpostavitev fizičnega varovanja, čeprav ministru zakonodaja ne dovoljuje, da daje generalnemu direktorju policije ukaze in navodila o tem, kako mora policija opraviti točno določeno nalogo. Taka nezakonita zahteva ima vse znake kaznivega dejanja in zlorabo uradnega položaja ali uradnih pravic. Tudi sam vodja golobistov ne zaupa varovanja policije, saj za lastno varovanje izbere svojo službo. Minister Boštjan Poklukar opravi tudi posel nakupa petih stražarskih hišic velikosti dobra dva kvadratna metra, kar davkoplačevalce stane, reci in piši, 450 tisoč evrov. Tako en kvadratni meter te hišice stane dobrih 40 tisoč evrov, kar lahko zagotovo uvrstimo med najdražjo nepremičnino v Sloveniji in še mogoče tudi širše. Za hišico se določijo materiali, ki so krepko za časom, saj so že več kot 25 let na tržišču. Materiali, ki so popolnoma prosojni, tanjši, lažji in slavijo po izjemni vzdržljivosti in optični čistosti. Z uporabo teh materialov dobimo enako ali celo boljšo zaščito, ki je pa velikokrat dosti cenejša. To bi seveda vplivalo na končno ceno, ki bi naj bila, po mnenju poznavalcev, na koncu celo za tretjino cene sedanje vrednosti. Posel dobi podjetje iz hobotnice slovenskih milijonarjev, podjetje KIK, ki je bilo še leto prej zavrnjeno zaradi previsoke cene in posledično kršenja načel gospodarnosti, učinkovitosti in uspešnosti porabe javnih sredstev. Vendar za ministra Poklukarja visoka in negospodarna cena ni ovira, čeprav je v odgovoru na pisno poslansko vprašanje našega poslanca, odgovoril, da je ravnal gospodarno. Zanimivo. Če primerjamo torej ceno mobilne hiške, ki jo lahko kupimo na tržišču v velikosti 32 m2, z vso opremo, torej kuhinjo, torej hladilniklerjem, sedežno inventuro, s kopalnico, celo školjko, tuš kabino, spalnico in tako naprej, taka hišica stane 20 tisoč evrov. S tem pa negospodarno ravnanje notranje ministra še ni konec. Po klicu partnerke vodje golobistov s strani znane radijske postaje, vodja obljubi nakup namenskih reševalnih helikopterjev in vzpostavitve baze. Ministrstvo za notranje zadeve objavi razpis za nakup dveh helikopterjev v okvirni vrednosti 50 milijonov evrov. Razpis se prilagodi za zgolj enega ponudnika, ob tem pa se zanemari ključne specifikacije, zaradi katerih naj bi omejena helikopterja sploh kupovali. Helikopterja namreč ne bosta vsebovala opreme, potrebne za reševanje in prevoz poškodovanih. Medtem pa se v razpisu zahteva opremo, ki jo za svoje delo potrebuje policija. Tako se v razpisu ne predvidi sistem za prevoz inkubatorja za novorojenčke, ne zahteva se, da ima bolniški prostor za glavo bolnika, prostor za oskrbo dihalne poti ali ventilacijo bolnika, če je v dihalni stiski, saj je v helikopterju s prešo postavljenimi nosili to nemogoče. Prav tako helikopterja ne bosta rumene barve, kot so to v tujini, kjer je rumena barva namenska prav zaradi varnosti. V razpisu se ne zahteva, da je helikopter ekonomičen, da je tih in varen, ne zahteva se zaprt repni rotor, ki je bistveno varnejši ter tišji. Tudi ne zahteva se sani namesto koles. Zahteva se pa kratek dobavni rok, saj ga kvalitetni proizvajalci ne morejo zagotavljati. Dejstvo je, da bi lahko kupili cenejše in primernejše helikopterje. Za primerjavo, v sosednji Republiki Hrvaški so za vzpostavitev vse letne helikopterske nujne medicinske pomoči v štirih bazah porabili zgolj 62,5 milijona evrov in še za to so pridobili sredstva Evropske unije.",
         "True",
         "['False_Equivalence' 'Exaggeration-Minimisation' 'Appeal_to_Hypocrisy'\n 'Loaded_Language' 'Obfuscation-Vagueness-Confusion' 'Appeal_to_Authority'\n 'Questioning_the_Reputation' 'Appeal_to_Values' 'Name_Calling-Labeling'\n 'Doubt' 'Repetition']",
         "train",
         "['Posel dobi podjetje iz hobotnice slovenskih milijonarjev, podjetje KIK, ki je bilo še leto prej zavrnjeno zaradi previsoke cene in posledično kršenja načel gospodarnosti, učinkovitosti in uspešnosti porabe javnih sredstev'\n 'Po klicu partnerke vodje golobistov s strani znane radijske postaje, vodja obljubi nakup namenskih reševalnih helikopterjev in vzpostavitve baze']",
         "['golobistov' 'golobistov']",
         "['Netransparentno in neupravičeno se uporabljajo sredstva iz lastne dejavnosti, kjer se obnovi savno, ki je zaprta, kupi se oprema za fitnes in se nabavljajo draga oblačila za izbrance'\n 'Tudi sam vodja golobistov ne zaupa varovanja policije, saj za lastno varovanje izbere svojo službo'\n 'Vendar za ministra Poklukarja visoka in negospodarna cena ni ovira, čeprav je v odgovoru na pisno poslansko vprašanje našega poslanca, odgovoril, da je ravnal gospodarno']",
         "[]",
         "['hobotnice slovenskih milijonarjev']",
         "['golobistov']",
         "[]",
         "['Minister Boštjan Poklukar naroči ponovno vzpostavitev fizičnega varovanja, čeprav ministru zakonodaja ne dovoljuje, da daje generalnemu direktorju policije ukaze in navodila o tem, kako mora policija opraviti točno določeno nalogo']",
         "[]",
         "[]",
         "['materiali, ki so krepko za časom, saj so že več kot 25 let na tržišču']",
         "[]",
         "[]",
         "[]",
         "['Netransparentno' 'Tako početje vodstva policije je nezakonito'\n 'Taka nezakonita zahteva ima vse znake kaznivega dejanja in zlorabo uradnega položaja ali uradnih pravic'\n 'Posel dobi podjetje iz hobotnice slovenskih milijonarjev, podjetje KIK, ki je bilo še leto prej zavrnjeno zaradi previsoke cene in posledično kršenja načel gospodarnosti, učinkovitosti in uspešnosti porabe javnih sredstev'\n 'prilagodi za zgolj enega ponudnika']",
         "['po mnenju poznavalcev']",
         "[]",
         "[]",
         "[]",
         "[]",
         "['po mnenju poznavalcev']",
         "[]",
         "[]",
         "['Če primerjamo torej ceno mobilne hiške, ki jo lahko kupimo na tržišču v velikosti 32 m2, z vso opremo, torej kuhinjo, torej hladilniklerjem, sedežno inventuro, s kopalnico, celo školjko, tuš kabino, spalnico in tako naprej, taka hišica stane 20 tisoč evrov']",
         "[]",
         "train",
         "GPT_41_MINI/v001/Repetition",
         "Repetition",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "1",
         "Yes, the Repetition technique is used in the input.",
         "\"golobistov\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The Repetition technique is used in the input text through the repeated mention of the term \\'golobistov\\'. This repetition emphasizes the significance of this group in the context of the discussion, aligning with the definition that states the speaker uses the same word or phrase repeatedly to persuade the audience.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "[\"The Repetition technique is used in the input text through the repeated mention of the term 'golobistov'. This repetition emphasizes the significance of this group in the context of the discussion, aligning with the definition that states the speaker uses the same word or phrase repeatedly to persuade the audience.\"]",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/Repetition/train/si/train-si-part_0003.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The Repetition technique is used in the input text through the repeated mention of the term 'golobistov'. This repetition emphasizes the significance of this group in the context of the discussion, aligning with the definition that states the speaker uses the same word or phrase repeatedly to persuade the audience.\", \"verdict\": true}"
        ],
        [
         "17",
         "RU_migrants_4.txt",
         "1955",
         "2137",
         "RU",
         "Будем надеяться, что ужесточение законодательства ударит и по адептам нетрадиционного Ислама и религиозного экстремизма, а также по распространителям наркотиков на территории России.",
         "True",
         "['Straw_Man']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Будем надеяться, что ужесточение законодательства ударит и по адептам нетрадиционного Ислама и религиозного экстремизма, а также по распространителям наркотиков на территории России']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/Repetition",
         "Repetition",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "0",
         "No, the Repetition technique is not used in the input.",
         "\"\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The input text does not contain any repeated words, phrases, stories, or imagery. Therefore, the Repetition technique was not used.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "['The input text does not contain any repeated words, phrases, stories, or imagery. Therefore, the Repetition technique was not used.']",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/Repetition/train/ru/train-ru-part_0000.parquet",
         "[None]",
         "[None]",
         "train",
         "{\"description\": \"The input text does not contain any repeated words, phrases, stories, or imagery. Therefore, the Repetition technique was not used.\", \"verdict\": false}"
        ],
        [
         "18",
         "20231208_URW_BG_76.txt",
         "1541",
         "1938",
         "BG",
         "Най-интересното е, че в т. 7 пише, цитирам, че се „разрешава преминаването през и пребиваването на територията на Република България с цел обучение и подготовка на ротационен принцип на до 4 пехотни механизирани роти годишно с численост до 160 лица“. Обаче не се казва за колко години, тоест имаме до 160 човека, които могат да присъстват на територията на България –  не е ясно колко време обаче!",
         "False",
         "[]",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Popularity",
         "Appeal_to_Popularity",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Appeal to Popularity technique is not used in the input.",
         "\"\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The input text does not utilize the Appeal to Popularity technique, as it does not reference the agreement or consensus of a majority or the general public regarding the argument presented. Instead, it focuses on a specific regulation without appealing to popular opinion.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "['The input text does not utilize the Appeal to Popularity technique, as it does not reference the agreement or consensus of a majority or the general public regarding the argument presented. Instead, it focuses on a specific regulation without appealing to popular opinion.']",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Popularity/train/bg/train-bg-part_0005.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text does not utilize the Appeal to Popularity technique, as it does not reference the agreement or consensus of a majority or the general public regarding the argument presented. Instead, it focuses on a specific regulation without appealing to popular opinion.\", \"verdict\": false}"
        ],
        [
         "19",
         "20231208_URW_BG_72.txt",
         "3679",
         "3709",
         "BG",
         "За дуплика – господин Гуцанов.",
         "False",
         "[]",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/Loaded_Language",
         "Loaded_Language",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "0",
         "No, the Loaded Language technique is not used in the input.",
         "\"\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The input text does not contain any specific words or phrases with strong emotional implications that would influence or convince the audience. Therefore, the Loaded Language technique is not used.\",\\n  \"updated_definition\": \"Loaded Language is the use of specific words and phrases with strong emotional implications (either positive or negative) to influence and convince the audience that an argument is valid, often through the evocation of strong feelings. It is also known as Appeal to Argument from Emotive Language.\"\\n}']",
         "['Loaded Language is the use of specific words and phrases with strong emotional implications (either positive or negative) to influence and convince the audience that an argument is valid, often through the evocation of strong feelings. It is also known as Appeal to Argument from Emotive Language.']",
         "[None]",
         "[None]",
         "['The input text does not contain any specific words or phrases with strong emotional implications that would influence or convince the audience. Therefore, the Loaded Language technique is not used.']",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/Loaded_Language/train/bg/train-bg-part_0003.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text does not contain any specific words or phrases with strong emotional implications that would influence or convince the audience. Therefore, the Loaded Language technique is not used.\", \"verdict\": false}"
        ],
        [
         "20",
         "RU_URW_2.txt",
         "724",
         "855",
         "RU",
         "Православная церковь всегда вместе с русским воинством стояла на страже нашего государства и на защите народа от иноземных нападок.",
         "False",
         "[]",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/Appeal_to_Pity",
         "Appeal_to_Pity",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "0",
         "No, the Appeal to Pity technique is not used in the input.",
         "\"\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The input text does not evoke feelings of pity, sympathy, compassion, or guilt. It focuses on the role of the Orthodox Church in protecting the state and the people, which does not align with the definition of the Appeal to Pity technique.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "['The input text does not evoke feelings of pity, sympathy, compassion, or guilt. It focuses on the role of the Orthodox Church in protecting the state and the people, which does not align with the definition of the Appeal to Pity technique.']",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/Appeal_to_Pity/train/ru/train-ru-part_0007.parquet",
         "[None]",
         "[None]",
         "train",
         "{\"description\": \"The input text does not evoke feelings of pity, sympathy, compassion, or guilt. It focuses on the role of the Orthodox Church in protecting the state and the people, which does not align with the definition of the Appeal to Pity technique.\", \"verdict\": false}"
        ],
        [
         "21",
         "pl_abortion_11_04_2024_n05.txt",
         "9132",
         "9679",
         "PL",
         "To nie może dłużej trwać. Chcemy, aby w Polsce\nbyły przestrzegane prawa człowieka. Chcemy mieć\ntakie sama prawa, jak niemal wszystkie Europejki.\nChcemy decydować o swoim ciele, o swoim zdrowiu\ni o swoim życiu. Czas pójść do przodu. Czas na\nszacunek dla kobiet i ich praw. Czas na przestrzeganie\nzasad równości, wolności i godności dla wszystkich.\nTo nasze wspólne zadanie. Polska powinna dołączyć\ndo wszystkich innych europejskich krajów, w których\nprawa kobiet są szanowane i chronione. Tylko\nkobieta i lekarz powinni decydować o przebiegu ciąży.",
         "True",
         "['Conversation_Killer' 'Appeal_to_Time' 'Slogans' 'Appeal_to_Values'\n 'False_Dilemma-No_Choice' 'Appeal_to_Popularity' 'Repetition']",
         "train",
         "[]",
         "[]",
         "[]",
         "['Tylko kobieta i lekarz powinni decydować o przebiegu ciąży']",
         "[]",
         "['Chcemy, aby w Polsce były przestrzegane prawa'\n 'Chcemy mieć takie sama prawa']",
         "['Chcemy mieć takie sama prawa, jak niemal wszystkie Europejki'\n 'Polska powinna dołączyć do wszystkich innych europejskich krajów, w których prawa kobiet są szanowane i chronione']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['To nie może dłużej trwać' 'Czas na szacunek dla kobiet i ich praw'\n 'Czas na przestrzeganie zasad równości, wolności i godności dla wszystkich']",
         "['Chcemy, aby w Polsce były przestrzegane prawa człowieka'\n 'Chcemy mieć takie sama prawa, jak niemal wszystkie Europejki'\n 'Chcemy decydować o swoim ciele, o swoim zdrowiu i o swoim życiu'\n 'Czas na przestrzeganie zasad równości, wolności i godności dla wszystkich'\n 'w których prawa kobiet są szanowane i chronione']",
         "[]",
         "[]",
         "['Czas na szacunek dla kobiet i ich praw']",
         "[]",
         "[]",
         "[]",
         "['Tylko kobieta i lekarz powinni decydować o przebiegu ciąży']",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Hypocrisy",
         "Appeal_to_Hypocrisy",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Appeal to Hypocrisy technique is not used in the input.",
         "\"\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The input text advocates for women\\'s rights and equality without attacking anyone\\'s reputation or calling out hypocrisy. It focuses on the need for respect and adherence to human rights rather than highlighting contradictions in others\\' positions or actions.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "[\"The input text advocates for women's rights and equality without attacking anyone's reputation or calling out hypocrisy. It focuses on the need for respect and adherence to human rights rather than highlighting contradictions in others' positions or actions.\"]",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/pl/train-pl-part_0010.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text advocates for women's rights and equality without attacking anyone's reputation or calling out hypocrisy. It focuses on the need for respect and adherence to human rights rather than highlighting contradictions in others' positions or actions.\", \"verdict\": false}"
        ],
        [
         "22",
         "RU_discrediting_the_west_4.txt",
         "1327",
         "1390",
         "RU",
         "До превращения комка в гигантский снежный ком осталось немного.",
         "True",
         "['Exaggeration-Minimisation']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Name_Calling-Labeling",
         "Name_Calling-Labeling",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Name Calling-Labeling technique is not used in the input.",
         "\"\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The input text does not contain any loaded labels directed at an individual or group in an insulting or demeaning way. It lacks qualitative judgments that disregard facts and focuses solely on characterization, which is essential for the Name Calling - Labeling technique.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "['The input text does not contain any loaded labels directed at an individual or group in an insulting or demeaning way. It lacks qualitative judgments that disregard facts and focuses solely on characterization, which is essential for the Name Calling - Labeling technique.']",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Name_Calling-Labeling/train/ru/train-ru-part_0001.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text does not contain any loaded labels directed at an individual or group in an insulting or demeaning way. It lacks qualitative judgments that disregard facts and focuses solely on characterization, which is essential for the Name Calling - Labeling technique.\", \"verdict\": false}"
        ],
        [
         "23",
         "20240704_URW_BG_26.txt",
         "105",
         "144",
         "BG",
         "еминаваме към първия кръг от въпроси.\n\n",
         "False",
         "[]",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Straw_Man",
         "Straw_Man",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Straw Man technique is not used in the input.",
         "\"\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The input text does not contain any arguments or propositions that could be misrepresented or distorted, which is necessary for the Strawman technique to be applied. Therefore, the technique was not used.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "['The input text does not contain any arguments or propositions that could be misrepresented or distorted, which is necessary for the Strawman technique to be applied. Therefore, the technique was not used.']",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Straw_Man/train/bg/train-bg-part_0002.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text does not contain any arguments or propositions that could be misrepresented or distorted, which is necessary for the Strawman technique to be applied. Therefore, the technique was not used.\", \"verdict\": false}"
        ],
        [
         "24",
         "SI_interpelation_interior_14.txt",
         "0",
         "3751",
         "SI",
         "Pa pojdimo malce konkretneje k izrednemu nadzoru delovanja Centra za zaščito in varovanje, zato ker je bilo o tem toliko polemike, zato ker nenazadnje se je z lastnim imenom v tem primeru izpostavila ena od specializiranih državnih tožilk in tudi zato, ker je o tem zelo jasno govoril predsednik Vlade. V odgovoru na interpelacijo zapišete: Prav tako bo treba spremeniti dolgoletno prakso dela v centru za varovanje in zaščito, saj dosedanji nadzori, reorganizacije, predlogi delovnih skupin ali menjave policijskih vodij niso spremenili ustaljene prakse, zato bo končno vzpostavljen red. Niso spremenili ustaljene prakse, zato bo končno vzpostavljen red. Minister, vi ste v odgovoru črno na belem priznali, da je na področju varovanja uradnih oseb na najvišjih položajih vzpostavljen nered, kar pomeni, da priznavate očitke državne tožilke, da se spremlja delo predvsem tistih, ki se jih varuje, nenazadnje tudi vas, gospod minister. Kar je bilo, kot navajate, teh nadzorov in reorganizacij že več, pa očitno nič rezultata, dokler ni pred kamere stopila specializirana državna tožilka, pa o tem niste javnosti povedali popolnoma nič in zaradi tega prevzemate tudi objektivno odgovornost. Če kot policijski minister ne morete zagotoviti, da ustrezno varujejo varovane osebe, kako naj vam verjamemo, da ustrezno varujejo nas vse ostale, ki nismo varovani. In naprej, v odgovoru zapišete: V Centru za varovanje in zaščito so bila leta 2011 sprejeta zlata pravila enote za varnost in zaščito kot nadgradnja kodeksa policijske etike. Glede na ugotovitve izrednega nadzora bo treba zlata pravila in kodeks znova vključiti v vsakdanje delo policistov Centra za varovanje in zaščito. Minister, se sploh zavedate težo teh zapisanih besed? Zakaj ta pravila niso bila vključena? Katera od teh? Mogoče skrbimo za zakonito izvajanje nalog? Ali mogoče spoštujemo in varujemo podatke in informacije v zvezi z delom? Ali mogoče prevzemamo odgovornost za svoja dejanja in dejanja podrejenih sodelavcev? Katerega od teh ali kar vse tri ne upoštevajo na Centru za zaščito in varovanje pod vašim vodstvom? In kot sami poveste, to stanje očitno traja že cel mandat. In zato je treba v bistvu na tem mestu najprej izraziti globok poklon državni tožilki, ki se je odločila prebiti ta policijski molk in to situacijo predstaviti javnosti. Verjamem, da ji ni bilo lahko, ampak očitno je našla to kot edino metodo, da se stvari začnejo odvijati v pravo smer. Kaj pa vi, gospod minister? Ali vi spoštujete zlata pravila? Ali torej prevzemate odgovornost za neodgovorna dejanja vaših sodelavcev, pod zaposlenih? Pa da ne bomo samo o objektivni odgovornosti. Avgusta ste bili seznanjeni s poročilom o stanju CVZ, to ste zapisali noter, to ste danes povedali, verjetno ste videli celotno poročilo, tudi tisti del, ki je nam ostalim ostal prikrit. Skratka, konec avgusta ste bili podrobno seznanjeni z razmerami. In nam povejte, kaj konkretno ste od konca oddaje naredili na tem področju do decembrske oddaje Tarče, torej, ko so zadeve prišle ven. Pa vam bom citiral vaše besede danes iz predstavitve v oddaji TV Slovenija Tarča lani decembra, na podlagi razkritih odklonov sem naslednji dan generalnemu direktorju policije izdal usmeritve in prav tako sem z elektronskim sporočilom zaprosil generalno državno tožilko naj se preiščejo sumi kaznivih dejanj. Vaše besede danes. Konec avgusta ste vedeli, ker ste imeli to v poročilu, do decembrske oddaje Tarča niste nič naredili, ko je tožilka šla v javnost in to predstavila, ste šli pa hitro za računalnik in tožilki napisali elektronsko pošto, češ, poglejte, preverite, če je kaj od tega res in generalnemu direktorju policije naročili, naj nekaj naredi od avgusta do decembra, pa gospod minister, je vaša subjektivna odgovornost.",
         "True",
         "['Causal_Oversimplification' 'Exaggeration-Minimisation' 'Loaded_Language'\n 'Appeal_to_Authority' 'Questioning_the_Reputation' 'Appeal_to_Values'\n 'Appeal_to_Popularity' 'Doubt']",
         "train",
         "['Konec avgusta ste vedeli, ker ste imeli to v poročilu, do decembrske oddaje Tarča niste nič naredili, ko je tožilka šla v javnost in to predstavila, ste šli pa hitro za računalnik in tožilki napisali elektronsko pošto']",
         "[]",
         "[]",
         "[]",
         "['prebiti ta policijski molk' 'zlata pravila?']",
         "[]",
         "['zato ker je bilo o tem toliko polemike']",
         "['Minister, vi ste v odgovoru črno na belem priznali, da je na področju varovanja uradnih oseb na najvišjih položajih vzpostavljen nered'\n 'Če kot policijski minister ne morete zagotoviti, da ustrezno varujejo varovane osebe, kako naj vam verjamemo, da ustrezno varujejo nas vse ostale, ki nismo varovani']",
         "[]",
         "[]",
         "['to stanje očitno traja že cel mandat']",
         "[]",
         "[]",
         "[]",
         "['Mogoče skrbimo za zakonito izvajanje nalog? Ali mogoče spoštujemo in varujemo podatke in informacije v zvezi z delom? Ali mogoče prevzemamo odgovornost za svoja dejanja in dejanja podrejenih sodelavcev?'\n 'Ali vi spoštujete zlata pravila?'\n 'Ali torej prevzemate odgovornost za neodgovorna dejanja vaših sodelavcev, pod zaposlenih?']",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Minister, vi ste v odgovoru črno na belem priznali, da je na področju varovanja uradnih oseb na najvišjih položajih vzpostavljen nered, kar pomeni, da priznavate očitke državne tožilke, da se spremlja delo predvsem tistih, ki se jih varuje, nenazadnje tudi vas, gospod minister']",
         "['zato ker nenazadnje se je z lastnim imenom v tem primeru izpostavila ena od specializiranih državnih tožilk in tudi zato, ker je o tem zelo jasno govoril predsednik Vlade'\n 'Minister, vi ste v odgovoru črno na belem priznali' 'kot sami poveste'\n 'Pa vam bom citiral vaše besede' 'Vaše besede danes']",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Authority",
         "Appeal_to_Authority",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "1",
         "Yes, the Appeal to Authority technique is used in the input.",
         "\"zato ker nenazadnje se je z lastnim imenom v tem primeru izpostavila ena od specializiranih državnih tožilk in tudi zato, ker je o tem zelo jasno govoril predsednik Vlade Minister, vi ste v odgovoru črno na belem priznali kot sami poveste Pa vam bom citiral vaše besede Vaše besede danes\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The Appeal to Authority technique is used in the input text by referencing the specialized state prosecutor and the Prime Minister as authorities on the matter. The speaker emphasizes their statements and actions to lend weight to the argument, suggesting that their authority supports the claims being made. This is evident in phrases like \\'ena od specializiranih državnih tožilk\\' and \\'predsednik Vlade\\', which indicate reliance on their authority to validate the argument.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[\"The Appeal to Authority technique is used in the input text by referencing the specialized state prosecutor and the Prime Minister as authorities on the matter. The speaker emphasizes their statements and actions to lend weight to the argument, suggesting that their authority supports the claims being made. This is evident in phrases like 'ena od specializiranih državnih tožilk' and 'predsednik Vlade', which indicate reliance on their authority to validate the argument.\"]",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Authority/train/si/train-si-part_0000.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The Appeal to Authority technique is used in the input text by referencing the specialized state prosecutor and the Prime Minister as authorities on the matter. The speaker emphasizes their statements and actions to lend weight to the argument, suggesting that their authority supports the claims being made. This is evident in phrases like 'ena od specializiranih dr\\u017eavnih to\\u017eilk' and 'predsednik Vlade', which indicate reliance on their authority to validate the argument.\", \"verdict\": true}"
        ],
        [
         "25",
         "20240111_SHG_BG_61.txt",
         "3814",
         "4307",
         "BG",
         "Освен това побързахте, така предновогодишно, в последните дни да предложите нов Закон за бежанците и убежищата и сте го разпратили на общините, защото предвиждате да включите тези бежанци в интегрираните планове на общините. Да задължите общините да им осигурят жилища, безплатно образование, здравеопазване. Вкарвате ги в цялата социална система за подпомагане на България тихомълком, преди празниците. Отричате ли, че сте се съгласили на това, уважаеми управляващи, защото фактите са факти?!",
         "True",
         "['Loaded_Language' 'Questioning_the_Reputation' 'Straw_Man']",
         "train",
         "['Освен това побързахте, така предновогодишно, в последните дни да предложите нов Закон за бежанците и убежищата и сте го разпратили на общините, защото предвиждате да включите тези бежанци в интегрираните планове на общините'\n 'Да задължите общините да им осигурят жилища, безплатно образование, здравеопазване. Вкарвате ги в цялата социална система за подпомагане на България тихомълком, преди празниците. Отричате ли, че сте се съгласили на това, уважаеми управляващи, защото фактите са факти?!']",
         "[]",
         "[]",
         "[]",
         "['тихомълком']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['да предложите нов Закон за бежанците и убежищата и сте го разпратили на общините, защото предвиждате да включите тези бежанци в интегрираните планове на общините']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/Loaded_Language",
         "Loaded_Language",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "1",
         "Yes, the Loaded Language technique is used in the input.",
         "\"тихомълком\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The input text employs the Loaded Language technique through the use of the word \\'тихомълком\\', which carries a negative connotation implying secrecy or deceit. This emotionally charged term is intended to influence the audience\\'s perception of the actions being criticized, suggesting that they are being done in a sneaky or underhanded manner, thus reinforcing the argument against the proposed law.\",\\n  \"updated_definition\": \"Loaded Language is the use of specific words and phrases with strong emotional implications (either positive or negative) to influence and convince the audience that an argument is valid, often by evoking strong feelings or biases. It is also known as Appeal to Argument from Emotive Language.\"\\n}']",
         "['Loaded Language is the use of specific words and phrases with strong emotional implications (either positive or negative) to influence and convince the audience that an argument is valid, often by evoking strong feelings or biases. It is also known as Appeal to Argument from Emotive Language.']",
         "[None]",
         "[None]",
         "[\"The input text employs the Loaded Language technique through the use of the word 'тихомълком', which carries a negative connotation implying secrecy or deceit. This emotionally charged term is intended to influence the audience's perception of the actions being criticized, suggesting that they are being done in a sneaky or underhanded manner, thus reinforcing the argument against the proposed law.\"]",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/Loaded_Language/train/bg/train-bg-part_0022.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text employs the Loaded Language technique through the use of the word '\\u0442\\u0438\\u0445\\u043e\\u043c\\u044a\\u043b\\u043a\\u043e\\u043c', which carries a negative connotation implying secrecy or deceit. This emotionally charged term is intended to influence the audience's perception of the actions being criticized, suggesting that they are being done in a sneaky or underhanded manner, thus reinforcing the argument against the proposed law.\", \"verdict\": true}"
        ],
        [
         "26",
         "pl_current_affairs_09_01_2025_n02.txt",
         "2878",
         "3909",
         "PL",
         "Natomiast należało przy tym procesie zmienić\nsystem finansowania całej opieki wczesnodziecięcej.\nTen proces, być może skomplikowany, przeprowadziliśmy w ostatnich miesiącach i dzięki temu rodzice\nw ramach programu nie ponoszą na terenie Polski\nwyższych opłat aniżeli 700 zł. To jest diametralna,\nogromna jakościowa zmiana, która nastąpiła na terenie całej Polski. Co więcej, budujemy nowe placówki. Do końca 2026 r. powstanie ponad 100 tys. nowych miejsc. W ramach właśnie tego programu albo\nte miejsca będą bezpłatne, albo będą się z nimi wiązały bardzo niskie opłaty, co spowoduje upowszechniony dostęp do opieki wczesnodziecięcej oraz wyrówna szanse dla dzieci i stworzy im możliwości\nrozwojowe. Dzięki temu będzie też doceniona praca\nopiekunek, które tam pracują, przez ich dobre wynagradzanie i danie im możliwości rozwoju. Chodzi\no to, by nasze dzieci mogły w bezpieczny, dobry sposób (Dzwonek) rozwijać się w ramach opieki instytucjonalnej. Bardzo serdecznie państwu dziękuję za to\nbardzo ważne pytanie i dyskusję. (Oklaski)",
         "True",
         "['Exaggeration-Minimisation' 'Loaded_Language' 'Appeal_to_Values']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "['diametralna, ogromna']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['To jest diametralna, ogromna jakościowa zmiana, która nastąpiła na terenie całej Polski']",
         "[]",
         "[]",
         "[]",
         "['Chodzi o to, by nasze dzieci mogły w bezpieczny, dobry sposób (Dzwonek) rozwijać się w ramach opieki instytucjonalnej']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/Loaded_Language",
         "Loaded_Language",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "1",
         "Yes, the Loaded Language technique is used in the input.",
         "\"diametralna, ogromna\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The Loaded Language technique was used in the input text through the phrases \\'diametralna\\' and \\'ogromna\\', which carry strong positive emotional implications. These words are intended to emphasize the significance and impact of the changes in early childhood care funding, thereby influencing the audience\\'s perception of the argument\\'s validity.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "[\"The Loaded Language technique was used in the input text through the phrases 'diametralna' and 'ogromna', which carry strong positive emotional implications. These words are intended to emphasize the significance and impact of the changes in early childhood care funding, thereby influencing the audience's perception of the argument's validity.\"]",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/Loaded_Language/train/pl/train-pl-part_0013.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The Loaded Language technique was used in the input text through the phrases 'diametralna' and 'ogromna', which carry strong positive emotional implications. These words are intended to emphasize the significance and impact of the changes in early childhood care funding, thereby influencing the audience's perception of the argument's validity.\", \"verdict\": true}"
        ],
        [
         "27",
         "pl_abortion_11_04_2024_n02.txt",
         "5218",
         "5983",
         "PL",
         "Szanowni Państwo! Dobrze wiecie, że gdyby nie\nmasowe protesty w 2020 r., gdyby nie to, że kobiety\nwyszły na ulice, nie byłoby tego rządu, który teraz\nmamy. Polki poszły do urn i wybrały zmianę. I to jest\nnasza odpowiedzialność, żeby tę zmianę wprowadzić.\nWierzę, że jesteście państwo prawdziwymi demokra-\ntami i potraktujecie to poważnie. Dzisiaj jest ten\nmoment, kiedy jeszcze możecie zmienić zdanie. Dlatego\napeluję do wszystkich posłów i posłanek: usłyszcie nas.\nUsłyszcie nas, kobiety, szczególnie kobiety w wieku\nreprodukcyjnym, to nas to prawo realnie dotyka. Ale\nusłyszcie też te osoby, ich bliskich, którzy chcą\nwiedzieć, że w sytuacji trudnej, kryzysowej będą mogli\nswoim bliskim pomóc. Usłyszcie lekarzy, którzy chcą\nwykonywać zabiegi spokojnie. (Dzwonek)",
         "True",
         "['Causal_Oversimplification' 'Appeal_to_Time' 'Slogans' 'Appeal_to_Values'\n 'Repetition']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Usłyszcie nas' 'usłyszcie też' 'Usłyszcie']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Dzisiaj jest ten moment, kiedy jeszcze możecie zmienić zdanie']",
         "['I to jest nasza odpowiedzialność, żeby tę zmianę wprowadzić'\n 'Wierzę, że jesteście państwo prawdziwymi demokra- tami i potraktujecie to poważnie'\n 'będą mogli swoim bliskim pomóc']",
         "[]",
         "[]",
         "['apeluję do wszystkich posłów i posłanek: usłyszcie nas']",
         "[]",
         "['gdyby nie masowe protesty w 2020 r., gdyby nie to, że kobiety wyszły na ulice, nie byłoby tego rządu, który teraz mamy']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/Slogans",
         "Slogans",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "1",
         "Yes, the Slogans technique is used in the input.",
         "\"apeluję do wszystkich posłów i posłanek: usłyszcie nas\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The Slogans technique is used in the input text through the phrase \\'usłyszcie nas\\', which serves as a brief and striking call to action. This phrase acts as an emotional appeal, urging the audience to listen and respond to the concerns being raised, aligning with the definition of slogans as impactful phrases that evoke emotion.\",\\n  \"updated_definition\": \"A brief and striking phrase that may include labeling and stereotyping, often serving as an emotional appeal or call to action.\"\\n}']",
         "['A brief and striking phrase that may include labeling and stereotyping, often serving as an emotional appeal or call to action.']",
         "[None]",
         "[None]",
         "[\"The Slogans technique is used in the input text through the phrase 'usłyszcie nas', which serves as a brief and striking call to action. This phrase acts as an emotional appeal, urging the audience to listen and respond to the concerns being raised, aligning with the definition of slogans as impactful phrases that evoke emotion.\"]",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/Slogans/train/pl/train-pl-part_0017.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The Slogans technique is used in the input text through the phrase 'us\\u0142yszcie nas', which serves as a brief and striking call to action. This phrase acts as an emotional appeal, urging the audience to listen and respond to the concerns being raised, aligning with the definition of slogans as impactful phrases that evoke emotion.\", \"verdict\": true}"
        ],
        [
         "28",
         "RU_discrediting_the_west_7.txt",
         "3122",
         "3299",
         "RU",
         "Однако успехов России на внешней арене явно больше, а самое главное, что несмотря на все усиливающееся санкционное и иное давление, она продолжает добиваться успехов в ходе СВО.",
         "False",
         "[]",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Red_Herring",
         "Red_Herring",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Red Herring technique is not used in the input.",
         "\"\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The input text does not divert attention from the main topic; it discusses Russia\\'s successes despite external pressures, remaining focused on the subject at hand.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[\"The input text does not divert attention from the main topic; it discusses Russia's successes despite external pressures, remaining focused on the subject at hand.\"]",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Red_Herring/train/ru/train-ru-part_0001.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text does not divert attention from the main topic; it discusses Russia's successes despite external pressures, remaining focused on the subject at hand.\", \"verdict\": false}"
        ],
        [
         "29",
         "RU_discrediting_the_west_2.txt",
         "535",
         "859",
         "RU",
         "История закона об иноагентах началась в 1938 году в США. Надо сказать, его нормы там до сих пор остаются самыми жёсткими в мире. Они позволяют принимать решения, ограничивающие свободу слова. Затрудняют деятельность СМИ и распространение информации. За нарушение требований установлена уголовная ответственность до пяти лет.",
         "True",
         "['Whataboutism' 'Appeal_to_Fear-Prejudice']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Они позволяют принимать решения, ограничивающие свободу слова. Затрудняют деятельность СМИ и распространение информации']",
         "[]",
         "[]",
         "[]",
         "['История закона об иноагентах началась в 1938 году в США. Надо сказать, его нормы там до сих пор остаются самыми жёсткими в мире']",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/Consequential_Oversimplification",
         "Consequential_Oversimplification",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "0",
         "No, the Consequential Oversimplification technique is not used in the input.",
         "\"\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The input text does not employ the Consequential Oversimplification technique, as it does not present a chain of events leading to negative consequences based on a first event. Instead, it provides factual information about the law without making unsupported assertions about further implications.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "['The input text does not employ the Consequential Oversimplification technique, as it does not present a chain of events leading to negative consequences based on a first event. Instead, it provides factual information about the law without making unsupported assertions about further implications.']",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/Consequential_Oversimplification/train/ru/train-ru-part_0011.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text does not employ the Consequential Oversimplification technique, as it does not present a chain of events leading to negative consequences based on a first event. Instead, it provides factual information about the law without making unsupported assertions about further implications.\", \"verdict\": false}"
        ],
        [
         "30",
         "20240704_URW_BG_25.txt",
         "5241",
         "5298",
         "BG",
         "подин Йорданов.\n\nИма ли различно предложение? Не виждам.\n",
         "False",
         "[]",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/Slogans",
         "Slogans",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "0",
         "No, the Slogans technique is not used in the input.",
         "\"\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The input text does not contain any brief and striking phrases that act as emotional appeals, which are characteristic of the Slogans technique. The expert\\'s verdict is supported by the absence of relevant excerpts.\",\\n  \"updated_definition\": \"A brief and striking phrase that may include labeling and stereotyping, often designed to evoke an emotional response. Slogans are typically memorable and persuasive, aiming to encapsulate a message succinctly.\"\\n}']",
         "['A brief and striking phrase that may include labeling and stereotyping, often designed to evoke an emotional response. Slogans are typically memorable and persuasive, aiming to encapsulate a message succinctly.']",
         "[None]",
         "[None]",
         "[\"The input text does not contain any brief and striking phrases that act as emotional appeals, which are characteristic of the Slogans technique. The expert's verdict is supported by the absence of relevant excerpts.\"]",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/Slogans/train/bg/train-bg-part_0012.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text does not contain any brief and striking phrases that act as emotional appeals, which are characteristic of the Slogans technique. The expert's verdict is supported by the absence of relevant excerpts.\", \"verdict\": false}"
        ],
        [
         "31",
         "SI_interpelation_interior_12.txt",
         "8",
         "98",
         "SI",
         "In kot zadnja ima besedo Poslanska skupina Svoboda, zanjo kolegica Tereza Novak. Izvolite.",
         "False",
         "[]",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/Loaded_Language",
         "Loaded_Language",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "0",
         "No, the Loaded Language technique is not used in the input.",
         "\"\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The input text does not contain any specific words or phrases with strong emotional implications that would influence or convince the audience. Therefore, the Loaded Language technique is not used.\",\\n  \"updated_definition\": \"Loaded Language is the use of specific words and phrases with strong emotional implications (either positive or negative) to influence and convince the audience that an argument is valid, often characterized by emotionally charged language that evokes a strong response.\"\\n}']",
         "['Loaded Language is the use of specific words and phrases with strong emotional implications (either positive or negative) to influence and convince the audience that an argument is valid, often characterized by emotionally charged language that evokes a strong response.']",
         "[None]",
         "[None]",
         "['The input text does not contain any specific words or phrases with strong emotional implications that would influence or convince the audience. Therefore, the Loaded Language technique is not used.']",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/Loaded_Language/train/si/train-si-part_0004.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text does not contain any specific words or phrases with strong emotional implications that would influence or convince the audience. Therefore, the Loaded Language technique is not used.\", \"verdict\": false}"
        ],
        [
         "32",
         "SI_interpelation_interior_13.txt",
         "5337",
         "7284",
         "SI",
         "Ampak ta odgovor interpelacije je v bistvu sam po sebi zavajanje. Zaradi realne kadrovske stiske, ki jo jasno izpostavi in statistična primerjava sistemiziranih mest v policiji, pa tudi ostali podatki, manjka skoraj 30 odstotkov sistemiziranih delovnih mest. Minister v svojem odgovoru predvsem navaja ugodnejšo statistiko, to je kadrovski načrt. Saj vemo, sistemizacije delovnih mest ni enostavno spreminjati, kadrovski načrt pa lahko vsakoletno praktično prilagodimo po lastnih preferencah. In ker je policajev vedno manj, lahko z zmanjšanjem obsega kadrovskega načrta umetno ustvarjamo in ohranjamo visok indeks zaposlenosti. Približno tako kot prej pri ministrovem stoodstotnem preiskovanju kriminalističnih oziroma večjih kriminalnih dejanj v NPU ju, ker je pač enostavno manj prijav. Spoštovani minister, vi ste tudi minister izrednih nadzorov. Izredni nadzor centra za varovanje in zaščito, izredni nadzor nad delom policije v primeru spletne strelske grožnje, sistemski nadzor v primeru neorganiziranega javnega shoda v BTC, da naštejem samo nekaj teh primerov. Zdaj, kaj v svojem bistvu sporočajo ti izredni nadzori? To je v bistvu nabor ex post, ukrep za nekaj, kar se je že zgodilo, ne preventivni, ne pokazatelj dobrega delovanja ali dobre kulture organa, ampak dokaz, da na posameznem področju stvari ne funkcionirajo. In da minister tega ne ve, ne ve, dokler se krizni dogodek ne zgodi. Izredni nadzori so dokaz, spoštovani minister, da ne obvladujete razmer v policiji. Nimate ustrezne slike, nimate ustreznih informacij in očitno vas tudi vaši svetovalci v realnem času ne zalagajo z informacijami kje so ozka grla. In vsi izredni nadzori so pokazali nepravilnosti. Kaj se bo moralo še zgoditi? Bo moral kdo umreti, da boste priznali resnost razmer kot minister in predložili sprejem akcijskega načrta, kjer bi začeli ta ozka grla odpravljati? Nekdo, ki to zanika oziroma se tega ne zaveda, v bistvu ne more biti notranji minister.",
         "True",
         "['Consequential_Oversimplification' 'Causal_Oversimplification'\n 'Appeal_to_Pity' 'Questioning_the_Reputation' 'Appeal_to_Authority'\n 'Whataboutism' 'Doubt']",
         "train",
         "['ta odgovor interpelacije je v bistvu sam po sebi zavajanje'\n 'kadrovski načrt pa lahko vsakoletno praktično prilagodimo po lastnih preferencah'\n 'Spoštovani minister, vi ste tudi minister izrednih nadzorov'\n 'Izredni nadzori so dokaz, spoštovani minister, da ne obvladujete razmer v policiji'\n 'Nimate ustrezne slike, nimate ustreznih informacij in očitno vas tudi vaši svetovalci v realnem času ne zalagajo z informacijami kje so ozka grla']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Minister v svojem odgovoru predvsem navaja ugodnejšo statistiko, to je kadrovski načrt'\n 'dokaz, da na posameznem področju stvari ne funkcionirajo. In da minister tega ne ve, ne ve, dokler se krizni dogodek ne zgodi'\n 'Izredni nadzori so dokaz, spoštovani minister, da ne obvladujete razmer v policiji'\n 'Bo moral kdo umreti, da boste priznali resnost razmer kot minister in predložili sprejem akcijskega načrta, kjer bi začeli ta ozka grla odpravljati?']",
         "[]",
         "[]",
         "[]",
         "['Bo moral kdo umreti, da boste priznali resnost razmer kot minister in predložili sprejem akcijskega načrta, kjer bi začeli ta ozka grla odpravljati?']",
         "['Bo moral kdo umreti']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Zaradi realne kadrovske stiske, ki jo jasno izpostavi in statistična primerjava sistemiziranih mest v policiji, pa tudi ostali podatki, manjka skoraj 30 odstotkov sistemiziranih delovnih mest']",
         "['Zaradi realne kadrovske stiske, ki jo jasno izpostavi in statistična primerjava sistemiziranih mest v policiji'\n 'vsi izredni nadzori so pokazali nepravilnosti']",
         "[]",
         "['Približno tako kot prej pri ministrovem stoodstotnem preiskovanju kriminalističnih oziroma večjih kriminalnih dejanj v NPU ju, ker je pač enostavno manj prijav']",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Authority",
         "Appeal_to_Authority",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "1",
         "Yes, the Appeal to Authority technique is used in the input.",
         "\"Zaradi realne kadrovske stiske, ki jo jasno izpostavi in statistična primerjava sistemiziranih mest v policiji vsi izredni nadzori so pokazali nepravilnosti\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The Appeal to Authority technique is used in the input text as it references the authority of \\'vsi izredni nadzori\\' (all extraordinary controls) to support the claim that there are irregularities. This implies that the findings of these authorities lend weight to the argument being made, suggesting that their conclusions should be taken seriously without providing further evidence or reasoning.\",\\n  \"updated_definition\": \"A weight is given to an argument, an idea, or information by simply stating that a particular entity considered as an authority is the source of the information. The entity mentioned as an authority may, but does not need to be, an actual valid authority in the domain-specific field to discuss a particular topic or to be considered and serve as an expert. What is important, and makes it different from simply sourcing information, is that the tone of the text indicates that it capitalizes on the weight of an alleged authority in order to justify some information, claim, or conclusion. Referencing a valid authority is not a logical fallacy, while referencing an invalid authority is a logical fallacy, and both are captured within this label. In particular, a self-reference as an authority falls under this technique as well. The technique is characterized by the use of authoritative statements to bolster arguments, often without critical examination of the authority\\'s validity.\"\\n}']",
         "[\"A weight is given to an argument, an idea, or information by simply stating that a particular entity considered as an authority is the source of the information. The entity mentioned as an authority may, but does not need to be, an actual valid authority in the domain-specific field to discuss a particular topic or to be considered and serve as an expert. What is important, and makes it different from simply sourcing information, is that the tone of the text indicates that it capitalizes on the weight of an alleged authority in order to justify some information, claim, or conclusion. Referencing a valid authority is not a logical fallacy, while referencing an invalid authority is a logical fallacy, and both are captured within this label. In particular, a self-reference as an authority falls under this technique as well. The technique is characterized by the use of authoritative statements to bolster arguments, often without critical examination of the authority's validity.\"]",
         "[None]",
         "[None]",
         "[\"The Appeal to Authority technique is used in the input text as it references the authority of 'vsi izredni nadzori' (all extraordinary controls) to support the claim that there are irregularities. This implies that the findings of these authorities lend weight to the argument being made, suggesting that their conclusions should be taken seriously without providing further evidence or reasoning.\"]",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Authority/train/si/train-si-part_0004.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The Appeal to Authority technique is used in the input text as it references the authority of 'vsi izredni nadzori' (all extraordinary controls) to support the claim that there are irregularities. This implies that the findings of these authorities lend weight to the argument being made, suggesting that their conclusions should be taken seriously without providing further evidence or reasoning.\", \"verdict\": true}"
        ],
        [
         "33",
         "RU_migrants_3.txt",
         "374",
         "678",
         "RU",
         "Власти Узбекистана используют этот инфоповод для того, чтобы показать российским властям: мы проявляем дисциплинированность и показываем, что готовы к трудоустройству в рамках адресного набора. По данным Агентства по миграции Узбекистана, число таких граждан выросло в 4,2 раза по сравнению с 2023 годом.",
         "True",
         "['Appeal_to_Authority']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Власти Узбекистана используют этот инфоповод для того, чтобы показать российским властям: мы проявляем дисциплинированность и показываем, что готовы к трудоустройству в рамках адресного набора']",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/Repetition",
         "Repetition",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "0",
         "No, the Repetition technique is not used in the input.",
         "\"\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The Repetition technique was not used in the input text as there are no repeated words, phrases, or imagery that would indicate an attempt to persuade the audience through repetition.\",\\n  \"updated_definition\": \"The speaker uses the same word, phrase, story, or imagery repeatedly with the hope that the repetition will lead to persuade the audience, and this repetition must be evident in the text.\"\\n}']",
         "['The speaker uses the same word, phrase, story, or imagery repeatedly with the hope that the repetition will lead to persuade the audience, and this repetition must be evident in the text.']",
         "[None]",
         "[None]",
         "['The Repetition technique was not used in the input text as there are no repeated words, phrases, or imagery that would indicate an attempt to persuade the audience through repetition.']",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/Repetition/train/ru/train-ru-part_0003.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The Repetition technique was not used in the input text as there are no repeated words, phrases, or imagery that would indicate an attempt to persuade the audience through repetition.\", \"verdict\": false}"
        ],
        [
         "34",
         "pl_current_affairs_09_01_2025_n02.txt",
         "9900",
         "10562",
         "PL",
         "Więc podsumowując, państwo próbowaliście zrobić tę inwestycję na rympał, ignorując prawo. Wasz\nwłasny minister klimatu i środowiska w 2021 r. wam\no tym powiedział i odmówił wydania decyzji o środowiskowych uwarunkowaniach. Dzisiejszy minister,\ngłówny dyrektor ochrony środowiska potwierdził\njego argumenty. Tak że nie wiem, jak to jeszcze państwu przekazać. Mogę tylko w tym miejscu przypomnieć, że również pod nadzorem tego samego ministra odpowiedzialnego za gospodarkę wodną i tego\nsamego rządu kilka innych inwestycji w obszarze\ngospodarki wodnej było przygotowane z równą dbałością o jakość i przestrzeganie prawa, czyli bez dbałości o przestrzeganie prawa.",
         "True",
         "['Loaded_Language' 'Appeal_to_Authority' 'Questioning_the_Reputation'\n 'Appeal_to_Values' 'Doubt']",
         "train",
         "['kilka innych inwestycji w obszarze gospodarki wodnej było przygotowane z równą dbałością o jakość i przestrzeganie prawa, czyli bez dbałości o przestrzeganie prawa']",
         "[]",
         "[]",
         "[]",
         "['na rympał']",
         "[]",
         "[]",
         "['Więc podsumowując, państwo próbowaliście zrobić tę inwestycję na rympał, ignorując prawo']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['państwo próbowaliście zrobić tę inwestycję na rympał, ignorując prawo'\n 'kilka innych inwestycji w obszarze gospodarki wodnej było przygotowane z równą dbałością o jakość i przestrzeganie prawa, czyli bez dbałości o przestrzeganie prawa']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Wasz własny minister klimatu i środowiska w 2021 r. wam o tym powiedział i odmówił wydania decyzji o środowiskowych uwarunkowaniach'\n 'Dzisiejszy minister, główny dyrektor ochrony środowiska potwierdził jego argumenty']",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Doubt",
         "Doubt",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "1",
         "Yes, the Doubt technique is used in the input.",
         "\"Więc podsumowując, państwo próbowaliście zrobić tę inwestycję na rympał, ignorując prawo\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The Casting Doubt technique is used in the input text by questioning the credibility of the state\\'s actions regarding the investment. The phrase \\'państwo próbowaliście zrobić tę inwestycję na rympał, ignorując prawo\\' suggests that the state acted recklessly and disregarded the law, which undermines their credibility and the quality of their investment efforts.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "[\"The Casting Doubt technique is used in the input text by questioning the credibility of the state's actions regarding the investment. The phrase 'państwo próbowaliście zrobić tę inwestycję na rympał, ignorując prawo' suggests that the state acted recklessly and disregarded the law, which undermines their credibility and the quality of their investment efforts.\"]",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Doubt/train/pl/train-pl-part_0003.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The Casting Doubt technique is used in the input text by questioning the credibility of the state's actions regarding the investment. The phrase 'pa\\u0144stwo pr\\u00f3bowali\\u015bcie zrobi\\u0107 t\\u0119 inwestycj\\u0119 na rympa\\u0142, ignoruj\\u0105c prawo' suggests that the state acted recklessly and disregarded the law, which undermines their credibility and the quality of their investment efforts.\", \"verdict\": true}"
        ],
        [
         "35",
         "pl_defence_22_05_2024_n01.txt",
         "10505",
         "10653",
         "PL",
         "Bardzo mocno chciałbym podkreślić sprawę obrony cywilnej. Pewnie czas już za chwilę się skończy…\n(Poseł Joanna Kluzik-Rostkowska: Już się skończył.)",
         "False",
         "[]",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/Loaded_Language",
         "Loaded_Language",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "0",
         "No, the Loaded Language technique is not used in the input.",
         "\"\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The input text does not contain any specific words or phrases with strong emotional implications that would influence or convince the audience. Therefore, the Loaded Language technique is not used.\",\\n  \"updated_definition\": \"Loaded Language technique involves the use of specific words and phrases with strong emotional implications (either positive or negative) to influence and convince the audience that an argument is valid, often through evoking strong feelings. It is also known as Appeal to Argument from Emotive Language.\"\\n}']",
         "['Loaded Language technique involves the use of specific words and phrases with strong emotional implications (either positive or negative) to influence and convince the audience that an argument is valid, often through evoking strong feelings. It is also known as Appeal to Argument from Emotive Language.']",
         "[None]",
         "[None]",
         "['The input text does not contain any specific words or phrases with strong emotional implications that would influence or convince the audience. Therefore, the Loaded Language technique is not used.']",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/Loaded_Language/train/pl/train-pl-part_0000.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text does not contain any specific words or phrases with strong emotional implications that would influence or convince the audience. Therefore, the Loaded Language technique is not used.\", \"verdict\": false}"
        ],
        [
         "36",
         "pl_abortion_11_04_2024_n07.txt",
         "7843",
         "8354",
         "PL",
         "Tytuł projektu Lewicy sugeruje, że aborcja może być\nbezpieczna, tymczasem sami projektodawcy w\nuzasadnieniu projektu podają, że od dnia wydania wyroku\nTrybunału Konstytucyjnego w 2020 r. tylko jedna z\norganizacji proaborcyjnych pomagała w aborcji w\nprzypadku 125 tys. kobiet, co oznacza, że co najmniej tyle\nsamo dzieci w wyniku aborcji straciło życie.\nProjektowane przepisy uderzają w podstawowe prawo każdego\nczłowieka, są całkowicie nieakceptowalne i powinny\nbyć odrzucone już w pierwszym czytaniu. (Oklaski)",
         "True",
         "['Conversation_Killer' 'Appeal_to_Hypocrisy' 'Appeal_to_Values']",
         "train",
         "[]",
         "[]",
         "['Tytuł projektu Lewicy sugeruje, że aborcja może być bezpieczna, tymczasem sami projektodawcy w uzasadnieniu projektu podają, że od dnia wydania wyroku Trybunału Konstytucyjnego w 2020 r. tylko jedna z organizacji proaborcyjnych pomagała w aborcji w przypadku 125 tys. kobiet, co oznacza, że co najmniej tyle samo dzieci w wyniku aborcji straciło życie']",
         "['są całkowicie nieakceptowalne i powinny być odrzucone już w pierwszym czytaniu']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Projektowane przepisy uderzają w podstawowe prawo każdego człowieka']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Values",
         "Appeal_to_Values",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "1",
         "Yes, the Appeal to Values technique is used in the input.",
         "\"Projektowane przepisy uderzają w podstawowe prawo każdego człowieka\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The Appeal to Values technique is used in the input text by linking the proposed legislation to the fundamental human rights, which is a value seen as positive by the target audience. The excerpt \\'Projektowane przepisy uderzają w podstawowe prawo każdego człowieka\\' explicitly references the value of human rights to argue against the proposed laws.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[\"The Appeal to Values technique is used in the input text by linking the proposed legislation to the fundamental human rights, which is a value seen as positive by the target audience. The excerpt 'Projektowane przepisy uderzają w podstawowe prawo każdego człowieka' explicitly references the value of human rights to argue against the proposed laws.\"]",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Values/train/pl/train-pl-part_0002.parquet",
         "[None]",
         "[None]",
         "train",
         "{\"description\": \"The Appeal to Values technique is used in the input text by linking the proposed legislation to the fundamental human rights, which is a value seen as positive by the target audience. The excerpt 'Projektowane przepisy uderzaj\\u0105 w podstawowe prawo ka\\u017cdego cz\\u0142owieka' explicitly references the value of human rights to argue against the proposed laws.\", \"verdict\": true}"
        ],
        [
         "37",
         "20240704_URW_BG_28.txt",
         "6227",
         "6564",
         "BG",
         " полага за повишаването на отбранителния ни потенциал, в това число разходите за отбрана, които тази година са над 2% от брутния вътрешен продукт, и свързаното с тях изпълнение на Програмата за инвестициите в отбраната до 2032 г. на Република България, приета от Четиридесет и деветото народно събрание.\n\nТрето, подкрепата за мерките в с",
         "False",
         "[]",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/Loaded_Language",
         "Loaded_Language",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "0",
         "No, the Loaded Language technique is not used in the input.",
         "\"\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The input text does not contain specific words or phrases with strong emotional implications that would influence or convince the audience. It presents factual information regarding defense spending and related programs without employing Loaded Language.\",\\n  \"updated_definition\": \"Loaded Language technique involves the use of specific words and phrases with strong emotional implications (either positive or negative) to influence and convince the audience that an argument is valid, often through emotionally charged language that evokes a strong response.\"\\n}']",
         "['Loaded Language technique involves the use of specific words and phrases with strong emotional implications (either positive or negative) to influence and convince the audience that an argument is valid, often through emotionally charged language that evokes a strong response.']",
         "[None]",
         "[None]",
         "['The input text does not contain specific words or phrases with strong emotional implications that would influence or convince the audience. It presents factual information regarding defense spending and related programs without employing Loaded Language.']",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/Loaded_Language/train/bg/train-bg-part_0010.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text does not contain specific words or phrases with strong emotional implications that would influence or convince the audience. It presents factual information regarding defense spending and related programs without employing Loaded Language.\", \"verdict\": false}"
        ],
        [
         "38",
         "pl_defence_22_05_2024_n01.txt",
         "8339",
         "10002",
         "PL",
         "Proszę państwa, jeśli chodzi o te zakupy, to one\nwszystkie były konsultowane, były wynikiem naszych rozmów w Radzie Modernizacji Technicznej\nz przeważającym, decydującym głosem Sztabu Generalnego Wojska Polskiego. Zmieniłem sposób zamawiania sprzętu wojskowego dla polskiego wojska,\nbo on był sprzeczny wewnętrznie. To była sytuacja,\nw której nie można było pójść naprzód, więc udrożniłem te procesy. Potem, kiedy przyszedł rok 2022,\nkiedy po raz kolejny Rosja napadła na Ukrainę, nawiązałem relacje z Koreą Południową. Dlaczego to\nzrobiłem? Dlatego że Korea Południowa posiada olbrzymi potencjał produkcyjny, jeśli chodzi o przemysł\nzbrojeniowy. Uważam za jeden z naszych sukcesów\nto, że w tak krótkim czasie doprowadziliśmy do tego,\nże w Wojsku Polskim już są czołgi K2, że obok\nHIMARS-ów, o których powiedziałem, są Chunmoo,\nczyli artyleria rakietowa o zasięgu do 300 km, że są\nsamoloty szkolno-bojowe FA-50. Pan powiedział, że\npiloci tak dużo zarabiają. Trzeba szkolić pilotów.\nFA-50 zostały zaprojektowane przez Lockheed Martin, a więc są taką mniejszą, to prawda, wersją\nF-16. W Wojsku Polskim, kiedy przyszliśmy do\nwładzy, w zasadzie tylko F-16 stanowiły jakąś siłę\nbojową. Pozostały sprzęt wojskowy był postsowiecki,\nbył zużyty. To był obraz nędzy i rozpaczy, a my doprowadziliśmy do tego, że dziś Wojsko Polskie liczy\nponad 200 tys. żołnierzy. Tylko jeszcze cele… Też\npan o tym nie wspomniał. Co najmniej 300 tys. żołnierzy. Można powiedzieć, że 300 tys. żołnierzy wojsk\noperacyjnych i 50 tys. żołnierzy Wojsk Obrony Terytorialnej – to powinien być nasz wspólny cel, mówię\no państwie polskim (Oklaski), bo w ten sposób możemy realnie odstraszyć agresora.",
         "True",
         "['Loaded_Language' 'Flag_Waving' 'Obfuscation-Vagueness-Confusion'\n 'Appeal_to_Authority' 'Name_Calling-Labeling' 'Red_Herring'\n 'Appeal_to_Fear-Prejudice']",
         "train",
         "[]",
         "['postsowiecki']",
         "[]",
         "[]",
         "['obraz nędzy i rozpaczy']",
         "[]",
         "[]",
         "[]",
         "['Pan powiedział, że piloci tak dużo zarabiają']",
         "['mówię o państwie polskim']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['To była sytuacja, w której nie można było pójść naprzód, więc udrożniłem te procesy']",
         "[]",
         "[]",
         "['realnie odstraszyć agresora']",
         "[]",
         "['jeśli chodzi o te zakupy, to one wszystkie były konsultowane, były wynikiem naszych rozmów w Radzie Modernizacji Technicznej z przeważającym, decydującym głosem Sztabu Generalnego Wojska Polskiego']",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/Loaded_Language",
         "Loaded_Language",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "1",
         "Yes, the Loaded Language technique is used in the input.",
         "\"obraz nędzy i rozpaczy\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The Loaded Language technique is used in the input text through the phrase \\'obraz nędzy i rozpaczy\\', which translates to \\'a picture of misery and despair\\'. This phrase carries strong negative emotional implications, effectively influencing the audience\\'s perception of the previous state of the military equipment. It aligns with the definition of Loaded Language, as it uses emotionally charged language to convince the audience of the argument\\'s validity regarding the need for military improvements.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[\"The Loaded Language technique is used in the input text through the phrase 'obraz nędzy i rozpaczy', which translates to 'a picture of misery and despair'. This phrase carries strong negative emotional implications, effectively influencing the audience's perception of the previous state of the military equipment. It aligns with the definition of Loaded Language, as it uses emotionally charged language to convince the audience of the argument's validity regarding the need for military improvements.\"]",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/Loaded_Language/train/pl/train-pl-part_0002.parquet",
         "[None]",
         "[None]",
         "train",
         "{\"description\": \"The Loaded Language technique is used in the input text through the phrase 'obraz n\\u0119dzy i rozpaczy', which translates to 'a picture of misery and despair'. This phrase carries strong negative emotional implications, effectively influencing the audience's perception of the previous state of the military equipment. It aligns with the definition of Loaded Language, as it uses emotionally charged language to convince the audience of the argument's validity regarding the need for military improvements.\", \"verdict\": true}"
        ],
        [
         "39",
         "pl_defence_22_05_2024_n01.txt",
         "11490",
         "11559",
         "PL",
         "(Głos z sali: Brawo!)\nDziękuję bardzo. (Część posłów wstaje, oklaski)",
         "False",
         "[]",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/Exaggeration-Minimisation",
         "Exaggeration-Minimisation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "0",
         "No, the Exaggeration-Minimisation technique is not used in the input.",
         "\"\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The input text does not contain any elements of exaggeration or minimisation. There are no statements that represent something in an excessive manner or downplay the importance of any argument.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "['The input text does not contain any elements of exaggeration or minimisation. There are no statements that represent something in an excessive manner or downplay the importance of any argument.']",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/Exaggeration-Minimisation/train/pl/train-pl-part_0018.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text does not contain any elements of exaggeration or minimisation. There are no statements that represent something in an excessive manner or downplay the importance of any argument.\", \"verdict\": false}"
        ],
        [
         "40",
         "pl_current_affairs_09_01_2025_n02.txt",
         "6479",
         "6590",
         "PL",
         "Wicemarszałek Włodzimierz Czarzasty:\nDziękuję serdecznie.\nBardzo proszę.\nCo z: tak dla Siarzewa, pani minister?",
         "False",
         "[]",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Name_Calling-Labeling",
         "Name_Calling-Labeling",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Name Calling-Labeling technique is not used in the input.",
         "\"\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The input text does not contain any loaded labels or derogatory terms directed at individuals or groups. It consists of polite dialogue without any qualitative judgments or manipulative wording, which aligns with the expert\\'s verdict that the Name Calling - Labeling technique is not used.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "[\"The input text does not contain any loaded labels or derogatory terms directed at individuals or groups. It consists of polite dialogue without any qualitative judgments or manipulative wording, which aligns with the expert's verdict that the Name Calling - Labeling technique is not used.\"]",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Name_Calling-Labeling/train/pl/train-pl-part_0017.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text does not contain any loaded labels or derogatory terms directed at individuals or groups. It consists of polite dialogue without any qualitative judgments or manipulative wording, which aligns with the expert's verdict that the Name Calling - Labeling technique is not used.\", \"verdict\": false}"
        ],
        [
         "41",
         "20231208_URW_BG_72.txt",
         "3079",
         "3277",
         "BG",
         "Иначе това, че там има четирима човека, не означава, че само четирима човека знаят за какво става дума, защото има една предишна справка от МВР, в която много ясно е казано всъщност какво изпращаме.",
         "False",
         "[]",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/Consequential_Oversimplification",
         "Consequential_Oversimplification",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "0",
         "No, the Consequential Oversimplification technique is not used in the input.",
         "\"\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The input text does not employ the Consequential Oversimplification technique, as it does not reject an argument by asserting that accepting it would lead to negative consequences without proof. Instead, it discusses the presence of individuals and references a previous report without implying a chain of negative events.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "['The input text does not employ the Consequential Oversimplification technique, as it does not reject an argument by asserting that accepting it would lead to negative consequences without proof. Instead, it discusses the presence of individuals and references a previous report without implying a chain of negative events.']",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/Consequential_Oversimplification/train/bg/train-bg-part_0005.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text does not employ the Consequential Oversimplification technique, as it does not reject an argument by asserting that accepting it would lead to negative consequences without proof. Instead, it discusses the presence of individuals and references a previous report without implying a chain of negative events.\", \"verdict\": false}"
        ],
        [
         "42",
         "20231208_URW_BG_73.txt",
         "4245",
         "4625",
         "BG",
         "Оттам нататък, нашият национален интерес – и с това завършвам, колеги, е тази война да спре до Украйна, защото всички знаем, особено пограничните държави прибалтийските, и Полша, многократно се заявявали, ако режимът на Путин не бъде спрян до Украйна, следващите сме ние. Може би не сега, може би не след пет години, но тези оръжия, които изпращаме там, ще ги ползват нашите деца.",
         "True",
         "['Consequential_Oversimplification' 'Appeal_to_Authority'\n 'Appeal_to_Fear-Prejudice']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['ако режимът на Путин не бъде спрян до Украйна, следващите сме ние']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Оттам нататък, нашият национален интерес – и с това завършвам, колеги, е тази война да спре до Украйна, защото всички знаем, особено пограничните държави прибалтийските, и Полша, многократно се заявявали, ако режимът на Путин не бъде спрян до Украйна, следващите сме ние'\n 'Може би не сега, може би не след пет години, но тези оръжия, които изпращаме там, ще ги ползват нашите деца']",
         "[]",
         "['защото всички знаем, особено пограничните държави прибалтийските, и Полша, многократно се заявявали']",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Authority",
         "Appeal_to_Authority",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "1",
         "Yes, the Appeal to Authority technique is used in the input.",
         "\"защото всички знаем, особено пограничните държави прибалтийските, и Полша, многократно се заявявали\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The Appeal to Authority technique is used in the input text by referencing the statements made by the Baltic states and Poland as authorities on the matter of national interest and the potential consequences of the war. The phrase \\'всички знаем, особено пограничните държави прибалтийските, и Полша, многократно се заявявали\\' implies that their repeated assertions lend weight to the argument being made, thus capitalizing on their authority in the context of regional security.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[\"The Appeal to Authority technique is used in the input text by referencing the statements made by the Baltic states and Poland as authorities on the matter of national interest and the potential consequences of the war. The phrase 'всички знаем, особено пограничните държави прибалтийските, и Полша, многократно се заявявали' implies that their repeated assertions lend weight to the argument being made, thus capitalizing on their authority in the context of regional security.\"]",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Authority/train/bg/train-bg-part_0006.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The Appeal to Authority technique is used in the input text by referencing the statements made by the Baltic states and Poland as authorities on the matter of national interest and the potential consequences of the war. The phrase '\\u0432\\u0441\\u0438\\u0447\\u043a\\u0438 \\u0437\\u043d\\u0430\\u0435\\u043c, \\u043e\\u0441\\u043e\\u0431\\u0435\\u043d\\u043e \\u043f\\u043e\\u0433\\u0440\\u0430\\u043d\\u0438\\u0447\\u043d\\u0438\\u0442\\u0435 \\u0434\\u044a\\u0440\\u0436\\u0430\\u0432\\u0438 \\u043f\\u0440\\u0438\\u0431\\u0430\\u043b\\u0442\\u0438\\u0439\\u0441\\u043a\\u0438\\u0442\\u0435, \\u0438 \\u041f\\u043e\\u043b\\u0448\\u0430, \\u043c\\u043d\\u043e\\u0433\\u043e\\u043a\\u0440\\u0430\\u0442\\u043d\\u043e \\u0441\\u0435 \\u0437\\u0430\\u044f\\u0432\\u044f\\u0432\\u0430\\u043b\\u0438' implies that their repeated assertions lend weight to the argument being made, thus capitalizing on their authority in the context of regional security.\", \"verdict\": true}"
        ],
        [
         "43",
         "SI_interpelation_interior_4.txt",
         "1345",
         "3161",
         "SI",
         "Naj zelo jasno povem, da zastarele pločevinaste stražarske hišice iz časa nekdanje skupne države zamenjujemo z novimi, sodobno izdelanimi varnostnimi objekti, izdelanimi iz neprebojnih materialov izključno in samo zaradi še večje varnosti in zaščite policistk in policistov na delovnem mestu. Nove stražarske hišice so nabavljene na predlog policije in drugih državnih organov, postopek je potekal transparentno in v skladu s postopkom javnega naročanja. Stražarske hiške pa so postavljene v skladu z vsemi veljavnimi predpisi. Na žalost imamo v Sloveniji primere, ko so se zgodili napadi s strelnim orožjem na policiste. Ničkolikokrat sem poudaril, da je varnost za zdravje, in da je varnost in zdravje policistk in policistov za mene kot ministra najbolj pomembna, najpomembnejša, to je osnovni pogoj, da policistke in policisti sploh lahko varno opravljajo svoje naloge in nova neprebojna varnostna objekta pred Vlado Republike Slovenije in Državnim zborom policistkam in policistom zagotavljata visoko stopnjo varnosti. Mimogrede, nova stražarska hišica nudi tudi možnost zavetja v slabih vremenskih pogojih in hrambo zaščitne opreme. Se pa čudim od kdaj predlagateljem moje interpelacije predstavlja varnost policistk in policistov problem in nepotreben strošek. No, srčno upam in si želim, da se vsi strinjamo, da pred življenje in zdravje policistk in policistov ne postavljamo prav ničesar. Sem pa vseeno neizmerno ponosen, da ravno v času mojega drugega mandata slovenska policija dobila po več kot 35 letih sodobne neprebojne varnostne objekte za varno opravljanje svojega dela. Dve stražarski hiški že služita namenu in skupaj s policistkami in policisti se veselim novih, ki jih bomo postavili še tam, ki jih kot država moramo postaviti izključno in samo zaradi še večje varnosti policistk in policistov.",
         "True",
         "['Exaggeration-Minimisation' 'Appeal_to_Authority' 'Appeal_to_Values'\n 'Doubt' 'Repetition' 'Appeal_to_Fear-Prejudice']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['varnost policistk in policistov' 'varnosti policistk in policistov']",
         "[]",
         "['Se pa čudim od kdaj predlagateljem moje interpelacije predstavlja varnost policistk in policistov problem in nepotreben strošek']",
         "[]",
         "[]",
         "['izključno in samo zaradi še večje varnosti']",
         "[]",
         "[]",
         "[]",
         "['Naj zelo jasno povem, da zastarele pločevinaste stražarske hišice iz časa nekdanje skupne države zamenjujemo z novimi, sodobno izdelanimi varnostnimi objekti, izdelanimi iz neprebojnih materialov izključno in samo zaradi še večje varnosti in zaščite policistk in policistov na delovnem mestu'\n 'transparentno' 'veljavnimi predpisi'\n 'varnost in zdravje policistk in policistov']",
         "[]",
         "[]",
         "[]",
         "['napadi s strelnim orožjem na policiste']",
         "[]",
         "['policije in drugih državnih organov' 'mene kot ministra']",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/Repetition",
         "Repetition",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "1",
         "Yes, the Repetition technique is used in the input.",
         "\"varnost policistk in policistov varnosti policistk in policistov\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"Repetition technique was explicitly used in the input text through the phrase \\'varnost policistk in policistov\\', which is repeated multiple times. This repetition emphasizes the importance of safety for police officers, aligning with the definition that states the speaker uses the same phrase repeatedly to persuade the audience.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[\"Repetition technique was explicitly used in the input text through the phrase 'varnost policistk in policistov', which is repeated multiple times. This repetition emphasizes the importance of safety for police officers, aligning with the definition that states the speaker uses the same phrase repeatedly to persuade the audience.\"]",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/Repetition/train/si/train-si-part_0004.parquet",
         null,
         null,
         "train",
         "{\"description\": \"Repetition technique was explicitly used in the input text through the phrase 'varnost policistk in policistov', which is repeated multiple times. This repetition emphasizes the importance of safety for police officers, aligning with the definition that states the speaker uses the same phrase repeatedly to persuade the audience.\", \"verdict\": true}"
        ],
        [
         "44",
         "pl_abortion_11_04_2024_n03.txt",
         "9280",
         "9741",
         "PL",
         "Zakaz aborcji zabija i nie likwiduje aborcji. Zakaz\naborcji powoduje, że w polskich szpitalach nie ma\ndzisiaj bezpiecznej aborcji. Ale od 30 lat te aborcje się\ndzieją tylko dlatego, że poszczególne osoby znajdują\nsposób na to, żeby je zrobić. Ostatnie lata to zasługa\ngrup nieformalnych i aktywistek działających\nw Polsce – to Aborcyjny Dream Team czy Aborcja bez Granic.\nWiem, że jesteście, pozdrawiam was bardzo serdecznie\ni dziękuję za waszą pracę. (Oklaski)",
         "True",
         "['Consequential_Oversimplification' 'Causal_Oversimplification'\n 'Loaded_Language' 'Flag_Waving' 'Appeal_to_Popularity' 'Doubt'\n 'Appeal_to_Fear-Prejudice']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "['zabija']",
         "[]",
         "['Ostatnie lata to zasługa grup nieformalnych i aktywistek działających w Polsce – to Aborcyjny Dream Team czy Aborcja bez Granic']",
         "['Zakaz aborcji zabija i nie likwiduje aborcji']",
         "[]",
         "['Wiem, że jesteście, pozdrawiam']",
         "[]",
         "['Zakaz aborcji zabija i nie likwiduje aborcji']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Zakaz aborcji zabija']",
         "['Zakaz aborcji powoduje, że w polskich szpitalach nie ma dzisiaj bezpiecznej aborcji']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/Consequential_Oversimplification",
         "Consequential_Oversimplification",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "1",
         "Yes, the Consequential Oversimplification technique is used in the input.",
         "\"Zakaz aborcji zabija i nie likwiduje aborcji\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The input text uses the Consequential Oversimplification technique by asserting that banning abortion leads to death without discussing the validity of the argument. The phrase \\'Zakaz aborcji zabija i nie likwiduje aborcji\\' implies that the consequence of banning abortion is death, suggesting a direct and negative outcome from the action of banning, which oversimplifies the complex issue of abortion and its implications.\",\\n  \"updated_definition\": \"An argument or an idea is rejected and instead of discussing whether it makes sense and/or is valid, the argument affirms, without proof, that accepting the proposition would imply accepting other propositions that are considered negative. This technique has the following logical form: if A will happen then B, C, D, ... will happen, often leading to a significant negative outcome. The core essence behind this fallacy is an assertion of some ‘first’ event/action leading to a domino-like chain of events that have significant negative effects, while ignoring or understating the likelihood of the sequence of events from the first event leading to the end point.\"\\n}']",
         "['An argument or an idea is rejected and instead of discussing whether it makes sense and/or is valid, the argument affirms, without proof, that accepting the proposition would imply accepting other propositions that are considered negative. This technique has the following logical form: if A will happen then B, C, D, ... will happen, often leading to a significant negative outcome. The core essence behind this fallacy is an assertion of some ‘first’ event/action leading to a domino-like chain of events that have significant negative effects, while ignoring or understating the likelihood of the sequence of events from the first event leading to the end point.']",
         "[None]",
         "[None]",
         "[\"The input text uses the Consequential Oversimplification technique by asserting that banning abortion leads to death without discussing the validity of the argument. The phrase 'Zakaz aborcji zabija i nie likwiduje aborcji' implies that the consequence of banning abortion is death, suggesting a direct and negative outcome from the action of banning, which oversimplifies the complex issue of abortion and its implications.\"]",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/Consequential_Oversimplification/train/pl/train-pl-part_0006.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text uses the Consequential Oversimplification technique by asserting that banning abortion leads to death without discussing the validity of the argument. The phrase 'Zakaz aborcji zabija i nie likwiduje aborcji' implies that the consequence of banning abortion is death, suggesting a direct and negative outcome from the action of banning, which oversimplifies the complex issue of abortion and its implications.\", \"verdict\": true}"
        ],
        [
         "45",
         "RU_Trump_1.txt",
         "0",
         "91",
         "RU",
         "Жизнь Зеленского сейчас под угрозой. Его могут устранить свои же, чтобы договориться с США.",
         "True",
         "['Causal_Oversimplification']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Жизнь Зеленского сейчас под угрозой. Его могут устранить свои же, чтобы договориться с США']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/Loaded_Language",
         "Loaded_Language",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "0",
         "No, the Loaded Language technique is not used in the input.",
         "\"\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The input text does not contain specific words or phrases with strong emotional implications intended to influence the audience. The statement is factual and does not employ Loaded Language.\",\\n  \"updated_definition\": \"Loaded Language technique involves the use of specific words and phrases with strong emotional implications (either positive or negative) to influence and convince the audience that an argument is valid, often through emotionally charged language that evokes a strong response.\"\\n}']",
         "['Loaded Language technique involves the use of specific words and phrases with strong emotional implications (either positive or negative) to influence and convince the audience that an argument is valid, often through emotionally charged language that evokes a strong response.']",
         "[None]",
         "[None]",
         "['The input text does not contain specific words or phrases with strong emotional implications intended to influence the audience. The statement is factual and does not employ Loaded Language.']",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/Loaded_Language/train/ru/train-ru-part_0001.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text does not contain specific words or phrases with strong emotional implications intended to influence the audience. The statement is factual and does not employ Loaded Language.\", \"verdict\": false}"
        ],
        [
         "46",
         "RU_migrants_3.txt",
         "680",
         "1158",
         "RU",
         "Сложившаяся модель устраивает и руководство Узбекистана. В том числе потому, что пресечение нелегальной миграции или даже ограничения стихийной миграции выгодно и властям Узбекистана. Тем самым казна в Ташкенте тоже получает большие средства, а также уменьшает риски попадания в неприятные, мягко говоря, ситуации, когда Шавкату Мирзиёеву и другим политикам страны приходится держать ответ за действия мигрантов в России. А это и наркомания, и насилие, и религиозный экстремизм.",
         "True",
         "['Questioning_the_Reputation' 'Appeal_to_Fear-Prejudice']",
         "train",
         "['В том числе потому, что пресечение нелегальной миграции или даже ограничения стихийной миграции выгодно и властям Узбекистана']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['А это и наркомания, и насилие, и религиозный экстремизм']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/Obfuscation-Vagueness-Confusion",
         "Obfuscation-Vagueness-Confusion",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "0",
         "No, the Obfuscation-Vagueness-Confusion technique is not used in the input.",
         "\"\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The input text presents clear statements regarding the benefits of the current model for the authorities in Uzbekistan, without using vague or confusing language. The expert\\'s verdict is supported as there are no excerpts indicating the use of Obfuscation, Intentional Vagueness, or Confusion.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "[\"The input text presents clear statements regarding the benefits of the current model for the authorities in Uzbekistan, without using vague or confusing language. The expert's verdict is supported as there are no excerpts indicating the use of Obfuscation, Intentional Vagueness, or Confusion.\"]",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/Obfuscation-Vagueness-Confusion/train/ru/train-ru-part_0001.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text presents clear statements regarding the benefits of the current model for the authorities in Uzbekistan, without using vague or confusing language. The expert's verdict is supported as there are no excerpts indicating the use of Obfuscation, Intentional Vagueness, or Confusion.\", \"verdict\": false}"
        ],
        [
         "47",
         "20240112_SHG_BG_60.txt",
         "5536",
         "6120",
         "BG",
         "По отношение на това, което казахте. В текста, който излезе от Вашите разговори с австрийците, има една думичка, която все пак хората, които са Ви го написали, защото не сте Вие, са доста по-запознати и сведущи от Вас и не са глупаци, те са Ви оставили точно тази вратичка, през която да можете да се изплъзнете като мишка –  стриктно прилагане пише, стриктно прилагане на Дъблинския регламент. Вие много добре знаете, че България до момента не прилагаше Дъблинския регламент, защото, ако го прилагахме този Дъблински регламент, държавата ни отдавна щеше да се е напълнила с мигранти.",
         "True",
         "['Consequential_Oversimplification' 'Exaggeration-Minimisation'\n 'Loaded_Language' 'Questioning_the_Reputation']",
         "train",
         "['която все пак хората, които са Ви го написали, защото не сте Вие, са доста по-запознати и сведущи от Вас и не са глупаци, те са Ви оставили точно тази вратичка, през която да можете да се изплъзнете като мишка']",
         "[]",
         "[]",
         "[]",
         "['мишка']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['думичка']",
         "['Вие много добре знаете, че България до момента не прилагаше Дъблинския регламент, защото, ако го прилагахме този Дъблински регламент, държавата ни отдавна щеше да се е напълнила с мигранти']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/Consequential_Oversimplification",
         "Consequential_Oversimplification",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "1",
         "Yes, the Consequential Oversimplification technique is used in the input.",
         "\"Вие много добре знаете, че България до момента не прилагаше Дъблинския регламент, защото, ако го прилагахме този Дъблински регламент, държавата ни отдавна щеше да се е напълнила с мигранти\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The technique of Consequential Oversimplification is used in the input text by asserting that if Bulgaria were to apply the Dublin Regulation, it would lead to an overwhelming influx of migrants. This claim simplifies the complex issue of migration by suggesting a direct and inevitable negative consequence (the country being filled with migrants) without providing evidence for this outcome, thus ignoring the likelihood of such a scenario.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "['The technique of Consequential Oversimplification is used in the input text by asserting that if Bulgaria were to apply the Dublin Regulation, it would lead to an overwhelming influx of migrants. This claim simplifies the complex issue of migration by suggesting a direct and inevitable negative consequence (the country being filled with migrants) without providing evidence for this outcome, thus ignoring the likelihood of such a scenario.']",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/Consequential_Oversimplification/train/bg/train-bg-part_0022.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The technique of Consequential Oversimplification is used in the input text by asserting that if Bulgaria were to apply the Dublin Regulation, it would lead to an overwhelming influx of migrants. This claim simplifies the complex issue of migration by suggesting a direct and inevitable negative consequence (the country being filled with migrants) without providing evidence for this outcome, thus ignoring the likelihood of such a scenario.\", \"verdict\": true}"
        ],
        [
         "48",
         "20231208_URW_BG_71.txt",
         "2637",
         "3890",
         "BG",
         "Комисията по отбрана трябваше да посети днес поделението, в което се намират голяма част от тези машини, и да се запознае на място със състоянието им. Аз отидох там заедно с още двама представители от партия ВЪЗРАЖДАНЕ. Ние сме тримата, които реално сме виждали, пипали и знаем за какво става въпрос, какво е реалното състояние на тази техника. Говорихме с хората, които я поддържат, разбрахме проблемите, виждаме и възможни решения. Бихме могли да Ви ги кажем, ако сте заинтересовани да чуете. Ако сте заинтересовани да получите поредната порция конграчулейшънс и телешки пържолки, потупвания по рамото, то няма какво да си говорим. Гласувайте, пренебрегнете и мнението на Върховния главнокомандващ, ако нямате доверие на експертизата на офицерите от ВЪЗРАЖДАНЕ. Поне чуйте какво Ви казва Върховният главнокомандващ, ако, разбира се, имате малко срам и малко свян и не Ви е срам от това, което правите. Събираме капачки за децата, облагаме бизнеса с безумни данъци и в същото време харчим милиарди в посока към Украйна в една братоубийствена война. Разбира се, ВЪЗРАЖДАНЕ няма да подкрепи това безсмислено предложение и препоръчваме да се вслушаме в аргументите на президента по отношение на ветото, което той е наложил на този законопроект. Благодаря.",
         "True",
         "['Exaggeration-Minimisation' 'Loaded_Language'\n 'Questioning_the_Reputation' 'Whataboutism' 'Appeal_to_Authority'\n 'Name_Calling-Labeling' 'Doubt']",
         "train",
         "['Ако сте заинтересовани да получите поредната порция конграчулейшънс и телешки пържолки, потупвания по рамото, то няма какво да си говорим'\n 'Поне чуйте какво Ви казва Върховният главнокомандващ, ако, разбира се, имате малко срам и малко свян и не Ви е срам от това, което правите']",
         "['братоубийствена война']",
         "[]",
         "[]",
         "['конграчулейшънс и телешки пържолки' 'малко срам и малко свян'\n 'братоубийствена']",
         "[]",
         "[]",
         "['ако сте заинтересовани да чуете']",
         "[]",
         "[]",
         "['безсмислено']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['препоръчваме да се вслушаме в аргументите на президента по отношение на ветото, което той е наложил на този законопроект']",
         "[]",
         "['Събираме капачки за децата, облагаме бизнеса с безумни данъци и в същото време харчим милиарди в посока към Украйна в една братоубийствена война']",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Questioning_the_Reputation",
         "Questioning_the_Reputation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "1",
         "Yes, the Questioning the Reputation technique is used in the input.",
         "\"Ако сте заинтересовани да получите поредната порция конграчулейшънс и телешки пържолки, потупвания по рамото, то няма какво да си говорим Поне чуйте какво Ви казва Върховният главнокомандващ, ако, разбира се, имате малко срам и малко свян и не Ви е срам от това, което правите\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The Questioning the Reputation technique is explicitly used in the input text by making strong negative claims about the audience\\'s character and moral standing. Phrases like \\'ако, разбира се, имате малко срам и малко свян и не Ви е срам от това, което правите\\' directly attack the audience\\'s integrity, suggesting that they lack shame for their actions. This aligns with the technique\\'s definition of undermining moral stature rather than focusing on the argument itself.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[\"The Questioning the Reputation technique is explicitly used in the input text by making strong negative claims about the audience's character and moral standing. Phrases like 'ако, разбира се, имате малко срам и малко свян и не Ви е срам от това, което правите' directly attack the audience's integrity, suggesting that they lack shame for their actions. This aligns with the technique's definition of undermining moral stature rather than focusing on the argument itself.\"]",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/bg/train-bg-part_0009.parquet",
         "[None]",
         "[None]",
         "train",
         "{\"description\": \"The Questioning the Reputation technique is explicitly used in the input text by making strong negative claims about the audience's character and moral standing. Phrases like '\\u0430\\u043a\\u043e, \\u0440\\u0430\\u0437\\u0431\\u0438\\u0440\\u0430 \\u0441\\u0435, \\u0438\\u043c\\u0430\\u0442\\u0435 \\u043c\\u0430\\u043b\\u043a\\u043e \\u0441\\u0440\\u0430\\u043c \\u0438 \\u043c\\u0430\\u043b\\u043a\\u043e \\u0441\\u0432\\u044f\\u043d \\u0438 \\u043d\\u0435 \\u0412\\u0438 \\u0435 \\u0441\\u0440\\u0430\\u043c \\u043e\\u0442 \\u0442\\u043e\\u0432\\u0430, \\u043a\\u043e\\u0435\\u0442\\u043e \\u043f\\u0440\\u0430\\u0432\\u0438\\u0442\\u0435' directly attack the audience's integrity, suggesting that they lack shame for their actions. This aligns with the technique's definition of undermining moral stature rather than focusing on the argument itself.\", \"verdict\": true}"
        ],
        [
         "49",
         "SI_interpelation_interior_2.txt",
         "392",
         "398",
         "SI",
         "Hvala.",
         "False",
         "[]",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/Repetition",
         "Repetition",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "0",
         "No, the Repetition technique is not used in the input.",
         "\"\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The input text consists of a single word, \\'Hvala\\', which does not demonstrate the use of Repetition as there is no repeated word, phrase, story, or imagery present.\",\\n  \"updated_definition\": \"The speaker uses the same word, phrase, story, or imagery repeatedly, with the hope that the repetition will lead to persuade the audience, and this must occur more than once in the text.\"\\n}']",
         "['The speaker uses the same word, phrase, story, or imagery repeatedly, with the hope that the repetition will lead to persuade the audience, and this must occur more than once in the text.']",
         "[None]",
         "[None]",
         "[\"The input text consists of a single word, 'Hvala', which does not demonstrate the use of Repetition as there is no repeated word, phrase, story, or imagery present.\"]",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/Repetition/train/si/train-si-part_0005.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text consists of a single word, 'Hvala', which does not demonstrate the use of Repetition as there is no repeated word, phrase, story, or imagery present.\", \"verdict\": false}"
        ]
       ],
       "shape": {
        "columns": 60,
        "rows": 3740
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>text_lang</th>\n",
       "      <th>text</th>\n",
       "      <th>label_bin</th>\n",
       "      <th>label_multi</th>\n",
       "      <th>base_split</th>\n",
       "      <th>Questioning_the_Reputation</th>\n",
       "      <th>Name_Calling-Labeling</th>\n",
       "      <th>...</th>\n",
       "      <th>updated_definition</th>\n",
       "      <th>think_content</th>\n",
       "      <th>illegal_value</th>\n",
       "      <th>explanation</th>\n",
       "      <th>extra_content</th>\n",
       "      <th>source_file</th>\n",
       "      <th>error</th>\n",
       "      <th>status</th>\n",
       "      <th>split</th>\n",
       "      <th>expected_output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RU_demography_3.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>108</td>\n",
       "      <td>RU</td>\n",
       "      <td>Вымирание ускоряется. Вышла статистика \"прорыв...</td>\n",
       "      <td>True</td>\n",
       "      <td>[Appeal_to_Time]</td>\n",
       "      <td>train</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>[The speaker uses the same word, phrase, story...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[The input text does not contain any repeated ...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41_MINI...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "      <td>{\"description\": \"The input text does not conta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pl_abortion_11_04_2024_n04.txt</td>\n",
       "      <td>7726</td>\n",
       "      <td>7807</td>\n",
       "      <td>PL</td>\n",
       "      <td>Przepraszam, że dopiero teraz, ale emocje,\\npr...</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>train</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[The input text does not contain any elements ...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41/v001...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "      <td>{\"description\": \"The input text does not conta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RU_discrediting_the_west_11.txt</td>\n",
       "      <td>129</td>\n",
       "      <td>594</td>\n",
       "      <td>RU</td>\n",
       "      <td>евой генерал, результативный, не мясник - не н...</td>\n",
       "      <td>True</td>\n",
       "      <td>[Loaded_Language, Obfuscation-Vagueness-Confus...</td>\n",
       "      <td>train</td>\n",
       "      <td>[]</td>\n",
       "      <td>[коррупционеры, которые отсиживаются в доброво...</td>\n",
       "      <td>...</td>\n",
       "      <td>[Loaded Language is the use of specific words ...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[The input text employs Loaded Language throug...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41_MINI...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "      <td>{\"description\": \"The input text employs Loaded...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20240704_URW_BG_30.txt</td>\n",
       "      <td>5823</td>\n",
       "      <td>6119</td>\n",
       "      <td>BG</td>\n",
       "      <td>заседанието, което ще бъде абсолютно безсмисле...</td>\n",
       "      <td>True</td>\n",
       "      <td>[Consequential_Oversimplification, Exaggeratio...</td>\n",
       "      <td>train</td>\n",
       "      <td>[]</td>\n",
       "      <td>[абсолютно безсмислено]</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[The input text does not contain any elements ...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41/v001...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>train</td>\n",
       "      <td>{\"description\": \"The input text does not conta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RU_migrants_4.txt</td>\n",
       "      <td>836</td>\n",
       "      <td>1171</td>\n",
       "      <td>RU</td>\n",
       "      <td>И еще один, тоже очень важный аспект. Родители...</td>\n",
       "      <td>True</td>\n",
       "      <td>[Questioning_the_Reputation]</td>\n",
       "      <td>train</td>\n",
       "      <td>[Среди детей мигрантов, в том числе подростков...</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[The input text does not employ the Exaggerati...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41_MINI...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "      <td>{\"description\": \"The input text does not emplo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3735</th>\n",
       "      <td>RU_discrediting_the_west_4.txt</td>\n",
       "      <td>244</td>\n",
       "      <td>418</td>\n",
       "      <td>RU</td>\n",
       "      <td>А там намечается самая радикальная перестройка...</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>train</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[The input text discusses a significant restru...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41/v001...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "      <td>{\"description\": \"The input text discusses a si...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3736</th>\n",
       "      <td>RU_URW_2.txt</td>\n",
       "      <td>2035</td>\n",
       "      <td>2295</td>\n",
       "      <td>RU</td>\n",
       "      <td>Наша партия в конце февраля проводит Всероссий...</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>train</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[The input text does not evoke feelings of pit...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41_MINI...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "      <td>{\"description\": \"The input text does not evoke...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3737</th>\n",
       "      <td>20231208_URW_BG_71.txt</td>\n",
       "      <td>973</td>\n",
       "      <td>1687</td>\n",
       "      <td>BG</td>\n",
       "      <td>Идеята да отхвърлим ветото на президента е кра...</td>\n",
       "      <td>True</td>\n",
       "      <td>[Exaggeration-Minimisation, Flag_Waving, Quest...</td>\n",
       "      <td>train</td>\n",
       "      <td>[Нямам съмнение, че евро-атлантическото мнозин...</td>\n",
       "      <td>[евро-атлантическото мнозинство]</td>\n",
       "      <td>...</td>\n",
       "      <td>[Name Calling - Labeling is a form of argument...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[The Name Calling - Labeling technique is used...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41/v001...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "      <td>{\"description\": \"The Name Calling - Labeling t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3738</th>\n",
       "      <td>pl_defence_22_05_2024_n02.txt</td>\n",
       "      <td>1232</td>\n",
       "      <td>1679</td>\n",
       "      <td>PL</td>\n",
       "      <td>Produkujemy śladowe ilości amunicji, 30 tys. s...</td>\n",
       "      <td>True</td>\n",
       "      <td>[Causal_Oversimplification, Red_Herring]</td>\n",
       "      <td>train</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>[The speaker uses the same word, phrase, story...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[The Repetition technique was not used in the ...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41_MINI...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "      <td>{\"description\": \"The Repetition technique was ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3739</th>\n",
       "      <td>SI_interpelation_interior_2.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>390</td>\n",
       "      <td>SI</td>\n",
       "      <td>Torej zaradi vsega naštetega in še marsičesa, ...</td>\n",
       "      <td>True</td>\n",
       "      <td>[Appeal_to_Values]</td>\n",
       "      <td>train</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[The input text does not contain any strong ne...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41/v001...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "      <td>{\"description\": \"The input text does not conta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3740 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             filename  start   end text_lang  \\\n",
       "0                 RU_demography_3.txt      0   108        RU   \n",
       "1      pl_abortion_11_04_2024_n04.txt   7726  7807        PL   \n",
       "2     RU_discrediting_the_west_11.txt    129   594        RU   \n",
       "3              20240704_URW_BG_30.txt   5823  6119        BG   \n",
       "4                   RU_migrants_4.txt    836  1171        RU   \n",
       "...                               ...    ...   ...       ...   \n",
       "3735   RU_discrediting_the_west_4.txt    244   418        RU   \n",
       "3736                     RU_URW_2.txt   2035  2295        RU   \n",
       "3737           20231208_URW_BG_71.txt    973  1687        BG   \n",
       "3738    pl_defence_22_05_2024_n02.txt   1232  1679        PL   \n",
       "3739  SI_interpelation_interior_2.txt      0   390        SI   \n",
       "\n",
       "                                                   text  label_bin  \\\n",
       "0     Вымирание ускоряется. Вышла статистика \"прорыв...       True   \n",
       "1     Przepraszam, że dopiero teraz, ale emocje,\\npr...      False   \n",
       "2     евой генерал, результативный, не мясник - не н...       True   \n",
       "3     заседанието, което ще бъде абсолютно безсмисле...       True   \n",
       "4     И еще один, тоже очень важный аспект. Родители...       True   \n",
       "...                                                 ...        ...   \n",
       "3735  А там намечается самая радикальная перестройка...      False   \n",
       "3736  Наша партия в конце февраля проводит Всероссий...      False   \n",
       "3737  Идеята да отхвърлим ветото на президента е кра...       True   \n",
       "3738  Produkujemy śladowe ilości amunicji, 30 tys. s...       True   \n",
       "3739  Torej zaradi vsega naštetega in še marsičesa, ...       True   \n",
       "\n",
       "                                            label_multi base_split  \\\n",
       "0                                      [Appeal_to_Time]      train   \n",
       "1                                                    []      train   \n",
       "2     [Loaded_Language, Obfuscation-Vagueness-Confus...      train   \n",
       "3     [Consequential_Oversimplification, Exaggeratio...      train   \n",
       "4                          [Questioning_the_Reputation]      train   \n",
       "...                                                 ...        ...   \n",
       "3735                                                 []      train   \n",
       "3736                                                 []      train   \n",
       "3737  [Exaggeration-Minimisation, Flag_Waving, Quest...      train   \n",
       "3738           [Causal_Oversimplification, Red_Herring]      train   \n",
       "3739                                 [Appeal_to_Values]      train   \n",
       "\n",
       "                             Questioning_the_Reputation  \\\n",
       "0                                                    []   \n",
       "1                                                    []   \n",
       "2                                                    []   \n",
       "3                                                    []   \n",
       "4     [Среди детей мигрантов, в том числе подростков...   \n",
       "...                                                 ...   \n",
       "3735                                                 []   \n",
       "3736                                                 []   \n",
       "3737  [Нямам съмнение, че евро-атлантическото мнозин...   \n",
       "3738                                                 []   \n",
       "3739                                                 []   \n",
       "\n",
       "                                  Name_Calling-Labeling  ...  \\\n",
       "0                                                    []  ...   \n",
       "1                                                    []  ...   \n",
       "2     [коррупционеры, которые отсиживаются в доброво...  ...   \n",
       "3                               [абсолютно безсмислено]  ...   \n",
       "4                                                    []  ...   \n",
       "...                                                 ...  ...   \n",
       "3735                                                 []  ...   \n",
       "3736                                                 []  ...   \n",
       "3737                   [евро-атлантическото мнозинство]  ...   \n",
       "3738                                                 []  ...   \n",
       "3739                                                 []  ...   \n",
       "\n",
       "                                     updated_definition think_content  \\\n",
       "0     [The speaker uses the same word, phrase, story...        [None]   \n",
       "1                                                [None]        [None]   \n",
       "2     [Loaded Language is the use of specific words ...        [None]   \n",
       "3                                                    []        [None]   \n",
       "4                                                    []        [None]   \n",
       "...                                                 ...           ...   \n",
       "3735                                             [None]        [None]   \n",
       "3736                                             [None]        [None]   \n",
       "3737  [Name Calling - Labeling is a form of argument...        [None]   \n",
       "3738  [The speaker uses the same word, phrase, story...        [None]   \n",
       "3739                                                 []        [None]   \n",
       "\n",
       "     illegal_value                                        explanation  \\\n",
       "0           [None]  [The input text does not contain any repeated ...   \n",
       "1           [None]  [The input text does not contain any elements ...   \n",
       "2           [None]  [The input text employs Loaded Language throug...   \n",
       "3           [None]  [The input text does not contain any elements ...   \n",
       "4           [None]  [The input text does not employ the Exaggerati...   \n",
       "...            ...                                                ...   \n",
       "3735        [None]  [The input text discusses a significant restru...   \n",
       "3736        [None]  [The input text does not evoke feelings of pit...   \n",
       "3737        [None]  [The Name Calling - Labeling technique is used...   \n",
       "3738        [None]  [The Repetition technique was not used in the ...   \n",
       "3739        [None]  [The input text does not contain any strong ne...   \n",
       "\n",
       "     extra_content                                        source_file   error  \\\n",
       "0           [None]  data/llm_output/persuasion/explain/GPT_41_MINI...     NaN   \n",
       "1           [None]  data/llm_output/persuasion/explain/GPT_41/v001...     NaN   \n",
       "2           [None]  data/llm_output/persuasion/explain/GPT_41_MINI...     NaN   \n",
       "3           [None]  data/llm_output/persuasion/explain/GPT_41/v001...  [None]   \n",
       "4           [None]  data/llm_output/persuasion/explain/GPT_41_MINI...     NaN   \n",
       "...            ...                                                ...     ...   \n",
       "3735        [None]  data/llm_output/persuasion/explain/GPT_41/v001...     NaN   \n",
       "3736        [None]  data/llm_output/persuasion/explain/GPT_41_MINI...     NaN   \n",
       "3737        [None]  data/llm_output/persuasion/explain/GPT_41/v001...     NaN   \n",
       "3738        [None]  data/llm_output/persuasion/explain/GPT_41_MINI...     NaN   \n",
       "3739        [None]  data/llm_output/persuasion/explain/GPT_41/v001...     NaN   \n",
       "\n",
       "      status  split                                    expected_output  \n",
       "0        NaN  train  {\"description\": \"The input text does not conta...  \n",
       "1        NaN  train  {\"description\": \"The input text does not conta...  \n",
       "2        NaN  train  {\"description\": \"The input text employs Loaded...  \n",
       "3     [None]  train  {\"description\": \"The input text does not conta...  \n",
       "4        NaN  train  {\"description\": \"The input text does not emplo...  \n",
       "...      ...    ...                                                ...  \n",
       "3735     NaN  train  {\"description\": \"The input text discusses a si...  \n",
       "3736     NaN  train  {\"description\": \"The input text does not evoke...  \n",
       "3737     NaN  train  {\"description\": \"The Name Calling - Labeling t...  \n",
       "3738     NaN  train  {\"description\": \"The Repetition technique was ...  \n",
       "3739     NaN  train  {\"description\": \"The input text does not conta...  \n",
       "\n",
       "[3740 rows x 60 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assume your DataFrame is called df\n",
    "label_1 = clean[clean['gold'] == 1]\n",
    "\n",
    "# Count how many label==1 per category\n",
    "counts = label_1['prompt_name'].value_counts()\n",
    "\n",
    "# For label == 0, sample same number of rows per category\n",
    "label_0_samples = (\n",
    "    df[df['gold'] == 0]\n",
    "    .groupby('prompt_name', group_keys=False)\n",
    "    .apply(lambda x: x.sample(n=3*counts.get(x.name, 0)))\n",
    ")\n",
    "\n",
    "# Combine both\n",
    "balanced_df31 = pd.concat([label_1, label_0_samples])\n",
    "balanced_df31 = balanced_df31.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "balanced_df31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "579c3f51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lp/5z8ys0rj1q960h2656xp8c680000gn/T/ipykernel_49770/374312229.py:11: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda x: x.sample(n=2*counts.get(x.name, 0)))\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "filename",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "start",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "end",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "text_lang",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "text",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "label_bin",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "label_multi",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "base_split",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Questioning_the_Reputation",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Name_Calling-Labeling",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Appeal_to_Hypocrisy",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Conversation_Killer",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Loaded_Language",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Repetition",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Appeal_to_Popularity",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Doubt",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Red_Herring",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Flag_Waving",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Exaggeration-Minimisation",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Consequential_Oversimplification",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Appeal_to_Pity",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Appeal_to_Time",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Appeal_to_Values",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Obfuscation-Vagueness-Confusion",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Straw_Man",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Slogans",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Appeal_to_Fear-Prejudice",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Causal_Oversimplification",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Appeal_to_Authority",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "False_Dilemma-No_Choice",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Whataboutism",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "False_Equivalence",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Guilt_by_Association",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "alt_split",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "output_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "prompt_name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "prompt_version",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "job",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "step",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "max_iterations",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "temperature",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "model_provider",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "model_name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "model_mode",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "gold",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "gold_text",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "spans",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "extra_properties",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "is_valid",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "raw",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "updated_definition",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "think_content",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "illegal_value",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "explanation",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "extra_content",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "source_file",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "error",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "status",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "split",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "expected_output",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "128a9455-2efa-4082-9cd8-43ca5f8994e7",
       "rows": [
        [
         "0",
         "20240229_URW_BG_67.txt",
         "4561",
         "5284",
         "BG",
         "ХРИСТО ГАДЖЕВ (ГЕРБ-СДС): Уважаеми господин Председател, господин Вицепремиер, господин Министър, уважаеми дами и господа народни представители! Взимам тази процедура, тъй като искам да избегна всякакъв вид фалшиви новини относно справката, която е изпратена до Секретното деловодство. Тя не е изпратена до Борисов, тя е изпратена лично до мен като отговор на моя въпрос. Така че, както всяко едно нещо, когато е изпратено от един народен представител, отговорът е до народния представител. Тя е разпределена до всички членове на Комисията по отбрана, включително и до лидерите на партиите, които подкрепят помощта, за да се запознаят какво точно се е случило, или по-скоро какво не се е случило последните няколко месеца. ",
         "False",
         "[]",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Hypocrisy",
         "Appeal_to_Hypocrisy",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Appeal to Hypocrisy technique is not used in the input.",
         "\"\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. There are no explicit or implicit references to contradictions between positions or actions, nor is there any mention of someone criticizing another for actions they themselves have taken in the past.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "['The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. There are no explicit or implicit references to contradictions between positions or actions, nor is there any mention of someone criticizing another for actions they themselves have taken in the past.']",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/bg/train-bg-part_0021.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. There are no explicit or implicit references to contradictions between positions or actions, nor is there any mention of someone criticizing another for actions they themselves have taken in the past.\", \"verdict\": false}"
        ],
        [
         "1",
         "20240704_URW_BG_28.txt",
         "8169",
         "8224",
         "BG",
         ".\n\nВИКТОРИЯ ВАСИЛЕВА (ВЕЛИЧИЕ): Благодаря Ви, госпожо П",
         "False",
         "[]",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Fear-Prejudice",
         "Appeal_to_Fear-Prejudice",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Appeal to Fear-Prejudice technique is not used in the input.",
         "\"\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The input text does not contain any elements that promote or reject an idea through fear or prejudice. There are no references to scary descriptions or preconceived judgments that would invoke fear in the audience.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "['The input text does not contain any elements that promote or reject an idea through fear or prejudice. There are no references to scary descriptions or preconceived judgments that would invoke fear in the audience.']",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Fear-Prejudice/train/bg/train-bg-part_0004.parquet",
         "[None]",
         "[None]",
         "train",
         "{\"description\": \"The input text does not contain any elements that promote or reject an idea through fear or prejudice. There are no references to scary descriptions or preconceived judgments that would invoke fear in the audience.\", \"verdict\": false}"
        ],
        [
         "2",
         "pl_abortion_11_04_2024_n04.txt",
         "5601",
         "6150",
         "PL",
         "Dzisiaj prezentujemy też ustawę, która odwraca\nbulwersujący wyrok Trybunału Konstytucyjnego, ale\ntakże poszerza pewien zakres. Po pierwsze,\nbezapelacyjnie należy przywrócić możliwość przerywania\nciąży ze względu na wadę płodu. Koniec ze\nzmuszaniem kobiet do heroizmu. Koniec z lękiem przed\nzajściem w ciążę. Zadbamy o kobiety po gwałtach.\nProkurator będzie miał 3 dni na stwierdzenie czynu\nzabronionego na podstawie oświadczenia pokrzywdzonej.\nTo kobieta jako ofiara musi być otoczona opieką, wspierana,\na nie traktowana niekiedy gorzej niż sprawcy.",
         "True",
         "['Conversation_Killer' 'Appeal_to_Pity' 'Slogans' 'Appeal_to_Values'\n 'Name_Calling-Labeling']",
         "train",
         "[]",
         "['bulwersujący wyrok']",
         "[]",
         "['bezapelacyjnie należy przywrócić możliwość przerywania ciąży ze względu na wadę płodu'\n 'Koniec ze zmuszaniem kobiet do heroizmu'\n 'Koniec z lękiem przed zajściem w ciążę']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Koniec ze zmuszaniem kobiet do heroizmu']",
         "[]",
         "['To kobieta jako ofiara musi być otoczona opieką, wspierana, a nie traktowana niekiedy gorzej niż sprawcy']",
         "[]",
         "[]",
         "['Koniec ze zmuszaniem kobiet do heroizmu'\n 'Koniec z lękiem przed zajściem w ciążę']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/Consequential_Oversimplification",
         "Consequential_Oversimplification",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "0",
         "No, the Consequential Oversimplification technique is not used in the input.",
         "\"\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The input text does not employ the Consequential Oversimplification technique, as it does not reject an argument by asserting that accepting it would lead to a series of negative consequences without proof. Instead, the text discusses the need for legal changes to support women without oversimplifying the implications of those changes.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "['The input text does not employ the Consequential Oversimplification technique, as it does not reject an argument by asserting that accepting it would lead to a series of negative consequences without proof. Instead, the text discusses the need for legal changes to support women without oversimplifying the implications of those changes.']",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/Consequential_Oversimplification/train/pl/train-pl-part_0012.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text does not employ the Consequential Oversimplification technique, as it does not reject an argument by asserting that accepting it would lead to a series of negative consequences without proof. Instead, the text discusses the need for legal changes to support women without oversimplifying the implications of those changes.\", \"verdict\": false}"
        ],
        [
         "3",
         "pl_eu_12_06_2024_n01.txt",
         "4530",
         "5548",
         "PL",
         "Natomiast to, co jest kłopotem przedłożonego projektu, to fakt, po pierwsze, że szereg rozwiązań, które znalazły się w tym projekcie, nie ma związku\nz tym celem, a dodatkowo budzi wątpliwości, które\nnie zostały wyjaśnione w toku procesu legislacyjnego. Z istotnym ryzykiem prawnym i faktycznym wiąże się art. 8 projektu, który wyłącza stosowanie Prawa zamówień publicznych do wszystkich zamówień\nna roboty budowlane, dostawy i usługi związane\nz przewodnictwem w Radzie. Celem wyłączenia miałoby być zapewnienie bezpieczeństwa publicznego. To\njest oczywiście zrozumiałe, jednak cel deklarowany\noraz rzeczywisty skutek przyjęcia takiego przepisu\nw takim brzmieniu, takiego rozwiązania to jest bardzo szerokie wyłączenie z Prawa zamówień publicznych, które obejmuje nie tylko zamówienia dotyczące\nbezpieczeństwa, lecz wszystkie zamówienia. Mogą to\nbyć zamówienia np. na materiały biurowe, na gadżety, na usługi kateringowe. Czy to jest potrzebne i czy\nto ma związek z bezpieczeństwem, można mieć daleko idące wątpliwości.",
         "True",
         "['Doubt']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Natomiast to, co jest kłopotem przedłożonego projektu, to fakt, po pierwsze, że szereg rozwiązań, które znalazły się w tym projekcie, nie ma związku z tym celem, a dodatkowo budzi wątpliwości, które nie zostały wyjaśnione w toku procesu legislacyjnego. Z istotnym ryzykiem prawnym i faktycznym wiąże się art. 8 projektu, który wyłącza stosowanie Prawa zamówień publicznych do wszystkich zamówień na roboty budowlane, dostawy i usługi związane z przewodnictwem w Radzie'\n 'Czy to jest potrzebne i czy to ma związek z bezpieczeństwem, można mieć daleko idące wątpliwości']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Red_Herring",
         "Red_Herring",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Red Herring technique is not used in the input.",
         "\"\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The input text discusses concerns about a legislative project and its implications, specifically focusing on the legal risks and the broad exclusion from public procurement laws. There is no diversion from the main topic, as the text remains focused on the issues at hand without introducing unrelated topics. Therefore, the Red Herring technique is not present.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "['The input text discusses concerns about a legislative project and its implications, specifically focusing on the legal risks and the broad exclusion from public procurement laws. There is no diversion from the main topic, as the text remains focused on the issues at hand without introducing unrelated topics. Therefore, the Red Herring technique is not present.']",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Red_Herring/train/pl/train-pl-part_0019.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text discusses concerns about a legislative project and its implications, specifically focusing on the legal risks and the broad exclusion from public procurement laws. There is no diversion from the main topic, as the text remains focused on the issues at hand without introducing unrelated topics. Therefore, the Red Herring technique is not present.\", \"verdict\": false}"
        ],
        [
         "4",
         "pl_defence_22_05_2024_n02.txt",
         "1232",
         "1679",
         "PL",
         "Produkujemy śladowe ilości amunicji, 30 tys. sztuk\namunicji artyleryjskiej rocznie. Dla porównania\nRosjanie zużywają 10 tys. sztuk dziennie. Nasza roczna\nprodukcja wystarczyłaby im na 3 dni walki. Ostatnio\nNiemcy rozpoczęli budowę fabryki amunicji\nartyleryjskiej produkującej 200 tys. sztuk rocznie. Koszt\nto zaledwie 200 mln euro. My niewiele mniej\nwydaliśmy na laptopy+ dla czwartoklasistów. Niestety na\nfabryki amunicji już nam nie wystarczyło.",
         "True",
         "['Causal_Oversimplification' 'Red_Herring']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['My niewiele mniej wydaliśmy na laptopy+ dla czwartoklasistów']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Koszt to zaledwie 200 mln euro. My niewiele mniej wydaliśmy na laptopy+ dla czwartoklasistów. Niestety na fabryki amunicji już nam nie wystarczyło']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/Consequential_Oversimplification",
         "Consequential_Oversimplification",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "0",
         "No, the Consequential Oversimplification technique is not used in the input.",
         "\"\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The input text does not employ the Consequential Oversimplification technique, as it does not reject an argument by asserting that accepting it would lead to a series of negative consequences. Instead, it presents factual comparisons about ammunition production without implying a domino effect of negative outcomes.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "['The input text does not employ the Consequential Oversimplification technique, as it does not reject an argument by asserting that accepting it would lead to a series of negative consequences. Instead, it presents factual comparisons about ammunition production without implying a domino effect of negative outcomes.']",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/Consequential_Oversimplification/train/pl/train-pl-part_0013.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text does not employ the Consequential Oversimplification technique, as it does not reject an argument by asserting that accepting it would lead to a series of negative consequences. Instead, it presents factual comparisons about ammunition production without implying a domino effect of negative outcomes.\", \"verdict\": false}"
        ],
        [
         "5",
         "pl_abortion_11_04_2024_n07.txt",
         "1337",
         "1787",
         "PL",
         "W całej tej debacie kobiety traktowane są\nprzedmiotowo. Są wykorzystywane, traktowane\ninstrumentalnie. A przez kogo? Przez aborcjonistów. Gdy\nci ludzie, kobiety i mężczyźni mówią: kobiety\nwybrały, kobiety nie mogą czekać, kobiety nie mogą czekać,\nkobiety tego chcą, kobiety zdecydowały, traktują je\ninstrumentalnie i pomijają wszystkie te kobiety,\nktóre wcale tego nie chcą, które wcale tego nie wybrały\ni które wcale o tym nie zdecydowały. (Oklaski)",
         "True",
         "['Loaded_Language' 'Appeal_to_Hypocrisy' 'Appeal_to_Pity'\n 'Questioning_the_Reputation']",
         "train",
         "['W całej tej debacie kobiety traktowane są przedmiotowo. Są wykorzystywane, traktowane instrumentalnie. A przez kogo?']",
         "[]",
         "['Gdy ci ludzie, kobiety i mężczyźni mówią: kobiety wybrały, kobiety nie mogą czekać, kobiety nie mogą czekać, kobiety tego chcą, kobiety zdecydowały, traktują je instrumentalnie i pomijają wszystkie te kobiety, które wcale tego nie chcą, które wcale tego nie wybrały i które wcale o tym nie zdecydowały']",
         "[]",
         "['przedmiotowo']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['W całej tej debacie kobiety traktowane są przedmiotowo']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Questioning_the_Reputation",
         "Questioning_the_Reputation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "1",
         "Yes, the Questioning the Reputation technique is used in the input.",
         "\"W całej tej debacie kobiety traktowane są przedmiotowo. Są wykorzystywane, traktowane instrumentalnie. A przez kogo?\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The Questioning the Reputation technique is explicitly used in the input text by making strong negative claims about how women are treated as objects and exploited, particularly by abortion advocates. This undermines the moral stature of these advocates by suggesting they disregard the true desires of women, thus attacking their reputation rather than engaging in a direct argument about the topic.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "['The Questioning the Reputation technique is explicitly used in the input text by making strong negative claims about how women are treated as objects and exploited, particularly by abortion advocates. This undermines the moral stature of these advocates by suggesting they disregard the true desires of women, thus attacking their reputation rather than engaging in a direct argument about the topic.']",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/pl/train-pl-part_0008.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The Questioning the Reputation technique is explicitly used in the input text by making strong negative claims about how women are treated as objects and exploited, particularly by abortion advocates. This undermines the moral stature of these advocates by suggesting they disregard the true desires of women, thus attacking their reputation rather than engaging in a direct argument about the topic.\", \"verdict\": true}"
        ],
        [
         "6",
         "trail_raw_BG_13.txt",
         "3446",
         "4689",
         "BG",
         " да се случи, когато се обърне колелото на историята Знаете ли какво може да се случи тогава Комисии, членове на комисии, ами евентуално по един, тези, които управляват тогава, по един член. Ето тук ще седи един депутат от управляващите, ще стане някой от Вас, ще каже две думи, председателят на Народното събрание ще даде думата на този, който е до стенографите, прекратяване на дебатите и довиждане. Това искате Вие. Вие искате комунизъм, Вие искате тоталитаризъм. Това искате. Вие сте самообявили се за демократи. Нямате нищо общо. Напротив. Вие не сте даже и такива, за които членувате и се обявявате, че сте икономисти за свобода на бизнеса. Вие наложихте поредица икономически рестрикции за свободата на бизнеса по всякакъв повод. Всичко, което Ви се иска и което Ви се спуска от европейски бюрократи, от презокеански началници, от посолство, Вие го изпълнявате. Нямате никакви скрупули. Всичко в името на това. Свобода на словото. Няма свобода на словото, няма такова нещо. Медии, бухалки. Сега малко се обърна позицията, защото една от медиите почна леко да Ви бие. Тогава обявихте ами и те са руски агенти. „Бърд“ – руски агенти. Защо Защото изкарахме Лорер и Асен Василев, че са гешефтари. (Реплика от ПП-ДБ „Времето!“)\n\n„Бърд“ – дир",
         "True",
         "['Conversation_Killer' 'Loaded_Language' 'Slogans'\n 'Questioning_the_Reputation' 'Name_Calling-Labeling'\n 'Guilt_by_Association' 'Repetition' 'Doubt']",
         "train",
         "['Вие не сте даже и такива, за които членувате и се обявявате, че сте икономисти за свобода на бизнеса. Вие наложихте поредица икономически рестрикции за свободата на бизнеса по всякакъв повод. Всичко, което Ви се иска и което Ви се спуска от европейски бюрократи, от презокеански началници, от посолство, Вие го изпълнявате'\n 'Нямате никакви скрупули'\n 'Медии, бухалки. Сега малко се обърна позицията, защото една от медиите почна леко да Ви бие. Тогава обявихте ами и те са руски агенти. „Бърд“ – руски агенти. Защо Защото изкарахме Лорер и Асен Василев, че са гешефтари']",
         "['руски агенти' 'руски агенти' 'гешефтари']",
         "[]",
         "['Това искате Вие' 'Това искате' 'Нямате нищо общо' 'Напротив'\n 'Няма свобода на словото, няма такова нещо']",
         "['Медии, бухалки']",
         "['Това искате Вие' 'искате комунизъм' 'искате тоталитаризъм' 'Това искате']",
         "[]",
         "['Вие сте самообявили се за демократи']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Свобода на словото']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Вие искате комунизъм, Вие искате тоталитаризъм']",
         "train",
         "GPT_41_MINI/v001/Repetition",
         "Repetition",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "1",
         "Yes, the Repetition technique is used in the input.",
         "\"Това искате Вие искате комунизъм искате тоталитаризъм Това искате\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"Repetition is explicitly used in the input text through the phrase \\'Това искате Вие искате комунизъм, Вие искате тоталитаризъм. Това искате.\\' The speaker repeats the phrase \\'Това искате\\' and the word \\'искате\\' to emphasize the accusation against the audience, aligning with the definition that states the same word or phrase is used repeatedly to persuade the audience.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[\"Repetition is explicitly used in the input text through the phrase 'Това искате Вие искате комунизъм, Вие искате тоталитаризъм. Това искате.' The speaker repeats the phrase 'Това искате' and the word 'искате' to emphasize the accusation against the audience, aligning with the definition that states the same word or phrase is used repeatedly to persuade the audience.\"]",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/Repetition/train/bg/train-bg-part_0003.parquet",
         null,
         null,
         "train",
         "{\"description\": \"Repetition is explicitly used in the input text through the phrase '\\u0422\\u043e\\u0432\\u0430 \\u0438\\u0441\\u043a\\u0430\\u0442\\u0435 \\u0412\\u0438\\u0435 \\u0438\\u0441\\u043a\\u0430\\u0442\\u0435 \\u043a\\u043e\\u043c\\u0443\\u043d\\u0438\\u0437\\u044a\\u043c, \\u0412\\u0438\\u0435 \\u0438\\u0441\\u043a\\u0430\\u0442\\u0435 \\u0442\\u043e\\u0442\\u0430\\u043b\\u0438\\u0442\\u0430\\u0440\\u0438\\u0437\\u044a\\u043c. \\u0422\\u043e\\u0432\\u0430 \\u0438\\u0441\\u043a\\u0430\\u0442\\u0435.' The speaker repeats the phrase '\\u0422\\u043e\\u0432\\u0430 \\u0438\\u0441\\u043a\\u0430\\u0442\\u0435' and the word '\\u0438\\u0441\\u043a\\u0430\\u0442\\u0435' to emphasize the accusation against the audience, aligning with the definition that states the same word or phrase is used repeatedly to persuade the audience.\", \"verdict\": true}"
        ],
        [
         "7",
         "20240111_SHG_BG_62.txt",
         "693",
         "1119",
         "BG",
         "Първо за бюджета. 2023 г. завърши с дупка в приходната част в размер на 2,4 млрд. лв. За справка, толкова е годишният бюджет на София. Дупката се отваря в 5-месечен срок, тъй като бюджетът беше приет в края на месец юли. Във финансовия свят това означава пълнен провал. Ако данните на една частна компания за две тримесечия покажат такова неизпълнение на заложената приходна част, това би причинило огромен спад на акциите ѝ. ",
         "True",
         "['False_Equivalence' 'Name_Calling-Labeling' 'Doubt']",
         "train",
         "[]",
         "['пълнен провал']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Първо за бюджета. 2023 г. завърши с дупка в приходната част в размер на 2,4 млрд. лв. За справка, толкова е годишният бюджет на София. Дупката се отваря в 5-месечен срок, тъй като бюджетът беше приет в края на месец юли']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Ако данните на една частна компания за две тримесечия покажат такова неизпълнение на заложената приходна част, това би причинило огромен спад на акциите ѝ']",
         "[]",
         "train",
         "GPT_41/v001/Doubt",
         "Doubt",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "1",
         "Yes, the Doubt technique is used in the input.",
         "\"Първо за бюджета. 2023 г. завърши с дупка в приходната част в размер на 2,4 млрд. лв. За справка, толкова е годишният бюджет на София. Дупката се отваря в 5-месечен срок, тъй като бюджетът беше приет в края на месец юли\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The Casting Doubt technique is used in the input text by highlighting the significant budget shortfall of 2.4 billion BGN and comparing it to the annual budget of Sofia. This comparison questions the credibility of the budget management by implying that such a deficit indicates a failure, thus casting doubt on the effectiveness of the financial decisions made.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "['The Casting Doubt technique is used in the input text by highlighting the significant budget shortfall of 2.4 billion BGN and comparing it to the annual budget of Sofia. This comparison questions the credibility of the budget management by implying that such a deficit indicates a failure, thus casting doubt on the effectiveness of the financial decisions made.']",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Doubt/train/bg/train-bg-part_0000.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The Casting Doubt technique is used in the input text by highlighting the significant budget shortfall of 2.4 billion BGN and comparing it to the annual budget of Sofia. This comparison questions the credibility of the budget management by implying that such a deficit indicates a failure, thus casting doubt on the effectiveness of the financial decisions made.\", \"verdict\": true}"
        ],
        [
         "8",
         "RU_migrants_7.txt",
         "80",
         "643",
         "RU",
         "С одной стороны, продолжающееся СВО, которое никак нельзя заканчивать до того, как его реальные задачи будут реализованы. А мы все понимаем, что это за задачи. И все понимаем, насколько они огромны и какое количество времени может на них уйти. Особенно при неблагоприятном развитии событий, если всё это зависнет ещё на годы и если шанс на относительно быструю победу (а она возможна) будет упущен. Я уже не говорю о том, сколько времени и сил уйдёт даже в случае самой блестящей Победы на устранение последствий того, что происходило на данной территории 35 лет.",
         "True",
         "['Appeal_to_Time' 'Obfuscation-Vagueness-Confusion'\n 'False_Dilemma-No_Choice']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Особенно при неблагоприятном развитии событий, если всё это зависнет ещё на годы и если шанс на относительно быструю победу (а она возможна) будет упущен'\n 'Я уже не говорю о том, сколько времени и сил уйдёт даже в случае самой блестящей Победы на устранение последствий того, что происходило на данной территории 35 лет']",
         "[]",
         "['А мы все понимаем, что это за задачи. И все понимаем, насколько они огромны и какое количество времени может на них уйти']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['С одной стороны, продолжающееся СВО, которое никак нельзя заканчивать до того, как его реальные задачи будут реализованы']",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Name_Calling-Labeling",
         "Name_Calling-Labeling",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Name Calling-Labeling technique is not used in the input.",
         "\"\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The input text does not contain any loaded labels directed at individuals or groups in an insulting or demeaning way. It discusses the ongoing situation without resorting to qualitative judgments or manipulative wording that characterizes subjects negatively. Therefore, the Name Calling - Labeling technique is not present.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "['The input text does not contain any loaded labels directed at individuals or groups in an insulting or demeaning way. It discusses the ongoing situation without resorting to qualitative judgments or manipulative wording that characterizes subjects negatively. Therefore, the Name Calling - Labeling technique is not present.']",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Name_Calling-Labeling/train/ru/train-ru-part_0010.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text does not contain any loaded labels directed at individuals or groups in an insulting or demeaning way. It discusses the ongoing situation without resorting to qualitative judgments or manipulative wording that characterizes subjects negatively. Therefore, the Name Calling - Labeling technique is not present.\", \"verdict\": false}"
        ],
        [
         "9",
         "RU_discrediting_the_west_1.txt",
         "0",
         "26",
         "RU",
         "Проект: «Расчеловечивание»",
         "True",
         "['Appeal_to_Fear-Prejudice']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Проект: «Расчеловечивание»']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/Repetition",
         "Repetition",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "0",
         "No, the Repetition technique is not used in the input.",
         "\"\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The input text does not contain any repeated words, phrases, stories, or imagery, indicating that the Repetition technique was not used.\",\\n  \"updated_definition\": \"The speaker uses the same word, phrase, story, or imagery repeatedly with the hope that the repetition will lead to persuade the audience; this includes instances where the same element is used multiple times throughout the text.\"\\n}']",
         "['The speaker uses the same word, phrase, story, or imagery repeatedly with the hope that the repetition will lead to persuade the audience; this includes instances where the same element is used multiple times throughout the text.']",
         "[None]",
         "[None]",
         "['The input text does not contain any repeated words, phrases, stories, or imagery, indicating that the Repetition technique was not used.']",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/Repetition/train/ru/train-ru-part_0004.parquet",
         "[None]",
         "[None]",
         "train",
         "{\"description\": \"The input text does not contain any repeated words, phrases, stories, or imagery, indicating that the Repetition technique was not used.\", \"verdict\": false}"
        ],
        [
         "10",
         "RU_URW_4.txt",
         "936",
         "1254",
         "RU",
         "И это первое, что следует иметь ввиду, обсуждая любые договоренности с той стороной, имея ввиду, что западная \"реал-политик\", которую проповедует Трамп – это не про честность, а про силу – если ты можешь отстоять свои требования, то у тебя есть право, если нет, то только обязанности. Все остальное – словесная шелуха.",
         "True",
         "['Whataboutism']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['И это первое, что следует иметь ввиду, обсуждая любые договоренности с той стороной, имея ввиду, что западная \"реал-политик\", которую проповедует Трамп – это не про честность, а про силу – если ты можешь отстоять свои требования, то у тебя есть право, если нет, то только обязанности. Все остальное – словесная шелуха']",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Name_Calling-Labeling",
         "Name_Calling-Labeling",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Name Calling-Labeling technique is not used in the input.",
         "\"\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The input text does not contain any loaded labels directed at individuals or groups in an insulting or demeaning way. It discusses political concepts and opinions without resorting to name-calling or labeling.\",\\n  \"updated_definition\": \"Name Calling - Labeling is a form of argument in which loaded labels are directed at an individual or a group, typically in an insulting or demeaning way, focusing on qualitative judgments that disregard facts. This technique is characterized by the use of adjectives and nouns as labels that refer to personal characteristics, opinions, or affiliations, often in a manipulative manner. It is distinct from Loaded Language in that it solely concerns the characterization of the subject without providing a full argument.\"\\n}']",
         "['Name Calling - Labeling is a form of argument in which loaded labels are directed at an individual or a group, typically in an insulting or demeaning way, focusing on qualitative judgments that disregard facts. This technique is characterized by the use of adjectives and nouns as labels that refer to personal characteristics, opinions, or affiliations, often in a manipulative manner. It is distinct from Loaded Language in that it solely concerns the characterization of the subject without providing a full argument.']",
         "[None]",
         "[None]",
         "['The input text does not contain any loaded labels directed at individuals or groups in an insulting or demeaning way. It discusses political concepts and opinions without resorting to name-calling or labeling.']",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Name_Calling-Labeling/train/ru/train-ru-part_0011.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text does not contain any loaded labels directed at individuals or groups in an insulting or demeaning way. It discusses political concepts and opinions without resorting to name-calling or labeling.\", \"verdict\": false}"
        ],
        [
         "11",
         "RU_discrediting_the_west_6.txt",
         "869",
         "1058",
         "RU",
         "При этом было подчёркнуто, что это – решение уходящей администрации и государственного секретаря, а «после 12 часов дня 20 января следующая администрация может высказать свою точку зрения».",
         "False",
         "[]",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/Repetition",
         "Repetition",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "0",
         "No, the Repetition technique is not used in the input.",
         "\"\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The input text does not contain any repeated words, phrases, stories, or imagery. Therefore, the Repetition technique was not used.\",\\n  \"updated_definition\": \"The speaker uses the same word, phrase, story, or imagery repeatedly with the hope that the repetition will lead to persuade the audience; this includes instances where the same concept is reiterated in different forms.\"\\n}']",
         "['The speaker uses the same word, phrase, story, or imagery repeatedly with the hope that the repetition will lead to persuade the audience; this includes instances where the same concept is reiterated in different forms.']",
         "[None]",
         "[None]",
         "['The input text does not contain any repeated words, phrases, stories, or imagery. Therefore, the Repetition technique was not used.']",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/Repetition/train/ru/train-ru-part_0015.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text does not contain any repeated words, phrases, stories, or imagery. Therefore, the Repetition technique was not used.\", \"verdict\": false}"
        ],
        [
         "12",
         "RU_discrediting_the_west_7.txt",
         "1655",
         "1890",
         "RU",
         "Задержание основателя Telegram Павла Дурова 24 августа во Франции ещё раз продемонстрировало, что России нужен полный цифровой суверенитет. Полумеры, например, в виде торможения Youtube, воспринимаются обществом как непоследовательные.",
         "True",
         "['False_Dilemma-No_Choice']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Задержание основателя Telegram Павла Дурова 24 августа во Франции ещё раз продемонстрировало, что России нужен полный цифровой суверенитет']",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Doubt",
         "Doubt",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Doubt technique is not used in the input.",
         "\"\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The input text discusses the need for digital sovereignty in Russia and mentions the detention of Pavel Durov, but it does not cast doubt on his character or credibility. There are no references that question his personal attributes or professional background, nor does it discredit his arguments. Therefore, the Casting Doubt technique is not used.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "['The input text discusses the need for digital sovereignty in Russia and mentions the detention of Pavel Durov, but it does not cast doubt on his character or credibility. There are no references that question his personal attributes or professional background, nor does it discredit his arguments. Therefore, the Casting Doubt technique is not used.']",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Doubt/train/ru/train-ru-part_0009.parquet",
         "[None]",
         "[None]",
         "train",
         "{\"description\": \"The input text discusses the need for digital sovereignty in Russia and mentions the detention of Pavel Durov, but it does not cast doubt on his character or credibility. There are no references that question his personal attributes or professional background, nor does it discredit his arguments. Therefore, the Casting Doubt technique is not used.\", \"verdict\": false}"
        ],
        [
         "13",
         "20240111_SHG_BG_61.txt",
         "3814",
         "4307",
         "BG",
         "Освен това побързахте, така предновогодишно, в последните дни да предложите нов Закон за бежанците и убежищата и сте го разпратили на общините, защото предвиждате да включите тези бежанци в интегрираните планове на общините. Да задължите общините да им осигурят жилища, безплатно образование, здравеопазване. Вкарвате ги в цялата социална система за подпомагане на България тихомълком, преди празниците. Отричате ли, че сте се съгласили на това, уважаеми управляващи, защото фактите са факти?!",
         "True",
         "['Loaded_Language' 'Questioning_the_Reputation' 'Straw_Man']",
         "train",
         "['Освен това побързахте, така предновогодишно, в последните дни да предложите нов Закон за бежанците и убежищата и сте го разпратили на общините, защото предвиждате да включите тези бежанци в интегрираните планове на общините'\n 'Да задължите общините да им осигурят жилища, безплатно образование, здравеопазване. Вкарвате ги в цялата социална система за подпомагане на България тихомълком, преди празниците. Отричате ли, че сте се съгласили на това, уважаеми управляващи, защото фактите са факти?!']",
         "[]",
         "[]",
         "[]",
         "['тихомълком']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['да предложите нов Закон за бежанците и убежищата и сте го разпратили на общините, защото предвиждате да включите тези бежанци в интегрираните планове на общините']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/Loaded_Language",
         "Loaded_Language",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "1",
         "Yes, the Loaded Language technique is used in the input.",
         "\"тихомълком\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The input text employs the Loaded Language technique through the use of the word \\'тихомълком\\', which carries a negative connotation implying secrecy or deceit. This emotionally charged term is intended to influence the audience\\'s perception of the actions being criticized, suggesting that they are being done in a sneaky or underhanded manner, thus reinforcing the argument against the proposed law.\",\\n  \"updated_definition\": \"Loaded Language is the use of specific words and phrases with strong emotional implications (either positive or negative) to influence and convince the audience that an argument is valid, often by evoking strong feelings or biases. It is also known as Appeal to Argument from Emotive Language.\"\\n}']",
         "['Loaded Language is the use of specific words and phrases with strong emotional implications (either positive or negative) to influence and convince the audience that an argument is valid, often by evoking strong feelings or biases. It is also known as Appeal to Argument from Emotive Language.']",
         "[None]",
         "[None]",
         "[\"The input text employs the Loaded Language technique through the use of the word 'тихомълком', which carries a negative connotation implying secrecy or deceit. This emotionally charged term is intended to influence the audience's perception of the actions being criticized, suggesting that they are being done in a sneaky or underhanded manner, thus reinforcing the argument against the proposed law.\"]",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/Loaded_Language/train/bg/train-bg-part_0022.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text employs the Loaded Language technique through the use of the word '\\u0442\\u0438\\u0445\\u043e\\u043c\\u044a\\u043b\\u043a\\u043e\\u043c', which carries a negative connotation implying secrecy or deceit. This emotionally charged term is intended to influence the audience's perception of the actions being criticized, suggesting that they are being done in a sneaky or underhanded manner, thus reinforcing the argument against the proposed law.\", \"verdict\": true}"
        ],
        [
         "14",
         "20240111_SHG_BG_62.txt",
         "5806",
         "7044",
         "BG",
         "Изкривената идеология и чистата нагла лъжа са Вашите изразни средства. Това сме го живели. Вашите бащи и майки, които бяха от висшия ешелон на Българската комунистическа партия, обявяваха по идеологически причини всяко мнение, което е различно от тяхното, за предателство. Вие като техни комунистически отрочета правите абсолютно същото. Вашите родители обвиняваха инакомислещите, че са предатели и капиталистически дегенерати. Вие обвинявате инакомислещите, че са предатели и путинисти. И в двата случая това е откровена тъпотия. Вашите родители се провалиха, Вие също ще се провалите. „Продължаваме Промяната“ така или иначе сте тръгнали към политическото бунище, а крепящите Ви ГЕРБ и ДПС колкото по-дълго останат с Вас, толкова повече се маргинализират накрая. И когато паднете от властта, а това е неизбежно, просто това са нормални социално-исторически процеси, бъдете сигурни, че не просто ще бъдете изгонени, но преди това хората ще Ви накарат да си платите за всичко. В онзи запис казахте, че ще ходите на някакъв остров – дано да сте намерили остров, дето да го няма на картата и където никой не може да Ви намери, защото, ако продължавате така, не до острова, ами и до летището няма да може да стигнете. (Ръкопляскания от ИТН.)",
         "True",
         "['False_Equivalence' 'Consequential_Oversimplification' 'Loaded_Language'\n 'Questioning_the_Reputation' 'Name_Calling-Labeling'\n 'Guilt_by_Association']",
         "train",
         "['Изкривената идеология и чистата нагла лъжа са Вашите изразни средства'\n '„Продължаваме Промяната“ така или иначе сте тръгнали към политическото бунище, а крепящите Ви ГЕРБ и ДПС колкото по-дълго останат с Вас, толкова повече се маргинализират накрая. И когато паднете от властта, а това е неизбежно, просто това са нормални социално-исторически процеси, бъдете сигурни, че не просто ще бъдете изгонени, но преди това хората ще Ви накарат да си платите за всичко'\n 'В онзи запис казахте, че ще ходите на някакъв остров – дано да сте намерили остров, дето да го няма на картата и където никой не може да Ви намери, защото, ако продължавате така, не до острова, ами и до летището няма да може да стигнете']",
         "['техни комунистически отрочета' 'откровена тъпотия'\n 'политическото бунище']",
         "[]",
         "[]",
         "['бунище']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Вашите родители се провалиха, Вие също ще се провалите'\n 'И когато паднете от властта, а това е неизбежно, просто това са нормални социално-исторически процеси, бъдете сигурни, че не просто ще бъдете изгонени, но преди това хората ще Ви накарат да си платите за всичко']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Вие като техни комунистически отрочета правите абсолютно същото'\n 'Вашите родители обвиняваха инакомислещите, че са предатели и капиталистически дегенерати. Вие обвинявате инакомислещите, че са предатели и путинисти']",
         "['Вашите бащи и майки, които бяха от висшия ешелон на Българската комунистическа партия, обявяваха по идеологически причини всяко мнение, което е различно от тяхното, за предателство']",
         "train",
         "GPT_41_MINI/v001/Loaded_Language",
         "Loaded_Language",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "1",
         "Yes, the Loaded Language technique is used in the input.",
         "\"бунище\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The input text employs Loaded Language through the use of the word \\'бунище\\' (dump), which carries strong negative emotional implications. This term is intended to evoke disdain and contempt towards the political group being addressed, aligning with the definition of Loaded Language as it aims to influence the audience\\'s perception by using emotionally charged words.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "[\"The input text employs Loaded Language through the use of the word 'бунище' (dump), which carries strong negative emotional implications. This term is intended to evoke disdain and contempt towards the political group being addressed, aligning with the definition of Loaded Language as it aims to influence the audience's perception by using emotionally charged words.\"]",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/Loaded_Language/train/bg/train-bg-part_0015.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text employs Loaded Language through the use of the word '\\u0431\\u0443\\u043d\\u0438\\u0449\\u0435' (dump), which carries strong negative emotional implications. This term is intended to evoke disdain and contempt towards the political group being addressed, aligning with the definition of Loaded Language as it aims to influence the audience's perception by using emotionally charged words.\", \"verdict\": true}"
        ],
        [
         "15",
         "SI_interpelation_interior_13.txt",
         "4213",
         "4233",
         "SI",
         "Hvala, predsedujoča.",
         "False",
         "[]",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Authority",
         "Appeal_to_Authority",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Appeal to Authority technique is not used in the input.",
         "\"\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The input text does not contain any references to an authority or an entity considered as an authority to support an argument or claim. Therefore, the Appeal to Authority technique is not used.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "['The input text does not contain any references to an authority or an entity considered as an authority to support an argument or claim. Therefore, the Appeal to Authority technique is not used.']",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Authority/train/si/train-si-part_0006.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text does not contain any references to an authority or an entity considered as an authority to support an argument or claim. Therefore, the Appeal to Authority technique is not used.\", \"verdict\": false}"
        ],
        [
         "16",
         "pl_defence_22_05_2024_n02.txt",
         "6612",
         "7661",
         "PL",
         "Panie Ministrze! Zmiany w prawie i nowelizacje\nustaw obronnych powinny się dokonywać natychmiast,\nnawet co miesiąc. Mamy zdiagnozowany problem, nie\nczekamy na następne poprawki, tylko natychmiast\nnowelizujemy. Czas ma dla Polski w dziedzinie\nobronności znaczenie strategiczne. Dzisiejsze Siły Zbrojne\nsą w stanie walczyć na ok. 3% terytorium Polski,\nwzmocnione przez sojuszników – na ok. 4% terytorium\nPolski, oczywiście bez koncentracji wysiłku obronnego.\nPrzypomnę, iż mamy cztery dywizje operacyjne, z\nktórych każda, według uśrednionych wskaźników\ntaktycznych, prowadzi działania obronne w pasie 50 km i na\ngłębokość 25 km. Proszę sobie samemu to obliczyć.\nA gdzie rotacja jednostek? Gdzie odwody? Dla\nnowych dywizji nie ma uzbrojenia, nawet dla tych\nzmobilizowanych na czas wojny, nie mówiąc już o\nuzupełnieniu strat sprzętu. Musimy drastycznie bardziej\nnasycić przestrzeń Polski wojskiem, ale do tego\nnależy zmienić system ilościowy i jakościowy wojsk\nobrony terytorialnej. Musimy je drastycznie rozbudować.\nPowtarzam: zmienić system. (Oklaski)",
         "True",
         "['Appeal_to_Time' 'Doubt' 'Repetition']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Musimy drastycznie' 'Musimy je drastycznie']",
         "[]",
         "['A gdzie rotacja jednostek?' 'Gdzie odwody?'\n 'Dla nowych dywizji nie ma uzbrojenia, nawet dla tych zmobilizowanych na czas wojny, nie mówiąc już o uzupełnieniu strat sprzętu. Musimy drastycznie bardziej nasycić przestrzeń Polski wojskiem, ale do tego należy zmienić system ilościowy i jakościowy wojsk obrony terytorialnej. Musimy je drastycznie rozbudować. Powtarzam: zmienić system']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Zmiany w prawie i nowelizacje ustaw obronnych powinny się dokonywać natychmiast, nawet co miesiąc']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Red_Herring",
         "Red_Herring",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Red Herring technique is not used in the input.",
         "\"\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The input text remains focused on the topic of military reforms and the need for immediate changes in defense laws. There are no instances of diverting attention to unrelated topics, which is characteristic of the Red Herring technique. Therefore, the expert\\'s verdict that the technique is not used is accurate.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[\"The input text remains focused on the topic of military reforms and the need for immediate changes in defense laws. There are no instances of diverting attention to unrelated topics, which is characteristic of the Red Herring technique. Therefore, the expert's verdict that the technique is not used is accurate.\"]",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Red_Herring/train/pl/train-pl-part_0010.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text remains focused on the topic of military reforms and the need for immediate changes in defense laws. There are no instances of diverting attention to unrelated topics, which is characteristic of the Red Herring technique. Therefore, the expert's verdict that the technique is not used is accurate.\", \"verdict\": false}"
        ],
        [
         "17",
         "RU_migrants_5.txt",
         "2013",
         "2271",
         "RU",
         "ия города, да и системы в том, что следователь спокойно вменяет за похищение и издевательства «хулиганку». Как верно сказал Михаил Маваши, не инкриминируется «по предварительному сговору», «совершенное группой лиц», а также «с особым цинизмом».\n\nНе нужно уже",
         "True",
         "['Loaded_Language' 'Appeal_to_Authority']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "['И тут деградация города, да и системы в том']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Как верно сказал Михаил Маваши, не инкриминируется «по предварительному сговору», «совершенное группой лиц», а также «с особым цинизмом»']",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Guilt_by_Association",
         "Guilt_by_Association",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Guilt by Association technique is not used in the input.",
         "\"\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The input text does not employ the Guilt by Association technique, as it does not attempt to link the actions or character of an individual or group to another entity with negative connotations. There are no comparisons or associations made that would invoke guilt by association.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "['The input text does not employ the Guilt by Association technique, as it does not attempt to link the actions or character of an individual or group to another entity with negative connotations. There are no comparisons or associations made that would invoke guilt by association.']",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Guilt_by_Association/train/ru/train-ru-part_0003.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text does not employ the Guilt by Association technique, as it does not attempt to link the actions or character of an individual or group to another entity with negative connotations. There are no comparisons or associations made that would invoke guilt by association.\", \"verdict\": false}"
        ],
        [
         "18",
         "20240111_SHG_BG_62.txt",
         "693",
         "1119",
         "BG",
         "Първо за бюджета. 2023 г. завърши с дупка в приходната част в размер на 2,4 млрд. лв. За справка, толкова е годишният бюджет на София. Дупката се отваря в 5-месечен срок, тъй като бюджетът беше приет в края на месец юли. Във финансовия свят това означава пълнен провал. Ако данните на една частна компания за две тримесечия покажат такова неизпълнение на заложената приходна част, това би причинило огромен спад на акциите ѝ. ",
         "True",
         "['False_Equivalence' 'Name_Calling-Labeling' 'Doubt']",
         "train",
         "[]",
         "['пълнен провал']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Първо за бюджета. 2023 г. завърши с дупка в приходната част в размер на 2,4 млрд. лв. За справка, толкова е годишният бюджет на София. Дупката се отваря в 5-месечен срок, тъй като бюджетът беше приет в края на месец юли']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Ако данните на една частна компания за две тримесечия покажат такова неизпълнение на заложената приходна част, това би причинило огромен спад на акциите ѝ']",
         "[]",
         "train",
         "GPT_41_MINI/v001/Loaded_Language",
         "Loaded_Language",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "0",
         "No, the Loaded Language technique is not used in the input.",
         "\"\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The input text does not employ Loaded Language, as it lacks specific words or phrases with strong emotional implications intended to influence the audience. The language used is factual and analytical, focusing on budgetary issues without emotive language.\",\\n  \"updated_definition\": \"Loaded Language technique involves the use of specific words and phrases with strong emotional implications (either positive or negative) to influence and convince the audience that an argument is valid, often through emotionally charged language that evokes a strong response.\"\\n}']",
         "['Loaded Language technique involves the use of specific words and phrases with strong emotional implications (either positive or negative) to influence and convince the audience that an argument is valid, often through emotionally charged language that evokes a strong response.']",
         "[None]",
         "[None]",
         "['The input text does not employ Loaded Language, as it lacks specific words or phrases with strong emotional implications intended to influence the audience. The language used is factual and analytical, focusing on budgetary issues without emotive language.']",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/Loaded_Language/train/bg/train-bg-part_0000.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text does not employ Loaded Language, as it lacks specific words or phrases with strong emotional implications intended to influence the audience. The language used is factual and analytical, focusing on budgetary issues without emotive language.\", \"verdict\": false}"
        ],
        [
         "19",
         "RU_discrediting_the_west_1.txt",
         "469",
         "604",
         "RU",
         "Это не ново. Запад под лозунгами освобождения человека на протяжении многих столетий последовательно его порабощает и лишает цельности.",
         "False",
         "[]",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Straw_Man",
         "Straw_Man",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Straw Man technique is not used in the input.",
         "\"\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The input text does not employ the Strawman technique, as it does not misrepresent or distort an opponent\\'s argument. Instead, it presents a direct assertion about the West\\'s historical actions without creating a false argument to refute.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "[\"The input text does not employ the Strawman technique, as it does not misrepresent or distort an opponent's argument. Instead, it presents a direct assertion about the West's historical actions without creating a false argument to refute.\"]",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Straw_Man/train/ru/train-ru-part_0012.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text does not employ the Strawman technique, as it does not misrepresent or distort an opponent's argument. Instead, it presents a direct assertion about the West's historical actions without creating a false argument to refute.\", \"verdict\": false}"
        ],
        [
         "20",
         "RU_discrediting_the_west_7.txt",
         "0",
         "363",
         "RU",
         "Если подводить внешнеполитические итоги 2024 года в хронологическом порядке, то сперва следует отметить интервью Владимира Путина американскому журналисту Такеру Карлсону от 6 февраля. Резонанс от этого интервью был серьёзный, в США его эффект пытались перебить информацией о выводе Россией в космос спутника с ядерным оружием, что, естественно, оказалось фейком.",
         "True",
         "['Whataboutism']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Резонанс от этого интервью был серьёзный, в США его эффект пытались перебить информацией о выводе Россией в космос спутника с ядерным оружием, что, естественно, оказалось фейком']",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/Whataboutism",
         "Whataboutism",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "1",
         "Yes, the Whataboutism technique is used in the input.",
         "\"Резонанс от этого интервью был серьёзный, в США его эффект пытались перебить информацией о выводе Россией в космос спутника с ядерным оружием, что, естественно, оказалось фейком\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"Whataboutism is used in the input text as it shifts the focus from the serious impact of Putin\\'s interview to a counter-accusation about the U.S. attempting to distract from it by spreading false information about Russia. This retort does not address the significance of the interview but instead introduces an unrelated critical claim about the U.S., thereby attempting to discredit their position.\",\\n  \"updated_definition\": \"A technique that attempts to discredit an opponent’s position by charging them with hypocrisy without directly disproving their argument. Instead of answering a critical question or argument, an attempt is made to retort with a critical counter-question or statement that expresses a counteraccusation, often involving double standards or unrelated criticisms. The intent is to distract from the content of a topic and to switch the topic actually. There is a fine distinction between this technique and Appeal to Hypocrisy, where the former introduces irrelevant information to the main topic, while the latter highlights the hypocrisy of double standards on the same or a very related topic.\"\\n}']",
         "['A technique that attempts to discredit an opponent’s position by charging them with hypocrisy without directly disproving their argument. Instead of answering a critical question or argument, an attempt is made to retort with a critical counter-question or statement that expresses a counteraccusation, often involving double standards or unrelated criticisms. The intent is to distract from the content of a topic and to switch the topic actually. There is a fine distinction between this technique and Appeal to Hypocrisy, where the former introduces irrelevant information to the main topic, while the latter highlights the hypocrisy of double standards on the same or a very related topic.']",
         "[None]",
         "[None]",
         "[\"Whataboutism is used in the input text as it shifts the focus from the serious impact of Putin's interview to a counter-accusation about the U.S. attempting to distract from it by spreading false information about Russia. This retort does not address the significance of the interview but instead introduces an unrelated critical claim about the U.S., thereby attempting to discredit their position.\"]",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/Whataboutism/train/ru/train-ru-part_0001.parquet",
         null,
         null,
         "train",
         "{\"description\": \"Whataboutism is used in the input text as it shifts the focus from the serious impact of Putin's interview to a counter-accusation about the U.S. attempting to distract from it by spreading false information about Russia. This retort does not address the significance of the interview but instead introduces an unrelated critical claim about the U.S., thereby attempting to discredit their position.\", \"verdict\": true}"
        ],
        [
         "21",
         "20240704_URW_BG_25.txt",
         "0",
         "1014",
         "BG",
         "СЛУЖЕБЕН МИНИСТЪР-ПРЕДСЕДАТЕЛ ДИМИТЪР ГЛАВЧЕВ: Уважаема госпожо Председател, уважаеми заместник-председатели, уважаеми народни представители! Аз във въведението казах, че това е лично решение на президента Радев, така че няма как да го коментирам. Какво го е смутило, може само той да каже. Изтъкнах и мотивите си защо го поканих да води делегацията. По-естествено от това не виждам. Това всъщност е пример как да си взаимодействат институциите според мен дори когато би трябвало да има единна позиция. Впрочем пак във встъпителните си думи казах, че винаги такъв е бил подходът – Министерството на отбраната и Министерството на външните работи с решение на Министерския съвет са утвърждавали позицията и после или президентът, или министър-председателят са представяли утвърдената позиция. Вие имате възможност всички да се запознаете каква е позицията. Аз специално не мога да отговоря какво го е смутило, но не искам и да навлизам в тази тема, тъй като очевидно има лични мотиви президентът Радев. Благодаря Ви.",
         "True",
         "['Doubt']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['тъй като очевидно има лични мотиви президентът Радев']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/Consequential_Oversimplification",
         "Consequential_Oversimplification",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "0",
         "No, the Consequential Oversimplification technique is not used in the input.",
         "\"\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The input text does not employ the Consequential Oversimplification technique, as it does not reject an argument by asserting that accepting it would lead to a series of negative consequences. Instead, the speaker discusses the situation without making unfounded claims about potential negative outcomes.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "['The input text does not employ the Consequential Oversimplification technique, as it does not reject an argument by asserting that accepting it would lead to a series of negative consequences. Instead, the speaker discusses the situation without making unfounded claims about potential negative outcomes.']",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/Consequential_Oversimplification/train/bg/train-bg-part_0002.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text does not employ the Consequential Oversimplification technique, as it does not reject an argument by asserting that accepting it would lead to a series of negative consequences. Instead, the speaker discusses the situation without making unfounded claims about potential negative outcomes.\", \"verdict\": false}"
        ],
        [
         "22",
         "RU_discrediting_the_west_7.txt",
         "1655",
         "1890",
         "RU",
         "Задержание основателя Telegram Павла Дурова 24 августа во Франции ещё раз продемонстрировало, что России нужен полный цифровой суверенитет. Полумеры, например, в виде торможения Youtube, воспринимаются обществом как непоследовательные.",
         "True",
         "['False_Dilemma-No_Choice']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Задержание основателя Telegram Павла Дурова 24 августа во Франции ещё раз продемонстрировало, что России нужен полный цифровой суверенитет']",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/Conversation_Killer",
         "Conversation_Killer",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "0",
         "No, the Conversation Killer technique is not used in the input.",
         "\"\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The input text does not contain any words or phrases that discourage critical thought or meaningful discussion. It presents an argument about digital sovereignty without employing Loaded Language or folk wisdom intended to end an argument.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "['The input text does not contain any words or phrases that discourage critical thought or meaningful discussion. It presents an argument about digital sovereignty without employing Loaded Language or folk wisdom intended to end an argument.']",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/Conversation_Killer/train/ru/train-ru-part_0009.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text does not contain any words or phrases that discourage critical thought or meaningful discussion. It presents an argument about digital sovereignty without employing Loaded Language or folk wisdom intended to end an argument.\", \"verdict\": false}"
        ],
        [
         "23",
         "20240704_URW_BG_25.txt",
         "1018",
         "1061",
         "BG",
         "ЕДСЕДАТЕЛ РАЯ НАЗАРЯН: И аз Ви благодаря.\n\n",
         "False",
         "[]",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/Repetition",
         "Repetition",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "0",
         "No, the Repetition technique is not used in the input.",
         "\"\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The Repetition technique was not used in the input text as there are no repeated words, phrases, or imagery present.\",\\n  \"updated_definition\": \"The speaker uses the same word, phrase, story, or imagery repeatedly with the hope that the repetition will lead to persuade the audience; this includes instances where the same element is used multiple times in close proximity.\"\\n}']",
         "['The speaker uses the same word, phrase, story, or imagery repeatedly with the hope that the repetition will lead to persuade the audience; this includes instances where the same element is used multiple times in close proximity.']",
         "[None]",
         "[None]",
         "['The Repetition technique was not used in the input text as there are no repeated words, phrases, or imagery present.']",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/Repetition/train/bg/train-bg-part_0010.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The Repetition technique was not used in the input text as there are no repeated words, phrases, or imagery present.\", \"verdict\": false}"
        ],
        [
         "24",
         "RU_Trump_1.txt",
         "95",
         "309",
         "RU",
         "Трамп, конечно, король сейчас. Он разыграл партию так, что любое решение Зеленского будет выгодно США. Война дальше - продолжение ослабления России. Прекращение войны - экономический захват Украины. Везде профит.\n\n",
         "True",
         "['Causal_Oversimplification' 'Loaded_Language']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "['А Трамп, конечно, король сейчас']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Война дальше - продолжение ослабления России. Прекращение войны - экономический захват Украины. Везде профит']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Questioning_the_Reputation",
         "Questioning_the_Reputation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Questioning the Reputation technique is not used in the input.",
         "\"\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The input text does not contain any strong negative claims aimed at undermining the character or moral stature of a specific target. Instead, it discusses political strategies and outcomes without attacking anyone\\'s reputation.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "[\"The input text does not contain any strong negative claims aimed at undermining the character or moral stature of a specific target. Instead, it discusses political strategies and outcomes without attacking anyone's reputation.\"]",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/ru/train-ru-part_0007.parquet",
         "[None]",
         "[None]",
         "train",
         "{\"description\": \"The input text does not contain any strong negative claims aimed at undermining the character or moral stature of a specific target. Instead, it discusses political strategies and outcomes without attacking anyone's reputation.\", \"verdict\": false}"
        ],
        [
         "25",
         "20240704_URW_BG_26.txt",
         "148",
         "202",
         "BG",
         "рупата на ГЕРБ-СДС – заповядайте, господин Гаджев.\n\nВИ",
         "False",
         "[]",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/Loaded_Language",
         "Loaded_Language",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "0",
         "No, the Loaded Language technique is not used in the input.",
         "\"\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The input text does not contain any specific words or phrases with strong emotional implications that would influence or convince the audience. Therefore, the Loaded Language technique is not used.\",\\n  \"updated_definition\": \"Loaded Language technique involves the use of specific words and phrases with strong emotional implications (either positive or negative) to influence and convince the audience that an argument is valid, often through emotionally charged language that evokes a strong response.\"\\n}']",
         "['Loaded Language technique involves the use of specific words and phrases with strong emotional implications (either positive or negative) to influence and convince the audience that an argument is valid, often through emotionally charged language that evokes a strong response.']",
         "[None]",
         "[None]",
         "['The input text does not contain any specific words or phrases with strong emotional implications that would influence or convince the audience. Therefore, the Loaded Language technique is not used.']",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/Loaded_Language/train/bg/train-bg-part_0024.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text does not contain any specific words or phrases with strong emotional implications that would influence or convince the audience. Therefore, the Loaded Language technique is not used.\", \"verdict\": false}"
        ],
        [
         "26",
         "pl_defence_22_05_2024_n01.txt",
         "3494",
         "3606",
         "PL",
         "A więc trzeba za to wszystko przeprosić i potem\nrealizować program Prawa i Sprawiedliwości, bo to\ndobry program.",
         "True",
         "['Slogans' 'False_Dilemma-No_Choice']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['bo to dobry program']",
         "[]",
         "[]",
         "[]",
         "['A więc trzeba za to wszystko przeprosić i potem realizować program Prawa i Sprawiedliwości, bo to dobry program']",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/Slogans",
         "Slogans",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "1",
         "Yes, the Slogans technique is used in the input.",
         "\"bo to dobry program\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The Slogans technique is used in the input text through the phrase \\'bo to dobry program\\', which serves as a brief and striking endorsement of the program, appealing emotionally to the audience by labeling it as \\'good\\'.\",\\n  \"updated_definition\": \"A brief and striking phrase that may include labeling and stereotyping, often acting as emotional appeals. Slogans are typically concise statements that encapsulate a belief or idea.\"\\n}']",
         "['A brief and striking phrase that may include labeling and stereotyping, often acting as emotional appeals. Slogans are typically concise statements that encapsulate a belief or idea.']",
         "[None]",
         "[None]",
         "[\"The Slogans technique is used in the input text through the phrase 'bo to dobry program', which serves as a brief and striking endorsement of the program, appealing emotionally to the audience by labeling it as 'good'.\"]",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/Slogans/train/pl/train-pl-part_0005.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The Slogans technique is used in the input text through the phrase 'bo to dobry program', which serves as a brief and striking endorsement of the program, appealing emotionally to the audience by labeling it as 'good'.\", \"verdict\": true}"
        ],
        [
         "27",
         "SI_interpelation_interior_2.txt",
         "0",
         "390",
         "SI",
         "Torej zaradi vsega naštetega in še marsičesa, kar bomo danes v razpravi povedali, sem prepričana, da poslanke in poslanci, ki premorete vsaj malo odgovornosti do te države, do njenih institucij, do državljank in do državljanov Republike Slovenije, boste danes glasovali za razrešitev gospoda Poklukarja, ministra za notranje zadeve, tako kot predlagamo podpisniki interpelacije. Hvala lepa.",
         "True",
         "['Appeal_to_Values']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['odgovornosti do te države, do njenih institucij']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Values",
         "Appeal_to_Values",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "1",
         "Yes, the Appeal to Values technique is used in the input.",
         "\"odgovornosti do te države, do njenih institucij\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The Appeal to Values technique is used in the input text by linking the argument for voting to remove the minister to the value of responsibility towards the state and its institutions. The speaker appeals to the audience\\'s sense of duty and accountability, which are seen as positive values, thereby strengthening the argument for the proposed action.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[\"The Appeal to Values technique is used in the input text by linking the argument for voting to remove the minister to the value of responsibility towards the state and its institutions. The speaker appeals to the audience's sense of duty and accountability, which are seen as positive values, thereby strengthening the argument for the proposed action.\"]",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Values/train/si/train-si-part_0003.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The Appeal to Values technique is used in the input text by linking the argument for voting to remove the minister to the value of responsibility towards the state and its institutions. The speaker appeals to the audience's sense of duty and accountability, which are seen as positive values, thereby strengthening the argument for the proposed action.\", \"verdict\": true}"
        ],
        [
         "28",
         "pl_eu_12_06_2024_n02.txt",
         "498",
         "1033",
         "PL",
         "Poseł Zbigniew Bogucki:\nDziękuję.\nPanie Marszałku! Wysoki Sejmie! Państwo Ministrowie! Podstawowe pytanie: Jaka to będzie prezydencja? Czy to będzie prezydencja faktycznie realizacji polskich interesów, czy ona będzie prezydencją\npolską wyłącznie z nazwy? Bo sam fakt, że obejmiemy prezydencję, jeszcze o niczym nie stanowi i niczego nie przesądza. Co zamierzacie państwo zrobić?\nMyślę, że mimo że ta ustawa dotyczy nieco innego\nzakresu spraw, trzeba powiedzieć, co chcecie zrobić\nw czasie tej prezydencji. A tego w ogóle nie słyszymy.",
         "True",
         "['Flag_Waving' 'Doubt']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Czy to będzie prezydencja faktycznie realizacji polskich interesów, czy ona będzie prezydencją polską wyłącznie z nazwy?'\n 'A tego w ogóle nie słyszymy']",
         "[]",
         "['Czy to będzie prezydencja faktycznie realizacji polskich interesów']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Flag_Waving",
         "Flag_Waving",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "1",
         "Yes, the Flag Waving technique is used in the input.",
         "\"Czy to będzie prezydencja faktycznie realizacji polskich interesów\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The Flag Waving technique is used in the input text as the speaker questions whether the presidency will genuinely serve Polish interests. This highlights a sense of national pride and concern for the benefits of the Polish group, aligning with the definition of the technique that emphasizes justifying ideas through group pride.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "['The Flag Waving technique is used in the input text as the speaker questions whether the presidency will genuinely serve Polish interests. This highlights a sense of national pride and concern for the benefits of the Polish group, aligning with the definition of the technique that emphasizes justifying ideas through group pride.']",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Flag_Waving/train/pl/train-pl-part_0009.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The Flag Waving technique is used in the input text as the speaker questions whether the presidency will genuinely serve Polish interests. This highlights a sense of national pride and concern for the benefits of the Polish group, aligning with the definition of the technique that emphasizes justifying ideas through group pride.\", \"verdict\": true}"
        ],
        [
         "29",
         "20240704_URW_BG_25.txt",
         "3086",
         "3152",
         "BG",
         " смисъл от закрито заседание. (Шум и реплики.)\n\nСамо да довършим о",
         "False",
         "[]",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Flag_Waving",
         "Flag_Waving",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Flag Waving technique is not used in the input.",
         "\"\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The input text does not contain any elements that justify or promote an idea by appealing to the pride of a group or highlighting benefits for a specific group. There are no references to group identity, emotions, or any form of nationalism or patriotism.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "['The input text does not contain any elements that justify or promote an idea by appealing to the pride of a group or highlighting benefits for a specific group. There are no references to group identity, emotions, or any form of nationalism or patriotism.']",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Flag_Waving/train/bg/train-bg-part_0020.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text does not contain any elements that justify or promote an idea by appealing to the pride of a group or highlighting benefits for a specific group. There are no references to group identity, emotions, or any form of nationalism or patriotism.\", \"verdict\": false}"
        ],
        [
         "30",
         "pl_abortion_11_04_2024_n03.txt",
         "1839",
         "2256",
         "PL",
         "Mam dzisiaj zaszczyt i przyjemność jako posłanka\nklubu parlamentarnego Lewicy i wnioskodawczyni\nprojektu o bezpiecznym przerywaniu ciąży\nprzedstawić państwu projekt, który jest oparty na trosce i\nempatii w stosunku do kobiet, które po 30 latach\nobowiązywania zakazu aborcji muszą w końcu odzyskać\nodebrane im wiele lat temu prawo do podejmowania\nsamodzielnych decyzji w sprawie macierzyństwa,\nswojego zdrowia i życia.",
         "True",
         "['Appeal_to_Time' 'Appeal_to_Pity' 'Appeal_to_Values']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['po 30 latach obowiązywania zakazu aborcji muszą w końcu odzyskać odebrane im wiele lat temu prawo do podejmowania samodzielnych decyzji w sprawie macierzyństwa, swojego zdrowia i życia']",
         "['po 30 latach obowiązywania zakazu aborcji muszą w końcu odzyskać odebrane im wiele lat temu prawo']",
         "['który jest oparty na trosce i empatii w stosunku do kobiet'\n 'muszą w końcu odzyskać odebrane im wiele lat temu prawo do podejmowania samodzielnych decyzji w sprawie macierzyństwa, swojego zdrowia i życia']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Values",
         "Appeal_to_Values",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "1",
         "Yes, the Appeal to Values technique is used in the input.",
         "\"który jest oparty na trosce i empatii w stosunku do kobiet muszą w końcu odzyskać odebrane im wiele lat temu prawo do podejmowania samodzielnych decyzji w sprawie macierzyństwa, swojego zdrowia i życia\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The Appeal to Values technique is used in the input text by linking the argument for safe abortion to the values of care and empathy towards women. The excerpt emphasizes the importance of women\\'s rights to make independent decisions about motherhood, health, and life, which are seen as positive values by the target audience.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[\"The Appeal to Values technique is used in the input text by linking the argument for safe abortion to the values of care and empathy towards women. The excerpt emphasizes the importance of women's rights to make independent decisions about motherhood, health, and life, which are seen as positive values by the target audience.\"]",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Values/train/pl/train-pl-part_0002.parquet",
         "[None]",
         "[None]",
         "train",
         "{\"description\": \"The Appeal to Values technique is used in the input text by linking the argument for safe abortion to the values of care and empathy towards women. The excerpt emphasizes the importance of women's rights to make independent decisions about motherhood, health, and life, which are seen as positive values by the target audience.\", \"verdict\": true}"
        ],
        [
         "31",
         "RU_demography_2.txt",
         "2428",
         "2925",
         "RU",
         "Но, ещё раз подчеркну, проблема абортов не может быть решена только запретительными или исключительно стимулирующими мерами. Нужен хорошо продуманный комплексный план, который позволит существенно снизить количество абортов. Именно над этим, полагаю, следует работать нашим законодателям и общественным организациям. Семья, дети – вот подлинное счастье любого нормального человека. Ведь как просто, и почему-то об этом у нас в последние десятилетия нигде – ни в СМИ, ни в культуре – почти ни слова",
         "True",
         "['Appeal_to_Values']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Семья, дети – вот подлинное счастье любого нормального человека']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/Conversation_Killer",
         "Conversation_Killer",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "0",
         "No, the Conversation Killer technique is not used in the input.",
         "\"\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The input text does not contain any words or phrases that discourage critical thought or meaningful discussion about the topic of abortion. Instead, it advocates for a comprehensive plan and emphasizes the importance of family and children, which encourages dialogue rather than ending it.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "['The input text does not contain any words or phrases that discourage critical thought or meaningful discussion about the topic of abortion. Instead, it advocates for a comprehensive plan and emphasizes the importance of family and children, which encourages dialogue rather than ending it.']",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/Conversation_Killer/train/ru/train-ru-part_0014.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text does not contain any words or phrases that discourage critical thought or meaningful discussion about the topic of abortion. Instead, it advocates for a comprehensive plan and emphasizes the importance of family and children, which encourages dialogue rather than ending it.\", \"verdict\": false}"
        ],
        [
         "32",
         "RU_discrediting_the_west_19.txt",
         "851",
         "1159",
         "RU",
         "При этом Вэнс даже не пытался играть в дипломатию. Например, отказал во встрече Шольцу, прямо указав, что ему не о чем с тем разговаривать, намекая, что тот не субъектен и не имеет полномочий принимать какие-либо самостоятельные решения. \"К тому же ему недолго осталось\", - по-простому прокомментировал Вэнс.",
         "True",
         "['Straw_Man']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Например, отказал во встрече Шольцу, прямо указав, что ему не о чем с тем разговаривать, намекая, что тот не субъектен и не имеет полномочий принимать какие-либо самостоятельные решения']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/Appeal_to_Pity",
         "Appeal_to_Pity",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "0",
         "No, the Appeal to Pity technique is not used in the input.",
         "\"\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The input text does not evoke feelings of pity, sympathy, compassion, or guilt. It focuses on a political interaction without attempting to sway opinions through emotional appeals. Therefore, the Appeal to Pity technique is not used.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "['The input text does not evoke feelings of pity, sympathy, compassion, or guilt. It focuses on a political interaction without attempting to sway opinions through emotional appeals. Therefore, the Appeal to Pity technique is not used.']",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/Appeal_to_Pity/train/ru/train-ru-part_0003.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text does not evoke feelings of pity, sympathy, compassion, or guilt. It focuses on a political interaction without attempting to sway opinions through emotional appeals. Therefore, the Appeal to Pity technique is not used.\", \"verdict\": false}"
        ],
        [
         "33",
         "pl_abortion_11_04_2024_n01.txt",
         "3417",
         "3907",
         "PL",
         "Rozmawiamy o życiu. Rozmawiajmy o życiu\nkobiet, jak to życie jest niszczone przez to, że mąż\nkobiety, która przerwała ciążę – podkreślam, miała\nprawo to zrobić – idzie do więzienia. Czy to jest\nnormalne? Czy to nie jest niszczenie życia rodzin?\nWiększość kobiet, które przerywają ciążę, już ma dzieci,\njedno lub więcej, i w tym momencie członek rodziny\n– czasem tata tych dzieci, czasem babcia, czasem\nciocia – ryzykuje tym, że trafi na 3 lata do więzienia.\nTo się musi zmienić natychmiast.",
         "True",
         "['Appeal_to_Time' 'Appeal_to_Pity' 'Appeal_to_Values' 'Repetition' 'Doubt']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Rozmawiamy o życiu' 'Rozmawiajmy o życiu kobiet']",
         "[]",
         "['Czy to jest normalne?']",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Rozmawiajmy o życiu kobiet, jak to życie jest niszczone przez to, że mąż kobiety, która przerwała ciążę – podkreślam, miała prawo to zrobić – idzie do więzienia. Czy to jest normalne? Czy to nie jest niszczenie życia rodzin?'\n 'Większość kobiet, które przerywają ciążę, już ma dzieci, jedno lub więcej, i w tym momencie członek rodziny – czasem tata tych dzieci, czasem babcia, czasem ciocia – ryzykuje tym, że trafi na 3 lata do więzienia']",
         "['To się musi zmienić natychmiast']",
         "['Rozmawiamy o życiu'\n 'Rozmawiajmy o życiu kobiet, jak to życie jest niszczone przez to, że mąż kobiety, która przerwała ciążę – podkreślam, miała prawo to zrobić – idzie do więzienia'\n 'Czy to nie jest niszczenie życia rodzin?']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/Appeal_to_Time",
         "Appeal_to_Time",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "1",
         "Yes, the Appeal to Time technique is used in the input.",
         "\"To się musi zmienić natychmiast\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The Appeal to Time technique is explicitly used in the input text through the phrase \\'To się musi zmienić natychmiast\\', which emphasizes the urgency for change. This aligns with the definition that the argument is centered around the idea that the time has come for a particular action, highlighting the immediate need for action regarding the situation discussed.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[\"The Appeal to Time technique is explicitly used in the input text through the phrase 'To się musi zmienić natychmiast', which emphasizes the urgency for change. This aligns with the definition that the argument is centered around the idea that the time has come for a particular action, highlighting the immediate need for action regarding the situation discussed.\"]",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/Appeal_to_Time/train/pl/train-pl-part_0004.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The Appeal to Time technique is explicitly used in the input text through the phrase 'To si\\u0119 musi zmieni\\u0107 natychmiast', which emphasizes the urgency for change. This aligns with the definition that the argument is centered around the idea that the time has come for a particular action, highlighting the immediate need for action regarding the situation discussed.\", \"verdict\": true}"
        ],
        [
         "34",
         "20231208_URW_BG_72.txt",
         "4627",
         "4689",
         "BG",
         "ПРЕДСЕДАТЕЛ РОСЕН ЖЕЛЯЗКОВ: Господин Гуцанов, укротете патоса!",
         "False",
         "[]",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/Repetition",
         "Repetition",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "0",
         "No, the Repetition technique is not used in the input.",
         "\"\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The Repetition technique was not used in the input text as there are no repeated words, phrases, or imagery present. The expert\\'s verdict is supported by the absence of any excerpts indicating repetition.\",\\n  \"updated_definition\": \"The speaker uses the same word, phrase, story, or imagery repeatedly with the hope that the repetition will lead to persuade the audience; this can be identified by the presence of at least one instance of such repetition in the text.\"\\n}']",
         "['The speaker uses the same word, phrase, story, or imagery repeatedly with the hope that the repetition will lead to persuade the audience; this can be identified by the presence of at least one instance of such repetition in the text.']",
         "[None]",
         "[None]",
         "[\"The Repetition technique was not used in the input text as there are no repeated words, phrases, or imagery present. The expert's verdict is supported by the absence of any excerpts indicating repetition.\"]",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/Repetition/train/bg/train-bg-part_0019.parquet",
         "[None]",
         "[None]",
         "train",
         "{\"description\": \"The Repetition technique was not used in the input text as there are no repeated words, phrases, or imagery present. The expert's verdict is supported by the absence of any excerpts indicating repetition.\", \"verdict\": false}"
        ],
        [
         "35",
         "SI_interpelation_interior_1.txt",
         "1091",
         "1376",
         "SI",
         "Predlagatelji interpelacije ob tem izpostavljamo dejstvo, da je Generalna policijska uprava potrebovala kar osem mesecev za ugotavljanje nepravilnosti, potem še na zadnjih nadaljnjega pol leta, da bi jih odpravila in napake še vedno niso odpravljene. Mogoče jih bo odpravil novi vodja.",
         "False",
         "[]",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Questioning_the_Reputation",
         "Questioning_the_Reputation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Questioning the Reputation technique is not used in the input.",
         "\"\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The input text does not contain any strong negative claims aimed at undermining the reputation or moral stature of a target. It discusses the delays and inefficiencies of the Generalna policijska uprava without attacking its character or credibility, which aligns with the expert\\'s verdict that the Questioning the Reputation technique is not used.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "[\"The input text does not contain any strong negative claims aimed at undermining the reputation or moral stature of a target. It discusses the delays and inefficiencies of the Generalna policijska uprava without attacking its character or credibility, which aligns with the expert's verdict that the Questioning the Reputation technique is not used.\"]",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/si/train-si-part_0006.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text does not contain any strong negative claims aimed at undermining the reputation or moral stature of a target. It discusses the delays and inefficiencies of the Generalna policijska uprava without attacking its character or credibility, which aligns with the expert's verdict that the Questioning the Reputation technique is not used.\", \"verdict\": false}"
        ],
        [
         "36",
         "20240704_URW_BG_29.txt",
         "3835",
         "4157",
         "BG",
         "тическата подкрепа за Украйна остава приоритет за България. Със седем решения на Народното събрание предоставяме широк спектър от мерки за подпомагане на Украйна – политически, военни, хуманитарни и възстановителни. Помощта се предоставя, без да бъдат нарушавани отбранителните способности на България.\n\nСред най-важните р",
         "False",
         "[]",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Straw_Man",
         "Straw_Man",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Straw Man technique is not used in the input.",
         "\"\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The input text discusses Bulgaria\\'s support for Ukraine and outlines the measures taken without misrepresenting any opposing arguments. There is no indication of creating a distorted version of an opponent\\'s argument, which is essential for the Strawman technique to be present.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "[\"The input text discusses Bulgaria's support for Ukraine and outlines the measures taken without misrepresenting any opposing arguments. There is no indication of creating a distorted version of an opponent's argument, which is essential for the Strawman technique to be present.\"]",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Straw_Man/train/bg/train-bg-part_0004.parquet",
         "[None]",
         "[None]",
         "train",
         "{\"description\": \"The input text discusses Bulgaria's support for Ukraine and outlines the measures taken without misrepresenting any opposing arguments. There is no indication of creating a distorted version of an opponent's argument, which is essential for the Strawman technique to be present.\", \"verdict\": false}"
        ],
        [
         "37",
         "SI_interpelation_interior_8.txt",
         "0",
         "953",
         "SI",
         "No, in ker je za pravljico značilno, da ima srečo in konec, se ta zgodba nekako zaključi takole. Poslanci opozicije zoper notranjega ministra vložijo interpelacijo, ki jo seveda v Poslanski skupini Slovenske demokratske stranke podpiramo, saj bi poslušni minister moral že zdavnaj odstopiti zaradi suma oškodovanja javnih financ, zlorabe uradnega položaja, odgovornosti za številne nepravilnosti v delovanju policije, predvsem pa odgovornosti, da je policijo popeljal na dno, kateri grozi celo kolaps. Kljub temu ni storil ničesar, da bi se stanje izboljšalo. Obnaša se, kot da se policiji cedita med in mleko. Državljane in državljanke prepričuje, da živimo varno in da policija dela dobro, čeprav v resnici iz leta v leto živimo vedno bolj v strahu. Golobisti ga seveda branijo in podprejo, in ker imajo večino, še naprej ostane minister ter tako kljub velikim problemom, ki tarejo njegovo ministrstvo v teh mrzlih dneh, uživa v vroči čokoladi. Hvala.",
         "True",
         "['Exaggeration-Minimisation' 'Loaded_Language'\n 'Questioning_the_Reputation' 'Name_Calling-Labeling' 'Doubt' 'Repetition'\n 'Appeal_to_Fear-Prejudice']",
         "train",
         "['poslušni minister moral že zdavnaj odstopiti zaradi suma oškodovanja javnih financ, zlorabe uradnega položaja, odgovornosti za številne nepravilnosti v delovanju policije, predvsem pa odgovornosti, da je policijo popeljal na dno']",
         "['Golobisti']",
         "[]",
         "[]",
         "['poslušni minister']",
         "['Golobisti']",
         "[]",
         "['Kljub temu ni storil ničesar, da bi se stanje izboljšalo'\n 'Obnaša se, kot da se policiji cedita med in mleko']",
         "[]",
         "[]",
         "['da je policijo popeljal na dno, kateri grozi celo kolaps']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Državljane in državljanke prepričuje, da živimo varno in da policija dela dobro, čeprav v resnici iz leta v leto živimo vedno bolj v strahu']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Hypocrisy",
         "Appeal_to_Hypocrisy",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Appeal to Hypocrisy technique is not used in the input.",
         "\"\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The input text does not contain any explicit or implicit accusations of hypocrisy against the target. It criticizes the actions and inactions of the internal minister but does not compare them to past actions or positions of the minister or others to highlight inconsistency.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "['The input text does not contain any explicit or implicit accusations of hypocrisy against the target. It criticizes the actions and inactions of the internal minister but does not compare them to past actions or positions of the minister or others to highlight inconsistency.']",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/si/train-si-part_0003.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text does not contain any explicit or implicit accusations of hypocrisy against the target. It criticizes the actions and inactions of the internal minister but does not compare them to past actions or positions of the minister or others to highlight inconsistency.\", \"verdict\": false}"
        ],
        [
         "38",
         "pl_abortion_11_04_2024_n07.txt",
         "5027",
         "5537",
         "PL",
         "…i jak często może wydawać się to nie do\npogodzenia z innymi planami życiowymi. Stoję przed\nwami z marzeniem dla mojej córki. Marzę, by\nwyrastała w takiej Polsce, w której w trudnej sytuacji\ndoświadczy wsparcia i pomocy. Marzę, by wyrastała\nw kraju, w którym każde dziecko, obojętnie w jakich\nwarunkach się poczęło, będzie postrzegane jako\nwielki dar i wielka radość, bo w przezwyciężaniu\nwszelkich przeszkód i trudności kobieta nie będzie sama.\n(Część posłów wstaje, oklaski)\n(Poseł Grzegorz Braun: Tak jest.)",
         "True",
         "['Flag_Waving' 'Slogans' 'Appeal_to_Values' 'Repetition']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Marzę, by wyrastała w takiej Polsce' 'Marzę, by wyrastała w kraju']",
         "[]",
         "[]",
         "[]",
         "['Marzę, by wyrastała w takiej Polsce, w której w trudnej sytuacji doświadczy wsparcia i pomocy']",
         "[]",
         "[]",
         "[]",
         "[]",
         "['każde dziecko, obojętnie w jakich warunkach się poczęło, będzie postrzegane jako wielki dar i wielka radość, bo w przezwyciężaniu wszelkich przeszkód i trudności kobieta nie będzie sama']",
         "[]",
         "[]",
         "['Tak jest']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/Slogans",
         "Slogans",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "1",
         "Yes, the Slogans technique is used in the input.",
         "\"Tak jest\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The Slogans technique is used in the input text through the phrase \\'Tak jest\\', which serves as a brief and striking affirmation that encapsulates the emotional appeal of the speaker\\'s vision for a supportive society. This aligns with the definition of slogans as they often act as emotional appeals.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[\"The Slogans technique is used in the input text through the phrase 'Tak jest', which serves as a brief and striking affirmation that encapsulates the emotional appeal of the speaker's vision for a supportive society. This aligns with the definition of slogans as they often act as emotional appeals.\"]",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/Slogans/train/pl/train-pl-part_0016.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The Slogans technique is used in the input text through the phrase 'Tak jest', which serves as a brief and striking affirmation that encapsulates the emotional appeal of the speaker's vision for a supportive society. This aligns with the definition of slogans as they often act as emotional appeals.\", \"verdict\": true}"
        ],
        [
         "39",
         "RU_discrediting_the_west_11.txt",
         "1733",
         "1910",
         "RU",
         "ы, когда с фронта будем убирать сильных, а приводить медиаменеджеров и коррупционеров, ну и еще контрактников с ДЦП и шизофренией, которым даже оружия нельзя давать.\n\nЯ долго мо",
         "True",
         "['Obfuscation-Vagueness-Confusion']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Победим ли мы, когда с фронта будем убирать сильных, а приводить медиаменеджеров и коррупционеров, ну и еще контрактников с ДЦП и шизофренией, которым даже оружия нельзя давать']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/Repetition",
         "Repetition",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "0",
         "No, the Repetition technique is not used in the input.",
         "\"\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The input text does not contain any repeated words, phrases, stories, or imagery that would indicate the use of the Repetition technique. Therefore, the expert\\'s verdict is correct.\",\\n  \"updated_definition\": \"The speaker uses the same word, phrase, story, or imagery repeatedly with the hope that the repetition will lead to persuade the audience; this includes instances where the same concept is reiterated in various forms.\"\\n}']",
         "['The speaker uses the same word, phrase, story, or imagery repeatedly with the hope that the repetition will lead to persuade the audience; this includes instances where the same concept is reiterated in various forms.']",
         "[None]",
         "[None]",
         "[\"The input text does not contain any repeated words, phrases, stories, or imagery that would indicate the use of the Repetition technique. Therefore, the expert's verdict is correct.\"]",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/Repetition/train/ru/train-ru-part_0010.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text does not contain any repeated words, phrases, stories, or imagery that would indicate the use of the Repetition technique. Therefore, the expert's verdict is correct.\", \"verdict\": false}"
        ],
        [
         "40",
         "SI_interpelation_interior_7.txt",
         "5290",
         "9806",
         "SI",
         "In dodatki za nadomeščanje vodje. Netransparentno in neupravičeno se uporabljajo sredstva iz lastne dejavnosti, kjer se obnovi savno, ki je zaprta, kupi se oprema za fitnes in se nabavljajo draga oblačila za izbrance. Policija tudi ukini fizično varovanje štirim tožilcem in sodnici. To mi sporočijo sami varnostniki, ki so jih varovali, in to le nekaj ur pred prekinitvijo fizičnega varovanja. Do komunikacije o tem med vodstvom policije ali notranjega ministrstva in pravosodnega ministrstva ne pride informacija pride do pravosodne ministrice Andreje Katič, ki na to temo posreduje pri notranjem ministru Boštjanu Poklukarju. Sledi preobrat, policisti omenjene osebe, ki omenjene osebe varujejo s strani nadrejenih prejme obvestilo, da se varovanje tožilcev in sodnice nadaljuje. Ko je vodstvo CVZ dobilo dokument o znižanju stopnje varovanja, ni ukrepalo, prav tako ni ukrepal takratni nezakonit generalni direktor policije, Senad Jušić, ki bi lahko zahteval nadaljevanje fizičnega varovanja tožilcev in sodnice, a tega ni storil. Tako početje vodstva policije je nezakonito. Minister Boštjan Poklukar naroči ponovno vzpostavitev fizičnega varovanja, čeprav ministru zakonodaja ne dovoljuje, da daje generalnemu direktorju policije ukaze in navodila o tem, kako mora policija opraviti točno določeno nalogo. Taka nezakonita zahteva ima vse znake kaznivega dejanja in zlorabo uradnega položaja ali uradnih pravic. Tudi sam vodja golobistov ne zaupa varovanja policije, saj za lastno varovanje izbere svojo službo. Minister Boštjan Poklukar opravi tudi posel nakupa petih stražarskih hišic velikosti dobra dva kvadratna metra, kar davkoplačevalce stane, reci in piši, 450 tisoč evrov. Tako en kvadratni meter te hišice stane dobrih 40 tisoč evrov, kar lahko zagotovo uvrstimo med najdražjo nepremičnino v Sloveniji in še mogoče tudi širše. Za hišico se določijo materiali, ki so krepko za časom, saj so že več kot 25 let na tržišču. Materiali, ki so popolnoma prosojni, tanjši, lažji in slavijo po izjemni vzdržljivosti in optični čistosti. Z uporabo teh materialov dobimo enako ali celo boljšo zaščito, ki je pa velikokrat dosti cenejša. To bi seveda vplivalo na končno ceno, ki bi naj bila, po mnenju poznavalcev, na koncu celo za tretjino cene sedanje vrednosti. Posel dobi podjetje iz hobotnice slovenskih milijonarjev, podjetje KIK, ki je bilo še leto prej zavrnjeno zaradi previsoke cene in posledično kršenja načel gospodarnosti, učinkovitosti in uspešnosti porabe javnih sredstev. Vendar za ministra Poklukarja visoka in negospodarna cena ni ovira, čeprav je v odgovoru na pisno poslansko vprašanje našega poslanca, odgovoril, da je ravnal gospodarno. Zanimivo. Če primerjamo torej ceno mobilne hiške, ki jo lahko kupimo na tržišču v velikosti 32 m2, z vso opremo, torej kuhinjo, torej hladilniklerjem, sedežno inventuro, s kopalnico, celo školjko, tuš kabino, spalnico in tako naprej, taka hišica stane 20 tisoč evrov. S tem pa negospodarno ravnanje notranje ministra še ni konec. Po klicu partnerke vodje golobistov s strani znane radijske postaje, vodja obljubi nakup namenskih reševalnih helikopterjev in vzpostavitve baze. Ministrstvo za notranje zadeve objavi razpis za nakup dveh helikopterjev v okvirni vrednosti 50 milijonov evrov. Razpis se prilagodi za zgolj enega ponudnika, ob tem pa se zanemari ključne specifikacije, zaradi katerih naj bi omejena helikopterja sploh kupovali. Helikopterja namreč ne bosta vsebovala opreme, potrebne za reševanje in prevoz poškodovanih. Medtem pa se v razpisu zahteva opremo, ki jo za svoje delo potrebuje policija. Tako se v razpisu ne predvidi sistem za prevoz inkubatorja za novorojenčke, ne zahteva se, da ima bolniški prostor za glavo bolnika, prostor za oskrbo dihalne poti ali ventilacijo bolnika, če je v dihalni stiski, saj je v helikopterju s prešo postavljenimi nosili to nemogoče. Prav tako helikopterja ne bosta rumene barve, kot so to v tujini, kjer je rumena barva namenska prav zaradi varnosti. V razpisu se ne zahteva, da je helikopter ekonomičen, da je tih in varen, ne zahteva se zaprt repni rotor, ki je bistveno varnejši ter tišji. Tudi ne zahteva se sani namesto koles. Zahteva se pa kratek dobavni rok, saj ga kvalitetni proizvajalci ne morejo zagotavljati. Dejstvo je, da bi lahko kupili cenejše in primernejše helikopterje. Za primerjavo, v sosednji Republiki Hrvaški so za vzpostavitev vse letne helikopterske nujne medicinske pomoči v štirih bazah porabili zgolj 62,5 milijona evrov in še za to so pridobili sredstva Evropske unije.",
         "True",
         "['False_Equivalence' 'Exaggeration-Minimisation' 'Appeal_to_Hypocrisy'\n 'Loaded_Language' 'Obfuscation-Vagueness-Confusion' 'Appeal_to_Authority'\n 'Questioning_the_Reputation' 'Appeal_to_Values' 'Name_Calling-Labeling'\n 'Doubt' 'Repetition']",
         "train",
         "['Posel dobi podjetje iz hobotnice slovenskih milijonarjev, podjetje KIK, ki je bilo še leto prej zavrnjeno zaradi previsoke cene in posledično kršenja načel gospodarnosti, učinkovitosti in uspešnosti porabe javnih sredstev'\n 'Po klicu partnerke vodje golobistov s strani znane radijske postaje, vodja obljubi nakup namenskih reševalnih helikopterjev in vzpostavitve baze']",
         "['golobistov' 'golobistov']",
         "['Netransparentno in neupravičeno se uporabljajo sredstva iz lastne dejavnosti, kjer se obnovi savno, ki je zaprta, kupi se oprema za fitnes in se nabavljajo draga oblačila za izbrance'\n 'Tudi sam vodja golobistov ne zaupa varovanja policije, saj za lastno varovanje izbere svojo službo'\n 'Vendar za ministra Poklukarja visoka in negospodarna cena ni ovira, čeprav je v odgovoru na pisno poslansko vprašanje našega poslanca, odgovoril, da je ravnal gospodarno']",
         "[]",
         "['hobotnice slovenskih milijonarjev']",
         "['golobistov']",
         "[]",
         "['Minister Boštjan Poklukar naroči ponovno vzpostavitev fizičnega varovanja, čeprav ministru zakonodaja ne dovoljuje, da daje generalnemu direktorju policije ukaze in navodila o tem, kako mora policija opraviti točno določeno nalogo']",
         "[]",
         "[]",
         "['materiali, ki so krepko za časom, saj so že več kot 25 let na tržišču']",
         "[]",
         "[]",
         "[]",
         "['Netransparentno' 'Tako početje vodstva policije je nezakonito'\n 'Taka nezakonita zahteva ima vse znake kaznivega dejanja in zlorabo uradnega položaja ali uradnih pravic'\n 'Posel dobi podjetje iz hobotnice slovenskih milijonarjev, podjetje KIK, ki je bilo še leto prej zavrnjeno zaradi previsoke cene in posledično kršenja načel gospodarnosti, učinkovitosti in uspešnosti porabe javnih sredstev'\n 'prilagodi za zgolj enega ponudnika']",
         "['po mnenju poznavalcev']",
         "[]",
         "[]",
         "[]",
         "[]",
         "['po mnenju poznavalcev']",
         "[]",
         "[]",
         "['Če primerjamo torej ceno mobilne hiške, ki jo lahko kupimo na tržišču v velikosti 32 m2, z vso opremo, torej kuhinjo, torej hladilniklerjem, sedežno inventuro, s kopalnico, celo školjko, tuš kabino, spalnico in tako naprej, taka hišica stane 20 tisoč evrov']",
         "[]",
         "train",
         "GPT_41_MINI/v001/False_Equivalence",
         "False_Equivalence",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "1",
         "Yes, the False Equivalence technique is used in the input.",
         "\"Če primerjamo torej ceno mobilne hiške, ki jo lahko kupimo na tržišču v velikosti 32 m2, z vso opremo, torej kuhinjo, torej hladilniklerjem, sedežno inventuro, s kopalnico, celo školjko, tuš kabino, spalnico in tako naprej, taka hišica stane 20 tisoč evrov\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The False Equivalence technique is used in the input text when the author compares the cost of a mobile home with full amenities (20,000 euros) to the cost of a small guardhouse (450,000 euros). This comparison oversimplifies the situation by treating these two significantly different items as if they are equal in terms of value and significance, ignoring important factors such as their purpose, size, and functionality.\",\\n  \"updated_definition\": \"A technique that attempts to treat scenarios that are significantly different as if they had equal merit or significance, particularly by emphasizing one specific shared characteristic that is oversimplified or ignores important additional factors. The introduction of certain shared characteristics is used to consider them equal, often leading to misleading conclusions. This technique has the following logical form: A and B share some characteristic X. Therefore, A and B are equal, despite significant differences in other relevant aspects.\"\\n}']",
         "['A technique that attempts to treat scenarios that are significantly different as if they had equal merit or significance, particularly by emphasizing one specific shared characteristic that is oversimplified or ignores important additional factors. The introduction of certain shared characteristics is used to consider them equal, often leading to misleading conclusions. This technique has the following logical form: A and B share some characteristic X. Therefore, A and B are equal, despite significant differences in other relevant aspects.']",
         "[None]",
         "[None]",
         "['The False Equivalence technique is used in the input text when the author compares the cost of a mobile home with full amenities (20,000 euros) to the cost of a small guardhouse (450,000 euros). This comparison oversimplifies the situation by treating these two significantly different items as if they are equal in terms of value and significance, ignoring important factors such as their purpose, size, and functionality.']",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/False_Equivalence/train/si/train-si-part_0003.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The False Equivalence technique is used in the input text when the author compares the cost of a mobile home with full amenities (20,000 euros) to the cost of a small guardhouse (450,000 euros). This comparison oversimplifies the situation by treating these two significantly different items as if they are equal in terms of value and significance, ignoring important factors such as their purpose, size, and functionality.\", \"verdict\": true}"
        ],
        [
         "41",
         "20231208_URW_BG_71.txt",
         "4359",
         "4957",
         "BG",
         "Не знам вече как да говорим пред Вас! Думите, които употребяваме, са толкова силни, а се обезсмислиха от Вашето поведение. Когато започнем да говорим с аргументи, залата е празна, както и в момента. От управляващата срамна сглобка на националното предателство и на войната няма повече от 15 – 20 човека в залата. Направих си труда да отида до Секретното деловодство днес и да проверя колко човека сте прочели какво в крайна сметка ще бъде предоставено на Украйна. Четирима сте, колеги! Четирима човека са прочели какво ще се даде на Украйна (реплика от ВЪЗРАЖДАНЕ), двама са от ВЪЗРАЖДАНЕ, така е. ",
         "True",
         "['Loaded_Language' 'Questioning_the_Reputation' 'Name_Calling-Labeling'\n 'Doubt']",
         "train",
         "['Не знам вече как да говорим пред Вас!'\n 'Думите, които употребяваме, са толкова силни, а се обезсмислиха от Вашето поведение']",
         "['управляващата срамна сглобка на националното предателство и на войната']",
         "[]",
         "[]",
         "['предателство']",
         "[]",
         "[]",
         "['Когато започнем да говорим с аргументи, залата е празна, както и в момента']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Red_Herring",
         "Red_Herring",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Red Herring technique is not used in the input.",
         "\"\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The input text does not divert attention from the main topic being discussed. Instead, it focuses on the behavior of the audience and the lack of engagement regarding the issue of support for Ukraine. There are no unrelated topics introduced that would constitute a Red Herring.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "['The input text does not divert attention from the main topic being discussed. Instead, it focuses on the behavior of the audience and the lack of engagement regarding the issue of support for Ukraine. There are no unrelated topics introduced that would constitute a Red Herring.']",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Red_Herring/train/bg/train-bg-part_0001.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text does not divert attention from the main topic being discussed. Instead, it focuses on the behavior of the audience and the lack of engagement regarding the issue of support for Ukraine. There are no unrelated topics introduced that would constitute a Red Herring.\", \"verdict\": false}"
        ],
        [
         "42",
         "RU_discrediting_the_west_19.txt",
         "205",
         "556",
         "RU",
         "Вице-президент США Вэнс в своём откровенно жёстком выступлении прямо указал, что сегодняшняя Европа далеко ушла и от реальной демократии (пример обнулённой победы румынского кандидата, представителя национальных элит), и от традиционных ценностей, внедряет антихристианскую толерантность и другие, в том числе \"зелёные\" вопросы глобалистской повестки.",
         "True",
         "['Straw_Man']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Вице-президент США Вэнс в своём откровенно жёстком выступлении прямо указал, что сегодняшняя Европа далеко ушла и от реальной демократии (пример обнулённой победы румынского кандидата, представителя национальных элит), и от традиционных ценностей, внедряет антихристианскую толерантность и другие, в том числе \"зелёные\" вопросы глобалистской повестки']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Name_Calling-Labeling",
         "Name_Calling-Labeling",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Name Calling-Labeling technique is not used in the input.",
         "\"\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The input text does not contain any loaded labels directed at individuals or groups in an insulting or demeaning way. The language used is critical but does not qualify as Name Calling - Labeling since it does not focus on qualitative judgments that disregard facts or characterize subjects with manipulative wording.\",\\n  \"updated_definition\": \"Name Calling - Labeling is a form of argument in which loaded labels are directed at an individual or a group, typically in an insulting or demeaning way, focusing on qualitative judgments that disregard facts. This technique is characterized by the use of adjectives and nouns as labels that refer to personal characteristics, opinions, or associations, often in a manipulative manner. It is distinct from Loaded Language in that it solely concerns the characterization of the subject without presenting a full argument.\"\\n}']",
         "['Name Calling - Labeling is a form of argument in which loaded labels are directed at an individual or a group, typically in an insulting or demeaning way, focusing on qualitative judgments that disregard facts. This technique is characterized by the use of adjectives and nouns as labels that refer to personal characteristics, opinions, or associations, often in a manipulative manner. It is distinct from Loaded Language in that it solely concerns the characterization of the subject without presenting a full argument.']",
         "[None]",
         "[None]",
         "['The input text does not contain any loaded labels directed at individuals or groups in an insulting or demeaning way. The language used is critical but does not qualify as Name Calling - Labeling since it does not focus on qualitative judgments that disregard facts or characterize subjects with manipulative wording.']",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Name_Calling-Labeling/train/ru/train-ru-part_0007.parquet",
         "[None]",
         "[None]",
         "train",
         "{\"description\": \"The input text does not contain any loaded labels directed at individuals or groups in an insulting or demeaning way. The language used is critical but does not qualify as Name Calling - Labeling since it does not focus on qualitative judgments that disregard facts or characterize subjects with manipulative wording.\", \"verdict\": false}"
        ],
        [
         "43",
         "RU_demography_1.txt",
         "299",
         "564",
         "RU",
         "Всё по схеме «отрицание, гнев, торг, депрессия, принятие». Есть очень субъективное ощущение, что сейчас наше общество где-то между гневом и депрессией. Принятие ещё не наступило, и это даёт надежду, что для русских ещё не всё кончено. Жёстко? Возможно. Но правдиво.",
         "True",
         "['Conversation_Killer']",
         "train",
         "[]",
         "[]",
         "[]",
         "['Всё по схеме «отрицание, гнев, торг, депрессия, принятие»']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/Obfuscation-Vagueness-Confusion",
         "Obfuscation-Vagueness-Confusion",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "0",
         "No, the Obfuscation-Vagueness-Confusion technique is not used in the input.",
         "\"\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The input text presents a clear sequence of emotions and a subjective observation about society\\'s current state. There are no deliberately unclear or vague phrases that would allow for multiple interpretations, thus the Obfuscation, Intentional Vagueness, Confusion technique is not present.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "[\"The input text presents a clear sequence of emotions and a subjective observation about society's current state. There are no deliberately unclear or vague phrases that would allow for multiple interpretations, thus the Obfuscation, Intentional Vagueness, Confusion technique is not present.\"]",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/Obfuscation-Vagueness-Confusion/train/ru/train-ru-part_0010.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text presents a clear sequence of emotions and a subjective observation about society's current state. There are no deliberately unclear or vague phrases that would allow for multiple interpretations, thus the Obfuscation, Intentional Vagueness, Confusion technique is not present.\", \"verdict\": false}"
        ],
        [
         "44",
         "RU_demography_2.txt",
         "0",
         "280",
         "RU",
         "Сегодняшнюю ситуацию с рождаемостью специалисты называют \"демографическая зима\". В условиях специальной военной операции и других серьёзных геополитических вызовов, на которые вынуждена отвечать наша страна, вопрос повышения рождаемости становится стратегическим и принципиальным.",
         "True",
         "['Exaggeration-Minimisation']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['вопрос повышения рождаемости становится стратегическим и принципиальным']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Name_Calling-Labeling",
         "Name_Calling-Labeling",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Name Calling-Labeling technique is not used in the input.",
         "\"\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The input text does not employ the Name Calling - Labeling technique as it does not direct loaded labels at individuals or groups in an insulting or demeaning way. The term \\'демографическая зима\\' is used descriptively to characterize a situation rather than to insult or demean a group.\",\\n  \"updated_definition\": \"Name Calling - Labeling technique is a form of argument in which loaded labels are directed at an individual or a group, typically in an insulting or demeaning way, and is characterized by qualitative judgments that disregard facts. This technique focuses solely on the essence of the subject being characterized, often using adjectives and nouns as labels that refer to personal characteristics, opinions, or associations, and is distinct from Loaded Language in that it does not present a full argument.\"\\n}']",
         "['Name Calling - Labeling technique is a form of argument in which loaded labels are directed at an individual or a group, typically in an insulting or demeaning way, and is characterized by qualitative judgments that disregard facts. This technique focuses solely on the essence of the subject being characterized, often using adjectives and nouns as labels that refer to personal characteristics, opinions, or associations, and is distinct from Loaded Language in that it does not present a full argument.']",
         "[None]",
         "[None]",
         "[\"The input text does not employ the Name Calling - Labeling technique as it does not direct loaded labels at individuals or groups in an insulting or demeaning way. The term 'демографическая зима' is used descriptively to characterize a situation rather than to insult or demean a group.\"]",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Name_Calling-Labeling/train/ru/train-ru-part_0009.parquet",
         "[None]",
         "[None]",
         "train",
         "{\"description\": \"The input text does not employ the Name Calling - Labeling technique as it does not direct loaded labels at individuals or groups in an insulting or demeaning way. The term '\\u0434\\u0435\\u043c\\u043e\\u0433\\u0440\\u0430\\u0444\\u0438\\u0447\\u0435\\u0441\\u043a\\u0430\\u044f \\u0437\\u0438\\u043c\\u0430' is used descriptively to characterize a situation rather than to insult or demean a group.\", \"verdict\": false}"
        ],
        [
         "45",
         "20231208_URW_BG_72.txt",
         "0",
         "890",
         "BG",
         "БОРИСЛАВ ГУЦАНОВ: Той наистина е предател и наистина в това Народно събрание трябва да влезе единствено и само с оставката си, или да бъде арестуван тук в залата на Народното събрание за национално предателство. (Реплика: „И това ще стане.“) И аз съм сигурен, че и това ще стане, но въпросът е кога ще стане, защото има голяма разлика. (Реплика от народния представител Георги Свиленски.) Няма по-голяма ценност от мира, няма по-голямо достойнство и по-важно нещо от живота на всеки един човек, защото той е един-единствен и уникален. С Вашите действия, откакто сте на власт, Вие правите всичко възможно България да влезе в този конфликт. И още по-подробно ще го говорим по следващата точка това, което вършите, защото Вие наистина сте правителството на войната, сглобката на войната, мнозинството на войната с всичките тези действия, които ги правите, с всички тези решения, които взимате.",
         "True",
         "['Appeal_to_Time' 'Questioning_the_Reputation' 'Appeal_to_Values'\n 'Name_Calling-Labeling' 'False_Dilemma-No_Choice' 'Repetition']",
         "train",
         "['Той наистина е предател и наистина в това Народно събрание трябва да влезе единствено и само с оставката си, или да бъде арестуван тук в залата на Народното събрание за национално предателство'\n 'С Вашите действия, откакто сте на власт, Вие правите всичко възможно България да влезе в този конфликт'\n 'И още по-подробно ще го говорим по следващата точка това, което вършите, защото Вие наистина сте правителството на войната, сглобката на войната, мнозинството на войната с всичките тези действия, които ги правите, с всички тези решения, които взимате']",
         "['предател'\n 'правителството на войната, сглобката на войната, мнозинството на войната']",
         "[]",
         "[]",
         "[]",
         "['войната' 'войната' 'войната']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['И аз съм сигурен, че и това ще стане, но въпросът е кога ще стане, защото има голяма разлика']",
         "['Няма по-голяма ценност от мира, няма по-голямо достойнство и по-важно нещо от живота на всеки един човек, защото той е един-единствен и уникален']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['трябва да влезе единствено и само с оставката си, или да бъде арестуван тук в залата на Народното събрание за национално предателство']",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Red_Herring",
         "Red_Herring",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Red Herring technique is not used in the input.",
         "\"\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The input text does not contain any diversion from the main topic being discussed. The speaker remains focused on the actions of the government and their implications for peace and conflict, without introducing unrelated topics. Therefore, the Red Herring technique is not present.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "['The input text does not contain any diversion from the main topic being discussed. The speaker remains focused on the actions of the government and their implications for peace and conflict, without introducing unrelated topics. Therefore, the Red Herring technique is not present.']",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Red_Herring/train/bg/train-bg-part_0006.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text does not contain any diversion from the main topic being discussed. The speaker remains focused on the actions of the government and their implications for peace and conflict, without introducing unrelated topics. Therefore, the Red Herring technique is not present.\", \"verdict\": false}"
        ],
        [
         "46",
         "RU_discrediting_the_west_2.txt",
         "422",
         "533",
         "RU",
         "Выступающие против принятия закона действуют однозначно в интересах другого государства, не своей страны точно.",
         "False",
         "[]",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Red_Herring",
         "Red_Herring",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Red Herring technique is not used in the input.",
         "\"\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The input text does not divert attention from the main topic. It directly addresses the stance of those opposing the law, without introducing an unrelated topic.\",\\n  \"updated_definition\": \"This technique consists in diverting the attention of the audience from the main topic being discussed by introducing another unrelated topic or issue. The aim is to redirect the argument to something the person doing the redirecting can better respond to or to leave the original topic unaddressed.\"\\n}']",
         "['This technique consists in diverting the attention of the audience from the main topic being discussed by introducing another unrelated topic or issue. The aim is to redirect the argument to something the person doing the redirecting can better respond to or to leave the original topic unaddressed.']",
         "[None]",
         "[None]",
         "['The input text does not divert attention from the main topic. It directly addresses the stance of those opposing the law, without introducing an unrelated topic.']",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Red_Herring/train/ru/train-ru-part_0008.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text does not divert attention from the main topic. It directly addresses the stance of those opposing the law, without introducing an unrelated topic.\", \"verdict\": false}"
        ],
        [
         "47",
         "RU_discrediting_the_west_5.txt",
         "1081",
         "1290",
         "RU",
         "Отказ администрации «Твиттера» соблюдать законодательство стран и удалять противоправный контент, в том числе экстремистского характера, ранее тоже не становился объектом критики со стороны европейских столиц.",
         "True",
         "['Appeal_to_Hypocrisy']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/Loaded_Language",
         "Loaded_Language",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "0",
         "No, the Loaded Language technique is not used in the input.",
         "\"\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The input text does not contain any specific words or phrases with strong emotional implications that would influence or convince the audience. It presents a factual statement without the use of Loaded Language.\",\\n  \"updated_definition\": \"Loaded Language technique involves the use of specific words and phrases with strong emotional implications (either positive or negative) to influence and convince the audience that an argument is valid, often through emotionally charged language that evokes a strong response. It is also known as Appeal to Argument from Emotive Language.\"\\n}']",
         "['Loaded Language technique involves the use of specific words and phrases with strong emotional implications (either positive or negative) to influence and convince the audience that an argument is valid, often through emotionally charged language that evokes a strong response. It is also known as Appeal to Argument from Emotive Language.']",
         "[None]",
         "[None]",
         "['The input text does not contain any specific words or phrases with strong emotional implications that would influence or convince the audience. It presents a factual statement without the use of Loaded Language.']",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/Loaded_Language/train/ru/train-ru-part_0006.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text does not contain any specific words or phrases with strong emotional implications that would influence or convince the audience. It presents a factual statement without the use of Loaded Language.\", \"verdict\": false}"
        ],
        [
         "48",
         "pl_defence_22_05_2024_n01.txt",
         "4288",
         "4362",
         "PL",
         "(Poseł Barbara Bartuś: Skandal.)\nCzy to nie jest skandal? To jest skandal.",
         "True",
         "['Loaded_Language' 'Repetition']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Skandal']",
         "['Czy to nie jest skandal?' 'To jest skandal']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Name_Calling-Labeling",
         "Name_Calling-Labeling",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Name Calling-Labeling technique is not used in the input.",
         "\"\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The input text does not contain any loaded labels directed at an individual or group in an insulting or demeaning way. The term \\'skandal\\' is used as a general expression of disapproval rather than a label aimed at characterizing a person or group negatively.\",\\n  \"updated_definition\": \"Name Calling - Labeling is a form of argument in which loaded labels are directed at an individual or a group, typically in an insulting or demeaning way, focusing on qualitative judgments that disregard facts. This technique involves using adjectives and nouns as labels that refer to personal characteristics, opinions, or associations, and is distinct from Loaded Language as it solely characterizes the subject without providing a full argument.\"\\n}']",
         "['Name Calling - Labeling is a form of argument in which loaded labels are directed at an individual or a group, typically in an insulting or demeaning way, focusing on qualitative judgments that disregard facts. This technique involves using adjectives and nouns as labels that refer to personal characteristics, opinions, or associations, and is distinct from Loaded Language as it solely characterizes the subject without providing a full argument.']",
         "[None]",
         "[None]",
         "[\"The input text does not contain any loaded labels directed at an individual or group in an insulting or demeaning way. The term 'skandal' is used as a general expression of disapproval rather than a label aimed at characterizing a person or group negatively.\"]",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Name_Calling-Labeling/train/pl/train-pl-part_0015.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text does not contain any loaded labels directed at an individual or group in an insulting or demeaning way. The term 'skandal' is used as a general expression of disapproval rather than a label aimed at characterizing a person or group negatively.\", \"verdict\": false}"
        ],
        [
         "49",
         "SI_interpelation_interior_6.txt",
         "177",
         "268",
         "SI",
         "Hvala spoštovana predsednica za besedo. Lep pozdrav predstavniki Vlade, kolegi in kolegice.",
         "False",
         "[]",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Questioning_the_Reputation",
         "Questioning_the_Reputation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Questioning the Reputation technique is not used in the input.",
         "\"\"",
         "[None]",
         "[False]",
         "['{\\n  \"explanation\": \"The input text does not contain any elements that attack the reputation of a target or make negative claims about it. It is a neutral greeting without any indication of undermining character or moral stature.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/si/train-si-part_0007.parquet",
         null,
         null,
         "train",
         "{\"description\": null, \"verdict\": false}"
        ]
       ],
       "shape": {
        "columns": 60,
        "rows": 2805
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>text_lang</th>\n",
       "      <th>text</th>\n",
       "      <th>label_bin</th>\n",
       "      <th>label_multi</th>\n",
       "      <th>base_split</th>\n",
       "      <th>Questioning_the_Reputation</th>\n",
       "      <th>Name_Calling-Labeling</th>\n",
       "      <th>...</th>\n",
       "      <th>updated_definition</th>\n",
       "      <th>think_content</th>\n",
       "      <th>illegal_value</th>\n",
       "      <th>explanation</th>\n",
       "      <th>extra_content</th>\n",
       "      <th>source_file</th>\n",
       "      <th>error</th>\n",
       "      <th>status</th>\n",
       "      <th>split</th>\n",
       "      <th>expected_output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20240229_URW_BG_67.txt</td>\n",
       "      <td>4561</td>\n",
       "      <td>5284</td>\n",
       "      <td>BG</td>\n",
       "      <td>ХРИСТО ГАДЖЕВ (ГЕРБ-СДС): Уважаеми господин Пр...</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>train</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[The input text does not contain any elements ...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41/v001...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "      <td>{\"description\": \"The input text does not conta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20240704_URW_BG_28.txt</td>\n",
       "      <td>8169</td>\n",
       "      <td>8224</td>\n",
       "      <td>BG</td>\n",
       "      <td>.\\n\\nВИКТОРИЯ ВАСИЛЕВА (ВЕЛИЧИЕ): Благодаря Ви...</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>train</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[The input text does not contain any elements ...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41/v001...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>train</td>\n",
       "      <td>{\"description\": \"The input text does not conta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pl_abortion_11_04_2024_n04.txt</td>\n",
       "      <td>5601</td>\n",
       "      <td>6150</td>\n",
       "      <td>PL</td>\n",
       "      <td>Dzisiaj prezentujemy też ustawę, która odwraca...</td>\n",
       "      <td>True</td>\n",
       "      <td>[Conversation_Killer, Appeal_to_Pity, Slogans,...</td>\n",
       "      <td>train</td>\n",
       "      <td>[]</td>\n",
       "      <td>[bulwersujący wyrok]</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[The input text does not employ the Consequent...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41_MINI...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "      <td>{\"description\": \"The input text does not emplo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pl_eu_12_06_2024_n01.txt</td>\n",
       "      <td>4530</td>\n",
       "      <td>5548</td>\n",
       "      <td>PL</td>\n",
       "      <td>Natomiast to, co jest kłopotem przedłożonego p...</td>\n",
       "      <td>True</td>\n",
       "      <td>[Doubt]</td>\n",
       "      <td>train</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[The input text discusses concerns about a leg...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41/v001...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "      <td>{\"description\": \"The input text discusses conc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pl_defence_22_05_2024_n02.txt</td>\n",
       "      <td>1232</td>\n",
       "      <td>1679</td>\n",
       "      <td>PL</td>\n",
       "      <td>Produkujemy śladowe ilości amunicji, 30 tys. s...</td>\n",
       "      <td>True</td>\n",
       "      <td>[Causal_Oversimplification, Red_Herring]</td>\n",
       "      <td>train</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[The input text does not employ the Consequent...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41_MINI...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "      <td>{\"description\": \"The input text does not emplo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2800</th>\n",
       "      <td>SI_interpelation_interior_2.txt</td>\n",
       "      <td>5949</td>\n",
       "      <td>8216</td>\n",
       "      <td>SI</td>\n",
       "      <td>Pred skoraj dvema letoma, natančneje 21. febru...</td>\n",
       "      <td>True</td>\n",
       "      <td>[Repetition]</td>\n",
       "      <td>train</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[The input text does not employ the Casting Do...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41/v001...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "      <td>{\"description\": \"The input text does not emplo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2801</th>\n",
       "      <td>SI_interpelation_interior_0.txt</td>\n",
       "      <td>988</td>\n",
       "      <td>1003</td>\n",
       "      <td>SI</td>\n",
       "      <td>Najlepša hvala.</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>train</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[The input text does not contain any elements ...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41/v001...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "      <td>{\"description\": \"The input text does not conta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2802</th>\n",
       "      <td>RU_discrediting_the_west_4.txt</td>\n",
       "      <td>244</td>\n",
       "      <td>418</td>\n",
       "      <td>RU</td>\n",
       "      <td>А там намечается самая радикальная перестройка...</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>train</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[The input text discusses a significant restru...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41/v001...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "      <td>{\"description\": \"The input text discusses a si...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2803</th>\n",
       "      <td>SI_interpelation_interior_7.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>274</td>\n",
       "      <td>SI</td>\n",
       "      <td>Zanimivo ob tem dejstvu je, da se pa na jugovz...</td>\n",
       "      <td>True</td>\n",
       "      <td>[Causal_Oversimplification, Appeal_to_Fear-Pre...</td>\n",
       "      <td>train</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[The Appeal to Time technique is not used in t...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41_MINI...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "      <td>{\"description\": \"The Appeal to Time technique ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2804</th>\n",
       "      <td>20231208_URW_BG_71.txt</td>\n",
       "      <td>973</td>\n",
       "      <td>1687</td>\n",
       "      <td>BG</td>\n",
       "      <td>Идеята да отхвърлим ветото на президента е кра...</td>\n",
       "      <td>True</td>\n",
       "      <td>[Exaggeration-Minimisation, Flag_Waving, Quest...</td>\n",
       "      <td>train</td>\n",
       "      <td>[Нямам съмнение, че евро-атлантическото мнозин...</td>\n",
       "      <td>[евро-атлантическото мнозинство]</td>\n",
       "      <td>...</td>\n",
       "      <td>[Name Calling - Labeling is a form of argument...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[The Name Calling - Labeling technique is used...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41/v001...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "      <td>{\"description\": \"The Name Calling - Labeling t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2805 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             filename  start   end text_lang  \\\n",
       "0              20240229_URW_BG_67.txt   4561  5284        BG   \n",
       "1              20240704_URW_BG_28.txt   8169  8224        BG   \n",
       "2      pl_abortion_11_04_2024_n04.txt   5601  6150        PL   \n",
       "3            pl_eu_12_06_2024_n01.txt   4530  5548        PL   \n",
       "4       pl_defence_22_05_2024_n02.txt   1232  1679        PL   \n",
       "...                               ...    ...   ...       ...   \n",
       "2800  SI_interpelation_interior_2.txt   5949  8216        SI   \n",
       "2801  SI_interpelation_interior_0.txt    988  1003        SI   \n",
       "2802   RU_discrediting_the_west_4.txt    244   418        RU   \n",
       "2803  SI_interpelation_interior_7.txt      0   274        SI   \n",
       "2804           20231208_URW_BG_71.txt    973  1687        BG   \n",
       "\n",
       "                                                   text  label_bin  \\\n",
       "0     ХРИСТО ГАДЖЕВ (ГЕРБ-СДС): Уважаеми господин Пр...      False   \n",
       "1     .\\n\\nВИКТОРИЯ ВАСИЛЕВА (ВЕЛИЧИЕ): Благодаря Ви...      False   \n",
       "2     Dzisiaj prezentujemy też ustawę, która odwraca...       True   \n",
       "3     Natomiast to, co jest kłopotem przedłożonego p...       True   \n",
       "4     Produkujemy śladowe ilości amunicji, 30 tys. s...       True   \n",
       "...                                                 ...        ...   \n",
       "2800  Pred skoraj dvema letoma, natančneje 21. febru...       True   \n",
       "2801                                    Najlepša hvala.      False   \n",
       "2802  А там намечается самая радикальная перестройка...      False   \n",
       "2803  Zanimivo ob tem dejstvu je, da se pa na jugovz...       True   \n",
       "2804  Идеята да отхвърлим ветото на президента е кра...       True   \n",
       "\n",
       "                                            label_multi base_split  \\\n",
       "0                                                    []      train   \n",
       "1                                                    []      train   \n",
       "2     [Conversation_Killer, Appeal_to_Pity, Slogans,...      train   \n",
       "3                                               [Doubt]      train   \n",
       "4              [Causal_Oversimplification, Red_Herring]      train   \n",
       "...                                                 ...        ...   \n",
       "2800                                       [Repetition]      train   \n",
       "2801                                                 []      train   \n",
       "2802                                                 []      train   \n",
       "2803  [Causal_Oversimplification, Appeal_to_Fear-Pre...      train   \n",
       "2804  [Exaggeration-Minimisation, Flag_Waving, Quest...      train   \n",
       "\n",
       "                             Questioning_the_Reputation  \\\n",
       "0                                                    []   \n",
       "1                                                    []   \n",
       "2                                                    []   \n",
       "3                                                    []   \n",
       "4                                                    []   \n",
       "...                                                 ...   \n",
       "2800                                                 []   \n",
       "2801                                                 []   \n",
       "2802                                                 []   \n",
       "2803                                                 []   \n",
       "2804  [Нямам съмнение, че евро-атлантическото мнозин...   \n",
       "\n",
       "                 Name_Calling-Labeling  ...  \\\n",
       "0                                   []  ...   \n",
       "1                                   []  ...   \n",
       "2                 [bulwersujący wyrok]  ...   \n",
       "3                                   []  ...   \n",
       "4                                   []  ...   \n",
       "...                                ...  ...   \n",
       "2800                                []  ...   \n",
       "2801                                []  ...   \n",
       "2802                                []  ...   \n",
       "2803                                []  ...   \n",
       "2804  [евро-атлантическото мнозинство]  ...   \n",
       "\n",
       "                                     updated_definition think_content  \\\n",
       "0                                                    []        [None]   \n",
       "1                                                [None]        [None]   \n",
       "2                                                    []        [None]   \n",
       "3                                                    []        [None]   \n",
       "4                                                [None]        [None]   \n",
       "...                                                 ...           ...   \n",
       "2800                                                 []        [None]   \n",
       "2801                                                 []        [None]   \n",
       "2802                                                 []        [None]   \n",
       "2803                                             [None]        [None]   \n",
       "2804  [Name Calling - Labeling is a form of argument...        [None]   \n",
       "\n",
       "     illegal_value                                        explanation  \\\n",
       "0           [None]  [The input text does not contain any elements ...   \n",
       "1           [None]  [The input text does not contain any elements ...   \n",
       "2           [None]  [The input text does not employ the Consequent...   \n",
       "3           [None]  [The input text discusses concerns about a leg...   \n",
       "4           [None]  [The input text does not employ the Consequent...   \n",
       "...            ...                                                ...   \n",
       "2800        [None]  [The input text does not employ the Casting Do...   \n",
       "2801        [None]  [The input text does not contain any elements ...   \n",
       "2802        [None]  [The input text discusses a significant restru...   \n",
       "2803        [None]  [The Appeal to Time technique is not used in t...   \n",
       "2804        [None]  [The Name Calling - Labeling technique is used...   \n",
       "\n",
       "     extra_content                                        source_file   error  \\\n",
       "0           [None]  data/llm_output/persuasion/explain/GPT_41/v001...     NaN   \n",
       "1           [None]  data/llm_output/persuasion/explain/GPT_41/v001...  [None]   \n",
       "2           [None]  data/llm_output/persuasion/explain/GPT_41_MINI...     NaN   \n",
       "3           [None]  data/llm_output/persuasion/explain/GPT_41/v001...     NaN   \n",
       "4           [None]  data/llm_output/persuasion/explain/GPT_41_MINI...     NaN   \n",
       "...            ...                                                ...     ...   \n",
       "2800        [None]  data/llm_output/persuasion/explain/GPT_41/v001...     NaN   \n",
       "2801        [None]  data/llm_output/persuasion/explain/GPT_41/v001...     NaN   \n",
       "2802        [None]  data/llm_output/persuasion/explain/GPT_41/v001...     NaN   \n",
       "2803        [None]  data/llm_output/persuasion/explain/GPT_41_MINI...     NaN   \n",
       "2804        [None]  data/llm_output/persuasion/explain/GPT_41/v001...     NaN   \n",
       "\n",
       "      status  split                                    expected_output  \n",
       "0        NaN  train  {\"description\": \"The input text does not conta...  \n",
       "1     [None]  train  {\"description\": \"The input text does not conta...  \n",
       "2        NaN  train  {\"description\": \"The input text does not emplo...  \n",
       "3        NaN  train  {\"description\": \"The input text discusses conc...  \n",
       "4        NaN  train  {\"description\": \"The input text does not emplo...  \n",
       "...      ...    ...                                                ...  \n",
       "2800     NaN  train  {\"description\": \"The input text does not emplo...  \n",
       "2801     NaN  train  {\"description\": \"The input text does not conta...  \n",
       "2802     NaN  train  {\"description\": \"The input text discusses a si...  \n",
       "2803     NaN  train  {\"description\": \"The Appeal to Time technique ...  \n",
       "2804     NaN  train  {\"description\": \"The Name Calling - Labeling t...  \n",
       "\n",
       "[2805 rows x 60 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assume your DataFrame is called df\n",
    "label_1 = clean[clean['gold'] == 1]\n",
    "\n",
    "# Count how many label==1 per category\n",
    "counts = label_1['prompt_name'].value_counts()\n",
    "\n",
    "# For label == 0, sample same number of rows per category\n",
    "label_0_samples = (\n",
    "    df[df['gold'] == 0]\n",
    "    .groupby('prompt_name', group_keys=False)\n",
    "    .apply(lambda x: x.sample(n=2*counts.get(x.name, 0)))\n",
    ")\n",
    "\n",
    "# Combine both\n",
    "balanced_df21 = pd.concat([label_1, label_0_samples])\n",
    "balanced_df21 = balanced_df21.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "balanced_df21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3f266253",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lp/5z8ys0rj1q960h2656xp8c680000gn/T/ipykernel_49770/294674448.py:11: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda x: x.sample(n=1*counts.get(x.name, 0)))\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "filename",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "start",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "end",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "text_lang",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "text",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "label_bin",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "label_multi",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "base_split",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Questioning_the_Reputation",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Name_Calling-Labeling",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Appeal_to_Hypocrisy",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Conversation_Killer",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Loaded_Language",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Repetition",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Appeal_to_Popularity",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Doubt",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Red_Herring",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Flag_Waving",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Exaggeration-Minimisation",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Consequential_Oversimplification",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Appeal_to_Pity",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Appeal_to_Time",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Appeal_to_Values",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Obfuscation-Vagueness-Confusion",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Straw_Man",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Slogans",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Appeal_to_Fear-Prejudice",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Causal_Oversimplification",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Appeal_to_Authority",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "False_Dilemma-No_Choice",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Whataboutism",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "False_Equivalence",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Guilt_by_Association",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "alt_split",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "output_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "prompt_name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "prompt_version",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "job",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "step",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "max_iterations",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "temperature",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "model_provider",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "model_name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "model_mode",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "gold",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "gold_text",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "spans",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "extra_properties",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "is_valid",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "raw",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "updated_definition",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "think_content",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "illegal_value",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "explanation",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "extra_content",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "source_file",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "error",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "status",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "split",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "expected_output",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "a71b9c31-6eb7-4d27-82da-608550485fcf",
       "rows": [
        [
         "0",
         "RU_discrediting_the_west_11.txt",
         "0",
         "125",
         "RU",
         "Генерала Попова отправили в СИЗО, уволили без его ведома из ВС РФ, пока он находился под домашним арестом и велось следствие.",
         "False",
         "[]",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Questioning_the_Reputation",
         "Questioning_the_Reputation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Questioning the Reputation technique is not used in the input.",
         "\"\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The input text does not contain any strong negative claims aimed at undermining the character or moral stature of General Popov. It merely states factual information about his situation without attacking his reputation.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "['The input text does not contain any strong negative claims aimed at undermining the character or moral stature of General Popov. It merely states factual information about his situation without attacking his reputation.']",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/ru/train-ru-part_0001.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text does not contain any strong negative claims aimed at undermining the character or moral stature of General Popov. It merely states factual information about his situation without attacking his reputation.\", \"verdict\": false}"
        ],
        [
         "1",
         "RU_migrants_5.txt",
         "354",
         "574",
         "RU",
         "йчас Каменск-Уральск во всех сводках новостей. Группа парней похитила двух девушек, привезли их на автомойку избивали, обливали пеной и ледяной водой, унижали. Как я понимаю, жертвы - русские девочки, истязатели - нет.\n\n",
         "True",
         "['Appeal_to_Fear-Prejudice']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Как я понимаю, жертвы - русские девочки, истязатели - нет']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/Loaded_Language",
         "Loaded_Language",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "0",
         "No, the Loaded Language technique is not used in the input.",
         "\"\"",
         "[None]",
         "[ True]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/Loaded_Language/train/ru/train-ru-part_0004.parquet",
         "[{'code': 'content_filter', 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'detected': False, 'filtered': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}, 'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'param': 'prompt', 'status': 400.0, 'type': None}]",
         "['no validation']",
         "train",
         "{\"description\": null, \"verdict\": false}"
        ],
        [
         "2",
         "pl_abortion_11_04_2024_n05.txt",
         "4987",
         "5641",
         "PL",
         "I jeszcze słowo o hipokrytach i hipokryzji.\nTwierdzenie, że zakaz aborcji rozwiązuje problem\nniechcianych ciąż to jak wyrzucenie nieopłaconego rachunku\ndo kosza na śmieci, co ma sprawić, że zniknie zobowiązanie.\nAlbo kiedy zamkniemy oczy i myślimy, że\nstaliśmy się niewidzialni. Można też uznać, że woda\nw kranie nie jest mokra, można też mówić, że Kopernik się\nmylił i że to jednak Słońce kręci się wokół\nZiemi. Jednak faktów to zmieni – aborcja była, jest\ni będzie, podziemie aborcyjne było, jest i będzie.\nTylko hipokryci zamykają oczy i udają, że aborcji nie ma.\nTylko hipokryci myślą, że zakazy i nakazy sprawią,\nże aborcji nie będzie. Aborcja jest.",
         "True",
         "['Conversation_Killer' 'Straw_Man' 'Repetition']",
         "train",
         "[]",
         "[]",
         "[]",
         "['aborcja była, jest i będzie, podziemie aborcyjne było, jest i będzie'\n 'Tylko hipokryci zamykają oczy i udają, że aborcji nie ma. Tylko hipokryci myślą, że zakazy i nakazy sprawią, że aborcji nie będzie. Aborcja jest']",
         "[]",
         "['aborcja była, jest i będzie' 'podziemie aborcyjne było, jest i będzie'\n 'Tylko hipokryci zamykają oczy i udają, że aborcji nie ma'\n 'Tylko hipokryci myślą, że zakazy i nakazy sprawią, że aborcji nie będzie']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['to jak wyrzucenie nieopłaconego rachunku do kosza na śmieci, co ma sprawić, że zniknie zobowiązanie. Albo kiedy zamkniemy oczy i myślimy, że staliśmy się niewidzialni. Można też uznać, że woda w kranie nie jest mokra, można też mówić, że Kopernik się mylił i że to jednak Słońce kręci się wokół Ziemi']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Straw_Man",
         "Straw_Man",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "1",
         "Yes, the Straw Man technique is used in the input.",
         "\"to jak wyrzucenie nieopłaconego rachunku do kosza na śmieci, co ma sprawić, że zniknie zobowiązanie. Albo kiedy zamkniemy oczy i myślimy, że staliśmy się niewidzialni. Można też uznać, że woda w kranie nie jest mokra, można też mówić, że Kopernik się mylił i że to jednak Słońce kręci się wokół Ziemi\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The Strawman technique is used in the input text by misrepresenting the argument that banning abortion solves the problem of unwanted pregnancies. The author creates exaggerated analogies, such as comparing the ban to throwing away an unpaid bill, which distorts the original argument and makes it easier to refute. This misrepresentation suggests that those in favor of the ban are naive or hypocritical, rather than addressing their actual reasoning.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "['The Strawman technique is used in the input text by misrepresenting the argument that banning abortion solves the problem of unwanted pregnancies. The author creates exaggerated analogies, such as comparing the ban to throwing away an unpaid bill, which distorts the original argument and makes it easier to refute. This misrepresentation suggests that those in favor of the ban are naive or hypocritical, rather than addressing their actual reasoning.']",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Straw_Man/train/pl/train-pl-part_0016.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The Strawman technique is used in the input text by misrepresenting the argument that banning abortion solves the problem of unwanted pregnancies. The author creates exaggerated analogies, such as comparing the ban to throwing away an unpaid bill, which distorts the original argument and makes it easier to refute. This misrepresentation suggests that those in favor of the ban are naive or hypocritical, rather than addressing their actual reasoning.\", \"verdict\": true}"
        ],
        [
         "3",
         "RU_URW_4.txt",
         "753",
         "934",
         "RU",
         "Как видим, от администрации Трампа тоже не слышно слов возмущения по поводу атаки на нашу нефтебазу, молчит Европа, молчат все. Но как только Россия ответит, то молчание закончится.",
         "True",
         "['Causal_Oversimplification' 'Appeal_to_Authority']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Как видим, от администрации Трампа тоже не слышно слов возмущения по поводу атаки на нашу нефтебазу, молчит Европа, молчат все']",
         "['Но как только Россия ответит, то молчание закончится']",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/Causal_Oversimplification",
         "Causal_Oversimplification",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "1",
         "Yes, the Causal Oversimplification technique is used in the input.",
         "\"Как видим, от администрации Трампа тоже не слышно слов возмущения по поводу атаки на нашу нефтебазу, молчит Европа, молчат все\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"Causal Oversimplification is used in the input text by implying that the lack of response from the Trump administration and Europe is solely due to their indifference to the attack on the oil base, without considering other possible reasons for their silence. This aligns with the definition, as it assumes a single cause (indifference) for the observed effect (silence) when there may be multiple factors at play.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "['Causal Oversimplification is used in the input text by implying that the lack of response from the Trump administration and Europe is solely due to their indifference to the attack on the oil base, without considering other possible reasons for their silence. This aligns with the definition, as it assumes a single cause (indifference) for the observed effect (silence) when there may be multiple factors at play.']",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/Causal_Oversimplification/train/ru/train-ru-part_0000.parquet",
         "[None]",
         "[None]",
         "train",
         "{\"description\": \"Causal Oversimplification is used in the input text by implying that the lack of response from the Trump administration and Europe is solely due to their indifference to the attack on the oil base, without considering other possible reasons for their silence. This aligns with the definition, as it assumes a single cause (indifference) for the observed effect (silence) when there may be multiple factors at play.\", \"verdict\": true}"
        ],
        [
         "4",
         "pl_abortion_11_04_2024_n05.txt",
         "9681",
         "10556",
         "PL",
         "Dziś jesteśmy w demograficznym kryzysie. Polki\nnie chcą rodzić dzieci w Polsce, która nie jest dla nich\nbezpieczna pod żadnym względem. Mówią: boję się\nbyć w ciąży, bo dziewczyny w moim wieku umierają.\nUmarły pan Iza, pani Agnieszka, pani Marta, pani\nDorota. Dlatego Koalicja Obywatelska przygotowała\ni przedstawia projekt ustawy o świadomym rodzicielstwie.\nZakaz aborcji w Polsce to restrykcyjne prawo,\nktóre zagraża zdrowiu, życiu i bezpieczeństwu kobiet,\na nasz projekt, projekt Koalicji Obywatelskiej,\nprzywraca kobietom wolność wyboru, przywraca kobietom\ngodność, przywraca kobietom podmiotowość. Zakłada\nmożliwość bezpiecznego i bezpłatnego przerywania\nciąży do 12 tygodnia jej trwania oraz po 12 tygodniu\nw określonych okolicznościach. Aborcja musi być\nbezpieczna, aborcja musi być legalna. Aborcja musi być\ndostępna, a kobieta musi być bezpieczna.\nDziękuję. (Oklaski)",
         "True",
         "['Conversation_Killer' 'Causal_Oversimplification' 'Slogans'\n 'Whataboutism' 'Appeal_to_Values' 'Repetition' 'Appeal_to_Fear-Prejudice']",
         "train",
         "[]",
         "[]",
         "[]",
         "['aborcja musi być legalna' 'Aborcja musi być dostępna']",
         "[]",
         "['przywraca kobietom wolność wyboru' 'przywraca kobietom godność'\n 'przywraca kobietom podmiotowość']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['zagraża zdrowiu, życiu i bezpieczeństwu kobiet']",
         "[]",
         "[]",
         "['Aborcja musi być bezpieczna, aborcja musi być legalna'\n 'Aborcja musi być dostępna, a kobieta musi być bezpieczna']",
         "['Mówią: boję się być w ciąży, bo dziewczyny w moim wieku umierają. Umarły pan Iza, pani Agnieszka, pani Marta, pani Dorota'\n 'Zakaz aborcji w Polsce to restrykcyjne prawo, które zagraża zdrowiu, życiu i bezpieczeństwu kobiet']",
         "['Polki nie chcą rodzić dzieci w Polsce, która nie jest dla nich bezpieczna pod żadnym względem']",
         "[]",
         "[]",
         "['Dziś jesteśmy w demograficznym kryzysie']",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/Slogans",
         "Slogans",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "1",
         "Yes, the Slogans technique is used in the input.",
         "\"Aborcja musi być bezpieczna, aborcja musi być legalna Aborcja musi być dostępna, a kobieta musi być bezpieczna\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The Slogans technique is explicitly used in the input text through the repeated phrases \\'Aborcja musi być bezpieczna, aborcja musi być legalna, aborcja musi być dostępna, a kobieta musi być bezpieczna.\\' These phrases are brief, striking, and serve as emotional appeals, encapsulating key messages about the importance of safe and legal abortion, which aligns with the definition of Slogans.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[\"The Slogans technique is explicitly used in the input text through the repeated phrases 'Aborcja musi być bezpieczna, aborcja musi być legalna, aborcja musi być dostępna, a kobieta musi być bezpieczna.' These phrases are brief, striking, and serve as emotional appeals, encapsulating key messages about the importance of safe and legal abortion, which aligns with the definition of Slogans.\"]",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/Slogans/train/pl/train-pl-part_0007.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The Slogans technique is explicitly used in the input text through the repeated phrases 'Aborcja musi by\\u0107 bezpieczna, aborcja musi by\\u0107 legalna, aborcja musi by\\u0107 dost\\u0119pna, a kobieta musi by\\u0107 bezpieczna.' These phrases are brief, striking, and serve as emotional appeals, encapsulating key messages about the importance of safe and legal abortion, which aligns with the definition of Slogans.\", \"verdict\": true}"
        ],
        [
         "5",
         "pl_abortion_11_04_2024_n07.txt",
         "3811",
         "4153",
         "PL",
         "My, kobiety i mężczyźni broniący prawa do życia\nchcemy poważnego traktowania kobiet i ich potrzeb,\nkiedy zachodzą w ciążę, kiedy stają się matkami,\nlepszej jakości i dostępności opieki zdrowotnej, wsparcia\npsychologicznego oraz pomocy w zakresie opieki nad\ndzieckiem, szczególnie gdy okaże się, że może być\nniepełnosprawne lub poważnie chore.",
         "True",
         "['Appeal_to_Values']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['chcemy poważnego traktowania kobiet i ich potrzeb, kiedy zachodzą w ciążę, kiedy stają się matkami, lepszej jakości i dostępności opieki zdrowotnej, wsparcia psychologicznego oraz pomocy w zakresie opieki nad dzieckiem']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/Obfuscation-Vagueness-Confusion",
         "Obfuscation-Vagueness-Confusion",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "0",
         "No, the Obfuscation-Vagueness-Confusion technique is not used in the input.",
         "\"\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The input text clearly articulates the needs and rights of women regarding healthcare and support during pregnancy and motherhood. There is no use of vague or confusing language that would allow for multiple interpretations, thus aligning with the expert\\'s verdict that the Obfuscation, Intentional Vagueness, Confusion technique is not present.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "[\"The input text clearly articulates the needs and rights of women regarding healthcare and support during pregnancy and motherhood. There is no use of vague or confusing language that would allow for multiple interpretations, thus aligning with the expert's verdict that the Obfuscation, Intentional Vagueness, Confusion technique is not present.\"]",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/Obfuscation-Vagueness-Confusion/train/pl/train-pl-part_0007.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text clearly articulates the needs and rights of women regarding healthcare and support during pregnancy and motherhood. There is no use of vague or confusing language that would allow for multiple interpretations, thus aligning with the expert's verdict that the Obfuscation, Intentional Vagueness, Confusion technique is not present.\", \"verdict\": false}"
        ],
        [
         "6",
         "pl_abortion_11_04_2024_n01.txt",
         "5610",
         "6179",
         "PL",
         "To jest absolutnie destrukcyjne też dla naszego\nspołeczeństwa obywatelskiego, żeby w trudnej sytuacji\nkobietę pozostawić samą, pozostawić ją samotną,\nprzerażoną, bezbronną, w lęku nawet nie tylko o siebie,\nnie tylko o swoje zdrowie, z racji którego czasami\nwłaśnie jest ta decyzja o przerwaniu ciąży podejmowana,\nale również w lęku o bliskich, bo to im grozi\nodpowiedzialność karna. To jest przewrotne, diabelskie prawo.\nTy nie odpowiadasz, ale twój ukochany, twoja\nukochana, mama, siostra, przyjaciółka pójdzie do więzienia.\nTo jest stawianie kobiet w takiej sytuacji.",
         "True",
         "['Exaggeration-Minimisation' 'Loaded_Language' 'Appeal_to_Pity'\n 'Appeal_to_Values' 'Repetition' 'Appeal_to_Fear-Prejudice']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "['przewrotne, diabelskie prawo']",
         "['pozostawić samą' 'pozostawić ją samotną']",
         "[]",
         "[]",
         "[]",
         "[]",
         "['absolutnie destrukcyjne']",
         "[]",
         "['żeby w trudnej sytuacji kobietę pozostawić samą, pozostawić ją samotną, przerażoną, bezbronną, w lęku nawet nie tylko o siebie, nie tylko o swoje zdrowie, z racji którego czasami właśnie jest ta decyzja o przerwaniu ciąży podejmowana, ale również w lęku o bliskich, bo to im grozi odpowiedzialność karna']",
         "[]",
         "['To jest absolutnie destrukcyjne też dla naszego społeczeństwa obywatelskiego, żeby w trudnej sytuacji kobietę pozostawić samą']",
         "[]",
         "[]",
         "[]",
         "['twój ukochany, twoja ukochana, mama, siostra, przyjaciółka pójdzie do więzienia']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/Appeal_to_Pity",
         "Appeal_to_Pity",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "1",
         "Yes, the Appeal to Pity technique is used in the input.",
         "\"żeby w trudnej sytuacji kobietę pozostawić samą, pozostawić ją samotną, przerażoną, bezbronną, w lęku nawet nie tylko o siebie, nie tylko o swoje zdrowie, z racji którego czasami właśnie jest ta decyzja o przerwaniu ciąży podejmowana, ale również w lęku o bliskich, bo to im grozi odpowiedzialność karna\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The Appeal to Pity technique is used in the input text by evoking feelings of sympathy and compassion for women who are left alone, scared, and defenseless in difficult situations. The excerpts highlight the emotional distress and fear not only for their own health but also for their loved ones facing legal consequences, which distracts from rational analysis of the situation and aims to sway the audience\\'s opinion based on these emotions.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[\"The Appeal to Pity technique is used in the input text by evoking feelings of sympathy and compassion for women who are left alone, scared, and defenseless in difficult situations. The excerpts highlight the emotional distress and fear not only for their own health but also for their loved ones facing legal consequences, which distracts from rational analysis of the situation and aims to sway the audience's opinion based on these emotions.\"]",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/Appeal_to_Pity/train/pl/train-pl-part_0001.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The Appeal to Pity technique is used in the input text by evoking feelings of sympathy and compassion for women who are left alone, scared, and defenseless in difficult situations. The excerpts highlight the emotional distress and fear not only for their own health but also for their loved ones facing legal consequences, which distracts from rational analysis of the situation and aims to sway the audience's opinion based on these emotions.\", \"verdict\": true}"
        ],
        [
         "7",
         "20240111_SHG_BG_61.txt",
         "6107",
         "6688",
         "BG",
         "Продължавам с това как изпратихме годината и как я посрещаме. Изпратихте 2023-а с нова конституция, която отново днес обявихте за голяма крачка напред. Да, голяма крачка към разграждане на държавността, към предателството на българския национален интерес, като допуснахте двойно гражданство. Като допуснахте чужденци, които са придобили българско гражданство не по рождение, а по натурализация, да бъдат министри, народни представители и да управляват България. В чий интерес? Кой гарантира, че няма да е в чужд интерес? Това ли Ви е големият напредък в промяната в Конституцията? ",
         "True",
         "['Causal_Oversimplification' 'Loaded_Language'\n 'Questioning_the_Reputation' 'Doubt']",
         "train",
         "['Да, голяма крачка към разграждане на държавността, към предателството на българския национален интерес, като допуснахте двойно гражданство']",
         "[]",
         "[]",
         "[]",
         "['разграждане' 'предателството']",
         "[]",
         "[]",
         "['В чий интерес? Кой гарантира, че няма да е в чужд интерес?'\n 'Това ли Ви е големият напредък в промяната в Конституцията?']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Да, голяма крачка към разграждане на държавността, към предателството на българския национален интерес, като допуснахте двойно гражданство']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/Loaded_Language",
         "Loaded_Language",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "1",
         "Yes, the Loaded Language technique is used in the input.",
         "\"разграждане предателството\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The Loaded Language technique is used in the input text through the phrases \\'разграждане\\' (dismantling) and \\'предателството\\' (betrayal), which carry strong negative emotional implications. These words are intended to influence the audience\\'s perception of the actions being discussed, framing them as harmful and treacherous, thus validating the speaker\\'s argument against the changes in the constitution.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[\"The Loaded Language technique is used in the input text through the phrases 'разграждане' (dismantling) and 'предателството' (betrayal), which carry strong negative emotional implications. These words are intended to influence the audience's perception of the actions being discussed, framing them as harmful and treacherous, thus validating the speaker's argument against the changes in the constitution.\"]",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/Loaded_Language/train/bg/train-bg-part_0001.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The Loaded Language technique is used in the input text through the phrases '\\u0440\\u0430\\u0437\\u0433\\u0440\\u0430\\u0436\\u0434\\u0430\\u043d\\u0435' (dismantling) and '\\u043f\\u0440\\u0435\\u0434\\u0430\\u0442\\u0435\\u043b\\u0441\\u0442\\u0432\\u043e\\u0442\\u043e' (betrayal), which carry strong negative emotional implications. These words are intended to influence the audience's perception of the actions being discussed, framing them as harmful and treacherous, thus validating the speaker's argument against the changes in the constitution.\", \"verdict\": true}"
        ],
        [
         "8",
         "pl_defence_22_05_2024_n01.txt",
         "8339",
         "10002",
         "PL",
         "Proszę państwa, jeśli chodzi o te zakupy, to one\nwszystkie były konsultowane, były wynikiem naszych rozmów w Radzie Modernizacji Technicznej\nz przeważającym, decydującym głosem Sztabu Generalnego Wojska Polskiego. Zmieniłem sposób zamawiania sprzętu wojskowego dla polskiego wojska,\nbo on był sprzeczny wewnętrznie. To była sytuacja,\nw której nie można było pójść naprzód, więc udrożniłem te procesy. Potem, kiedy przyszedł rok 2022,\nkiedy po raz kolejny Rosja napadła na Ukrainę, nawiązałem relacje z Koreą Południową. Dlaczego to\nzrobiłem? Dlatego że Korea Południowa posiada olbrzymi potencjał produkcyjny, jeśli chodzi o przemysł\nzbrojeniowy. Uważam za jeden z naszych sukcesów\nto, że w tak krótkim czasie doprowadziliśmy do tego,\nże w Wojsku Polskim już są czołgi K2, że obok\nHIMARS-ów, o których powiedziałem, są Chunmoo,\nczyli artyleria rakietowa o zasięgu do 300 km, że są\nsamoloty szkolno-bojowe FA-50. Pan powiedział, że\npiloci tak dużo zarabiają. Trzeba szkolić pilotów.\nFA-50 zostały zaprojektowane przez Lockheed Martin, a więc są taką mniejszą, to prawda, wersją\nF-16. W Wojsku Polskim, kiedy przyszliśmy do\nwładzy, w zasadzie tylko F-16 stanowiły jakąś siłę\nbojową. Pozostały sprzęt wojskowy był postsowiecki,\nbył zużyty. To był obraz nędzy i rozpaczy, a my doprowadziliśmy do tego, że dziś Wojsko Polskie liczy\nponad 200 tys. żołnierzy. Tylko jeszcze cele… Też\npan o tym nie wspomniał. Co najmniej 300 tys. żołnierzy. Można powiedzieć, że 300 tys. żołnierzy wojsk\noperacyjnych i 50 tys. żołnierzy Wojsk Obrony Terytorialnej – to powinien być nasz wspólny cel, mówię\no państwie polskim (Oklaski), bo w ten sposób możemy realnie odstraszyć agresora.",
         "True",
         "['Loaded_Language' 'Flag_Waving' 'Obfuscation-Vagueness-Confusion'\n 'Appeal_to_Authority' 'Name_Calling-Labeling' 'Red_Herring'\n 'Appeal_to_Fear-Prejudice']",
         "train",
         "[]",
         "['postsowiecki']",
         "[]",
         "[]",
         "['obraz nędzy i rozpaczy']",
         "[]",
         "[]",
         "[]",
         "['Pan powiedział, że piloci tak dużo zarabiają']",
         "['mówię o państwie polskim']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['To była sytuacja, w której nie można było pójść naprzód, więc udrożniłem te procesy']",
         "[]",
         "[]",
         "['realnie odstraszyć agresora']",
         "[]",
         "['jeśli chodzi o te zakupy, to one wszystkie były konsultowane, były wynikiem naszych rozmów w Radzie Modernizacji Technicznej z przeważającym, decydującym głosem Sztabu Generalnego Wojska Polskiego']",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/Loaded_Language",
         "Loaded_Language",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "1",
         "Yes, the Loaded Language technique is used in the input.",
         "\"obraz nędzy i rozpaczy\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The Loaded Language technique is used in the input text through the phrase \\'obraz nędzy i rozpaczy\\', which translates to \\'a picture of misery and despair\\'. This phrase carries strong negative emotional implications, effectively influencing the audience\\'s perception of the previous state of the military equipment. It aligns with the definition of Loaded Language, as it uses emotionally charged language to convince the audience of the argument\\'s validity regarding the need for military improvements.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[\"The Loaded Language technique is used in the input text through the phrase 'obraz nędzy i rozpaczy', which translates to 'a picture of misery and despair'. This phrase carries strong negative emotional implications, effectively influencing the audience's perception of the previous state of the military equipment. It aligns with the definition of Loaded Language, as it uses emotionally charged language to convince the audience of the argument's validity regarding the need for military improvements.\"]",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/Loaded_Language/train/pl/train-pl-part_0002.parquet",
         "[None]",
         "[None]",
         "train",
         "{\"description\": \"The Loaded Language technique is used in the input text through the phrase 'obraz n\\u0119dzy i rozpaczy', which translates to 'a picture of misery and despair'. This phrase carries strong negative emotional implications, effectively influencing the audience's perception of the previous state of the military equipment. It aligns with the definition of Loaded Language, as it uses emotionally charged language to convince the audience of the argument's validity regarding the need for military improvements.\", \"verdict\": true}"
        ],
        [
         "9",
         "20231208_URW_BG_76.txt",
         "3409",
         "3886",
         "BG",
         "И между другото, тук използвам повод да се обърна към уважавания професор Гечев. Господин Професоре, Вие говорихте няколко пъти, че тук, в залата, има еничари. Абсолютно не сте прав. Еничарите, за съжаление, са били нещастни християнски момчета, които са били насила откъснати от своите родители. Те са били насила ислямизирани, насила турцизирани, насила превърнати в роби на султана, насила са ставали част от неговата гвардия. Нито един еничар не е станал такъв доброволно. ",
         "True",
         "['Exaggeration-Minimisation' 'Name_Calling-Labeling' 'Red_Herring'\n 'Repetition']",
         "train",
         "[]",
         "['еничари' 'нещастни християнски момчета' 'ислямизирани']",
         "[]",
         "[]",
         "[]",
         "['ислямизирани' 'насила турцизирани' 'насила превърнати'\n 'насила са ставали част от неговата гвардия']",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Те са били насила ислямизирани, насила турцизирани, насила превърнати в роби на султана, насила са ставали част от неговата гвардия']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/Repetition",
         "Repetition",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "1",
         "Yes, the Repetition technique is used in the input.",
         "\"ислямизирани насила турцизирани насила превърнати насила са ставали част от неговата гвардия\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"Repetition technique was used in the input text through the repeated use of the word \\'насила\\' (forcibly). This repetition emphasizes the coercive nature of the actions described, aligning with the definition that states the same word or phrase is used repeatedly to persuade the audience.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[\"Repetition technique was used in the input text through the repeated use of the word 'насила' (forcibly). This repetition emphasizes the coercive nature of the actions described, aligning with the definition that states the same word or phrase is used repeatedly to persuade the audience.\"]",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/Repetition/train/bg/train-bg-part_0006.parquet",
         null,
         null,
         "train",
         "{\"description\": \"Repetition technique was used in the input text through the repeated use of the word '\\u043d\\u0430\\u0441\\u0438\\u043b\\u0430' (forcibly). This repetition emphasizes the coercive nature of the actions described, aligning with the definition that states the same word or phrase is used repeatedly to persuade the audience.\", \"verdict\": true}"
        ],
        [
         "10",
         "pl_abortion_11_04_2024_n02.txt",
         "2916",
         "3709",
         "PL",
         "Ale to nie koniec. Art. 152, jak wiemy, jest\nprzyczyną tragedii także w polskich szpitalach, bo od\n30 lat aborcja jest traktowana nie jak zabieg\nmedyczny, tylko jak przestępstwo. To sprawia, że lekarze nie\nuczą się o tym, jak przeprowadzać aborcję, nie mają\npraktyki, nie wiedzą, jak to się robi, i kiedy stają\nwobec takiej sytuacji, że mają przerwać ciążę, to się\nboją, próbują tego uniknąć. Nawet wtedy, kiedy ta\ndecyzja zagraża życiu i zdrowiu pacjentki.\nBo brakuje im kompetencji, bo boją się o swoją karierę.\nI właśnie to spychanie aborcji do sfery świata\nkryminalnego doprowadziło do śmierci Izy z Pszczyny,\ndoprowadziło do śmierci Doroty z Nowego Targu i innych\nmłodych kobiet, które miały przed sobą całe życie,\nktóre miały małe dzieci, które mogły dalej\nżyć i wychowywać swoje dzieci.",
         "True",
         "['Causal_Oversimplification' 'Loaded_Language'\n 'Questioning_the_Reputation' 'Appeal_to_Values' 'Doubt']",
         "train",
         "['bo boją się o swoją karierę']",
         "[]",
         "[]",
         "[]",
         "['spychanie aborcji do sfery świata kryminalnego']",
         "[]",
         "[]",
         "['Art. 152, jak wiemy, jest przyczyną tragedii także w polskich szpitalach, bo od 30 lat aborcja jest traktowana nie jak zabieg medyczny, tylko jak przestępstwo'\n 'Bo brakuje im kompetencji']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Nawet wtedy, kiedy ta decyzja zagraża życiu i zdrowiu pacjentki'\n 'które miały przed sobą całe życie, które miały małe dzieci, które mogły dalej żyć i wychowywać swoje dzieci']",
         "[]",
         "[]",
         "[]",
         "[]",
         "['To sprawia, że lekarze nie uczą się o tym, jak przeprowadzać aborcję, nie mają praktyki, nie wiedzą, jak to się robi, i kiedy stają wobec takiej sytuacji, że mają przerwać ciążę, to się boją, próbują tego uniknąć'\n 'I właśnie to spychanie aborcji do sfery świata kryminalnego doprowadziło do śmierci Izy z Pszczyny, doprowadziło do śmierci Doroty z Nowego Targu i innych młodych kobiet, które miały przed sobą całe życie, które miały małe dzieci, które mogły dalej żyć i wychowywać swoje dzieci']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Doubt",
         "Doubt",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "1",
         "Yes, the Doubt technique is used in the input.",
         "\"Art. 152, jak wiemy, jest przyczyną tragedii także w polskich szpitalach, bo od 30 lat aborcja jest traktowana nie jak zabieg medyczny, tylko jak przestępstwo Bo brakuje im kompetencji\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The Casting Doubt technique is used in the input text by questioning the competence of doctors in handling abortions due to the legal framing of abortion as a crime rather than a medical procedure. This implies that their professional abilities are inadequate, which undermines their credibility in performing such procedures. The excerpt highlights that doctors lack the necessary skills and fear for their careers, casting doubt on their overall capability to provide safe medical care.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "['The Casting Doubt technique is used in the input text by questioning the competence of doctors in handling abortions due to the legal framing of abortion as a crime rather than a medical procedure. This implies that their professional abilities are inadequate, which undermines their credibility in performing such procedures. The excerpt highlights that doctors lack the necessary skills and fear for their careers, casting doubt on their overall capability to provide safe medical care.']",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Doubt/train/pl/train-pl-part_0004.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The Casting Doubt technique is used in the input text by questioning the competence of doctors in handling abortions due to the legal framing of abortion as a crime rather than a medical procedure. This implies that their professional abilities are inadequate, which undermines their credibility in performing such procedures. The excerpt highlights that doctors lack the necessary skills and fear for their careers, casting doubt on their overall capability to provide safe medical care.\", \"verdict\": true}"
        ],
        [
         "11",
         "pl_abortion_11_04_2024_n07.txt",
         "7421",
         "7841",
         "PL",
         "W omawianym projekcie, podobnie jak w\nprojektach KO i Trzeciej Drogi, znalazły się przepisy\nbezprawnie ograniczające konstytucyjną wolność\nsumienia i nakładające na ordynatora oddziału lub\nkierownika podmiotu leczniczego obowiązek zapewnienia\nwykonania aborcji w podmiocie leczniczym, co jest\nniezgodne z wyrokiem Trybunału Konstytucyjnego\nz 7 października 2015 r. obradującego pod\nprzewodnictwem Andrzeja Rzeplińskiego.",
         "True",
         "['Appeal_to_Authority']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['W omawianym projekcie, podobnie jak w projektach KO i Trzeciej Drogi, znalazły się przepisy bezprawnie ograniczające konstytucyjną wolność sumienia i nakładające na ordynatora oddziału lub kierownika podmiotu leczniczego obowiązek zapewnienia wykonania aborcji w podmiocie leczniczym, co jest niezgodne z wyrokiem Trybunału Konstytucyjnego z 7 października 2015 r. obradującego pod przewodnictwem Andrzeja Rzeplińskiego']",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/Appeal_to_Time",
         "Appeal_to_Time",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "0",
         "No, the Appeal to Time technique is not used in the input.",
         "\"\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The Appeal to Time technique is not used in the input text as there is no reference to the timeliness of the argument or a call for immediate action based on time. The text discusses legal issues without emphasizing the urgency or appropriateness of the timing for action.\",\\n  \"updated_definition\": \"The argument is centered around the idea that time has come for a particular action, emphasizing the urgency or appropriateness of the timing as part of the argument.\"\\n}']",
         "['The argument is centered around the idea that time has come for a particular action, emphasizing the urgency or appropriateness of the timing as part of the argument.']",
         "[None]",
         "[None]",
         "['The Appeal to Time technique is not used in the input text as there is no reference to the timeliness of the argument or a call for immediate action based on time. The text discusses legal issues without emphasizing the urgency or appropriateness of the timing for action.']",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/Appeal_to_Time/train/pl/train-pl-part_0015.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The Appeal to Time technique is not used in the input text as there is no reference to the timeliness of the argument or a call for immediate action based on time. The text discusses legal issues without emphasizing the urgency or appropriateness of the timing for action.\", \"verdict\": false}"
        ],
        [
         "12",
         "RU_discrediting_the_west_4.txt",
         "420",
         "626",
         "RU",
         "Начинается битва за новый политико-экономический уклад, где главным движителем будет не паровая тяга и не ДВС на нефтепродуктах, в свое время радикально перевернувшие мир, а искусственный интеллект. И чипы.",
         "True",
         "['Obfuscation-Vagueness-Confusion']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Начинается битва за новый политико-экономический уклад, где главным движителем будет не паровая тяга и не ДВС на нефтепродуктах, в свое время радикально перевернувшие мир, а искусственный интеллект. И чипы']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Doubt",
         "Doubt",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Doubt technique is not used in the input.",
         "\"\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The input text discusses the emergence of artificial intelligence and chips as the main drivers of a new political and economic order, without casting doubt on any individual or entity\\'s credibility or attributes. Therefore, the Casting Doubt technique is not used.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "[\"The input text discusses the emergence of artificial intelligence and chips as the main drivers of a new political and economic order, without casting doubt on any individual or entity's credibility or attributes. Therefore, the Casting Doubt technique is not used.\"]",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Doubt/train/ru/train-ru-part_0005.parquet",
         "[None]",
         "[None]",
         "train",
         "{\"description\": \"The input text discusses the emergence of artificial intelligence and chips as the main drivers of a new political and economic order, without casting doubt on any individual or entity's credibility or attributes. Therefore, the Casting Doubt technique is not used.\", \"verdict\": false}"
        ],
        [
         "13",
         "RU_URW_3.txt",
         "1665",
         "1847",
         "RU",
         "или, что вроде как, по описанию, этих бабушек и дедушек эвакуировала группа Хохла Спецназа «Ахмат». Мы пока ещё их не нашли, но по всем данным наши милые старички живы.\n\nЭта история ",
         "True",
         "['Loaded_Language']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "['группа Хохла' 'наши милые старички']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/Loaded_Language",
         "Loaded_Language",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "1",
         "Yes, the Loaded Language technique is used in the input.",
         "\"группа Хохла наши милые старички\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"Loaded Language was used in the input text through the phrases \\'группа Хохла\\' and \\'наши милые старички\\'. The term \\'группа Хохла\\' carries a negative connotation, potentially evoking feelings of disdain or prejudice, while \\'наши милые старички\\' has a positive emotional implication, creating a sense of affection and care. This use of emotionally charged language aims to influence the audience\\'s perception of the subjects involved.\",\\n  \"updated_definition\": \"Loaded Language is the use of specific words and phrases with strong emotional implications (either positive or negative) to influence and convince the audience that an argument is valid, often by evoking feelings that align with the speaker\\'s intent. It is also known as Appeal to Argument from Emotive Language.\"\\n}']",
         "[\"Loaded Language is the use of specific words and phrases with strong emotional implications (either positive or negative) to influence and convince the audience that an argument is valid, often by evoking feelings that align with the speaker's intent. It is also known as Appeal to Argument from Emotive Language.\"]",
         "[None]",
         "[None]",
         "[\"Loaded Language was used in the input text through the phrases 'группа Хохла' and 'наши милые старички'. The term 'группа Хохла' carries a negative connotation, potentially evoking feelings of disdain or prejudice, while 'наши милые старички' has a positive emotional implication, creating a sense of affection and care. This use of emotionally charged language aims to influence the audience's perception of the subjects involved.\"]",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/Loaded_Language/train/ru/train-ru-part_0016.parquet",
         null,
         null,
         "train",
         "{\"description\": \"Loaded Language was used in the input text through the phrases '\\u0433\\u0440\\u0443\\u043f\\u043f\\u0430 \\u0425\\u043e\\u0445\\u043b\\u0430' and '\\u043d\\u0430\\u0448\\u0438 \\u043c\\u0438\\u043b\\u044b\\u0435 \\u0441\\u0442\\u0430\\u0440\\u0438\\u0447\\u043a\\u0438'. The term '\\u0433\\u0440\\u0443\\u043f\\u043f\\u0430 \\u0425\\u043e\\u0445\\u043b\\u0430' carries a negative connotation, potentially evoking feelings of disdain or prejudice, while '\\u043d\\u0430\\u0448\\u0438 \\u043c\\u0438\\u043b\\u044b\\u0435 \\u0441\\u0442\\u0430\\u0440\\u0438\\u0447\\u043a\\u0438' has a positive emotional implication, creating a sense of affection and care. This use of emotionally charged language aims to influence the audience's perception of the subjects involved.\", \"verdict\": true}"
        ],
        [
         "14",
         "SI_interpelation_interior_2.txt",
         "392",
         "398",
         "SI",
         "Hvala.",
         "False",
         "[]",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Name_Calling-Labeling",
         "Name_Calling-Labeling",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Name Calling-Labeling technique is not used in the input.",
         "\"\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The input text \\'Hvala\\' is a simple expression of gratitude and does not contain any loaded labels or characterizations directed at individuals or groups. Therefore, the Name Calling - Labeling technique is not used.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "[\"The input text 'Hvala' is a simple expression of gratitude and does not contain any loaded labels or characterizations directed at individuals or groups. Therefore, the Name Calling - Labeling technique is not used.\"]",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Name_Calling-Labeling/train/si/train-si-part_0005.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text 'Hvala' is a simple expression of gratitude and does not contain any loaded labels or characterizations directed at individuals or groups. Therefore, the Name Calling - Labeling technique is not used.\", \"verdict\": false}"
        ],
        [
         "15",
         "SI_interpelation_interior_4.txt",
         "3163",
         "7586",
         "SI",
         "V javnosti najodmevnejši očitek, ki so ga seveda prevzeli tudi predlagatelji, je očitek glede delovanja Centra za varovanje in zaščito. Situacija v zvezi z delovanjem in organizacijo Centra za varovanje in zaščito je bistveno bolj kompleksna, kot jo sicer nekateri radi prikazujejo in je trenutno v fazi preiskave morebitnih sumov storitve kaznivih dejanj pripadnikov te enote, ki jo vodi specializirano državno tožilstvo. Naj povem, da je Center za varovanje in zaščito vseeno zelo profesionalna enota policije z dolgoletno tradicijo in je sposobna brezhibno izvesti tudi najzahtevnejša varovanja, vključno z zagotavljanjem najvišje stopnje varovanja svetovnim voditeljem, ki so izpostavljeni visokim varnostnim tveganjem in grožnjam. Pri osebnem varovanju je ključno vzpostaviti zaupanje med varnostniki in varovano osebo. Iz lastnih izkušenj že drugič kot varovana oseba lahko potrdim, da policisti varnostniki svoje naloge opravljajo profesionalno in dosledno. Naj pa jasno povem, da je bil zadnji izredni nadzor nad Centrom za varovanje in zaščito uveden leta 2010 s strani takratne ministrice za notranje zadeve, zaradi tako imenovane afere katarske ure, in ponovni nadzor nad enoto leta 2012 s strani takratnega notranjega ministra. Dejstvo je tudi, da v vsem tem času direktorat za policijo in druge varnostne naloge ministrstva v obravnavo ni prejel nobene pritožbe zoper dela policistov varnostnikov centra za varovanje in zaščito. Nekdanji generalni direktor Policije magister Senad Jušić je takoj po nastopu funkcije leta 2023 aktivno pričel z različnimi aktivnostmi in ukrepi za izboljšanje stanja v Centru za varovanje in zaščito. Zaradi določenih nepravilnosti in napak v enoti je večkrat odredil notranje varnostne postopke, ki pa so v izključni pristojnosti generalnega direktorja policije in ne ministra za notranje zadeve. Kot minister za notranje zadeve sem na podlagi nekaterih medijskih objav o nepravilnostih v Centru za varovanje in zaščito 28. februarja lani v skladu s svojo zakonsko pristojnostjo direktoratu za policijo in druge varnostne naloge Ministrstva za notranje zadeve odredil izredni strokovni nadzor nad izvajanjem policijskih nalog in pooblastil v Centru za varovanje in zaščito, ki sta ga izvedla nadzornika direktorata. Po zaključnem nadzoru sta nadzornika direktorata konec avgusta leta 2024 zaključila poročilo o izrednem nadzoru v centru za varovanje in zaščito, ki je pod oznako stopnje zaupnosti interno. V samem izrednem strokovnem nadzoru so bile ugotovljene nepravilnosti in napake, ki so zapisane v poročilu izrednega nadzora. Na podlagi teh ugotovitev sem generalnemu direktorju policije z usmeritvami in obveznimi navodili ministra naložil ukrepe za izboljšanje stanja v Centru za varovanje in zaščito. Policija je takoj pristopila k odpravljanju nepravilnosti in pripravila načrt za odpravo ugotovljenih nepravilnosti in pomanjkljivosti na podlagi mojih usmeritev in obveznih navodil in ga začela tudi izvajati. V oddaji TV Slovenija Tarča lani decembra, so bile razkrite operativne informacije o varovanju varovanih oseb, izpostavljene so bile nepravilnosti in podani morebitni sumi storitve kaznivih dejanj v Centru za varovanje in zaščito na podlagi razkritih odklonov sem naslednji dan generalnemu direktorju policije izdal usmeritev in obvezno navodilo za reorganizacijo centra za varovanje in zaščito do 1. aprila letos. Prav tako sem zaradi javnega dvoma v zakonitost in transparentnost postopka javnega naročanja izdal sklep o izvedbi notranje revizije uporabe nastanitvenih kapacitet za potrebe Centra za varovanje in zaščito. Na podlagi medijskih očitkov in nekaterih neresničnih informacij ter predvsem zaradi velikega interesa javnosti, je bila delno umaknjena stopnja zaupnosti sporočila izrednega nadzora, ki ga je na tiskovni konferenci predstavil direktor direktorata za policijo in druge varnostne naloge, prav tako pa so ga prejeli nekateri mediji po dostopu do informacij javnega značaja in ga tudi javno objavili. Prav tako sem z elektronskim sporočilom zaprosil generalno državno tožilko, da v skladu s svojimi pristojnostmi naredi vse, da se čim prej preiščejo sumi morebitnih kaznivih dejanj v Centru za varovanje in zaščito. Njen odgovor je bil, da je preiskava že uvedena po uradni dolžnosti. Naj še dodam, da je Specializirano državno tožilstvo zahtevalo celotno poročilo o izrednem nadzoru, ki ga je Ministrstvo za notranje zadeve tudi predal.",
         "True",
         "['Exaggeration-Minimisation' 'Loaded_Language'\n 'Obfuscation-Vagueness-Confusion' 'Appeal_to_Authority'\n 'Appeal_to_Values' 'Appeal_to_Popularity' 'Doubt']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "['seveda'\n 'vseeno zelo profesionalna enota policije z dolgoletno tradicijo'\n 'brezhibno izvesti tudi najzahtevnejša varovanja, vključno z zagotavljanjem najvišje stopnje varovanja'\n 'operativne informacije']",
         "[]",
         "['ni prejel nobene pritožbe']",
         "['nekaterih neresničnih informacij']",
         "[]",
         "[]",
         "['V javnosti najodmevnejši očitek' 'aktivno pričel']",
         "[]",
         "[]",
         "[]",
         "['javnega dvoma v zakonitost in transparentnost postopka javnega naročanja']",
         "['bolj kompleksna, kot jo sicer nekateri radi prikazujejo'\n 'različnimi aktivnostmi in ukrepi' 'določenih nepravilnosti in napak'\n 'operativne informacije' 'nepravilnosti'\n 'morebitni sumi storitve kaznivih dejanj' 'javnega dvoma']",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Naj povem, da je Center za varovanje in zaščito vseeno zelo profesionalna enota policije z dolgoletno tradicijo in je sposobna brezhibno izvesti tudi najzahtevnejša varovanja, vključno z zagotavljanjem najvišje stopnje varovanja svetovnim voditeljem, ki so izpostavljeni visokim varnostnim tveganjem in grožnjam'\n 'kot varovana oseba lahko potrdim' 'Kot minister za notranje zadeve'\n 'v skladu s svojo zakonsko pristojnostjo' 'nadzornika direktorata'\n 'izrednem strokovnem nadzoru']",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Values",
         "Appeal_to_Values",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "1",
         "Yes, the Appeal to Values technique is used in the input.",
         "\"javnega dvoma v zakonitost in transparentnost postopka javnega naročanja\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The Appeal to Values technique is used in the input text by referencing the values of \\'legality\\' and \\'transparency\\' in the context of public procurement processes. These values are presented as positive and authoritative, supporting the argument for the need for oversight and investigation into the actions of the Center for Protection and Security. This aligns with the definition, as it links the argument to values that the target audience likely views as important.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[\"The Appeal to Values technique is used in the input text by referencing the values of 'legality' and 'transparency' in the context of public procurement processes. These values are presented as positive and authoritative, supporting the argument for the need for oversight and investigation into the actions of the Center for Protection and Security. This aligns with the definition, as it links the argument to values that the target audience likely views as important.\"]",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Values/train/si/train-si-part_0001.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The Appeal to Values technique is used in the input text by referencing the values of 'legality' and 'transparency' in the context of public procurement processes. These values are presented as positive and authoritative, supporting the argument for the need for oversight and investigation into the actions of the Center for Protection and Security. This aligns with the definition, as it links the argument to values that the target audience likely views as important.\", \"verdict\": true}"
        ],
        [
         "16",
         "pl_abortion_11_04_2024_n02.txt",
         "2916",
         "3709",
         "PL",
         "Ale to nie koniec. Art. 152, jak wiemy, jest\nprzyczyną tragedii także w polskich szpitalach, bo od\n30 lat aborcja jest traktowana nie jak zabieg\nmedyczny, tylko jak przestępstwo. To sprawia, że lekarze nie\nuczą się o tym, jak przeprowadzać aborcję, nie mają\npraktyki, nie wiedzą, jak to się robi, i kiedy stają\nwobec takiej sytuacji, że mają przerwać ciążę, to się\nboją, próbują tego uniknąć. Nawet wtedy, kiedy ta\ndecyzja zagraża życiu i zdrowiu pacjentki.\nBo brakuje im kompetencji, bo boją się o swoją karierę.\nI właśnie to spychanie aborcji do sfery świata\nkryminalnego doprowadziło do śmierci Izy z Pszczyny,\ndoprowadziło do śmierci Doroty z Nowego Targu i innych\nmłodych kobiet, które miały przed sobą całe życie,\nktóre miały małe dzieci, które mogły dalej\nżyć i wychowywać swoje dzieci.",
         "True",
         "['Causal_Oversimplification' 'Loaded_Language'\n 'Questioning_the_Reputation' 'Appeal_to_Values' 'Doubt']",
         "train",
         "['bo boją się o swoją karierę']",
         "[]",
         "[]",
         "[]",
         "['spychanie aborcji do sfery świata kryminalnego']",
         "[]",
         "[]",
         "['Art. 152, jak wiemy, jest przyczyną tragedii także w polskich szpitalach, bo od 30 lat aborcja jest traktowana nie jak zabieg medyczny, tylko jak przestępstwo'\n 'Bo brakuje im kompetencji']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Nawet wtedy, kiedy ta decyzja zagraża życiu i zdrowiu pacjentki'\n 'które miały przed sobą całe życie, które miały małe dzieci, które mogły dalej żyć i wychowywać swoje dzieci']",
         "[]",
         "[]",
         "[]",
         "[]",
         "['To sprawia, że lekarze nie uczą się o tym, jak przeprowadzać aborcję, nie mają praktyki, nie wiedzą, jak to się robi, i kiedy stają wobec takiej sytuacji, że mają przerwać ciążę, to się boją, próbują tego uniknąć'\n 'I właśnie to spychanie aborcji do sfery świata kryminalnego doprowadziło do śmierci Izy z Pszczyny, doprowadziło do śmierci Doroty z Nowego Targu i innych młodych kobiet, które miały przed sobą całe życie, które miały małe dzieci, które mogły dalej żyć i wychowywać swoje dzieci']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/Whataboutism",
         "Whataboutism",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "0",
         "No, the Whataboutism technique is not used in the input.",
         "\"\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The input text discusses the consequences of treating abortion as a criminal act in Poland, focusing on the impact on medical professionals and patients. It does not attempt to discredit an opponent\\'s position by introducing a counter-accusation or shifting the topic, which is a key characteristic of Whataboutism. Therefore, the technique is not used.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "[\"The input text discusses the consequences of treating abortion as a criminal act in Poland, focusing on the impact on medical professionals and patients. It does not attempt to discredit an opponent's position by introducing a counter-accusation or shifting the topic, which is a key characteristic of Whataboutism. Therefore, the technique is not used.\"]",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/Whataboutism/train/pl/train-pl-part_0004.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text discusses the consequences of treating abortion as a criminal act in Poland, focusing on the impact on medical professionals and patients. It does not attempt to discredit an opponent's position by introducing a counter-accusation or shifting the topic, which is a key characteristic of Whataboutism. Therefore, the technique is not used.\", \"verdict\": false}"
        ],
        [
         "17",
         "20231208_URW_BG_76.txt",
         "5170",
         "5523",
         "BG",
         "Това, което всъщност в момента даваме тук, е разрешение да унищожим Българската армия, да изпразним складовете, да оголим българския резерв, ако въобще такъв е останал след престъпниците, които управляват Армията и управляват Министерството на отбраната най-вече, защото в Армията все пак, за разлика от Министерството на отбраната, има професионалисти.",
         "True",
         "['Consequential_Oversimplification' 'Loaded_Language'\n 'Questioning_the_Reputation' 'Straw_Man']",
         "train",
         "['след престъпниците, които управляват Армията и управляват Министерството на отбраната най-вече, защото в Армията все пак, за разлика от Министерството на отбраната, има професионалисти']",
         "[]",
         "[]",
         "[]",
         "['унищожим']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Това, което всъщност в момента даваме тук, е разрешение да унищожим Българската армия, да изпразним складовете, да оголим българския резерв']",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Това, което всъщност в момента даваме тук, е разрешение да унищожим Българската армия, да изпразним складовете, да оголим българския резерв, ако въобще такъв е останал след престъпниците, които управляват Армията и управляват Министерството на отбраната най-вече, защото в Армията все пак, за разлика от Министерството на отбраната, има професионалисти']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/Consequential_Oversimplification",
         "Consequential_Oversimplification",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "1",
         "Yes, the Consequential Oversimplification technique is used in the input.",
         "\"Това, което всъщност в момента даваме тук, е разрешение да унищожим Българската армия, да изпразним складовете, да оголим българския резерв\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The input text employs the Consequential Oversimplification technique by suggesting that a current decision will lead to extreme negative outcomes, such as the destruction of the Bulgarian army and depletion of reserves. This aligns with the technique\\'s definition, as it asserts that accepting the current proposition will result in a series of dire consequences without providing evidence for this chain of events.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[\"The input text employs the Consequential Oversimplification technique by suggesting that a current decision will lead to extreme negative outcomes, such as the destruction of the Bulgarian army and depletion of reserves. This aligns with the technique's definition, as it asserts that accepting the current proposition will result in a series of dire consequences without providing evidence for this chain of events.\"]",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/Consequential_Oversimplification/train/bg/train-bg-part_0009.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text employs the Consequential Oversimplification technique by suggesting that a current decision will lead to extreme negative outcomes, such as the destruction of the Bulgarian army and depletion of reserves. This aligns with the technique's definition, as it asserts that accepting the current proposition will result in a series of dire consequences without providing evidence for this chain of events.\", \"verdict\": true}"
        ],
        [
         "18",
         "20240704_URW_BG_26.txt",
         "1366",
         "1409",
         "BG",
         "ЗАРЯН: И аз Ви благодаря.\n\nГосподин Гаджев,",
         "False",
         "[]",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Authority",
         "Appeal_to_Authority",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Appeal to Authority technique is not used in the input.",
         "\"\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The input text does not contain any references to an authority or an attempt to leverage the weight of an authority to support an argument or claim. Therefore, the Appeal to Authority technique is not used.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "['The input text does not contain any references to an authority or an attempt to leverage the weight of an authority to support an argument or claim. Therefore, the Appeal to Authority technique is not used.']",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Authority/train/bg/train-bg-part_0003.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text does not contain any references to an authority or an attempt to leverage the weight of an authority to support an argument or claim. Therefore, the Appeal to Authority technique is not used.\", \"verdict\": false}"
        ],
        [
         "19",
         "SI_interpelation_interior_3.txt",
         "0",
         "1540",
         "SI",
         "Očitek v zvezi s slabimi upravljanji nezakonitih migracijskih tokov zavrača. V lanskem letu smo s skupnim ukrepanjem vseh držav Evropske unije in držav na zahodnem Balkanu zmanjšali število nezakonitih prehodov meja. Slovenska policija je zabeležila za skoraj 20 odstotkov manj nezakonitih prehodov državne meje kot leto poprej. Dejstvo je, da migracije ni mogoče učinkovito opravljati šele na notranjih mejah držav Evropske unije, ampak predvsem na zunanjih mejah Evropske unije ter s tesnim sodelovanjem vseh držav in njihovih varnostnih organov. V letošnjem letu je zunanja schengenska meja Evropske unije še bolj varovana, saj sta v schengenski prostor polnopravno vstopili Bolgarija in Romunija, ki sta imeli močno in trdno podporo Slovenije, ki sem jo vseskozi zastopal na Svetu Evropske unije za notranje zadeve. Varnostna vprašanja povezana z izzivi upravljanja nezakonitih migracij obravnavamo prednostno in celostno. Dnevno spremljamo vse varnostno relevantne dogodke in jih smiselno razvrščamo. Vrednotimo in analiziramo na strateški, operativni in taktični ravni odločanja. Močno smo vpeti v mednarodno policijsko sodelovanje. Včeraj ob robu srečanja ministrov za notranje zadeve Slovenije, Italije in Hrvaške v Novi Gorici je bil s strani slovenske, italijanske in hrvaške policije podpisan operativni memorandum o soglasju, s katerim smo se dogovorili in način izvajanja skupnih trilateralnih mešanih patrulj. Dokument predstavlja pomemben uspeh našega skupnega sodelovanja in dogovora med notranjimi ministri in šefi policij.",
         "True",
         "['Appeal_to_Authority' 'Appeal_to_Values']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['skupnim ukrepanjem']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['močno in trdno podporo Slovenije, ki sem jo vseskozi zastopal na Svetu Evropske unije za notranje zadeve']",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/Conversation_Killer",
         "Conversation_Killer",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "0",
         "No, the Conversation Killer technique is not used in the input.",
         "\"\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The input text does not contain any words or phrases that discourage critical thought or meaningful discussion about the topic of illegal migration management. It presents information and analysis without employing Loaded Language or folk wisdom intended to end an argument.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "['The input text does not contain any words or phrases that discourage critical thought or meaningful discussion about the topic of illegal migration management. It presents information and analysis without employing Loaded Language or folk wisdom intended to end an argument.']",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/Conversation_Killer/train/si/train-si-part_0002.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text does not contain any words or phrases that discourage critical thought or meaningful discussion about the topic of illegal migration management. It presents information and analysis without employing Loaded Language or folk wisdom intended to end an argument.\", \"verdict\": false}"
        ],
        [
         "20",
         "pl_current_affairs_09_01_2025_n03.txt",
         "2672",
         "3168",
         "PL",
         "A ponieważ mamy jeszcze chwilę, to wrócę do tej\nlisty, którą należy państwu przypomnieć. To było\nbardzo niedawno, więc jeszcze raz podkreślę i przypomnę. Mówicie o bezpieczeństwie przeciwpowodziowym, o zbiornikach suchych, retencyjnych, które\nbyły potrzebne w Kotlinie Kłodzkiej, a to właśnie\nwasz minister odmówił ich budowy. Mówił: Po co te\nzbiorniki? Chyba psu na budę. Już wyszedł, bo nie\nchce się z tego tutaj wytłumaczyć.\n(Poseł Anna Gembicka: Marszałek Wielichowska\norganizowała protesty…)",
         "True",
         "['Appeal_to_Hypocrisy' 'Loaded_Language' 'Questioning_the_Reputation']",
         "train",
         "['Już wyszedł, bo nie chce się z tego tutaj wytłumaczyć']",
         "[]",
         "['Mówicie o bezpieczeństwie przeciwpowodziowym, o zbiornikach suchych, retencyjnych, które były potrzebne w Kotlinie Kłodzkiej, a to właśnie wasz minister odmówił ich budowy']",
         "[]",
         "['psu na budę']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/Loaded_Language",
         "Loaded_Language",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "1",
         "Yes, the Loaded Language technique is used in the input.",
         "\"psu na budę\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The Loaded Language technique is used in the input text through the phrase \\'psu na budę,\\' which carries a strong negative emotional implication. This phrase suggests that the proposed reservoirs are worthless, thereby influencing the audience\\'s perception of the argument against their construction. This aligns with the definition of Loaded Language, which involves using emotionally charged words to sway the audience\\'s opinion.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[\"The Loaded Language technique is used in the input text through the phrase 'psu na budę,' which carries a strong negative emotional implication. This phrase suggests that the proposed reservoirs are worthless, thereby influencing the audience's perception of the argument against their construction. This aligns with the definition of Loaded Language, which involves using emotionally charged words to sway the audience's opinion.\"]",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/Loaded_Language/train/pl/train-pl-part_0015.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The Loaded Language technique is used in the input text through the phrase 'psu na bud\\u0119,' which carries a strong negative emotional implication. This phrase suggests that the proposed reservoirs are worthless, thereby influencing the audience's perception of the argument against their construction. This aligns with the definition of Loaded Language, which involves using emotionally charged words to sway the audience's opinion.\", \"verdict\": true}"
        ],
        [
         "21",
         "pl_abortion_11_04_2024_n03.txt",
         "4168",
         "5204",
         "PL",
         "W latach 90., które już bardzo dobrze pamiętam,\nmiały miejsce kolejne próby zaostrzenia prawa\naborcyjnego. Najpierw efektem tego było prawo aborcyjne\noparte na czterech przesłankach, w tym przesłance\nekonomiczno-społecznej, a finalnie, po wyroku\nTrybunału Konstytucyjnego w 1997 r. zakończyło się to\nwprowadzeniem zakazu aborcji opartego na trzech\nwąskich przesłankach, dla niepoznaki i czystych\nsumień konserwatywnych polityków i duchownych\nKościoła katolickiego zwanego kompromisem aborcyjnym.\nNikt nie pytał wtedy kobiet o zdanie w sprawie\nplanowania rodziny, ochrony płodu ludzkiego i\nwarunków dopuszczalności przerywania ciąży – tak\nnazywała się ta ustawa. Nie pytano kobiet, bo ta ustawa\nbyła początkiem wymazywania kobiet z debaty o aborcji.\nCzęść polityków miała czyste ręce i czyste sumienia.\nPrawo zabraniało kobiecie przerywania ciąży,\nlekarze przestali wykonywać aborcję, ale tylko w\npublicznych szpitalach. Według rządowych statystyk\nciążę przerywało 600–1000 kobiet rocznie, a w rze-\nczywistości miała ją co trzecia Polka.",
         "True",
         "['Appeal_to_Hypocrisy' 'Loaded_Language' 'Questioning_the_Reputation'\n 'Appeal_to_Popularity' 'Repetition']",
         "train",
         "['ustawa była początkiem wymazywania kobiet z debaty o aborcji'\n 'Część polityków miała czyste ręce i czyste sumienia']",
         "[]",
         "['zakazu aborcji opartego na trzech wąskich przesłankach, dla niepoznaki i czystych sumień konserwatywnych polityków i duchownych Kościoła katolickiego zwanego kompromisem aborcyjnym']",
         "[]",
         "['wymazywania kobiet' 'wymazywania']",
         "['Nikt nie pytał wtedy kobiet' 'Nie pytano kobiet']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Popularity",
         "Appeal_to_Popularity",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "1",
         "Yes, the Appeal to Popularity technique is used in the input.",
         "\"\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The Appeal to Popularity technique is used in the input text by implying that a significant number of women (one in three) were undergoing abortions, suggesting that this is a common practice among women in Poland. This aligns with the definition, as it indicates that the audience should consider this widespread behavior as a justification for the argument being made about the law and women\\'s rights. The mention of \\'co trzecia Polka\\' (one in three Polish women) serves to highlight that many women are affected by the law, thus appealing to the idea that if so many women are involved, it should be a matter of concern for society.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[\"The Appeal to Popularity technique is used in the input text by implying that a significant number of women (one in three) were undergoing abortions, suggesting that this is a common practice among women in Poland. This aligns with the definition, as it indicates that the audience should consider this widespread behavior as a justification for the argument being made about the law and women's rights. The mention of 'co trzecia Polka' (one in three Polish women) serves to highlight that many women are affected by the law, thus appealing to the idea that if so many women are involved, it should be a matter of concern for society.\"]",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Popularity/train/pl/train-pl-part_0000.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The Appeal to Popularity technique is used in the input text by implying that a significant number of women (one in three) were undergoing abortions, suggesting that this is a common practice among women in Poland. This aligns with the definition, as it indicates that the audience should consider this widespread behavior as a justification for the argument being made about the law and women's rights. The mention of 'co trzecia Polka' (one in three Polish women) serves to highlight that many women are affected by the law, thus appealing to the idea that if so many women are involved, it should be a matter of concern for society.\", \"verdict\": true}"
        ],
        [
         "22",
         "pl_abortion_11_04_2024_n05.txt",
         "0",
         "364",
         "PL",
         "Poseł Urszula Pasławska:\nSzanowny Panie Marszałku! Wysoka Izbo! Polacy\n15 października zagłosowali na nas, prosili nas o to,\nżebyśmy rządzili skutecznie. Dlatego dzisiaj jako\nTrzecia Droga przedstawiamy projekt ustawy, który\nskutecznie rozwiąże problem terminacji ciąży,\nponieważ jako jedyny ma szansę zarówno na poparcie\nprawej strony, jak i na podpis prezydenta.",
         "True",
         "['Appeal_to_Authority']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['jako jedyny ma szansę zarówno na poparcie prawej strony, jak i na podpis prezydenta']",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/Causal_Oversimplification",
         "Causal_Oversimplification",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "0",
         "No, the Causal Oversimplification technique is not used in the input.",
         "\"\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The input text does not exhibit Causal Oversimplification as it does not assume a single cause for an issue. The speaker discusses a legislative proposal without attributing the success or failure of the issue solely to one factor.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "['The input text does not exhibit Causal Oversimplification as it does not assume a single cause for an issue. The speaker discusses a legislative proposal without attributing the success or failure of the issue solely to one factor.']",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/Causal_Oversimplification/train/pl/train-pl-part_0007.parquet",
         "[None]",
         "[None]",
         "train",
         "{\"description\": \"The input text does not exhibit Causal Oversimplification as it does not assume a single cause for an issue. The speaker discusses a legislative proposal without attributing the success or failure of the issue solely to one factor.\", \"verdict\": false}"
        ],
        [
         "23",
         "pl_abortion_11_04_2024_n05.txt",
         "2068",
         "2783",
         "PL",
         "Szanowni Państwo! Mam poglądy niezwykle liberalne\ni traktuję tę ustawę jako pierwszy element w dojściu\ndo liberalizacji prawa aborcyjnego. I chociaż\npewnie chciałabym, żeby ta ustawa wychodziła\nzdecydowanie dalej, to czasami marzenia trzeba szyć na\nmiarę. Nie wystarczy gadać, dyskutować na ten\ntemat, ale trzeba przeprowadzić skuteczne rozwiązania.\nJeżeli ktokolwiek z państwa ma jakąkolwiek\npropozycję, która skutecznie doprowadzi do liberalizacji\nprawa aborcyjnego, będziemy o tym rozmawiać.\nBardzo chętnie. Trzecia Droga jest otwarta na dyskusję.\nAle prawda jest taka, że mam nieodparte wrażenie,\nże lewicy chodzi tylko o dyskusję, tak samo jak\nprawicy, a problemy kobiet do tej pory są nierozwiązane. (Oklaski)",
         "True",
         "['Straw_Man']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Ale prawda jest taka, że mam nieodparte wrażenie, że lewicy chodzi tylko o dyskusję, tak samo jak prawicy, a problemy kobiet do tej pory są nierozwiązane']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Doubt",
         "Doubt",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Doubt technique is not used in the input.",
         "\"\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The input text does not contain any elements that cast doubt on the character or personal attributes of any individual or group. The speaker expresses a desire for liberalization of abortion laws and critiques the current state of discussion without questioning the credibility or quality of any opposing views or individuals. Therefore, the Casting Doubt technique is not used.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "['The input text does not contain any elements that cast doubt on the character or personal attributes of any individual or group. The speaker expresses a desire for liberalization of abortion laws and critiques the current state of discussion without questioning the credibility or quality of any opposing views or individuals. Therefore, the Casting Doubt technique is not used.']",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Doubt/train/pl/train-pl-part_0003.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text does not contain any elements that cast doubt on the character or personal attributes of any individual or group. The speaker expresses a desire for liberalization of abortion laws and critiques the current state of discussion without questioning the credibility or quality of any opposing views or individuals. Therefore, the Casting Doubt technique is not used.\", \"verdict\": false}"
        ],
        [
         "24",
         "SI_interpelation_interior_11.txt",
         "3647",
         "7212",
         "SI",
         "Zamislite si, NSi problema z uporabo nacističnih in fašističnih simbolov nima, kajne, danes pa bi rušila ministra. Narobe svet. Pravzaprav dobrodošli v strašljivi novi krasni svet, ki ga vse bolj poosebljajo novi fašizmi, ki v Evropi in po svetu dvigajo glavo in ki predlagatelje današnje interpelacije očitno niti malo ne motijo. Kot jih ni motil Poklukarjev predhodnik, nekdanji minister Hojs, človek, ki je bil zdaleč najbolj brutalni notranji minister v zgodovini te države. Minister, ki je označil rumene jopiče, malikovalce Hitlerja, za bisere. Minister, ki je s svojimi zakoni in s svojim obnašanjem omogočal in demonstriral politično vmešavanje v delo policije in še več političnega kadrovanja, ki je podrejal in ustrahoval tako policijo kot državljane, ki je policijo instrumentaliziral za represijo nad državljankami in državljani, ki so si kakorkoli drznili kritizirati Janševo oblast, v kateri je veselo kolaborirala tudi NSi. Oblast, ki je, kot vemo, povsem izgubila kompas, ko se je nad ljudstvo spravila z vodnim topom s solzivcem in pendreki, in je zaplinila širši center prestolnice. Niti to jih ni zmotilo, da je Hojs sam podal odstopno izjavo, Janša pa kuverte z odstopom ni nikdar odprl. Je NSi takrat reagirala, kot bi se spodobilo od neke državotvorne in kredibilne politične stranke? So oni kadarkoli kogarkoli kot Janševi koalicijski partnerji pozvali k sprejetju odgovornosti? So po škandaloznem zaplinjanju Ljubljane k odstopu pozvali takratnega generalnega direktorja policije? Seveda ne. Bili so tiho kot miške, danes pa s polnimi jadri in pljuči uprizarjajo politični cirkus v optimističnem, čeprav Sizifovem poskusu destabilizirati vladajočo koalicijo in v žep pospraviti nekaj cenenih političnih točk. Zato je današnja interpelacija zoper ministra dobesedno patetična. Mar res mislite v NSi, da imamo državljanke in državljani spomin zlate ribice, da je nastopila vsesplošna in množična amnezija in se nihče več ne spomni vašega pridnega asistiranja pri najbolj brutalnem obračunavanju z ljudstvom po taktirko Hojsa, kar ga pomnimo v tej državi. Toliko o vaši kredibilnosti. Zato o ostalih navedbah interpelacije in strokovnjaških ocenah iz nje, kot so razne preplačane stražarske hiške ali prepočasno delovanje NPU in podobno, ne mislim tratiti besed. Glede na dvojna merila predlagateljev in njihove več kot očitno bizarne kriterije o tem kaj varnost je in kaj ni, res ne. V Levici nismo skrivali zaskrbljenosti ob razkritjih situacije na CVZ ob aferi Gončin in tudi ne glede dvomov pri imenovanju nekdanjega generalnega direktorja Jušića. Bili smo kritični in jasni, povedali smo, da je v primeru CVZ potrebno sprejeti politično odgovornost in povedali smo, da bi v imenu politične higiene in transparentnosti nekdanji direktor moral že takoj, ko je sodišče presodilo, da je sklep o njegovem izpolnjevanju pogojev za generalnega direktorja policije nezakonit, odstopiti in s tem omogočiti ponovitev razpisa. Ko se je k temu pritaknila še afera v zvezi s škandaloznim stanjem na CVZ, smo izrazili pričakovanje, da Jušić kot neposredno odgovorna oseba za stanje stvari na CVZ odstopi. Kar se je potem dejansko tudi zgodilo in s čimer je, kot rečeno, nekdanji generalni direktor razbremenil policijo, pa konec koncev tudi ministra Poklukarja. Skratka, razkritja glede CVZ so zaenkrat dobila ustrezen epilog in s tem je za nas trenutno ta zgodba zaključena. Higienski minimum je z odstopom generalnega direktorja dosežen, zaupanje v policijo pa ubranjeno. V Levici se bomo ob interpelaciji v luči vsega povedanega vzdržali. Hvala lepa.",
         "True",
         "['Causal_Oversimplification' 'Exaggeration-Minimisation'\n 'Appeal_to_Hypocrisy' 'Loaded_Language' 'Whataboutism'\n 'Questioning_the_Reputation' 'Appeal_to_Values' 'Guilt_by_Association'\n 'Appeal_to_Popularity' 'Appeal_to_Fear-Prejudice']",
         "train",
         "['Je NSi takrat reagirala, kot bi se spodobilo od neke državotvorne in kredibilne politične stranke?'\n 'So oni kadarkoli kogarkoli kot Janševi koalicijski partnerji pozvali k sprejetju odgovornosti?'\n 'So po škandaloznem zaplinjanju Ljubljane k odstopu pozvali takratnega generalnega direktorja policije?'\n 'Toliko o vaši kredibilnosti']",
         "[]",
         "['Zamislite si, NSi problema z uporabo nacističnih in fašističnih simbolov nima, kajne, danes pa bi rušila ministra'\n 'Kot jih ni motil Poklukarjev predhodnik, nekdanji minister Hojs, človek, ki je bil zdaleč najbolj brutalni notranji minister v zgodovini te države'\n 'Bili so tiho kot miške, danes pa s polnimi jadri in pljuči uprizarjajo politični cirkus v optimističnem, čeprav Sizifovem poskusu destabilizirati vladajočo koalicijo in v žep pospraviti nekaj cenenih političnih točk'\n 'Mar res mislite v NSi, da imamo državljanke in državljani spomin zlate ribice, da je nastopila vsesplošna in množična amnezija in se nihče več ne spomni vašega pridnega asistiranja pri najbolj brutalnem obračunavanju z ljudstvom po taktirko Hojsa, kar ga pomnimo v tej državi'\n 'Glede na dvojna merila predlagateljev in njihove več kot očitno bizarne kriterije o tem kaj varnost je in kaj ni, res ne']",
         "[]",
         "['strašljivi novi krasni svet' 'brutalni'\n 'rumene jopiče, malikovalce Hitlerja' 'politični cirkus'\n 'Sizifovem poskusu' 'pridnega asistiranja' 'strokovnjaških ocenah']",
         "[]",
         "['kot vemo']",
         "[]",
         "[]",
         "[]",
         "['Oblast, ki je, kot vemo, povsem izgubila kompas, ko se je nad ljudstvo spravila z vodnim topom s solzivcem in pendreki, in je zaplinila širši center prestolnice'\n 'spomin zlate ribice, da je nastopila vsesplošna in množična amnezija'\n 'pridnega asistiranja pri najbolj brutalnem obračunavanju z ljudstvom po taktirko Hojsa, kar ga pomnimo v tej državi'\n 'Skratka, razkritja glede CVZ so zaenkrat dobila ustrezen epilog in s tem je za nas trenutno ta zgodba zaključena']",
         "[]",
         "[]",
         "[]",
         "['Bili smo kritični in jasni'\n 'v imenu politične higiene in transparentnosti']",
         "[]",
         "[]",
         "[]",
         "['dobrodošli v strašljivi novi krasni svet, ki ga vse bolj poosebljajo novi fašizmi'\n 'ko se je nad ljudstvo spravila z vodnim topom s solzivcem in pendreki, in je zaplinila širši center prestolnice']",
         "['Higienski minimum je z odstopom generalnega direktorja dosežen, zaupanje v policijo pa ubranjeno']",
         "[]",
         "[]",
         "['Niti to jih ni zmotilo, da je Hojs sam podal odstopno izjavo, Janša pa kuverte z odstopom ni nikdar odprl. Je NSi takrat reagirala, kot bi se spodobilo od neke državotvorne in kredibilne politične stranke? So oni kadarkoli kogarkoli kot Janševi koalicijski partnerji pozvali k sprejetju odgovornosti? So po škandaloznem zaplinjanju Ljubljane k odstopu pozvali takratnega generalnega direktorja policije?']",
         "[]",
         "['Zamislite si, NSi problema z uporabo nacističnih in fašističnih simbolov nima, kajne, danes pa bi rušila ministra'\n 'Minister, ki je s svojimi zakoni in s svojim obnašanjem omogočal in demonstriral politično vmešavanje v delo policije in še več političnega kadrovanja, ki je podrejal in ustrahoval tako policijo kot državljane, ki je policijo instrumentaliziral za represijo nad državljankami in državljani, ki so si kakorkoli drznili kritizirati Janševo oblast, v kateri je veselo kolaborirala tudi NSi']",
         "train",
         "GPT_41/v001/Appeal_to_Popularity",
         "Appeal_to_Popularity",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "1",
         "Yes, the Appeal to Popularity technique is used in the input.",
         "\"kot vemo\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The Appeal to Popularity technique is used in the input text through the phrase \\'kot vemo\\', which implies that the speaker is referencing a commonly accepted belief or understanding among the audience. This suggests that the argument is supported by the idea that \\'everyone knows\\' or agrees with this perspective, encouraging the audience to align with this widely held view.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[\"The Appeal to Popularity technique is used in the input text through the phrase 'kot vemo', which implies that the speaker is referencing a commonly accepted belief or understanding among the audience. This suggests that the argument is supported by the idea that 'everyone knows' or agrees with this perspective, encouraging the audience to align with this widely held view.\"]",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Popularity/train/si/train-si-part_0001.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The Appeal to Popularity technique is used in the input text through the phrase 'kot vemo', which implies that the speaker is referencing a commonly accepted belief or understanding among the audience. This suggests that the argument is supported by the idea that 'everyone knows' or agrees with this perspective, encouraging the audience to align with this widely held view.\", \"verdict\": true}"
        ],
        [
         "25",
         "pl_defence_22_05_2024_n02.txt",
         "8695",
         "10123",
         "PL",
         "Wciąż nie mamy wydanych brakujących\nrozporządzeń do pisanej na kolanie przez PiS ustawy o\nobronie Ojczyzny. Uzupełnijcie je jak najszybciej, zamiast\nzapowiadać, że to zrobicie. Wciąż nie mamy strategii\nrozwoju polskiego przemysłu obronnego. Co więcej,\nani Sztab Generalny, ani pan minister na ten\nprzemysł nie mają żadnego formalnego wpływu.\nUporządkujcie kompetencje w rządzie. Wciąż nie mamy\njednoznacznego wzmocnienia polskich służb\nwywiadowczych, mimo że tylko jedna z nich meldowała, że\nRosjanie wejdą na Ukrainę. Dofinansujmy i\nwzmocnijmy polskie służby wywiadowcze. Wciąż nie mamy\nszczegółów na temat polonizacji czołgu K2 i\nrozpoczęcia produkcji. Zróbcie to. Proszę o wystąpienie,\nw którym pan minister powie, jakie są efekty\nrządzenia, a nie jakie są zamiary. Wciąż nie mamy ustawy\no obronie cywilnej. Ustanówmy tę ustawę. Co stoi na\nprzeszkodzie? Wciąż nie mamy dyskusji, której\ntchórzliwie PiS unikał, o prawie do posiadania broni.\nŻołnierze zawodowi, funkcjonariusze służb nie mogą\nlegalnie posiadać broni, chodzić i z niej strzelać. (Oklaski)\nTo jest absurd. Wciąż nie mamy rezerwy, nie mamy\nzachęt do szkoleń, nie mamy planu ćwiczeń.\nDowódcy, z którymi rozmawiam i których pytam, czy są\nw stanie walczyć z patologicznym piciem na\nćwiczeniach rezerwy (Dzwonek), mówią, że nie mają na to\nwpływu. Przywróćcie wpływ na polskie wojsko\npolskim dowódcom. Przywróćcie honor polskiemu\nżołnierzowi. Dziękuję bardzo. (Oklaski",
         "True",
         "['Conversation_Killer' 'Exaggeration-Minimisation' 'Loaded_Language'\n 'Appeal_to_Hypocrisy' 'Appeal_to_Time' 'Flag_Waving' 'Slogans'\n 'Appeal_to_Values' 'Red_Herring' 'Repetition' 'Doubt']",
         "train",
         "[]",
         "[]",
         "['Uzupełnijcie je jak najszybciej, zamiast zapowiadać, że to zrobicie'\n 'Proszę o wystąpienie, w którym pan minister powie, jakie są efekty rządzenia, a nie jakie są zamiary']",
         "['To jest absurd']",
         "['pisanej na kolanie' 'tchórzliwie']",
         "['Wciąż nie mamy' 'Wciąż nie mamy' 'Wciąż nie mamy' 'Wciąż nie mamy'\n 'Wciąż nie mamy' 'Wciąż nie mamy' 'Wciąż nie mamy']",
         "[]",
         "['Co więcej, ani Sztab Generalny, ani pan minister na ten przemysł nie mają żadnego formalnego wpływu. Uporządkujcie kompetencje w rządzie'\n 'Wciąż nie mamy jednoznacznego wzmocnienia polskich służb wywiadowczych, mimo że tylko jedna z nich meldowała, że Rosjanie wejdą na Ukrainę'\n 'Dowódcy, z którymi rozmawiam i których pytam, czy są w stanie walczyć z patologicznym piciem na ćwiczeniach rezerwy (Dzwonek), mówią, że nie mają na to wpływu']",
         "['mimo że tylko jedna z nich meldowała, że Rosjanie wejdą na Ukrainę']",
         "['polonizacji czołgu K2'\n 'Przywróćcie wpływ na polskie wojsko polskim dowódcom'\n 'polskiemu żołnierzowi']",
         "['nie mamy planu ćwiczeń' 'patologicznym piciem']",
         "[]",
         "[]",
         "['jak najszybciej']",
         "['Przywróćcie honor polskiemu żołnierzowi']",
         "[]",
         "[]",
         "['Zróbcie to']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Red_Herring",
         "Red_Herring",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "1",
         "Yes, the Red Herring technique is used in the input.",
         "\"mimo że tylko jedna z nich meldowała, że Rosjanie wejdą na Ukrainę\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The Red Herring technique is used in the input text by diverting attention from the main issues regarding the lack of military preparedness and legislation to a specific claim about intelligence reports on Russian actions in Ukraine. This statement does not address the broader concerns raised about the defense strategy and instead shifts focus to a single instance of intelligence, which may distract the audience from the original topic of military readiness and legislative action.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "['The Red Herring technique is used in the input text by diverting attention from the main issues regarding the lack of military preparedness and legislation to a specific claim about intelligence reports on Russian actions in Ukraine. This statement does not address the broader concerns raised about the defense strategy and instead shifts focus to a single instance of intelligence, which may distract the audience from the original topic of military readiness and legislative action.']",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Red_Herring/train/pl/train-pl-part_0012.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The Red Herring technique is used in the input text by diverting attention from the main issues regarding the lack of military preparedness and legislation to a specific claim about intelligence reports on Russian actions in Ukraine. This statement does not address the broader concerns raised about the defense strategy and instead shifts focus to a single instance of intelligence, which may distract the audience from the original topic of military readiness and legislative action.\", \"verdict\": true}"
        ],
        [
         "26",
         "20240111_SHG_BG_62.txt",
         "5426",
         "5804",
         "BG",
         "И за финал, оказа се, че винаги, когато човек си мисли, че по-зле не може да стане, трябва добре да си помисли, защото може да се пръкне някое ПП и да докаже обратното. Оказа се, че най-голямото дъно в българския политически живот всъщност са „Продължаваме Промяната“. С тяхната поява започна безпрецедентно насъскване на едни групи хора от българите срещу други групи българи. ",
         "True",
         "['Causal_Oversimplification' 'Exaggeration-Minimisation'\n 'Questioning_the_Reputation' 'Name_Calling-Labeling']",
         "train",
         "['И за финал, оказа се, че винаги, когато човек си мисли, че по-зле не може да стане, трябва добре да си помисли, защото може да се пръкне някое ПП и да докаже обратното'\n 'Оказа се, че най-голямото дъно в българския политически живот всъщност са „Продължаваме Промяната“']",
         "['най-голямото дъно в българския политически живот']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['най-голямото дъно']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['С тяхната поява започна безпрецедентно насъскване на едни групи хора от българите срещу други групи българи']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/Repetition",
         "Repetition",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "0",
         "No, the Repetition technique is not used in the input.",
         "\"\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The input text does not demonstrate the use of the Repetition technique, as there are no words, phrases, stories, or imagery that are repeated to persuade the audience.\",\\n  \"updated_definition\": \"The speaker uses the same word, phrase, story, or imagery repeatedly with the hope that the repetition will lead to persuade the audience, specifically emphasizing the impact of the repeated elements on the audience\\'s perception.\"\\n}']",
         "[\"The speaker uses the same word, phrase, story, or imagery repeatedly with the hope that the repetition will lead to persuade the audience, specifically emphasizing the impact of the repeated elements on the audience's perception.\"]",
         "[None]",
         "[None]",
         "['The input text does not demonstrate the use of the Repetition technique, as there are no words, phrases, stories, or imagery that are repeated to persuade the audience.']",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/Repetition/train/bg/train-bg-part_0014.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text does not demonstrate the use of the Repetition technique, as there are no words, phrases, stories, or imagery that are repeated to persuade the audience.\", \"verdict\": false}"
        ],
        [
         "27",
         "SI_interpelation_interior_14.txt",
         "0",
         "3751",
         "SI",
         "Pa pojdimo malce konkretneje k izrednemu nadzoru delovanja Centra za zaščito in varovanje, zato ker je bilo o tem toliko polemike, zato ker nenazadnje se je z lastnim imenom v tem primeru izpostavila ena od specializiranih državnih tožilk in tudi zato, ker je o tem zelo jasno govoril predsednik Vlade. V odgovoru na interpelacijo zapišete: Prav tako bo treba spremeniti dolgoletno prakso dela v centru za varovanje in zaščito, saj dosedanji nadzori, reorganizacije, predlogi delovnih skupin ali menjave policijskih vodij niso spremenili ustaljene prakse, zato bo končno vzpostavljen red. Niso spremenili ustaljene prakse, zato bo končno vzpostavljen red. Minister, vi ste v odgovoru črno na belem priznali, da je na področju varovanja uradnih oseb na najvišjih položajih vzpostavljen nered, kar pomeni, da priznavate očitke državne tožilke, da se spremlja delo predvsem tistih, ki se jih varuje, nenazadnje tudi vas, gospod minister. Kar je bilo, kot navajate, teh nadzorov in reorganizacij že več, pa očitno nič rezultata, dokler ni pred kamere stopila specializirana državna tožilka, pa o tem niste javnosti povedali popolnoma nič in zaradi tega prevzemate tudi objektivno odgovornost. Če kot policijski minister ne morete zagotoviti, da ustrezno varujejo varovane osebe, kako naj vam verjamemo, da ustrezno varujejo nas vse ostale, ki nismo varovani. In naprej, v odgovoru zapišete: V Centru za varovanje in zaščito so bila leta 2011 sprejeta zlata pravila enote za varnost in zaščito kot nadgradnja kodeksa policijske etike. Glede na ugotovitve izrednega nadzora bo treba zlata pravila in kodeks znova vključiti v vsakdanje delo policistov Centra za varovanje in zaščito. Minister, se sploh zavedate težo teh zapisanih besed? Zakaj ta pravila niso bila vključena? Katera od teh? Mogoče skrbimo za zakonito izvajanje nalog? Ali mogoče spoštujemo in varujemo podatke in informacije v zvezi z delom? Ali mogoče prevzemamo odgovornost za svoja dejanja in dejanja podrejenih sodelavcev? Katerega od teh ali kar vse tri ne upoštevajo na Centru za zaščito in varovanje pod vašim vodstvom? In kot sami poveste, to stanje očitno traja že cel mandat. In zato je treba v bistvu na tem mestu najprej izraziti globok poklon državni tožilki, ki se je odločila prebiti ta policijski molk in to situacijo predstaviti javnosti. Verjamem, da ji ni bilo lahko, ampak očitno je našla to kot edino metodo, da se stvari začnejo odvijati v pravo smer. Kaj pa vi, gospod minister? Ali vi spoštujete zlata pravila? Ali torej prevzemate odgovornost za neodgovorna dejanja vaših sodelavcev, pod zaposlenih? Pa da ne bomo samo o objektivni odgovornosti. Avgusta ste bili seznanjeni s poročilom o stanju CVZ, to ste zapisali noter, to ste danes povedali, verjetno ste videli celotno poročilo, tudi tisti del, ki je nam ostalim ostal prikrit. Skratka, konec avgusta ste bili podrobno seznanjeni z razmerami. In nam povejte, kaj konkretno ste od konca oddaje naredili na tem področju do decembrske oddaje Tarče, torej, ko so zadeve prišle ven. Pa vam bom citiral vaše besede danes iz predstavitve v oddaji TV Slovenija Tarča lani decembra, na podlagi razkritih odklonov sem naslednji dan generalnemu direktorju policije izdal usmeritve in prav tako sem z elektronskim sporočilom zaprosil generalno državno tožilko naj se preiščejo sumi kaznivih dejanj. Vaše besede danes. Konec avgusta ste vedeli, ker ste imeli to v poročilu, do decembrske oddaje Tarča niste nič naredili, ko je tožilka šla v javnost in to predstavila, ste šli pa hitro za računalnik in tožilki napisali elektronsko pošto, češ, poglejte, preverite, če je kaj od tega res in generalnemu direktorju policije naročili, naj nekaj naredi od avgusta do decembra, pa gospod minister, je vaša subjektivna odgovornost.",
         "True",
         "['Causal_Oversimplification' 'Exaggeration-Minimisation' 'Loaded_Language'\n 'Appeal_to_Authority' 'Questioning_the_Reputation' 'Appeal_to_Values'\n 'Appeal_to_Popularity' 'Doubt']",
         "train",
         "['Konec avgusta ste vedeli, ker ste imeli to v poročilu, do decembrske oddaje Tarča niste nič naredili, ko je tožilka šla v javnost in to predstavila, ste šli pa hitro za računalnik in tožilki napisali elektronsko pošto']",
         "[]",
         "[]",
         "[]",
         "['prebiti ta policijski molk' 'zlata pravila?']",
         "[]",
         "['zato ker je bilo o tem toliko polemike']",
         "['Minister, vi ste v odgovoru črno na belem priznali, da je na področju varovanja uradnih oseb na najvišjih položajih vzpostavljen nered'\n 'Če kot policijski minister ne morete zagotoviti, da ustrezno varujejo varovane osebe, kako naj vam verjamemo, da ustrezno varujejo nas vse ostale, ki nismo varovani']",
         "[]",
         "[]",
         "['to stanje očitno traja že cel mandat']",
         "[]",
         "[]",
         "[]",
         "['Mogoče skrbimo za zakonito izvajanje nalog? Ali mogoče spoštujemo in varujemo podatke in informacije v zvezi z delom? Ali mogoče prevzemamo odgovornost za svoja dejanja in dejanja podrejenih sodelavcev?'\n 'Ali vi spoštujete zlata pravila?'\n 'Ali torej prevzemate odgovornost za neodgovorna dejanja vaših sodelavcev, pod zaposlenih?']",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Minister, vi ste v odgovoru črno na belem priznali, da je na področju varovanja uradnih oseb na najvišjih položajih vzpostavljen nered, kar pomeni, da priznavate očitke državne tožilke, da se spremlja delo predvsem tistih, ki se jih varuje, nenazadnje tudi vas, gospod minister']",
         "['zato ker nenazadnje se je z lastnim imenom v tem primeru izpostavila ena od specializiranih državnih tožilk in tudi zato, ker je o tem zelo jasno govoril predsednik Vlade'\n 'Minister, vi ste v odgovoru črno na belem priznali' 'kot sami poveste'\n 'Pa vam bom citiral vaše besede' 'Vaše besede danes']",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/Loaded_Language",
         "Loaded_Language",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "1",
         "Yes, the Loaded Language technique is used in the input.",
         "\"prebiti ta policijski molk zlata pravila?\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The Loaded Language technique is used in the input text through the phrase \\'prebiti ta policijski molk\\', which carries strong negative emotional implications about the state of communication and transparency within the police. This phrase suggests a serious issue that needs to be addressed, influencing the audience\\'s perception of the situation. The use of \\'zlata pravila\\' also implies a high standard that is not being met, further emphasizing the emotional weight of the argument.\",\\n  \"updated_definition\": \"Loaded Language technique involves the use of specific words and phrases with strong emotional implications (either positive or negative) to influence and convince the audience that an argument is valid, often by evoking strong feelings about the subject matter. It is also known as Appeal to Argument from Emotive Language.\"\\n}']",
         "['Loaded Language technique involves the use of specific words and phrases with strong emotional implications (either positive or negative) to influence and convince the audience that an argument is valid, often by evoking strong feelings about the subject matter. It is also known as Appeal to Argument from Emotive Language.']",
         "[None]",
         "[None]",
         "[\"The Loaded Language technique is used in the input text through the phrase 'prebiti ta policijski molk', which carries strong negative emotional implications about the state of communication and transparency within the police. This phrase suggests a serious issue that needs to be addressed, influencing the audience's perception of the situation. The use of 'zlata pravila' also implies a high standard that is not being met, further emphasizing the emotional weight of the argument.\"]",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/Loaded_Language/train/si/train-si-part_0000.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The Loaded Language technique is used in the input text through the phrase 'prebiti ta policijski molk', which carries strong negative emotional implications about the state of communication and transparency within the police. This phrase suggests a serious issue that needs to be addressed, influencing the audience's perception of the situation. The use of 'zlata pravila' also implies a high standard that is not being met, further emphasizing the emotional weight of the argument.\", \"verdict\": true}"
        ],
        [
         "28",
         "pl_defence_22_05_2024_n02.txt",
         "520",
         "805",
         "PL",
         "Przede wszystkim mamy olbrzymi bałagan w dowodzeniu.\nSystem kierowania i dowodzenia Siłami\nZbrojnymi był kilkanaście razy zmieniany od czasu\nupadku PRL-u. Jest skomplikowany, jest niejasny,\na generalny dowódca rodzajów Sił Zbrojnych do tej\npory dowodził co najwyżej pułkiem specjalnym.",
         "True",
         "['Doubt']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['System kierowania i dowodzenia Siłami Zbrojnymi był kilkanaście razy zmieniany od czasu upadku PRL-u. Jest skomplikowany, jest niejasny, a generalny dowódca rodzajów Sił Zbrojnych do tej pory dowodził co najwyżej pułkiem specjalnym']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/Loaded_Language",
         "Loaded_Language",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "0",
         "No, the Loaded Language technique is not used in the input.",
         "\"\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The input text does not contain any specific words or phrases with strong emotional implications that would influence or convince the audience. The language used is factual and descriptive without employing Loaded Language.\",\\n  \"updated_definition\": \"Loaded Language technique involves the use of specific words and phrases with strong emotional implications (either positive or negative) to influence and convince the audience that an argument is valid, often through emotionally charged language that evokes a strong response.\"\\n}']",
         "['Loaded Language technique involves the use of specific words and phrases with strong emotional implications (either positive or negative) to influence and convince the audience that an argument is valid, often through emotionally charged language that evokes a strong response.']",
         "[None]",
         "[None]",
         "['The input text does not contain any specific words or phrases with strong emotional implications that would influence or convince the audience. The language used is factual and descriptive without employing Loaded Language.']",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/Loaded_Language/train/pl/train-pl-part_0003.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text does not contain any specific words or phrases with strong emotional implications that would influence or convince the audience. The language used is factual and descriptive without employing Loaded Language.\", \"verdict\": false}"
        ],
        [
         "29",
         "20240704_URW_BG_26.txt",
         "206",
         "255",
         "BG",
         "ИЯ ВАСИЛЕВА (ВЕЛИЧИЕ, от място): Процедура!\n\nПРЕД",
         "False",
         "[]",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/Appeal_to_Time",
         "Appeal_to_Time",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "0",
         "No, the Appeal to Time technique is not used in the input.",
         "\"\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The input text does not contain any elements that suggest the Appeal to Time technique was used, as there is no reference to the timeliness of an action or the idea that the time has come for a particular action.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "['The input text does not contain any elements that suggest the Appeal to Time technique was used, as there is no reference to the timeliness of an action or the idea that the time has come for a particular action.']",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/Appeal_to_Time/train/bg/train-bg-part_0022.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text does not contain any elements that suggest the Appeal to Time technique was used, as there is no reference to the timeliness of an action or the idea that the time has come for a particular action.\", \"verdict\": false}"
        ],
        [
         "30",
         "pl_defence_22_05_2024_n01.txt",
         "8339",
         "10002",
         "PL",
         "Proszę państwa, jeśli chodzi o te zakupy, to one\nwszystkie były konsultowane, były wynikiem naszych rozmów w Radzie Modernizacji Technicznej\nz przeważającym, decydującym głosem Sztabu Generalnego Wojska Polskiego. Zmieniłem sposób zamawiania sprzętu wojskowego dla polskiego wojska,\nbo on był sprzeczny wewnętrznie. To była sytuacja,\nw której nie można było pójść naprzód, więc udrożniłem te procesy. Potem, kiedy przyszedł rok 2022,\nkiedy po raz kolejny Rosja napadła na Ukrainę, nawiązałem relacje z Koreą Południową. Dlaczego to\nzrobiłem? Dlatego że Korea Południowa posiada olbrzymi potencjał produkcyjny, jeśli chodzi o przemysł\nzbrojeniowy. Uważam za jeden z naszych sukcesów\nto, że w tak krótkim czasie doprowadziliśmy do tego,\nże w Wojsku Polskim już są czołgi K2, że obok\nHIMARS-ów, o których powiedziałem, są Chunmoo,\nczyli artyleria rakietowa o zasięgu do 300 km, że są\nsamoloty szkolno-bojowe FA-50. Pan powiedział, że\npiloci tak dużo zarabiają. Trzeba szkolić pilotów.\nFA-50 zostały zaprojektowane przez Lockheed Martin, a więc są taką mniejszą, to prawda, wersją\nF-16. W Wojsku Polskim, kiedy przyszliśmy do\nwładzy, w zasadzie tylko F-16 stanowiły jakąś siłę\nbojową. Pozostały sprzęt wojskowy był postsowiecki,\nbył zużyty. To był obraz nędzy i rozpaczy, a my doprowadziliśmy do tego, że dziś Wojsko Polskie liczy\nponad 200 tys. żołnierzy. Tylko jeszcze cele… Też\npan o tym nie wspomniał. Co najmniej 300 tys. żołnierzy. Można powiedzieć, że 300 tys. żołnierzy wojsk\noperacyjnych i 50 tys. żołnierzy Wojsk Obrony Terytorialnej – to powinien być nasz wspólny cel, mówię\no państwie polskim (Oklaski), bo w ten sposób możemy realnie odstraszyć agresora.",
         "True",
         "['Loaded_Language' 'Flag_Waving' 'Obfuscation-Vagueness-Confusion'\n 'Appeal_to_Authority' 'Name_Calling-Labeling' 'Red_Herring'\n 'Appeal_to_Fear-Prejudice']",
         "train",
         "[]",
         "['postsowiecki']",
         "[]",
         "[]",
         "['obraz nędzy i rozpaczy']",
         "[]",
         "[]",
         "[]",
         "['Pan powiedział, że piloci tak dużo zarabiają']",
         "['mówię o państwie polskim']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['To była sytuacja, w której nie można było pójść naprzód, więc udrożniłem te procesy']",
         "[]",
         "[]",
         "['realnie odstraszyć agresora']",
         "[]",
         "['jeśli chodzi o te zakupy, to one wszystkie były konsultowane, były wynikiem naszych rozmów w Radzie Modernizacji Technicznej z przeważającym, decydującym głosem Sztabu Generalnego Wojska Polskiego']",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Authority",
         "Appeal_to_Authority",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "1",
         "Yes, the Appeal to Authority technique is used in the input.",
         "\"jeśli chodzi o te zakupy, to one wszystkie były konsultowane, były wynikiem naszych rozmów w Radzie Modernizacji Technicznej z przeważającym, decydującym głosem Sztabu Generalnego Wojska Polskiego\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The Appeal to Authority technique is used in the input text by referencing the \\'Sztab Generalny Wojska Polskiego\\' as an authority that had a decisive voice in the consultations regarding military purchases. This aligns with the definition, as the speaker emphasizes the weight of this authority to justify the decisions made.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[\"The Appeal to Authority technique is used in the input text by referencing the 'Sztab Generalny Wojska Polskiego' as an authority that had a decisive voice in the consultations regarding military purchases. This aligns with the definition, as the speaker emphasizes the weight of this authority to justify the decisions made.\"]",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Authority/train/pl/train-pl-part_0002.parquet",
         "[None]",
         "[None]",
         "train",
         "{\"description\": \"The Appeal to Authority technique is used in the input text by referencing the 'Sztab Generalny Wojska Polskiego' as an authority that had a decisive voice in the consultations regarding military purchases. This aligns with the definition, as the speaker emphasizes the weight of this authority to justify the decisions made.\", \"verdict\": true}"
        ],
        [
         "31",
         "20231208_URW_BG_75.txt",
         "5038",
         "5278",
         "BG",
         "И въпросът не е финансов, колега Гуцанов, тъй като националната сигурност – какво ни струват на нас парите, като ще останем без армия. Няма ВВС, няма противовъздушна отбрана. Новите еничари подлагат Република България на изключителен риск. ",
         "True",
         "['Loaded_Language' 'Name_Calling-Labeling' 'Appeal_to_Fear-Prejudice']",
         "train",
         "[]",
         "['Новите еничари']",
         "[]",
         "[]",
         "['изключителен']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Новите еничари подлагат Република България на изключителен риск']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/Loaded_Language",
         "Loaded_Language",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "1",
         "Yes, the Loaded Language technique is used in the input.",
         "\"изключителен\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The Loaded Language technique was used in the input text through the word \\'изключителен\\' (exceptional), which carries a strong negative emotional implication regarding the risk posed to national security. This word is intended to influence the audience\\'s perception of the seriousness of the situation, aligning with the definition of Loaded Language as it aims to convince the audience of the validity of the argument by evoking strong emotions.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[\"The Loaded Language technique was used in the input text through the word 'изключителен' (exceptional), which carries a strong negative emotional implication regarding the risk posed to national security. This word is intended to influence the audience's perception of the seriousness of the situation, aligning with the definition of Loaded Language as it aims to convince the audience of the validity of the argument by evoking strong emotions.\"]",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/Loaded_Language/train/bg/train-bg-part_0017.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The Loaded Language technique was used in the input text through the word '\\u0438\\u0437\\u043a\\u043b\\u044e\\u0447\\u0438\\u0442\\u0435\\u043b\\u0435\\u043d' (exceptional), which carries a strong negative emotional implication regarding the risk posed to national security. This word is intended to influence the audience's perception of the seriousness of the situation, aligning with the definition of Loaded Language as it aims to convince the audience of the validity of the argument by evoking strong emotions.\", \"verdict\": true}"
        ],
        [
         "32",
         "pl_abortion_11_04_2024_n01.txt",
         "268",
         "371",
         "PL",
         "Panowie, halo, szanujmy wszystkich gości.\nDziękujemy wam bardzo za przybycie.\nSuper, bardzo dziękujemy.",
         "False",
         "[]",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/Repetition",
         "Repetition",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "0",
         "No, the Repetition technique is not used in the input.",
         "\"\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The Repetition technique was not used in the input text as there are no repeated words, phrases, or imagery that aim to persuade the audience.\",\\n  \"updated_definition\": \"The speaker uses the same word, phrase, story, or imagery repeatedly with the hope that the repetition will lead to persuade the audience; this includes instances where the same elements are reiterated to emphasize a point.\"\\n}']",
         "['The speaker uses the same word, phrase, story, or imagery repeatedly with the hope that the repetition will lead to persuade the audience; this includes instances where the same elements are reiterated to emphasize a point.']",
         "[None]",
         "[None]",
         "['The Repetition technique was not used in the input text as there are no repeated words, phrases, or imagery that aim to persuade the audience.']",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/Repetition/train/pl/train-pl-part_0006.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The Repetition technique was not used in the input text as there are no repeated words, phrases, or imagery that aim to persuade the audience.\", \"verdict\": false}"
        ],
        [
         "33",
         "RU_migrants_5.txt",
         "1784",
         "2009",
         "RU",
         "ый гражданин знает, что закон будет строг, но справедлив, что ни один преступник не уйдет от наказания вне зависимости от статуса, национальной и религиозной принадлежности, тогда и воцаряется межнациональный мир.\n\nИ тут дегр",
         "True",
         "['Consequential_Oversimplification']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['И когда каждый гражданин знает, что закон будет строг, но справедлив, что ни один преступник не уйдет от наказания вне зависимости от статуса, национальной и религиозной принадлежности, тогда и воцаряется межнациональный мир']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/Consequential_Oversimplification",
         "Consequential_Oversimplification",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "1",
         "Yes, the Consequential Oversimplification technique is used in the input.",
         "\"И когда каждый гражданин знает, что закон будет строг, но справедлив, что ни один преступник не уйдет от наказания вне зависимости от статуса, национальной и религиозной принадлежности, тогда и воцаряется межнациональный мир\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The input text uses the Consequential Oversimplification technique by asserting that if every citizen knows the law will be strict and fair, then this will lead to interethnic peace. This simplifies the complex relationship between law enforcement and societal harmony by implying a direct and inevitable positive outcome (interethnic peace) from a single condition (knowledge of strict and fair law), without providing evidence for this causal link.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "['The input text uses the Consequential Oversimplification technique by asserting that if every citizen knows the law will be strict and fair, then this will lead to interethnic peace. This simplifies the complex relationship between law enforcement and societal harmony by implying a direct and inevitable positive outcome (interethnic peace) from a single condition (knowledge of strict and fair law), without providing evidence for this causal link.']",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/Consequential_Oversimplification/train/ru/train-ru-part_0002.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text uses the Consequential Oversimplification technique by asserting that if every citizen knows the law will be strict and fair, then this will lead to interethnic peace. This simplifies the complex relationship between law enforcement and societal harmony by implying a direct and inevitable positive outcome (interethnic peace) from a single condition (knowledge of strict and fair law), without providing evidence for this causal link.\", \"verdict\": true}"
        ],
        [
         "34",
         "pl_current_affairs_09_01_2025_n02.txt",
         "8069",
         "9438",
         "PL",
         "W decyzji generalny dyrektor ochrony środowiska\npodkreśla, że poważne ustawowe braki w raporcie\no oddziaływaniu na środowisko nie pozwalały na wydanie takiej decyzji. Po pierwsze, zabrakło tam wariantowania przedsięwzięcia. Raport nie zawierał ustawowo wymaganej analizy wariantowej z uwzględnieniem opisu oddziaływania poszczególnych wariantów\nna środowisko. W oparciu o informacje zawarte w raporcie nie można było wskazać, który wariant jest\nnajkorzystniejszy dla środowiska i czy istnieją w ogóle przesłanki wyboru innego wariantu niż ten wskazany do realizacji przez inwestora. Inwestor nie przeanalizował innych działań w zakresie możliwości\nosiągnięcia celu środowiskowego środkami mniej\ndolegliwymi dla środowiska i nie udowodnił, że ten\ncel nie może być za ich pomocą osiągnięty. Raport nie\nzawierał również opisu oddziaływania przedsięwzięcia na obszary Natura 2000, na rezerwaty przyrody\nczy opisu działań mających na celu jakąkolwiek minimalizację, kompensację negatywnych oddziaływań\nprzedsięwzięcia w tym zakresie. Na podstawie informacji znajdujących się w raporcie nie można było\nwykluczyć w żaden sposób, że to przedsięwzięcie nie\nbędzie znacząco negatywnie oddziaływać na obszary\nNatura 2000 typu Włocławska Dolina Wisły, Nieszawska Dolina Wisły, Dolina Dolnej Wisły, Dolny\nDunajec, Dorzecze Górnego Sanu, Wisłoka z dopływami, rezerwat przyrody Kulin.",
         "True",
         "['Appeal_to_Authority' 'Appeal_to_Values']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Na podstawie informacji znajdujących się w raporcie nie można było wykluczyć w żaden sposób, że to przedsięwzięcie nie będzie znacząco negatywnie oddziaływać na obszary Natura 2000 typu Włocławska Dolina Wisły, Nieszawska Dolina Wisły, Dolina Dolnej Wisły, Dolny Dunajec, Dorzecze Górnego Sanu, Wisłoka z dopływami, rezerwat przyrody Kulin']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['W decyzji generalny dyrektor ochrony środowiska podkreśla, że poważne ustawowe braki w raporcie o oddziaływaniu na środowisko nie pozwalały na wydanie takiej decyzji']",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/Appeal_to_Pity",
         "Appeal_to_Pity",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "0",
         "No, the Appeal to Pity technique is not used in the input.",
         "\"\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The input text discusses the deficiencies in an environmental report and the implications of these shortcomings without attempting to evoke feelings of pity, sympathy, or guilt. It focuses on factual analysis and logical reasoning regarding environmental impacts, which aligns with the expert\\'s verdict that the Appeal to Pity technique is not used.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "[\"The input text discusses the deficiencies in an environmental report and the implications of these shortcomings without attempting to evoke feelings of pity, sympathy, or guilt. It focuses on factual analysis and logical reasoning regarding environmental impacts, which aligns with the expert's verdict that the Appeal to Pity technique is not used.\"]",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/Appeal_to_Pity/train/pl/train-pl-part_0007.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text discusses the deficiencies in an environmental report and the implications of these shortcomings without attempting to evoke feelings of pity, sympathy, or guilt. It focuses on factual analysis and logical reasoning regarding environmental impacts, which aligns with the expert's verdict that the Appeal to Pity technique is not used.\", \"verdict\": false}"
        ],
        [
         "35",
         "RU_discrediting_the_west_4.txt",
         "1327",
         "1390",
         "RU",
         "До превращения комка в гигантский снежный ком осталось немного.",
         "True",
         "['Exaggeration-Minimisation']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Authority",
         "Appeal_to_Authority",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Appeal to Authority technique is not used in the input.",
         "\"\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The input text does not reference any authority or entity to support its claims, thus the Appeal to Authority technique is not used.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "['The input text does not reference any authority or entity to support its claims, thus the Appeal to Authority technique is not used.']",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Authority/train/ru/train-ru-part_0001.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text does not reference any authority or entity to support its claims, thus the Appeal to Authority technique is not used.\", \"verdict\": false}"
        ],
        [
         "36",
         "20231208_URW_BG_71.txt",
         "0",
         "433",
         "BG",
         "НИКОЛАЙ ДРЕНЧЕВ (ВЪЗРАЖДАНЕ): Господин Председател, уважаеми дами и господа народни представители! Кой какво прави в нашата държава, каквито и проблеми да се решават – социални, образователни, здравеопазващи, Народното събрание денем и нощем се занимава с изпращане на оръжие в Украйна, откъдето, каквото, както се намери по складове, по хамбари, по паланки се пакетира, минава през Народното събрание и се изнася към Източния фронт.",
         "True",
         "['Exaggeration-Minimisation' 'Questioning_the_Reputation']",
         "train",
         "['Кой какво прави в нашата държава, каквито и проблеми да се решават – социални, образователни, здравеопазващи, Народното събрание денем и нощем се занимава с изпращане на оръжие в Украйна, откъдето, каквото, както се намери по складове, по хамбари, по паланки се пакетира, минава през Народното събрание и се изнася към Източния фронт']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Народното събрание денем и нощем се занимава с изпращане на оръжие в Украйна, откъдето, каквото, както се намери по складове, по хамбари, по паланки се пакетира']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/Loaded_Language",
         "Loaded_Language",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "0",
         "No, the Loaded Language technique is not used in the input.",
         "\"\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The input text does not contain specific words or phrases with strong emotional implications intended to influence the audience. The language used is factual and descriptive without the use of loaded terms that evoke strong positive or negative emotions.\",\\n  \"updated_definition\": \"Loaded Language technique involves the use of specific words and phrases with strong emotional implications (either positive or negative) to influence and convince the audience that an argument is valid, often through emotionally charged language that elicits a strong response.\"\\n}']",
         "['Loaded Language technique involves the use of specific words and phrases with strong emotional implications (either positive or negative) to influence and convince the audience that an argument is valid, often through emotionally charged language that elicits a strong response.']",
         "[None]",
         "[None]",
         "['The input text does not contain specific words or phrases with strong emotional implications intended to influence the audience. The language used is factual and descriptive without the use of loaded terms that evoke strong positive or negative emotions.']",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/Loaded_Language/train/bg/train-bg-part_0016.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text does not contain specific words or phrases with strong emotional implications intended to influence the audience. The language used is factual and descriptive without the use of loaded terms that evoke strong positive or negative emotions.\", \"verdict\": false}"
        ],
        [
         "37",
         "20231208_URW_BG_71.txt",
         "5801",
         "6564",
         "BG",
         "Знаете ли, че тези машини с новите двигатели могат да изпълняват функции, близки до тези машини, които гласувахте само преди една седмица да се закупят от САЩ – страйкърите, на цена от 1 млрд. и 370 млн. долара? Наясно ли сте, че и като години са едни и същи, и като модел на производство са близки един до друг?! Предполагам, че не сте! Защото, страйкърите – и към тях също има доклад на Сухопътните войски от преди години, които казват, че не ги искат, и то преди около 10-ина години. Кое правите в момента? Продаваме едни бойни машини, даваме ги, подаряваме ги и купуваме на тяхно място други за милиарди от бедна България, която подпомага най-голямата икономика на света и най-голямата военна сила на света. Е, това, ако не е национално предателство, кое е?! ",
         "True",
         "['Appeal_to_Hypocrisy' 'Questioning_the_Reputation'\n 'Name_Calling-Labeling' 'Doubt']",
         "train",
         "['Е, това, ако не е национално предателство, кое е?!']",
         "['национално предателство']",
         "['Знаете ли, че тези машини с новите двигатели могат да изпълняват функции, близки до тези машини, които гласувахте само преди една седмица да се закупят от САЩ – страйкърите, на цена от 1 млрд. и 370 млн. долара? Наясно ли сте, че и като години са едни и същи, и като модел на производство са близки един до друг?!'\n 'Защото, страйкърите – и към тях също има доклад на Сухопътните войски от преди години, които казват, че не ги искат, и то преди около 10-ина години. Кое правите в момента? Продаваме едни бойни машини, даваме ги, подаряваме ги и купуваме на тяхно място други за милиарди от бедна България, която подпомага най-голямата икономика на света и най-голямата военна сила на света']",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Предполагам, че не сте!']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/Whataboutism",
         "Whataboutism",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "0",
         "No, the Whataboutism technique is not used in the input.",
         "\"\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The input text does not employ the Whataboutism technique, as it does not attempt to discredit an opponent\\'s position by diverting the discussion to a different issue or by making a counteraccusation. Instead, it focuses on criticizing the current actions regarding military purchases without shifting the topic to another argument or issue.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "[\"The input text does not employ the Whataboutism technique, as it does not attempt to discredit an opponent's position by diverting the discussion to a different issue or by making a counteraccusation. Instead, it focuses on criticizing the current actions regarding military purchases without shifting the topic to another argument or issue.\"]",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/Whataboutism/train/bg/train-bg-part_0010.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text does not employ the Whataboutism technique, as it does not attempt to discredit an opponent's position by diverting the discussion to a different issue or by making a counteraccusation. Instead, it focuses on criticizing the current actions regarding military purchases without shifting the topic to another argument or issue.\", \"verdict\": false}"
        ],
        [
         "38",
         "20240112_SHG_BG_60.txt",
         "83",
         "539",
         "BG",
         "Преди да започна въпроса, ще споделя някои цифри, които са от официални доклади на европейски институции. Доклад за убежището за 2023 г. на Агенцията на Европейския съюз в областта на убежището, публикуван преди една седмица. Според този доклад за 2020 г. в България има 3525 молби, които са подадени за убежище. През 2021 г. са 11 000, през 2022 г. са 20 390, през 2023 г. тези хора, които са подали молба за постоянно убежище в България, са вече 22 213. ",
         "False",
         "[]",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/Appeal_to_Time",
         "Appeal_to_Time",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "0",
         "No, the Appeal to Time technique is not used in the input.",
         "\"\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The Appeal to Time technique is not used in the input text as it does not center around the idea that the time has come for a particular action. The text presents statistics from reports without suggesting urgency or timeliness for action based on those statistics.\",\\n  \"updated_definition\": \"The argument is centered around the idea that time has come for a particular action, emphasizing the urgency or timeliness of the idea as part of the argument.\"\\n}']",
         "['The argument is centered around the idea that time has come for a particular action, emphasizing the urgency or timeliness of the idea as part of the argument.']",
         "[None]",
         "[None]",
         "['The Appeal to Time technique is not used in the input text as it does not center around the idea that the time has come for a particular action. The text presents statistics from reports without suggesting urgency or timeliness for action based on those statistics.']",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/Appeal_to_Time/train/bg/train-bg-part_0014.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The Appeal to Time technique is not used in the input text as it does not center around the idea that the time has come for a particular action. The text presents statistics from reports without suggesting urgency or timeliness for action based on those statistics.\", \"verdict\": false}"
        ],
        [
         "39",
         "pl_abortion_11_04_2024_n04.txt",
         "2892",
         "3287",
         "PL",
         "O projekcie Lewicy liberalizującym aborcję, przy\nktórym właśnie jako wnioskodawczynie z panią\nministrą Kotulą zabieramy głos, wiecie już wszystko.\nCzas najwyższy, by po ponad 30 latach hipokryzji,\nzakłamania, dyskryminacji, karania za empatię i\npoświęcania praw kobiet w imię innych ważnych spraw\nuchwalić projekt Lewicy liberalizujący aborcję.\n(Poseł Czesław Hoc: Litości.)\n(Głos z sali: Czas.)",
         "True",
         "['Appeal_to_Time' 'Appeal_to_Values']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Czas najwyższy, by po ponad 30 latach hipokryzji, zakłamania, dyskryminacji, karania za empatię i poświęcania praw kobiet w imię innych ważnych spraw uchwalić projekt Lewicy liberalizujący aborcję']",
         "['po ponad 30 latach hipokryzji, zakłamania, dyskryminacji, karania za empatię i poświęcania praw kobiet w imię innych ważnych spraw']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Name_Calling-Labeling",
         "Name_Calling-Labeling",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Name Calling-Labeling technique is not used in the input.",
         "\"\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The input text does not contain any instances of Name Calling - Labeling, as it does not direct loaded labels at individuals or groups in an insulting or demeaning way. The language used focuses on the project and its implications rather than characterizing individuals or groups with negative labels.\",\\n  \"updated_definition\": \"Name Calling - Labeling is a form of argument in which loaded labels are directed at an individual or a group, typically in an insulting or demeaning way, focusing on qualitative judgments that disregard facts. This technique is characterized by the use of adjectives and nouns as labels that refer to personal characteristics, opinions, or affiliations, often in a manipulative manner. It is distinct from Loaded Language in that it specifically concerns the characterization of the subject rather than presenting a full argument.\"\\n}']",
         "['Name Calling - Labeling is a form of argument in which loaded labels are directed at an individual or a group, typically in an insulting or demeaning way, focusing on qualitative judgments that disregard facts. This technique is characterized by the use of adjectives and nouns as labels that refer to personal characteristics, opinions, or affiliations, often in a manipulative manner. It is distinct from Loaded Language in that it specifically concerns the characterization of the subject rather than presenting a full argument.']",
         "[None]",
         "[None]",
         "['The input text does not contain any instances of Name Calling - Labeling, as it does not direct loaded labels at individuals or groups in an insulting or demeaning way. The language used focuses on the project and its implications rather than characterizing individuals or groups with negative labels.']",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Name_Calling-Labeling/train/pl/train-pl-part_0019.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text does not contain any instances of Name Calling - Labeling, as it does not direct loaded labels at individuals or groups in an insulting or demeaning way. The language used focuses on the project and its implications rather than characterizing individuals or groups with negative labels.\", \"verdict\": false}"
        ],
        [
         "40",
         "20231208_URW_BG_73.txt",
         "1849",
         "2732",
         "BG",
         "Оттам нататък, чухте и от – казвам проруската ВЪЗРАЖДАНЕ, но за съжаление, и БСП вече е в това число. (Шум и реплики.) Даваме милиарди, те не казват колко, защото нямат никаква представа какво се дава. (Шум и реплики.)  Истината обаче е една – милиарди се дават в обратната посока. И това не е някакъв факт, от който трябва да изпитваме радост, защото там умират хора, но България получи над 7 милиарда, защото нашата военна индустрия е в подем, тя работи, тя получава заплащане и продукцията, която произвежда, се заплаща. Тези данъци влизат в нашата хазна. Български работници работят в своите заводи. И няма да спра да напомням, че именно проруската партия ВЪЗРАЖДАНЕ се опита да затвори завод „Арсенал“, български завод, произвеждащ българска продукция (реплика от ВЪЗРАЖДАНЕ: „Палячо!“), плащаш данъци в българската хазна, но за съжаление, тази продукция не се харесва на Русия.",
         "True",
         "['Conversation_Killer' 'Appeal_to_Hypocrisy' 'Flag_Waving'\n 'Questioning_the_Reputation' 'Name_Calling-Labeling'\n 'Guilt_by_Association' 'Appeal_to_Fear-Prejudice']",
         "train",
         "['милиарди се дават в обратната посока'\n 'И няма да спра да напомням, че именно проруската партия ВЪЗРАЖДАНЕ се опита да затвори завод „Арсенал“, български завод, произвеждащ българска продукция']",
         "['проруската ВЪЗРАЖДАНЕ' 'проруската партия ВЪЗРАЖДАНЕ' 'Палячо!']",
         "['Даваме милиарди, те не казват колко, защото нямат никаква представа какво се дава']",
         "['Истината обаче е една']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['но България получи над 7 милиарда, защото нашата военна индустрия е в подем, тя работи, тя получава заплащане и продукцията, която произвежда, се заплаща. Тези данъци влизат в нашата хазна. Български работници работят в своите заводи']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['И това не е някакъв факт, от който трябва да изпитваме радост, защото там умират хора']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Оттам нататък, чухте и от – казвам проруската ВЪЗРАЖДАНЕ, но за съжаление, и БСП вече е в това число'\n 'плащаш данъци в българската хазна, но за съжаление, тази продукция не се харесва на Русия']",
         "train",
         "GPT_41/v001/Guilt_by_Association",
         "Guilt_by_Association",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "1",
         "Yes, the Guilt by Association technique is used in the input.",
         "\"Оттам нататък, чухте и от – казвам проруската ВЪЗРАЖДАНЕ, но за съжаление, и БСП вече е в това число плащаш данъци в българската хазна, но за съжаление, тази продукция не се харесва на Русия\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The Guilt by Association technique is used in the input text by linking the \\'проруската ВЪЗРАЖДАНЕ\\' party with negative connotations associated with being pro-Russian. The speaker implies that this association is detrimental, especially in the context of the party\\'s actions against a Bulgarian factory, suggesting that their stance is harmful to national interests. This aligns with the definition, as it attacks the party by associating it with a negative perception of pro-Russian sentiment.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[\"The Guilt by Association technique is used in the input text by linking the 'проруската ВЪЗРАЖДАНЕ' party with negative connotations associated with being pro-Russian. The speaker implies that this association is detrimental, especially in the context of the party's actions against a Bulgarian factory, suggesting that their stance is harmful to national interests. This aligns with the definition, as it attacks the party by associating it with a negative perception of pro-Russian sentiment.\"]",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Guilt_by_Association/train/bg/train-bg-part_0018.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The Guilt by Association technique is used in the input text by linking the '\\u043f\\u0440\\u043e\\u0440\\u0443\\u0441\\u043a\\u0430\\u0442\\u0430 \\u0412\\u042a\\u0417\\u0420\\u0410\\u0416\\u0414\\u0410\\u041d\\u0415' party with negative connotations associated with being pro-Russian. The speaker implies that this association is detrimental, especially in the context of the party's actions against a Bulgarian factory, suggesting that their stance is harmful to national interests. This aligns with the definition, as it attacks the party by associating it with a negative perception of pro-Russian sentiment.\", \"verdict\": true}"
        ],
        [
         "41",
         "pl_current_affairs_09_01_2025_n02.txt",
         "7617",
         "7814",
         "PL",
         "Dzisiaj generalny dyrektor ochrony środowiska\nde facto powtórzył te argumenty, które były argumentami niepozostawiającymi żadnych wątpliwości.\n(Poseł Joanna Borowiak: Dlatego przegrał pan\nKurtyka.)",
         "True",
         "['Conversation_Killer' 'Appeal_to_Authority']",
         "train",
         "[]",
         "[]",
         "[]",
         "['które były argumentami niepozostawiającymi żadnych wątpliwości']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Dzisiaj generalny dyrektor ochrony środowiska de facto powtórzył te argumenty, które były argumentami niepozostawiającymi żadnych wątpliwości']",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/Conversation_Killer",
         "Conversation_Killer",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "1",
         "Yes, the Conversation Killer technique is used in the input.",
         "\"które były argumentami niepozostawiającymi żadnych wątpliwości\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The Conversation Killer technique was used in the input text through the phrase \\'argumentami niepozostawiającymi żadnych wątpliwości\\', which discourages further discussion by implying that the arguments presented are definitive and beyond question. This aligns with the definition, as it stifles critical thought and suggests that there is no room for debate.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[\"The Conversation Killer technique was used in the input text through the phrase 'argumentami niepozostawiającymi żadnych wątpliwości', which discourages further discussion by implying that the arguments presented are definitive and beyond question. This aligns with the definition, as it stifles critical thought and suggests that there is no room for debate.\"]",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/Conversation_Killer/train/pl/train-pl-part_0007.parquet",
         "[None]",
         "[None]",
         "train",
         "{\"description\": \"The Conversation Killer technique was used in the input text through the phrase 'argumentami niepozostawiaj\\u0105cymi \\u017cadnych w\\u0105tpliwo\\u015bci', which discourages further discussion by implying that the arguments presented are definitive and beyond question. This aligns with the definition, as it stifles critical thought and suggests that there is no room for debate.\", \"verdict\": true}"
        ],
        [
         "42",
         "pl_abortion_11_04_2024_n05.txt",
         "9681",
         "10556",
         "PL",
         "Dziś jesteśmy w demograficznym kryzysie. Polki\nnie chcą rodzić dzieci w Polsce, która nie jest dla nich\nbezpieczna pod żadnym względem. Mówią: boję się\nbyć w ciąży, bo dziewczyny w moim wieku umierają.\nUmarły pan Iza, pani Agnieszka, pani Marta, pani\nDorota. Dlatego Koalicja Obywatelska przygotowała\ni przedstawia projekt ustawy o świadomym rodzicielstwie.\nZakaz aborcji w Polsce to restrykcyjne prawo,\nktóre zagraża zdrowiu, życiu i bezpieczeństwu kobiet,\na nasz projekt, projekt Koalicji Obywatelskiej,\nprzywraca kobietom wolność wyboru, przywraca kobietom\ngodność, przywraca kobietom podmiotowość. Zakłada\nmożliwość bezpiecznego i bezpłatnego przerywania\nciąży do 12 tygodnia jej trwania oraz po 12 tygodniu\nw określonych okolicznościach. Aborcja musi być\nbezpieczna, aborcja musi być legalna. Aborcja musi być\ndostępna, a kobieta musi być bezpieczna.\nDziękuję. (Oklaski)",
         "True",
         "['Conversation_Killer' 'Causal_Oversimplification' 'Slogans'\n 'Whataboutism' 'Appeal_to_Values' 'Repetition' 'Appeal_to_Fear-Prejudice']",
         "train",
         "[]",
         "[]",
         "[]",
         "['aborcja musi być legalna' 'Aborcja musi być dostępna']",
         "[]",
         "['przywraca kobietom wolność wyboru' 'przywraca kobietom godność'\n 'przywraca kobietom podmiotowość']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['zagraża zdrowiu, życiu i bezpieczeństwu kobiet']",
         "[]",
         "[]",
         "['Aborcja musi być bezpieczna, aborcja musi być legalna'\n 'Aborcja musi być dostępna, a kobieta musi być bezpieczna']",
         "['Mówią: boję się być w ciąży, bo dziewczyny w moim wieku umierają. Umarły pan Iza, pani Agnieszka, pani Marta, pani Dorota'\n 'Zakaz aborcji w Polsce to restrykcyjne prawo, które zagraża zdrowiu, życiu i bezpieczeństwu kobiet']",
         "['Polki nie chcą rodzić dzieci w Polsce, która nie jest dla nich bezpieczna pod żadnym względem']",
         "[]",
         "[]",
         "['Dziś jesteśmy w demograficznym kryzysie']",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Fear-Prejudice",
         "Appeal_to_Fear-Prejudice",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "1",
         "Yes, the Appeal to Fear-Prejudice technique is used in the input.",
         "\"Mówią: boję się być w ciąży, bo dziewczyny w moim wieku umierają. Umarły pan Iza, pani Agnieszka, pani Marta, pani Dorota Zakaz aborcji w Polsce to restrykcyjne prawo, które zagraża zdrowiu, życiu i bezpieczeństwu kobiet\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The Appeal to Fear - Prejudice technique is explicitly used in the input text by invoking fear regarding pregnancy and the safety of women. The speaker mentions that women are afraid to become pregnant due to the deaths of peers, which exploits the audience\\'s fear of mortality and danger associated with the current legal restrictions on abortion. This aligns with the technique\\'s definition of promoting fear towards an idea (in this case, the status quo of restrictive abortion laws) and its consequences.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[\"The Appeal to Fear - Prejudice technique is explicitly used in the input text by invoking fear regarding pregnancy and the safety of women. The speaker mentions that women are afraid to become pregnant due to the deaths of peers, which exploits the audience's fear of mortality and danger associated with the current legal restrictions on abortion. This aligns with the technique's definition of promoting fear towards an idea (in this case, the status quo of restrictive abortion laws) and its consequences.\"]",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Fear-Prejudice/train/pl/train-pl-part_0007.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The Appeal to Fear - Prejudice technique is explicitly used in the input text by invoking fear regarding pregnancy and the safety of women. The speaker mentions that women are afraid to become pregnant due to the deaths of peers, which exploits the audience's fear of mortality and danger associated with the current legal restrictions on abortion. This aligns with the technique's definition of promoting fear towards an idea (in this case, the status quo of restrictive abortion laws) and its consequences.\", \"verdict\": true}"
        ],
        [
         "43",
         "pl_abortion_11_04_2024_n06.txt",
         "3465",
         "3708",
         "PL",
         "Poseł Monika Rosa:\nPanie Pośle! Pan nigdy nie był w ciąży i pan nie\nwie, co to znaczy nosić dziecko i się bać. A więc proszę\nnie wychodzić mi z jakimiś moralnymi według pana\ni etycznymi komentarzami. (Oklaski)\n(Poseł Piotr Kaleta: Ojej, ojej…)",
         "True",
         "['Loaded_Language' 'Questioning_the_Reputation' 'Straw_Man']",
         "train",
         "['Pan nigdy nie był w ciąży i pan nie wie, co to znaczy nosić dziecko i się bać. A więc proszę nie wychodzić mi z jakimiś moralnymi według pana i etycznymi komentarzami']",
         "[]",
         "[]",
         "[]",
         "['nie wychodzić mi']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Pan nigdy nie był w ciąży i pan nie wie, co to znaczy nosić dziecko i się bać. A więc proszę nie wychodzić mi z jakimiś moralnymi według pana i etycznymi komentarzami']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Hypocrisy",
         "Appeal_to_Hypocrisy",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Appeal to Hypocrisy technique is not used in the input.",
         "\"\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The input text does not contain any elements that attack the reputation of the target by charging them with hypocrisy or inconsistency. Monika Rosa\\'s statement focuses on the personal experience of pregnancy and does not reference any past actions or positions of the other individual that would indicate hypocrisy.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "[\"The input text does not contain any elements that attack the reputation of the target by charging them with hypocrisy or inconsistency. Monika Rosa's statement focuses on the personal experience of pregnancy and does not reference any past actions or positions of the other individual that would indicate hypocrisy.\"]",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/pl/train-pl-part_0004.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text does not contain any elements that attack the reputation of the target by charging them with hypocrisy or inconsistency. Monika Rosa's statement focuses on the personal experience of pregnancy and does not reference any past actions or positions of the other individual that would indicate hypocrisy.\", \"verdict\": false}"
        ],
        [
         "44",
         "RU_discrediting_the_west_21.txt",
         "1417",
         "1655",
         "RU",
         "olihull, United Kingdom\nСтоит ли за этим пожаром Россия? Абсолютно во всех бедах, которые случаются с этой страной, виновата Россия, верно? Начиная с резиновых лодок и заканчивая тем, что Стармер стал премьер-министром.\n\n\nlondonvir, Londo",
         "True",
         "['Causal_Oversimplification']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Абсолютно во всех бедах, которые случаются с этой страной, виновата Россия, верно? Начиная с резиновых лодок и заканчивая тем, что Стармер стал премьер-министром']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/Exaggeration-Minimisation",
         "Exaggeration-Minimisation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "0",
         "No, the Exaggeration-Minimisation technique is not used in the input.",
         "\"\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The input text does not employ the Exaggeration - Minimisation technique, as it does not exaggerate or downplay any statements or events. The claims made do not represent anything in an excessive manner or minimize their importance.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "['The input text does not employ the Exaggeration - Minimisation technique, as it does not exaggerate or downplay any statements or events. The claims made do not represent anything in an excessive manner or minimize their importance.']",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/Exaggeration-Minimisation/train/ru/train-ru-part_0007.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text does not employ the Exaggeration - Minimisation technique, as it does not exaggerate or downplay any statements or events. The claims made do not represent anything in an excessive manner or minimize their importance.\", \"verdict\": false}"
        ],
        [
         "45",
         "20240111_SHG_BG_62.txt",
         "5426",
         "5804",
         "BG",
         "И за финал, оказа се, че винаги, когато човек си мисли, че по-зле не може да стане, трябва добре да си помисли, защото може да се пръкне някое ПП и да докаже обратното. Оказа се, че най-голямото дъно в българския политически живот всъщност са „Продължаваме Промяната“. С тяхната поява започна безпрецедентно насъскване на едни групи хора от българите срещу други групи българи. ",
         "True",
         "['Causal_Oversimplification' 'Exaggeration-Minimisation'\n 'Questioning_the_Reputation' 'Name_Calling-Labeling']",
         "train",
         "['И за финал, оказа се, че винаги, когато човек си мисли, че по-зле не може да стане, трябва добре да си помисли, защото може да се пръкне някое ПП и да докаже обратното'\n 'Оказа се, че най-голямото дъно в българския политически живот всъщност са „Продължаваме Промяната“']",
         "['най-голямото дъно в българския политически живот']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['най-голямото дъно']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['С тяхната поява започна безпрецедентно насъскване на едни групи хора от българите срещу други групи българи']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/Causal_Oversimplification",
         "Causal_Oversimplification",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "1",
         "Yes, the Causal Oversimplification technique is used in the input.",
         "\"С тяхната поява започна безпрецедентно насъскване на едни групи хора от българите срещу други групи българи\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The input text uses Causal Oversimplification by suggesting that the emergence of \\'Продължаваме Промяната\\' is the sole cause of unprecedented incitement among different groups of Bulgarians. This aligns with the definition, as it implies that their appearance alone triggered this conflict, ignoring other potential contributing factors.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "[\"The input text uses Causal Oversimplification by suggesting that the emergence of 'Продължаваме Промяната' is the sole cause of unprecedented incitement among different groups of Bulgarians. This aligns with the definition, as it implies that their appearance alone triggered this conflict, ignoring other potential contributing factors.\"]",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/Causal_Oversimplification/train/bg/train-bg-part_0014.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text uses Causal Oversimplification by suggesting that the emergence of '\\u041f\\u0440\\u043e\\u0434\\u044a\\u043b\\u0436\\u0430\\u0432\\u0430\\u043c\\u0435 \\u041f\\u0440\\u043e\\u043c\\u044f\\u043d\\u0430\\u0442\\u0430' is the sole cause of unprecedented incitement among different groups of Bulgarians. This aligns with the definition, as it implies that their appearance alone triggered this conflict, ignoring other potential contributing factors.\", \"verdict\": true}"
        ],
        [
         "46",
         "pl_current_affairs_09_01_2025_n02.txt",
         "9440",
         "9898",
         "PL",
         "Wreszcie raport nie zawierał analizy wpływu na\njakość wód. Nie przeprowadzono dokładnej oceny, jak\nbudowa stopnia wodnego wpłynie na jakość wody\nw Wiśle, w jej dopływach czy na wyznaczone dla niej\ncele środowiskowe. Warto podkreślić, że inwestor\nw całym tym bardzo długim procesie od 2017 r. był\nwielokrotnie wzywany do przedłożenia i uzupełnienia raportu w zakresie braków ustawowych, które\nw tym raporcie były, jednak nie uzupełnił go zgodnie\nz wezwaniami.",
         "True",
         "['Doubt']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Warto podkreślić, że inwestor w całym tym bardzo długim procesie od 2017 r. był wielokrotnie wzywany do przedłożenia i uzupełnienia raportu w zakresie braków ustawowych, które w tym raporcie były, jednak nie uzupełnił go zgodnie z wezwaniami']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Doubt",
         "Doubt",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "1",
         "Yes, the Doubt technique is used in the input.",
         "\"Warto podkreślić, że inwestor w całym tym bardzo długim procesie od 2017 r. był wielokrotnie wzywany do przedłożenia i uzupełnienia raportu w zakresie braków ustawowych, które w tym raporcie były, jednak nie uzupełnił go zgodnie z wezwaniami\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The Casting Doubt technique is used in the input text by highlighting the investor\\'s failure to comply with legal requests to supplement the report. This raises questions about the investor\\'s credibility and the quality of the report, suggesting that their actions may indicate a lack of reliability in their assessments.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "[\"The Casting Doubt technique is used in the input text by highlighting the investor's failure to comply with legal requests to supplement the report. This raises questions about the investor's credibility and the quality of the report, suggesting that their actions may indicate a lack of reliability in their assessments.\"]",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Doubt/train/pl/train-pl-part_0003.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The Casting Doubt technique is used in the input text by highlighting the investor's failure to comply with legal requests to supplement the report. This raises questions about the investor's credibility and the quality of the report, suggesting that their actions may indicate a lack of reliability in their assessments.\", \"verdict\": true}"
        ],
        [
         "47",
         "RU_URW_3.txt",
         "739",
         "941",
         "RU",
         "ебята принесли дроном еду , сбросили во дворе и увидели, что пять человек - три бабушки и два дедушки. С этого дня наши бойцы стали аккуратно сбрасывать старикам еду, чтобы они не умерли с голода.\n\nДо н",
         "True",
         "['Appeal_to_Pity']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/Loaded_Language",
         "Loaded_Language",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "0",
         "No, the Loaded Language technique is not used in the input.",
         "\"\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The input text does not contain any specific words or phrases with strong emotional implications intended to influence the audience. The language used is straightforward and descriptive without any loaded terms.\",\\n  \"updated_definition\": \"Loaded Language technique involves the use of specific words and phrases with strong emotional implications (either positive or negative) to influence and convince the audience that an argument is valid, often through emotionally charged language that evokes a strong response.\"\\n}']",
         "['Loaded Language technique involves the use of specific words and phrases with strong emotional implications (either positive or negative) to influence and convince the audience that an argument is valid, often through emotionally charged language that evokes a strong response.']",
         "[None]",
         "[None]",
         "['The input text does not contain any specific words or phrases with strong emotional implications intended to influence the audience. The language used is straightforward and descriptive without any loaded terms.']",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/Loaded_Language/train/ru/train-ru-part_0003.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text does not contain any specific words or phrases with strong emotional implications intended to influence the audience. The language used is straightforward and descriptive without any loaded terms.\", \"verdict\": false}"
        ],
        [
         "48",
         "RU_discrediting_the_west_1.txt",
         "1091",
         "1256",
         "RU",
         "А то, ради чего существует человечество, — продолжение рода, передача из поколения в поколение веры, моральных ценностей, истории и культуры — намеренно блокируется.",
         "True",
         "['Appeal_to_Values']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/Causal_Oversimplification",
         "Causal_Oversimplification",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "0",
         "No, the Causal Oversimplification technique is not used in the input.",
         "\"\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The input text does not assume a single cause for an issue; instead, it discusses multiple aspects of humanity\\'s existence without attributing the blocking of these aspects to a single cause. Therefore, Causal Oversimplification is not present.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "[\"The input text does not assume a single cause for an issue; instead, it discusses multiple aspects of humanity's existence without attributing the blocking of these aspects to a single cause. Therefore, Causal Oversimplification is not present.\"]",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/Causal_Oversimplification/train/ru/train-ru-part_0011.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text does not assume a single cause for an issue; instead, it discusses multiple aspects of humanity's existence without attributing the blocking of these aspects to a single cause. Therefore, Causal Oversimplification is not present.\", \"verdict\": false}"
        ],
        [
         "49",
         "RU_Trump_1.txt",
         "1302",
         "1987",
         "RU",
         "мпа стратегия «only business», то есть экономическая выгода для США, у Путина стратегия «realpolitik» - прагматизм в интересах общества, но с элементами нравственности. А вот стратегия Зеленского - сохранить не Украину, а себя. У него цугцванг- любой ход ведет к проигрышу. Сделка - продажа Украины, отказ от сделки - разрушение государства. А договориться он не смог, так как человек недалекий. И, вероятно, Зеленский не думал, что будут вопросы к нему по поводу махинаций с выделяемыми средствами из бюджета США, что сумеет проскочить и Трампу он выгоден, но Трамп хочет полного контроля над ресурсами Украины и полного подчинения Зеленского - такова цена военной помощи.\n\nЛишившись ",
         "True",
         "['False_Dilemma-No_Choice' 'Name_Calling-Labeling' 'Straw_Man' 'Doubt']",
         "train",
         "[]",
         "['так как человек недалекий']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['А вот стратегия Зеленского - сохранить не Украину, а себя. У него цугцванг- любой ход ведет к проигрышу']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['И, вероятно, Зеленский не думал, что будут вопросы к нему по поводу махинаций с выделяемыми средствами из бюджета США, что сумеет проскочить и Трампу он выгоден, но Трамп хочет полного контроля над ресурсами Украины и полного подчинения Зеленского - такова цена военной помощи']",
         "[]",
         "[]",
         "[]",
         "[]",
         "['А вот стратегия Зеленского - сохранить не Украину, а себя'\n 'Сделка - продажа Украины, отказ от сделки - разрушение государства']",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Doubt",
         "Doubt",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "1",
         "Yes, the Doubt technique is used in the input.",
         "\"А вот стратегия Зеленского - сохранить не Украину, а себя. У него цугцванг- любой ход ведет к проигрышу\"",
         "[None]",
         "[ True]",
         "['{\\n  \"explanation\": \"The Casting Doubt technique is used in the input text by questioning Zelensky\\'s motivations and capabilities. The statement \\'А вот стратегия Зеленского - сохранить не Украину, а себя\\' implies that Zelensky is self-serving rather than acting in the best interest of Ukraine, which casts doubt on his credibility as a leader. Additionally, the phrase \\'У него цугцванг- любой ход ведет к проигрышу\\' suggests that he is in a hopeless situation, further undermining his effectiveness and decision-making abilities.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "[\"The Casting Doubt technique is used in the input text by questioning Zelensky's motivations and capabilities. The statement 'А вот стратегия Зеленского - сохранить не Украину, а себя' implies that Zelensky is self-serving rather than acting in the best interest of Ukraine, which casts doubt on his credibility as a leader. Additionally, the phrase 'У него цугцванг- любой ход ведет к проигрышу' suggests that he is in a hopeless situation, further undermining his effectiveness and decision-making abilities.\"]",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Doubt/train/ru/train-ru-part_0000.parquet",
         "[None]",
         "[None]",
         "train",
         "{\"description\": \"The Casting Doubt technique is used in the input text by questioning Zelensky's motivations and capabilities. The statement '\\u0410 \\u0432\\u043e\\u0442 \\u0441\\u0442\\u0440\\u0430\\u0442\\u0435\\u0433\\u0438\\u044f \\u0417\\u0435\\u043b\\u0435\\u043d\\u0441\\u043a\\u043e\\u0433\\u043e - \\u0441\\u043e\\u0445\\u0440\\u0430\\u043d\\u0438\\u0442\\u044c \\u043d\\u0435 \\u0423\\u043a\\u0440\\u0430\\u0438\\u043d\\u0443, \\u0430 \\u0441\\u0435\\u0431\\u044f' implies that Zelensky is self-serving rather than acting in the best interest of Ukraine, which casts doubt on his credibility as a leader. Additionally, the phrase '\\u0423 \\u043d\\u0435\\u0433\\u043e \\u0446\\u0443\\u0433\\u0446\\u0432\\u0430\\u043d\\u0433- \\u043b\\u044e\\u0431\\u043e\\u0439 \\u0445\\u043e\\u0434 \\u0432\\u0435\\u0434\\u0435\\u0442 \\u043a \\u043f\\u0440\\u043e\\u0438\\u0433\\u0440\\u044b\\u0448\\u0443' suggests that he is in a hopeless situation, further undermining his effectiveness and decision-making abilities.\", \"verdict\": true}"
        ]
       ],
       "shape": {
        "columns": 60,
        "rows": 1870
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>text_lang</th>\n",
       "      <th>text</th>\n",
       "      <th>label_bin</th>\n",
       "      <th>label_multi</th>\n",
       "      <th>base_split</th>\n",
       "      <th>Questioning_the_Reputation</th>\n",
       "      <th>Name_Calling-Labeling</th>\n",
       "      <th>...</th>\n",
       "      <th>updated_definition</th>\n",
       "      <th>think_content</th>\n",
       "      <th>illegal_value</th>\n",
       "      <th>explanation</th>\n",
       "      <th>extra_content</th>\n",
       "      <th>source_file</th>\n",
       "      <th>error</th>\n",
       "      <th>status</th>\n",
       "      <th>split</th>\n",
       "      <th>expected_output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RU_discrediting_the_west_11.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "      <td>RU</td>\n",
       "      <td>Генерала Попова отправили в СИЗО, уволили без ...</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>train</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[The input text does not contain any strong ne...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41/v001...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "      <td>{\"description\": \"The input text does not conta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RU_migrants_5.txt</td>\n",
       "      <td>354</td>\n",
       "      <td>574</td>\n",
       "      <td>RU</td>\n",
       "      <td>йчас Каменск-Уральск во всех сводках новостей....</td>\n",
       "      <td>True</td>\n",
       "      <td>[Appeal_to_Fear-Prejudice]</td>\n",
       "      <td>train</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41_MINI...</td>\n",
       "      <td>[{'code': 'content_filter', 'innererror': {'co...</td>\n",
       "      <td>[no validation]</td>\n",
       "      <td>train</td>\n",
       "      <td>{\"description\": null, \"verdict\": false}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pl_abortion_11_04_2024_n05.txt</td>\n",
       "      <td>4987</td>\n",
       "      <td>5641</td>\n",
       "      <td>PL</td>\n",
       "      <td>I jeszcze słowo o hipokrytach i hipokryzji.\\nT...</td>\n",
       "      <td>True</td>\n",
       "      <td>[Conversation_Killer, Straw_Man, Repetition]</td>\n",
       "      <td>train</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[The Strawman technique is used in the input t...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41/v001...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "      <td>{\"description\": \"The Strawman technique is use...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RU_URW_4.txt</td>\n",
       "      <td>753</td>\n",
       "      <td>934</td>\n",
       "      <td>RU</td>\n",
       "      <td>Как видим, от администрации Трампа тоже не слы...</td>\n",
       "      <td>True</td>\n",
       "      <td>[Causal_Oversimplification, Appeal_to_Authority]</td>\n",
       "      <td>train</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[Causal Oversimplification is used in the inpu...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41_MINI...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>train</td>\n",
       "      <td>{\"description\": \"Causal Oversimplification is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pl_abortion_11_04_2024_n05.txt</td>\n",
       "      <td>9681</td>\n",
       "      <td>10556</td>\n",
       "      <td>PL</td>\n",
       "      <td>Dziś jesteśmy w demograficznym kryzysie. Polki...</td>\n",
       "      <td>True</td>\n",
       "      <td>[Conversation_Killer, Causal_Oversimplificatio...</td>\n",
       "      <td>train</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[The Slogans technique is explicitly used in t...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41_MINI...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "      <td>{\"description\": \"The Slogans technique is expl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1865</th>\n",
       "      <td>20240704_URW_BG_29.txt</td>\n",
       "      <td>7361</td>\n",
       "      <td>7404</td>\n",
       "      <td>BG</td>\n",
       "      <td>\\nГосподин Запрянов, искате ли да добавите н</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>train</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[The Appeal to Values technique was not used i...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41/v001...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "      <td>{\"description\": \"The Appeal to Values techniqu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1866</th>\n",
       "      <td>RU_discrediting_the_west_1.txt</td>\n",
       "      <td>952</td>\n",
       "      <td>1002</td>\n",
       "      <td>RU</td>\n",
       "      <td>Одиноким намного легче манипулировать и управл...</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>train</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[The input text does not contain any elements ...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41/v001...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>train</td>\n",
       "      <td>{\"description\": \"The input text does not conta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867</th>\n",
       "      <td>20231208_URW_BG_71.txt</td>\n",
       "      <td>973</td>\n",
       "      <td>1687</td>\n",
       "      <td>BG</td>\n",
       "      <td>Идеята да отхвърлим ветото на президента е кра...</td>\n",
       "      <td>True</td>\n",
       "      <td>[Exaggeration-Minimisation, Flag_Waving, Quest...</td>\n",
       "      <td>train</td>\n",
       "      <td>[Нямам съмнение, че евро-атлантическото мнозин...</td>\n",
       "      <td>[евро-атлантическото мнозинство]</td>\n",
       "      <td>...</td>\n",
       "      <td>[Name Calling - Labeling is a form of argument...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[The Name Calling - Labeling technique is used...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41/v001...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "      <td>{\"description\": \"The Name Calling - Labeling t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1868</th>\n",
       "      <td>20240704_URW_BG_30.txt</td>\n",
       "      <td>4089</td>\n",
       "      <td>4570</td>\n",
       "      <td>BG</td>\n",
       "      <td>на позиция от миналата седмица в Народното съб...</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>train</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[The input text does not contain any elements ...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41/v001...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>train</td>\n",
       "      <td>{\"description\": \"The input text does not conta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1869</th>\n",
       "      <td>SI_interpelation_interior_5.txt</td>\n",
       "      <td>3686</td>\n",
       "      <td>5081</td>\n",
       "      <td>SI</td>\n",
       "      <td>Naj se na koncu dotaknem še očitka o imenovanj...</td>\n",
       "      <td>True</td>\n",
       "      <td>[Appeal_to_Authority, Red_Herring]</td>\n",
       "      <td>train</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[The input text does not reference any positiv...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41/v001...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "      <td>{\"description\": \"The input text does not refer...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1870 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             filename  start    end text_lang  \\\n",
       "0     RU_discrediting_the_west_11.txt      0    125        RU   \n",
       "1                   RU_migrants_5.txt    354    574        RU   \n",
       "2      pl_abortion_11_04_2024_n05.txt   4987   5641        PL   \n",
       "3                        RU_URW_4.txt    753    934        RU   \n",
       "4      pl_abortion_11_04_2024_n05.txt   9681  10556        PL   \n",
       "...                               ...    ...    ...       ...   \n",
       "1865           20240704_URW_BG_29.txt   7361   7404        BG   \n",
       "1866   RU_discrediting_the_west_1.txt    952   1002        RU   \n",
       "1867           20231208_URW_BG_71.txt    973   1687        BG   \n",
       "1868           20240704_URW_BG_30.txt   4089   4570        BG   \n",
       "1869  SI_interpelation_interior_5.txt   3686   5081        SI   \n",
       "\n",
       "                                                   text  label_bin  \\\n",
       "0     Генерала Попова отправили в СИЗО, уволили без ...      False   \n",
       "1     йчас Каменск-Уральск во всех сводках новостей....       True   \n",
       "2     I jeszcze słowo o hipokrytach i hipokryzji.\\nT...       True   \n",
       "3     Как видим, от администрации Трампа тоже не слы...       True   \n",
       "4     Dziś jesteśmy w demograficznym kryzysie. Polki...       True   \n",
       "...                                                 ...        ...   \n",
       "1865       \\nГосподин Запрянов, искате ли да добавите н      False   \n",
       "1866  Одиноким намного легче манипулировать и управл...      False   \n",
       "1867  Идеята да отхвърлим ветото на президента е кра...       True   \n",
       "1868  на позиция от миналата седмица в Народното съб...      False   \n",
       "1869  Naj se na koncu dotaknem še očitka o imenovanj...       True   \n",
       "\n",
       "                                            label_multi base_split  \\\n",
       "0                                                    []      train   \n",
       "1                            [Appeal_to_Fear-Prejudice]      train   \n",
       "2          [Conversation_Killer, Straw_Man, Repetition]      train   \n",
       "3      [Causal_Oversimplification, Appeal_to_Authority]      train   \n",
       "4     [Conversation_Killer, Causal_Oversimplificatio...      train   \n",
       "...                                                 ...        ...   \n",
       "1865                                                 []      train   \n",
       "1866                                                 []      train   \n",
       "1867  [Exaggeration-Minimisation, Flag_Waving, Quest...      train   \n",
       "1868                                                 []      train   \n",
       "1869                 [Appeal_to_Authority, Red_Herring]      train   \n",
       "\n",
       "                             Questioning_the_Reputation  \\\n",
       "0                                                    []   \n",
       "1                                                    []   \n",
       "2                                                    []   \n",
       "3                                                    []   \n",
       "4                                                    []   \n",
       "...                                                 ...   \n",
       "1865                                                 []   \n",
       "1866                                                 []   \n",
       "1867  [Нямам съмнение, че евро-атлантическото мнозин...   \n",
       "1868                                                 []   \n",
       "1869                                                 []   \n",
       "\n",
       "                 Name_Calling-Labeling  ...  \\\n",
       "0                                   []  ...   \n",
       "1                                   []  ...   \n",
       "2                                   []  ...   \n",
       "3                                   []  ...   \n",
       "4                                   []  ...   \n",
       "...                                ...  ...   \n",
       "1865                                []  ...   \n",
       "1866                                []  ...   \n",
       "1867  [евро-атлантическото мнозинство]  ...   \n",
       "1868                                []  ...   \n",
       "1869                                []  ...   \n",
       "\n",
       "                                     updated_definition think_content  \\\n",
       "0                                                    []        [None]   \n",
       "1                                                [None]        [None]   \n",
       "2                                                [None]        [None]   \n",
       "3                                                [None]        [None]   \n",
       "4                                                [None]        [None]   \n",
       "...                                                 ...           ...   \n",
       "1865                                             [None]        [None]   \n",
       "1866                                                 []        [None]   \n",
       "1867  [Name Calling - Labeling is a form of argument...        [None]   \n",
       "1868                                             [None]        [None]   \n",
       "1869                                             [None]        [None]   \n",
       "\n",
       "     illegal_value                                        explanation  \\\n",
       "0           [None]  [The input text does not contain any strong ne...   \n",
       "1           [None]                                             [None]   \n",
       "2           [None]  [The Strawman technique is used in the input t...   \n",
       "3           [None]  [Causal Oversimplification is used in the inpu...   \n",
       "4           [None]  [The Slogans technique is explicitly used in t...   \n",
       "...            ...                                                ...   \n",
       "1865        [None]  [The Appeal to Values technique was not used i...   \n",
       "1866        [None]  [The input text does not contain any elements ...   \n",
       "1867        [None]  [The Name Calling - Labeling technique is used...   \n",
       "1868        [None]  [The input text does not contain any elements ...   \n",
       "1869        [None]  [The input text does not reference any positiv...   \n",
       "\n",
       "     extra_content                                        source_file  \\\n",
       "0           [None]  data/llm_output/persuasion/explain/GPT_41/v001...   \n",
       "1           [None]  data/llm_output/persuasion/explain/GPT_41_MINI...   \n",
       "2           [None]  data/llm_output/persuasion/explain/GPT_41/v001...   \n",
       "3           [None]  data/llm_output/persuasion/explain/GPT_41_MINI...   \n",
       "4           [None]  data/llm_output/persuasion/explain/GPT_41_MINI...   \n",
       "...            ...                                                ...   \n",
       "1865        [None]  data/llm_output/persuasion/explain/GPT_41/v001...   \n",
       "1866        [None]  data/llm_output/persuasion/explain/GPT_41/v001...   \n",
       "1867        [None]  data/llm_output/persuasion/explain/GPT_41/v001...   \n",
       "1868        [None]  data/llm_output/persuasion/explain/GPT_41/v001...   \n",
       "1869        [None]  data/llm_output/persuasion/explain/GPT_41/v001...   \n",
       "\n",
       "                                                  error           status  \\\n",
       "0                                                   NaN              NaN   \n",
       "1     [{'code': 'content_filter', 'innererror': {'co...  [no validation]   \n",
       "2                                                   NaN              NaN   \n",
       "3                                                [None]           [None]   \n",
       "4                                                   NaN              NaN   \n",
       "...                                                 ...              ...   \n",
       "1865                                                NaN              NaN   \n",
       "1866                                             [None]           [None]   \n",
       "1867                                                NaN              NaN   \n",
       "1868                                             [None]           [None]   \n",
       "1869                                                NaN              NaN   \n",
       "\n",
       "      split                                    expected_output  \n",
       "0     train  {\"description\": \"The input text does not conta...  \n",
       "1     train            {\"description\": null, \"verdict\": false}  \n",
       "2     train  {\"description\": \"The Strawman technique is use...  \n",
       "3     train  {\"description\": \"Causal Oversimplification is ...  \n",
       "4     train  {\"description\": \"The Slogans technique is expl...  \n",
       "...     ...                                                ...  \n",
       "1865  train  {\"description\": \"The Appeal to Values techniqu...  \n",
       "1866  train  {\"description\": \"The input text does not conta...  \n",
       "1867  train  {\"description\": \"The Name Calling - Labeling t...  \n",
       "1868  train  {\"description\": \"The input text does not conta...  \n",
       "1869  train  {\"description\": \"The input text does not refer...  \n",
       "\n",
       "[1870 rows x 60 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assume your DataFrame is called df\n",
    "label_1 = clean[clean['gold'] == 1]\n",
    "\n",
    "# Count how many label==1 per category\n",
    "counts = label_1['prompt_name'].value_counts()\n",
    "\n",
    "# For label == 0, sample same number of rows per category\n",
    "label_0_samples = (\n",
    "    df[df['gold'] == 0]\n",
    "    .groupby('prompt_name', group_keys=False)\n",
    "    .apply(lambda x: x.sample(n=1*counts.get(x.name, 0)))\n",
    ")\n",
    "\n",
    "# Combine both\n",
    "balanced_df11 = pd.concat([label_1, label_0_samples])\n",
    "balanced_df11 = balanced_df11.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "balanced_df11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "075abb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PART_NAME = \"system\"\n",
    "USER_PART_NAME = \"user\"\n",
    "\n",
    "def build_messages(text,expected_output,job=\"persuasion\", step=\"detect\", prompt_name=\"Name_Calling-Labeling\", prompt_version=\"v001\"):\n",
    "    prompt_layout, prompt_content = load_template_parts(\n",
    "        job=\"persuasion\", step=\"detect\", prompt_name=\"Name_Calling-Labeling\", prompt_version=\"v001\"\n",
    "    )\n",
    "\n",
    "    json_line = {\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": prompt_layout[SYSTEM_PART_NAME].format(technique_name=prompt_content['technique_name'],\n",
    "                                                                                     technique_desc=prompt_content['technique_desc'],\n",
    "                                                                                     input_example = prompt_content['input_example'],\n",
    "                                                                                     output_example = prompt_content['output_example'])},\n",
    "                {\"role\": \"user\", \"content\": prompt_layout[USER_PART_NAME].format(text = text)},\n",
    "                {\"role\": \"assistant\", \"content\": expected_output}\n",
    "            ]\n",
    "        }\n",
    "    return json_line\n",
    "    # return(json.dumps(json_line, ensure_ascii=False) + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "45e322b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_layout, prompt_content = load_template_parts(\n",
    "        job=\"persuasion\", step=\"detect\", prompt_name=\"Name_Calling-Labeling\", prompt_version=\"v001\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2a76222a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write DataFrame to JSONL\n",
    "ft_df = balanced_df11\n",
    "with open(\"data/finetuning/explain2detect_pers_v2_11.jsonl\", \"w\", encoding=\"utf-8\") as file:\n",
    "    for _, row in ft_df[ft_df.error.isna()].iterrows():\n",
    "        json_line = build_messages(text = row['text'],expected_output = row['expected_output'])\n",
    "        file.write(json.dumps(json_line, ensure_ascii=False) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "af6aeb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write DataFrame to JSONL\n",
    "ft_df = balanced_df21\n",
    "with open(\"data/finetuning/explain2detect_pers_v2_21.jsonl\", \"w\", encoding=\"utf-8\") as file:\n",
    "    for _, row in ft_df[ft_df.error.isna()].iterrows():\n",
    "        json_line = build_messages(text = row['text'],expected_output = row['expected_output'])\n",
    "        file.write(json.dumps(json_line, ensure_ascii=False) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9eef020a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write DataFrame to JSONL\n",
    "ft_df = balanced_df31\n",
    "with open(\"data/finetuning/explain2detect_pers_v2_31.jsonl\", \"w\", encoding=\"utf-8\") as file:\n",
    "    for _, row in ft_df[ft_df.error.isna()].iterrows():\n",
    "        json_line = build_messages(text = row['text'],expected_output = row['expected_output'])\n",
    "        file.write(json.dumps(json_line, ensure_ascii=False) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7133e54a",
   "metadata": {},
   "source": [
    "# errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff84010",
   "metadata": {},
   "source": [
    "Unhandled exception during LLM call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "eb9a5425",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "filename",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "start",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "end",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "text_lang",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "text",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "label_bin",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "label_multi",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "base_split",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Questioning_the_Reputation",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Name_Calling-Labeling",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Appeal_to_Hypocrisy",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Conversation_Killer",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Loaded_Language",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Repetition",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Appeal_to_Popularity",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Doubt",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Red_Herring",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Flag_Waving",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Exaggeration-Minimisation",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Consequential_Oversimplification",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Appeal_to_Pity",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Appeal_to_Time",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Appeal_to_Values",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Obfuscation-Vagueness-Confusion",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Straw_Man",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Slogans",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Appeal_to_Fear-Prejudice",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Causal_Oversimplification",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Appeal_to_Authority",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "False_Dilemma-No_Choice",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Whataboutism",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "False_Equivalence",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Guilt_by_Association",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "alt_split",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "output_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "prompt_name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "prompt_version",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "job",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "step",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "max_iterations",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "temperature",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "model_provider",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "model_name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "model_mode",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "gold",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "gold_text",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "spans",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "raw",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "extra_properties",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "explanation",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "is_valid",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "illegal_value",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "think_content",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "extra_content",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "updated_definition",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "source_file",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "error",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "status",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "split",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "expected_output",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "d8c6e99e-c1e9-4aa1-afa8-31fc86adca52",
       "rows": [],
       "shape": {
        "columns": 60,
        "rows": 0
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>text_lang</th>\n",
       "      <th>text</th>\n",
       "      <th>label_bin</th>\n",
       "      <th>label_multi</th>\n",
       "      <th>base_split</th>\n",
       "      <th>Questioning_the_Reputation</th>\n",
       "      <th>Name_Calling-Labeling</th>\n",
       "      <th>...</th>\n",
       "      <th>is_valid</th>\n",
       "      <th>illegal_value</th>\n",
       "      <th>think_content</th>\n",
       "      <th>extra_content</th>\n",
       "      <th>updated_definition</th>\n",
       "      <th>source_file</th>\n",
       "      <th>error</th>\n",
       "      <th>status</th>\n",
       "      <th>split</th>\n",
       "      <th>expected_output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [filename, start, end, text_lang, text, label_bin, label_multi, base_split, Questioning_the_Reputation, Name_Calling-Labeling, Appeal_to_Hypocrisy, Conversation_Killer, Loaded_Language, Repetition, Appeal_to_Popularity, Doubt, Red_Herring, Flag_Waving, Exaggeration-Minimisation, Consequential_Oversimplification, Appeal_to_Pity, Appeal_to_Time, Appeal_to_Values, Obfuscation-Vagueness-Confusion, Straw_Man, Slogans, Appeal_to_Fear-Prejudice, Causal_Oversimplification, Appeal_to_Authority, False_Dilemma-No_Choice, Whataboutism, False_Equivalence, Guilt_by_Association, alt_split, output_id, prompt_name, prompt_version, job, step, max_iterations, temperature, model_provider, model_name, model_mode, gold, gold_text, spans, raw, extra_properties, explanation, is_valid, illegal_value, think_content, extra_content, updated_definition, source_file, error, status, split, expected_output]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 60 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errs_to_delete = df[df['error'].apply(lambda x: isinstance(x, np.ndarray) and 'Unhandled exception during LLM call' in x)]\n",
    "errs_to_delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f324f2d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "source_file",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "count",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "5f234bb6-b9bd-498f-92ff-e57d85fdbbc7",
       "rows": [
        [
         "0",
         "data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/bg/train-bg-part_0007.parquet",
         "4"
        ],
        [
         "1",
         "data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/pl/train-pl-part_0008.parquet",
         "4"
        ],
        [
         "2",
         "data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/ru/train-ru-part_0008.parquet",
         "4"
        ],
        [
         "3",
         "data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/si/train-si-part_0007.parquet",
         "4"
        ],
        [
         "4",
         "data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/pl/train-pl-part_0001.parquet",
         "3"
        ],
        [
         "5",
         "data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/pl/train-pl-part_0007.parquet",
         "3"
        ],
        [
         "6",
         "data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/ru/train-ru-part_0003.parquet",
         "2"
        ],
        [
         "7",
         "data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/ru/train-ru-part_0000.parquet",
         "1"
        ],
        [
         "8",
         "data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/ru/train-ru-part_0007.parquet",
         "1"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 9
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_file</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41/v001...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41/v001...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41/v001...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41/v001...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41/v001...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41/v001...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41/v001...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41/v001...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41/v001...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         source_file  count\n",
       "0  data/llm_output/persuasion/explain/GPT_41/v001...      4\n",
       "1  data/llm_output/persuasion/explain/GPT_41/v001...      4\n",
       "2  data/llm_output/persuasion/explain/GPT_41/v001...      4\n",
       "3  data/llm_output/persuasion/explain/GPT_41/v001...      4\n",
       "4  data/llm_output/persuasion/explain/GPT_41/v001...      3\n",
       "5  data/llm_output/persuasion/explain/GPT_41/v001...      3\n",
       "6  data/llm_output/persuasion/explain/GPT_41/v001...      2\n",
       "7  data/llm_output/persuasion/explain/GPT_41/v001...      1\n",
       "8  data/llm_output/persuasion/explain/GPT_41/v001...      1"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errs_to_delete = df[(df[\"explanation\"].apply(lambda x: isinstance(x, (list, np.ndarray)) and list(x) == [None]))&(df.prompt_name==\"Questioning_the_Reputation\")].value_counts('source_file').reset_index().head(28)\n",
    "errs_to_delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "5bf21d19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "source_file",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "count",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "aeacb45d-1a0f-404b-978c-3aac0cfac5a2",
       "rows": [
        [
         "0",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/si/train-si-part_0000.parquet",
         "5"
        ],
        [
         "1",
         "data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/pl/train-pl-part_0008.parquet",
         "4"
        ],
        [
         "2",
         "data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/si/train-si-part_0007.parquet",
         "4"
        ],
        [
         "3",
         "data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/bg/train-bg-part_0007.parquet",
         "4"
        ],
        [
         "4",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/si/train-si-part_0001.parquet",
         "4"
        ],
        [
         "5",
         "data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/ru/train-ru-part_0008.parquet",
         "4"
        ],
        [
         "6",
         "data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/pl/train-pl-part_0001.parquet",
         "3"
        ],
        [
         "7",
         "data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/pl/train-pl-part_0007.parquet",
         "3"
        ],
        [
         "8",
         "data/llm_output/persuasion/explain/GPT_41/v001/Doubt/train/bg/train-bg-part_0000.parquet",
         "3"
        ],
        [
         "9",
         "data/llm_output/persuasion/explain/GPT_41/v001/Doubt/train/si/train-si-part_0006.parquet",
         "3"
        ],
        [
         "10",
         "data/llm_output/persuasion/explain/GPT_41/v001/Doubt/train/si/train-si-part_0004.parquet",
         "2"
        ],
        [
         "11",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/si/train-si-part_0004.parquet",
         "2"
        ],
        [
         "12",
         "data/llm_output/persuasion/explain/GPT_41/v001/Guilt_by_Association/train/si/train-si-part_0006.parquet",
         "2"
        ],
        [
         "13",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/Conversation_Killer/train/ru/train-ru-part_0007.parquet",
         "2"
        ],
        [
         "14",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/Conversation_Killer/train/pl/train-pl-part_0007.parquet",
         "2"
        ],
        [
         "15",
         "data/llm_output/persuasion/explain/GPT_41/v001/Name_Calling-Labeling/train/si/train-si-part_0006.parquet",
         "2"
        ],
        [
         "16",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/Consequential_Oversimplification/train/ru/train-ru-part_0007.parquet",
         "2"
        ],
        [
         "17",
         "data/llm_output/persuasion/explain/GPT_41/v001/Doubt/train/ru/train-ru-part_0006.parquet",
         "2"
        ],
        [
         "18",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/si/train-si-part_0006.parquet",
         "2"
        ],
        [
         "19",
         "data/llm_output/persuasion/explain/GPT_41/v001/Straw_Man/train/bg/train-bg-part_0009.parquet",
         "2"
        ],
        [
         "20",
         "data/llm_output/persuasion/explain/GPT_41/v001/Doubt/train/si/train-si-part_0001.parquet",
         "2"
        ],
        [
         "21",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/Conversation_Killer/train/pl/train-pl-part_0004.parquet",
         "2"
        ],
        [
         "22",
         "data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/ru/train-ru-part_0003.parquet",
         "2"
        ],
        [
         "23",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/bg/train-bg-part_0009.parquet",
         "2"
        ],
        [
         "24",
         "data/llm_output/persuasion/explain/GPT_41/v001/Guilt_by_Association/train/bg/train-bg-part_0004.parquet",
         "2"
        ],
        [
         "25",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/Causal_Oversimplification/train/ru/train-ru-part_0004.parquet",
         "1"
        ],
        [
         "26",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/Appeal_to_Time/train/ru/train-ru-part_0007.parquet",
         "1"
        ],
        [
         "27",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/Causal_Oversimplification/train/pl/train-pl-part_0007.parquet",
         "1"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 28
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_file</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41/v001...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41/v001...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41/v001...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41/v001...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41/v001...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41/v001...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41/v001...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41/v001...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41/v001...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41/v001...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41/v001...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41/v001...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41/v001...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41_MINI...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41_MINI...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41/v001...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41_MINI...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41/v001...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41/v001...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41/v001...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41/v001...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41_MINI...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41/v001...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41/v001...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41/v001...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41_MINI...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41_MINI...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41_MINI...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          source_file  count\n",
       "0   data/llm_output/persuasion/explain/GPT_41/v001...      5\n",
       "1   data/llm_output/persuasion/explain/GPT_41/v001...      4\n",
       "2   data/llm_output/persuasion/explain/GPT_41/v001...      4\n",
       "3   data/llm_output/persuasion/explain/GPT_41/v001...      4\n",
       "4   data/llm_output/persuasion/explain/GPT_41/v001...      4\n",
       "5   data/llm_output/persuasion/explain/GPT_41/v001...      4\n",
       "6   data/llm_output/persuasion/explain/GPT_41/v001...      3\n",
       "7   data/llm_output/persuasion/explain/GPT_41/v001...      3\n",
       "8   data/llm_output/persuasion/explain/GPT_41/v001...      3\n",
       "9   data/llm_output/persuasion/explain/GPT_41/v001...      3\n",
       "10  data/llm_output/persuasion/explain/GPT_41/v001...      2\n",
       "11  data/llm_output/persuasion/explain/GPT_41/v001...      2\n",
       "12  data/llm_output/persuasion/explain/GPT_41/v001...      2\n",
       "13  data/llm_output/persuasion/explain/GPT_41_MINI...      2\n",
       "14  data/llm_output/persuasion/explain/GPT_41_MINI...      2\n",
       "15  data/llm_output/persuasion/explain/GPT_41/v001...      2\n",
       "16  data/llm_output/persuasion/explain/GPT_41_MINI...      2\n",
       "17  data/llm_output/persuasion/explain/GPT_41/v001...      2\n",
       "18  data/llm_output/persuasion/explain/GPT_41/v001...      2\n",
       "19  data/llm_output/persuasion/explain/GPT_41/v001...      2\n",
       "20  data/llm_output/persuasion/explain/GPT_41/v001...      2\n",
       "21  data/llm_output/persuasion/explain/GPT_41_MINI...      2\n",
       "22  data/llm_output/persuasion/explain/GPT_41/v001...      2\n",
       "23  data/llm_output/persuasion/explain/GPT_41/v001...      2\n",
       "24  data/llm_output/persuasion/explain/GPT_41/v001...      2\n",
       "25  data/llm_output/persuasion/explain/GPT_41_MINI...      1\n",
       "26  data/llm_output/persuasion/explain/GPT_41_MINI...      1\n",
       "27  data/llm_output/persuasion/explain/GPT_41_MINI...      1"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errs_to_delete = df[(df[\"explanation\"].apply(lambda x: isinstance(x, (list, np.ndarray)) and list(x) == [None]))].value_counts('source_file').reset_index().head(28)\n",
    "errs_to_delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a7c2fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted: data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/bg/train-bg-part_0003.parquet\n",
      "Deleted: data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/bg/train-bg-part_0001.parquet\n",
      "Deleted: data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/ru/train-ru-part_0009.parquet\n",
      "Deleted: data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/bg/train-bg-part_0000.parquet\n",
      "Deleted: data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/pl/train-pl-part_0006.parquet\n",
      "Deleted: data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/bg/train-bg-part_0002.parquet\n",
      "Deleted: data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/si/train-si-part_0001.parquet\n",
      "Deleted: data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/bg/train-bg-part_0005.parquet\n",
      "Deleted: data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/si/train-si-part_0002.parquet\n",
      "Deleted: data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/bg/train-bg-part_0008.parquet\n",
      "Deleted: data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/bg/train-bg-part_0009.parquet\n",
      "Deleted: data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/si/train-si-part_0005.parquet\n",
      "Deleted: data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/ru/train-ru-part_0001.parquet\n",
      "Deleted: data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/si/train-si-part_0004.parquet\n",
      "Deleted: data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/ru/train-ru-part_0006.parquet\n",
      "Deleted: data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/ru/train-ru-part_0002.parquet\n",
      "Deleted: data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/pl/train-pl-part_0004.parquet\n",
      "Deleted: data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/pl/train-pl-part_0005.parquet\n",
      "Deleted: data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/si/train-si-part_0006.parquet\n",
      "Deleted: data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/pl/train-pl-part_0003.parquet\n",
      "Deleted: data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/si/train-si-part_0003.parquet\n",
      "Deleted: data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/pl/train-pl-part_0002.parquet\n",
      "Deleted: data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/pl/train-pl-part_0000.parquet\n",
      "Deleted: data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/ru/train-ru-part_0004.parquet\n",
      "Deleted: data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/ru/train-ru-part_0005.parquet\n",
      "Deleted: data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/bg/train-bg-part_0006.parquet\n",
      "Deleted: data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/bg/train-bg-part_0004.parquet\n",
      "Deleted: data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/si/train-si-part_0000.parquet\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# List of file paths\n",
    "files_to_delete = errs_to_delete['source_file'].dropna().unique().tolist()\n",
    "\n",
    "# Delete each file safely\n",
    "for path in files_to_delete:\n",
    "    if os.path.isfile(path):\n",
    "        try:\n",
    "            # os.remove(path)\n",
    "            print(f\"Deleted: {path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error deleting {path}: {e}\")\n",
    "    else:\n",
    "        print(f\"File not found: {path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "53751190",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "filename",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "start",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "end",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "text_lang",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "text",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "label_bin",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "label_multi",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "base_split",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Questioning_the_Reputation",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Name_Calling-Labeling",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Appeal_to_Hypocrisy",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Conversation_Killer",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Loaded_Language",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Repetition",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Appeal_to_Popularity",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Doubt",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Red_Herring",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Flag_Waving",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Exaggeration-Minimisation",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Consequential_Oversimplification",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Appeal_to_Pity",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Appeal_to_Time",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Appeal_to_Values",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Obfuscation-Vagueness-Confusion",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Straw_Man",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Slogans",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Appeal_to_Fear-Prejudice",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Causal_Oversimplification",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Appeal_to_Authority",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "False_Dilemma-No_Choice",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Whataboutism",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "False_Equivalence",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Guilt_by_Association",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "alt_split",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "output_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "prompt_name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "prompt_version",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "job",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "step",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "max_iterations",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "temperature",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "model_provider",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "model_name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "model_mode",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "gold",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "gold_text",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "spans",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "raw",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "extra_properties",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "explanation",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "is_valid",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "illegal_value",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "think_content",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "extra_content",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "updated_definition",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "source_file",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "error",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "status",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "split",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "expected_output",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "aa37c04c-8ea5-4f5e-9407-f027088f4b90",
       "rows": [
        [
         "30",
         "pl_abortion_11_04_2024_n07.txt",
         "3811",
         "4153",
         "PL",
         "My, kobiety i mężczyźni broniący prawa do życia\nchcemy poważnego traktowania kobiet i ich potrzeb,\nkiedy zachodzą w ciążę, kiedy stają się matkami,\nlepszej jakości i dostępności opieki zdrowotnej, wsparcia\npsychologicznego oraz pomocy w zakresie opieki nad\ndzieckiem, szczególnie gdy okaże się, że może być\nniepełnosprawne lub poważnie chore.",
         "True",
         "['Appeal_to_Values']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['chcemy poważnego traktowania kobiet i ich potrzeb, kiedy zachodzą w ciążę, kiedy stają się matkami, lepszej jakości i dostępności opieki zdrowotnej, wsparcia psychologicznego oraz pomocy w zakresie opieki nad dzieckiem']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/False_Dilemma-No_Choice",
         "False_Dilemma-No_Choice",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "0",
         "No, the False Dilemma-No Choice technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text discusses the needs and rights of women and men regarding healthcare and support during pregnancy and motherhood. It does not present a limited choice between two options, nor does it depict one option as a no-go, which is characteristic of the False Dilemma or No Choice technique. Therefore, the expert\\'s verdict is correct.\",\\n  \"updated_definition\": \"\"\\n}']",
         "[None]",
         "[\"The input text discusses the needs and rights of women and men regarding healthcare and support during pregnancy and motherhood. It does not present a limited choice between two options, nor does it depict one option as a no-go, which is characteristic of the False Dilemma or No Choice technique. Therefore, the expert's verdict is correct.\"]",
         "[ True]",
         "[None]",
         "[None]",
         "[None]",
         "['']",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/False_Dilemma-No_Choice/train/pl/train-pl-part_0007.parquet",
         "[None]",
         "[None]",
         "train",
         "{\"description\": \"The input text discusses the needs and rights of women and men regarding healthcare and support during pregnancy and motherhood. It does not present a limited choice between two options, nor does it depict one option as a no-go, which is characteristic of the False Dilemma or No Choice technique. Therefore, the expert's verdict is correct.\", \"verdict\": false}"
        ],
        [
         "31",
         "pl_abortion_11_04_2024_n08.txt",
         "3138",
         "3188",
         "PL",
         "(Poseł Joanna Scheuring-Wielgus: Zejdź z mównicy.)",
         "True",
         "['Loaded_Language']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Zejdź z mównicy']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/False_Dilemma-No_Choice",
         "False_Dilemma-No_Choice",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "0",
         "No, the False Dilemma-No Choice technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not present a situation where only two options are provided, nor does it eliminate other possible choices. Therefore, the False Dilemma or No Choice technique is not used.\",\\n  \"updated_definition\": \"\"\\n}']",
         "[None]",
         "['The input text does not present a situation where only two options are provided, nor does it eliminate other possible choices. Therefore, the False Dilemma or No Choice technique is not used.']",
         "[ True]",
         "[None]",
         "[None]",
         "[None]",
         "['']",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/False_Dilemma-No_Choice/train/pl/train-pl-part_0007.parquet",
         "[None]",
         "[None]",
         "train",
         "{\"description\": \"The input text does not present a situation where only two options are provided, nor does it eliminate other possible choices. Therefore, the False Dilemma or No Choice technique is not used.\", \"verdict\": false}"
        ],
        [
         "32",
         "pl_current_affairs_09_01_2025_n02.txt",
         "8069",
         "9438",
         "PL",
         "W decyzji generalny dyrektor ochrony środowiska\npodkreśla, że poważne ustawowe braki w raporcie\no oddziaływaniu na środowisko nie pozwalały na wydanie takiej decyzji. Po pierwsze, zabrakło tam wariantowania przedsięwzięcia. Raport nie zawierał ustawowo wymaganej analizy wariantowej z uwzględnieniem opisu oddziaływania poszczególnych wariantów\nna środowisko. W oparciu o informacje zawarte w raporcie nie można było wskazać, który wariant jest\nnajkorzystniejszy dla środowiska i czy istnieją w ogóle przesłanki wyboru innego wariantu niż ten wskazany do realizacji przez inwestora. Inwestor nie przeanalizował innych działań w zakresie możliwości\nosiągnięcia celu środowiskowego środkami mniej\ndolegliwymi dla środowiska i nie udowodnił, że ten\ncel nie może być za ich pomocą osiągnięty. Raport nie\nzawierał również opisu oddziaływania przedsięwzięcia na obszary Natura 2000, na rezerwaty przyrody\nczy opisu działań mających na celu jakąkolwiek minimalizację, kompensację negatywnych oddziaływań\nprzedsięwzięcia w tym zakresie. Na podstawie informacji znajdujących się w raporcie nie można było\nwykluczyć w żaden sposób, że to przedsięwzięcie nie\nbędzie znacząco negatywnie oddziaływać na obszary\nNatura 2000 typu Włocławska Dolina Wisły, Nieszawska Dolina Wisły, Dolina Dolnej Wisły, Dolny\nDunajec, Dorzecze Górnego Sanu, Wisłoka z dopływami, rezerwat przyrody Kulin.",
         "True",
         "['Appeal_to_Authority' 'Appeal_to_Values']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Na podstawie informacji znajdujących się w raporcie nie można było wykluczyć w żaden sposób, że to przedsięwzięcie nie będzie znacząco negatywnie oddziaływać na obszary Natura 2000 typu Włocławska Dolina Wisły, Nieszawska Dolina Wisły, Dolina Dolnej Wisły, Dolny Dunajec, Dorzecze Górnego Sanu, Wisłoka z dopływami, rezerwat przyrody Kulin']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['W decyzji generalny dyrektor ochrony środowiska podkreśla, że poważne ustawowe braki w raporcie o oddziaływaniu na środowisko nie pozwalały na wydanie takiej decyzji']",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/False_Dilemma-No_Choice",
         "False_Dilemma-No_Choice",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "0",
         "No, the False Dilemma-No Choice technique is not used in the input.",
         "\"\"",
         "[None]",
         "[None]",
         "[None]",
         "[ True]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/False_Dilemma-No_Choice/train/pl/train-pl-part_0007.parquet",
         "[{'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-12-01-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit. For Free Account customers, upgrade to Pay as you Go here: https://aka.ms/429TrialUpgrade.'}]",
         "['no validation']",
         "train",
         "{\"description\": null, \"verdict\": false}"
        ],
        [
         "33",
         "pl_eu_12_06_2024_n02.txt",
         "5000",
         "5586",
         "PL",
         "Poseł Marcin Porzucek:\nPanie Marszałku! Wysoka Izbo! Szanowni Państwo! W okresie COVID-u, gdy sytuacje pandemiczne\npojawiały się w ciągu nie roku, nie miesięcy, nie tygodnia, ale wręcz dni, i podejmowaliśmy stosowne\ndziałania, państwo nas krytykowaliście. Gdy Rosja\nnapadała pełnoskalowo na Ukrainę, było podobnie.\nSytuacja wojny hybrydowej na granicy polsko-białoruskiej, podobnie. A dzisiaj państwo macie jeszcze\ntyle czasu, chociaż zmarnowaliście ostatnie pół roku,\nproponujecie rozwiązania ekstraordynaryjne, choć\nmożna to w wielu aspektach zrobić tradycyjnie. To\njest jedna sprawa.",
         "True",
         "['Questioning_the_Reputation']",
         "train",
         "['podejmowaliśmy stosowne działania, państwo nas krytykowaliście'\n 'Gdy Rosja napadała pełnoskalowo na Ukrainę, było podobnie. Sytuacja wojny hybrydowej na granicy polsko-białoruskiej, podobnie'\n 'zmarnowaliście ostatnie pół roku']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/False_Dilemma-No_Choice",
         "False_Dilemma-No_Choice",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "0",
         "No, the False Dilemma-No Choice technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not present a false dilemma or restrict the audience to only two options. Instead, it discusses various situations and actions taken without implying that there are only two choices available. Therefore, the False Dilemma or No Choice technique is not used.\",\\n  \"updated_definition\": \"\"\\n}']",
         "[None]",
         "['The input text does not present a false dilemma or restrict the audience to only two options. Instead, it discusses various situations and actions taken without implying that there are only two choices available. Therefore, the False Dilemma or No Choice technique is not used.']",
         "[ True]",
         "[None]",
         "[None]",
         "[None]",
         "['']",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/False_Dilemma-No_Choice/train/pl/train-pl-part_0007.parquet",
         "[None]",
         "[None]",
         "train",
         "{\"description\": \"The input text does not present a false dilemma or restrict the audience to only two options. Instead, it discusses various situations and actions taken without implying that there are only two choices available. Therefore, the False Dilemma or No Choice technique is not used.\", \"verdict\": false}"
        ],
        [
         "34",
         "pl_eu_12_06_2024_n01.txt",
         "2653",
         "3161",
         "PL",
         "Po prezentacji przez ministrów uzasadnienia projektu ustawy odbyła się krótka debata. Po niej członkowie obu komisji przystąpili do analizy poszczególnych artykułów. W trakcie Biuro Legislacyjne zaproponowało wprowadzenie 20 poprawek redakcyjnych\ni legislacyjnych, które zarówno przez ministerstwo,\njak i członków obu komisji zostały przyjęte. W trakcie\nrozpatrywania poszczególnych artykułów poseł Sebastian Kaleta złożył wniosek mniejszości z propozycją skreślenia art. 8. dotyczącego zamówień publicznych.",
         "False",
         "[]",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/False_Dilemma-No_Choice",
         "False_Dilemma-No_Choice",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "0",
         "No, the False Dilemma-No Choice technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not present a situation where only two options are provided, nor does it eliminate other possible choices. It discusses a legislative process without framing it as a false dilemma.\",\\n  \"updated_definition\": \"\"\\n}']",
         "[None]",
         "['The input text does not present a situation where only two options are provided, nor does it eliminate other possible choices. It discusses a legislative process without framing it as a false dilemma.']",
         "[ True]",
         "[None]",
         "[None]",
         "[None]",
         "['']",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/False_Dilemma-No_Choice/train/pl/train-pl-part_0007.parquet",
         "[None]",
         "[None]",
         "train",
         "{\"description\": \"The input text does not present a situation where only two options are provided, nor does it eliminate other possible choices. It discusses a legislative process without framing it as a false dilemma.\", \"verdict\": false}"
        ],
        [
         "35",
         "pl_abortion_11_04_2024_n05.txt",
         "9681",
         "10556",
         "PL",
         "Dziś jesteśmy w demograficznym kryzysie. Polki\nnie chcą rodzić dzieci w Polsce, która nie jest dla nich\nbezpieczna pod żadnym względem. Mówią: boję się\nbyć w ciąży, bo dziewczyny w moim wieku umierają.\nUmarły pan Iza, pani Agnieszka, pani Marta, pani\nDorota. Dlatego Koalicja Obywatelska przygotowała\ni przedstawia projekt ustawy o świadomym rodzicielstwie.\nZakaz aborcji w Polsce to restrykcyjne prawo,\nktóre zagraża zdrowiu, życiu i bezpieczeństwu kobiet,\na nasz projekt, projekt Koalicji Obywatelskiej,\nprzywraca kobietom wolność wyboru, przywraca kobietom\ngodność, przywraca kobietom podmiotowość. Zakłada\nmożliwość bezpiecznego i bezpłatnego przerywania\nciąży do 12 tygodnia jej trwania oraz po 12 tygodniu\nw określonych okolicznościach. Aborcja musi być\nbezpieczna, aborcja musi być legalna. Aborcja musi być\ndostępna, a kobieta musi być bezpieczna.\nDziękuję. (Oklaski)",
         "True",
         "['Conversation_Killer' 'Causal_Oversimplification' 'Slogans'\n 'Whataboutism' 'Appeal_to_Values' 'Repetition' 'Appeal_to_Fear-Prejudice']",
         "train",
         "[]",
         "[]",
         "[]",
         "['aborcja musi być legalna' 'Aborcja musi być dostępna']",
         "[]",
         "['przywraca kobietom wolność wyboru' 'przywraca kobietom godność'\n 'przywraca kobietom podmiotowość']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['zagraża zdrowiu, życiu i bezpieczeństwu kobiet']",
         "[]",
         "[]",
         "['Aborcja musi być bezpieczna, aborcja musi być legalna'\n 'Aborcja musi być dostępna, a kobieta musi być bezpieczna']",
         "['Mówią: boję się być w ciąży, bo dziewczyny w moim wieku umierają. Umarły pan Iza, pani Agnieszka, pani Marta, pani Dorota'\n 'Zakaz aborcji w Polsce to restrykcyjne prawo, które zagraża zdrowiu, życiu i bezpieczeństwu kobiet']",
         "['Polki nie chcą rodzić dzieci w Polsce, która nie jest dla nich bezpieczna pod żadnym względem']",
         "[]",
         "[]",
         "['Dziś jesteśmy w demograficznym kryzysie']",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/False_Dilemma-No_Choice",
         "False_Dilemma-No_Choice",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "0",
         "No, the False Dilemma-No Choice technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text discusses the issue of abortion and women\\'s rights without presenting a false dilemma. It acknowledges the complexity of the situation and advocates for safe and legal abortion options, rather than limiting the audience to only two choices. Therefore, the False Dilemma or No Choice technique is not used.\",\\n  \"updated_definition\": \"\"\\n}']",
         "[None]",
         "[\"The input text discusses the issue of abortion and women's rights without presenting a false dilemma. It acknowledges the complexity of the situation and advocates for safe and legal abortion options, rather than limiting the audience to only two choices. Therefore, the False Dilemma or No Choice technique is not used.\"]",
         "[ True]",
         "[None]",
         "[None]",
         "[None]",
         "['']",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/False_Dilemma-No_Choice/train/pl/train-pl-part_0007.parquet",
         "[None]",
         "[None]",
         "train",
         "{\"description\": \"The input text discusses the issue of abortion and women's rights without presenting a false dilemma. It acknowledges the complexity of the situation and advocates for safe and legal abortion options, rather than limiting the audience to only two choices. Therefore, the False Dilemma or No Choice technique is not used.\", \"verdict\": false}"
        ],
        [
         "36",
         "pl_abortion_11_04_2024_n04.txt",
         "6500",
         "6777",
         "PL",
         "Natomiast trzecim elementem jest referendum.\nTego chcą Polki i Polacy, ponad 66%. Jest to rozwiązanie\nskuteczne. To jest rozwiązanie, do którego\nmusi zastosować się prezydent. To rozwiązanie\nzagwarantuje nam także pokój, bo to decyzja\nobywatelek i obywateli ma najgłębszy sens.",
         "True",
         "['Conversation_Killer' 'Appeal_to_Values' 'Appeal_to_Popularity']",
         "train",
         "[]",
         "[]",
         "[]",
         "['Jest to rozwiązanie skuteczne'\n 'To jest rozwiązanie, do którego musi zastosować się prezydent']",
         "[]",
         "[]",
         "['Natomiast trzecim elementem jest referendum. Tego chcą Polki i Polacy, ponad 66%. Jest to rozwiązanie skuteczne']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['To rozwiązanie zagwarantuje nam także pokój, bo to decyzja obywatelek i obywateli ma najgłębszy sens']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/False_Dilemma-No_Choice",
         "False_Dilemma-No_Choice",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "0",
         "No, the False Dilemma-No Choice technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not present a false dilemma as it does not limit the options to only two choices or depict one option as a no-go. Instead, it discusses the referendum as a solution without excluding other possibilities.\",\\n  \"updated_definition\": \"\"\\n}']",
         "[None]",
         "['The input text does not present a false dilemma as it does not limit the options to only two choices or depict one option as a no-go. Instead, it discusses the referendum as a solution without excluding other possibilities.']",
         "[ True]",
         "[None]",
         "[None]",
         "[None]",
         "['']",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/False_Dilemma-No_Choice/train/pl/train-pl-part_0007.parquet",
         "[None]",
         "[None]",
         "train",
         "{\"description\": \"The input text does not present a false dilemma as it does not limit the options to only two choices or depict one option as a no-go. Instead, it discusses the referendum as a solution without excluding other possibilities.\", \"verdict\": false}"
        ],
        [
         "37",
         "pl_current_affairs_09_01_2025_n02.txt",
         "7617",
         "7814",
         "PL",
         "Dzisiaj generalny dyrektor ochrony środowiska\nde facto powtórzył te argumenty, które były argumentami niepozostawiającymi żadnych wątpliwości.\n(Poseł Joanna Borowiak: Dlatego przegrał pan\nKurtyka.)",
         "True",
         "['Conversation_Killer' 'Appeal_to_Authority']",
         "train",
         "[]",
         "[]",
         "[]",
         "['które były argumentami niepozostawiającymi żadnych wątpliwości']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Dzisiaj generalny dyrektor ochrony środowiska de facto powtórzył te argumenty, które były argumentami niepozostawiającymi żadnych wątpliwości']",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/False_Dilemma-No_Choice",
         "False_Dilemma-No_Choice",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "0",
         "No, the False Dilemma-No Choice technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not present a situation where only two options are provided, nor does it eliminate other possible choices. Therefore, the False Dilemma or No Choice technique is not used.\",\\n  \"updated_definition\": \"\"\\n}']",
         "[None]",
         "['The input text does not present a situation where only two options are provided, nor does it eliminate other possible choices. Therefore, the False Dilemma or No Choice technique is not used.']",
         "[ True]",
         "[None]",
         "[None]",
         "[None]",
         "['']",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/False_Dilemma-No_Choice/train/pl/train-pl-part_0007.parquet",
         "[None]",
         "[None]",
         "train",
         "{\"description\": \"The input text does not present a situation where only two options are provided, nor does it eliminate other possible choices. Therefore, the False Dilemma or No Choice technique is not used.\", \"verdict\": false}"
        ],
        [
         "38",
         "pl_abortion_11_04_2024_n05.txt",
         "0",
         "364",
         "PL",
         "Poseł Urszula Pasławska:\nSzanowny Panie Marszałku! Wysoka Izbo! Polacy\n15 października zagłosowali na nas, prosili nas o to,\nżebyśmy rządzili skutecznie. Dlatego dzisiaj jako\nTrzecia Droga przedstawiamy projekt ustawy, który\nskutecznie rozwiąże problem terminacji ciąży,\nponieważ jako jedyny ma szansę zarówno na poparcie\nprawej strony, jak i na podpis prezydenta.",
         "True",
         "['Appeal_to_Authority']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['jako jedyny ma szansę zarówno na poparcie prawej strony, jak i na podpis prezydenta']",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/False_Dilemma-No_Choice",
         "False_Dilemma-No_Choice",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "0",
         "No, the False Dilemma-No Choice technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not present a false dilemma as it does not limit the options to only two choices or depict one option as a no-go. Instead, it discusses a proposed law that aims to address a specific issue without excluding other potential solutions or alternatives.\",\\n  \"updated_definition\": \"\"\\n}']",
         "[None]",
         "['The input text does not present a false dilemma as it does not limit the options to only two choices or depict one option as a no-go. Instead, it discusses a proposed law that aims to address a specific issue without excluding other potential solutions or alternatives.']",
         "[ True]",
         "[None]",
         "[None]",
         "[None]",
         "['']",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/False_Dilemma-No_Choice/train/pl/train-pl-part_0007.parquet",
         "[None]",
         "[None]",
         "train",
         "{\"description\": \"The input text does not present a false dilemma as it does not limit the options to only two choices or depict one option as a no-go. Instead, it discusses a proposed law that aims to address a specific issue without excluding other potential solutions or alternatives.\", \"verdict\": false}"
        ],
        [
         "39",
         "pl_abortion_11_04_2024_n05.txt",
         "7984",
         "9130",
         "PL",
         "I jeszcze heroizm. Obowiązujące prawo w Polsce\nzmusza kobiety do heroizmu. Dziś w Polsce ciążę\nprowadzą prokurator, polityk i ksiądz. Dziś ciążę w\nPolsce prowadzą ideologia, zabobony i religia. W 2016 r.\nJarosław Kaczyński zapowiedział, że będą dążyli do\ntego, by nawet przypadki ciąż bardzo trudnych,\nkiedy dziecko jest skazane na śmierć, mocno\nzdeformowane, kończyły się jednak porodem, by to dziecko\nmogło być ochrzczone, pochowane, miało imię i było\nokrutnym początkiem. Czarę goryczy przelał wyrok\nTrybunału Konstytucyjnego Julii Przyłębskiej. I to,\nco się wydarzyło, jest czarnym scenariuszem, który\nwłaśnie się cały czas realizuje. To był impuls do\ndziałania polityków PiS-u, Konfederacji i\nultrakonserwatywnych fundamentalistów, dla których\nnajważniejsze to urodzić. Nieważne, czy dziecko z gwałtu, czy\ndziecko z niepełnosprawnością, która zakończy jego\nżycie w cierpieniach, nie ważne, czy płód jest martwy\ni czy przy okazji trudnego porodu umrze matka.\nNajważniejsze to urodzić. Scenariusz, o którym mówię\njest scenariuszem dramatycznego filmu opartego na\nfaktach, w którym dochodzi do rzeczywistych\ntragedii, bo umierają młode kobiety.",
         "True",
         "['Exaggeration-Minimisation' 'Loaded_Language' 'Appeal_to_Pity'\n 'Name_Calling-Labeling' 'Straw_Man' 'Repetition'\n 'Appeal_to_Fear-Prejudice']",
         "train",
         "[]",
         "['ultrakonserwatywnych fundamentalistów']",
         "[]",
         "[]",
         "['skazane na śmierć' 'mocno zdeformowane' 'okrutnym' 'Czarę goryczy'\n 'czarnym scenariuszem']",
         "['Dziś w Polsce ciążę prowadzą' 'Dziś ciążę w Polsce prowadzą']",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Obowiązujące prawo w Polsce zmusza kobiety do heroizmu'\n 'Dziś w Polsce ciążę prowadzą prokurator, polityk i ksiądz'\n 'Dziś ciążę w Polsce prowadzą ideologia, zabobony i religia'\n 'I to, co się wydarzyło, jest czarnym scenariuszem, który właśnie się cały czas realizuje']",
         "[]",
         "['Nieważne, czy dziecko z gwałtu, czy dziecko z niepełnosprawnością, która zakończy jego życie w cierpieniach, nie ważne, czy płód jest martwy i czy przy okazji trudnego porodu umrze matka']",
         "[]",
         "[]",
         "[]",
         "['To był impuls do działania polityków PiS-u, Konfederacji i ultrakonserwatywnych fundamentalistów, dla których najważniejsze to urodzić'\n 'Najważniejsze to urodzić']",
         "[]",
         "['by nawet przypadki ciąż bardzo trudnych, kiedy dziecko jest skazane na śmierć, mocno zdeformowane, kończyły się jednak porodem'\n 'przy okazji trudnego porodu umrze matka'\n 'dochodzi do rzeczywistych tragedii, bo umierają młode kobiety']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/False_Dilemma-No_Choice",
         "False_Dilemma-No_Choice",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "0",
         "No, the False Dilemma-No Choice technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not present a false dilemma or an either-or situation. Instead, it discusses various complex scenarios regarding pregnancy and the implications of certain laws without limiting the options to just two. Therefore, the False Dilemma or No Choice technique is not used.\",\\n  \"updated_definition\": \"\"\\n}']",
         "[None]",
         "['The input text does not present a false dilemma or an either-or situation. Instead, it discusses various complex scenarios regarding pregnancy and the implications of certain laws without limiting the options to just two. Therefore, the False Dilemma or No Choice technique is not used.']",
         "[ True]",
         "[None]",
         "[None]",
         "[None]",
         "['']",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/False_Dilemma-No_Choice/train/pl/train-pl-part_0007.parquet",
         "[None]",
         "[None]",
         "train",
         "{\"description\": \"The input text does not present a false dilemma or an either-or situation. Instead, it discusses various complex scenarios regarding pregnancy and the implications of certain laws without limiting the options to just two. Therefore, the False Dilemma or No Choice technique is not used.\", \"verdict\": false}"
        ],
        [
         "40",
         "pl_abortion_11_04_2024_n08.txt",
         "150",
         "288",
         "PL",
         "Wicemarszałek Monika Wielichowska:\nSam pan wywołał reakcję pań, które znajdują się na\ngalerii. Proszę kontynuować. (Gwar na sali, dzwonek)",
         "True",
         "['Questioning_the_Reputation']",
         "train",
         "['Sam pan wywołał reakcję pań, które znajdują się na galerii']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/False_Dilemma-No_Choice",
         "False_Dilemma-No_Choice",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "0",
         "No, the False Dilemma-No Choice technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not present a situation where only two options are provided, nor does it eliminate other possible choices. Therefore, the False Dilemma or No Choice technique is not used.\",\\n  \"updated_definition\": \"\"\\n}']",
         "[None]",
         "['The input text does not present a situation where only two options are provided, nor does it eliminate other possible choices. Therefore, the False Dilemma or No Choice technique is not used.']",
         "[ True]",
         "[None]",
         "[None]",
         "[None]",
         "['']",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/False_Dilemma-No_Choice/train/pl/train-pl-part_0002.parquet",
         "[None]",
         "[None]",
         "train",
         "{\"description\": \"The input text does not present a situation where only two options are provided, nor does it eliminate other possible choices. Therefore, the False Dilemma or No Choice technique is not used.\", \"verdict\": false}"
        ],
        [
         "41",
         "pl_abortion_11_04_2024_n04.txt",
         "1320",
         "1701",
         "PL",
         "Zakaz aborcji w Polsce nie działa i wiedzą o tym\ndoskonale pomagające w aborcjach aktywistki i\nprzedstawicielki organizacji pozarządowych, które są tutaj\ndziś z nami. Nie wiem, czy wszystkie, bo nie wszystkie\notrzymały dziś rano zgodę od marszałka Hołowni\nna wejście na galerię. Podobno powodem są jakieś\nlimity, limity w otwartości i w uśmiechu.\nPierwsze słyszę, ale się zdarzyło.",
         "True",
         "['Conversation_Killer' 'Appeal_to_Pity' 'Repetition']",
         "train",
         "[]",
         "[]",
         "[]",
         "['Zakaz aborcji w Polsce nie działa']",
         "[]",
         "['Zakaz aborcji w Polsce nie działa']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Podobno powodem są jakieś limity, limity w otwartości i w uśmiechu']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/False_Dilemma-No_Choice",
         "False_Dilemma-No_Choice",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "0",
         "No, the False Dilemma-No Choice technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not present a false dilemma or an either-or situation. It discusses the issue of abortion in Poland without limiting the options to just two, nor does it depict one option as a no-go. Therefore, the False Dilemma or No Choice technique is not used.\",\\n  \"updated_definition\": \"\"\\n}']",
         "[None]",
         "['The input text does not present a false dilemma or an either-or situation. It discusses the issue of abortion in Poland without limiting the options to just two, nor does it depict one option as a no-go. Therefore, the False Dilemma or No Choice technique is not used.']",
         "[ True]",
         "[None]",
         "[None]",
         "[None]",
         "['']",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/False_Dilemma-No_Choice/train/pl/train-pl-part_0002.parquet",
         "[None]",
         "[None]",
         "train",
         "{\"description\": \"The input text does not present a false dilemma or an either-or situation. It discusses the issue of abortion in Poland without limiting the options to just two, nor does it depict one option as a no-go. Therefore, the False Dilemma or No Choice technique is not used.\", \"verdict\": false}"
        ],
        [
         "42",
         "pl_defence_22_05_2024_n01.txt",
         "8339",
         "10002",
         "PL",
         "Proszę państwa, jeśli chodzi o te zakupy, to one\nwszystkie były konsultowane, były wynikiem naszych rozmów w Radzie Modernizacji Technicznej\nz przeważającym, decydującym głosem Sztabu Generalnego Wojska Polskiego. Zmieniłem sposób zamawiania sprzętu wojskowego dla polskiego wojska,\nbo on był sprzeczny wewnętrznie. To była sytuacja,\nw której nie można było pójść naprzód, więc udrożniłem te procesy. Potem, kiedy przyszedł rok 2022,\nkiedy po raz kolejny Rosja napadła na Ukrainę, nawiązałem relacje z Koreą Południową. Dlaczego to\nzrobiłem? Dlatego że Korea Południowa posiada olbrzymi potencjał produkcyjny, jeśli chodzi o przemysł\nzbrojeniowy. Uważam za jeden z naszych sukcesów\nto, że w tak krótkim czasie doprowadziliśmy do tego,\nże w Wojsku Polskim już są czołgi K2, że obok\nHIMARS-ów, o których powiedziałem, są Chunmoo,\nczyli artyleria rakietowa o zasięgu do 300 km, że są\nsamoloty szkolno-bojowe FA-50. Pan powiedział, że\npiloci tak dużo zarabiają. Trzeba szkolić pilotów.\nFA-50 zostały zaprojektowane przez Lockheed Martin, a więc są taką mniejszą, to prawda, wersją\nF-16. W Wojsku Polskim, kiedy przyszliśmy do\nwładzy, w zasadzie tylko F-16 stanowiły jakąś siłę\nbojową. Pozostały sprzęt wojskowy był postsowiecki,\nbył zużyty. To był obraz nędzy i rozpaczy, a my doprowadziliśmy do tego, że dziś Wojsko Polskie liczy\nponad 200 tys. żołnierzy. Tylko jeszcze cele… Też\npan o tym nie wspomniał. Co najmniej 300 tys. żołnierzy. Można powiedzieć, że 300 tys. żołnierzy wojsk\noperacyjnych i 50 tys. żołnierzy Wojsk Obrony Terytorialnej – to powinien być nasz wspólny cel, mówię\no państwie polskim (Oklaski), bo w ten sposób możemy realnie odstraszyć agresora.",
         "True",
         "['Loaded_Language' 'Flag_Waving' 'Obfuscation-Vagueness-Confusion'\n 'Appeal_to_Authority' 'Name_Calling-Labeling' 'Red_Herring'\n 'Appeal_to_Fear-Prejudice']",
         "train",
         "[]",
         "['postsowiecki']",
         "[]",
         "[]",
         "['obraz nędzy i rozpaczy']",
         "[]",
         "[]",
         "[]",
         "['Pan powiedział, że piloci tak dużo zarabiają']",
         "['mówię o państwie polskim']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['To była sytuacja, w której nie można było pójść naprzód, więc udrożniłem te procesy']",
         "[]",
         "[]",
         "['realnie odstraszyć agresora']",
         "[]",
         "['jeśli chodzi o te zakupy, to one wszystkie były konsultowane, były wynikiem naszych rozmów w Radzie Modernizacji Technicznej z przeważającym, decydującym głosem Sztabu Generalnego Wojska Polskiego']",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/False_Dilemma-No_Choice",
         "False_Dilemma-No_Choice",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "0",
         "No, the False Dilemma-No Choice technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not present a false dilemma or an either-or situation. It discusses military procurement and the growth of the Polish military without limiting the options to just two choices or depicting one as a no-go option. Therefore, the technique is not used.\",\\n  \"updated_definition\": \"\"\\n}']",
         "[None]",
         "['The input text does not present a false dilemma or an either-or situation. It discusses military procurement and the growth of the Polish military without limiting the options to just two choices or depicting one as a no-go option. Therefore, the technique is not used.']",
         "[ True]",
         "[None]",
         "[None]",
         "[None]",
         "['']",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/False_Dilemma-No_Choice/train/pl/train-pl-part_0002.parquet",
         "[None]",
         "[None]",
         "train",
         "{\"description\": \"The input text does not present a false dilemma or an either-or situation. It discusses military procurement and the growth of the Polish military without limiting the options to just two choices or depicting one as a no-go option. Therefore, the technique is not used.\", \"verdict\": false}"
        ],
        [
         "43",
         "pl_abortion_11_04_2024_n03.txt",
         "1839",
         "2256",
         "PL",
         "Mam dzisiaj zaszczyt i przyjemność jako posłanka\nklubu parlamentarnego Lewicy i wnioskodawczyni\nprojektu o bezpiecznym przerywaniu ciąży\nprzedstawić państwu projekt, który jest oparty na trosce i\nempatii w stosunku do kobiet, które po 30 latach\nobowiązywania zakazu aborcji muszą w końcu odzyskać\nodebrane im wiele lat temu prawo do podejmowania\nsamodzielnych decyzji w sprawie macierzyństwa,\nswojego zdrowia i życia.",
         "True",
         "['Appeal_to_Time' 'Appeal_to_Pity' 'Appeal_to_Values']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['po 30 latach obowiązywania zakazu aborcji muszą w końcu odzyskać odebrane im wiele lat temu prawo do podejmowania samodzielnych decyzji w sprawie macierzyństwa, swojego zdrowia i życia']",
         "['po 30 latach obowiązywania zakazu aborcji muszą w końcu odzyskać odebrane im wiele lat temu prawo']",
         "['który jest oparty na trosce i empatii w stosunku do kobiet'\n 'muszą w końcu odzyskać odebrane im wiele lat temu prawo do podejmowania samodzielnych decyzji w sprawie macierzyństwa, swojego zdrowia i życia']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/False_Dilemma-No_Choice",
         "False_Dilemma-No_Choice",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "0",
         "No, the False Dilemma-No Choice technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not present a false dilemma or an either-or situation. It discusses the importance of women\\'s rights and the need to restore their autonomy without limiting the options available to them. Therefore, the technique is not used.\",\\n  \"updated_definition\": \"\"\\n}']",
         "[None]",
         "[\"The input text does not present a false dilemma or an either-or situation. It discusses the importance of women's rights and the need to restore their autonomy without limiting the options available to them. Therefore, the technique is not used.\"]",
         "[ True]",
         "[None]",
         "[None]",
         "[None]",
         "['']",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/False_Dilemma-No_Choice/train/pl/train-pl-part_0002.parquet",
         "[None]",
         "[None]",
         "train",
         "{\"description\": \"The input text does not present a false dilemma or an either-or situation. It discusses the importance of women's rights and the need to restore their autonomy without limiting the options available to them. Therefore, the technique is not used.\", \"verdict\": false}"
        ],
        [
         "44",
         "pl_current_affairs_09_01_2025_n01.txt",
         "1187",
         "2227",
         "PL",
         "Poseł Maria Koc:\nDziękuję, panie marszałku.\nSzanowny Panie Marszałku! Szanowna Pani Minister! Wysoka Izbo! Jedną ze sztandarowych obietnic złożonych w trakcie kampanii wyborczej w 2023 r.\nprzez Koalicję Obywatelską, przez pana Donalda\nTuska była obietnica wprowadzenia w ciągu pierwszych 100 dni rządów tzw. świadczenia babciowego.\nTo pieniądze dla rodziców na zapewnienie opieki nad\nmałymi dziećmi, po to aby ci rodzice mogli wrócić na\nrynek pracy. Nie udało się koalicji rządzącej wprowadzić tego świadczenia w życie w ciągu pierwszych\n100 dni rządów, ale jesienią ta ustawa weszła w życie.\nOd 1 października 2024 r. rodzice mogli już składać\nwnioski do ZUS-u i wielu rodziców takie wnioski złożyło. Były opóźnienia w wypłatach, rodzice komunikowali się z ZUS-em, ZUS zapewniał, że wszystkie\nświadczenia, łącznie z wyrównaniami od 1 października, zostaną wypłacone rodzicom do dnia 20 grudnia. Niestety mamy rok 2025 i media ogólnopolskie\ndonoszą, że wielu rodziców nadal nie otrzymało tego\nświadczenia, mimo że składali wnioski w 2024 r.",
         "True",
         "['Doubt']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Niestety mamy rok 2025 i media ogólnopolskie donoszą, że wielu rodziców nadal nie otrzymało tego świadczenia, mimo że składali wnioski w 2024 r']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/False_Dilemma-No_Choice",
         "False_Dilemma-No_Choice",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "0",
         "No, the False Dilemma-No Choice technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not present a false dilemma or an either-or situation. It discusses the implementation of a specific benefit without suggesting that there are only two options available or that one option is a no-go. Therefore, the technique is not used.\",\\n  \"updated_definition\": \"\"\\n}']",
         "[None]",
         "['The input text does not present a false dilemma or an either-or situation. It discusses the implementation of a specific benefit without suggesting that there are only two options available or that one option is a no-go. Therefore, the technique is not used.']",
         "[ True]",
         "[None]",
         "[None]",
         "[None]",
         "['']",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/False_Dilemma-No_Choice/train/pl/train-pl-part_0002.parquet",
         "[None]",
         "[None]",
         "train",
         "{\"description\": \"The input text does not present a false dilemma or an either-or situation. It discusses the implementation of a specific benefit without suggesting that there are only two options available or that one option is a no-go. Therefore, the technique is not used.\", \"verdict\": false}"
        ],
        [
         "45",
         "pl_abortion_11_04_2024_n07.txt",
         "7843",
         "8354",
         "PL",
         "Tytuł projektu Lewicy sugeruje, że aborcja może być\nbezpieczna, tymczasem sami projektodawcy w\nuzasadnieniu projektu podają, że od dnia wydania wyroku\nTrybunału Konstytucyjnego w 2020 r. tylko jedna z\norganizacji proaborcyjnych pomagała w aborcji w\nprzypadku 125 tys. kobiet, co oznacza, że co najmniej tyle\nsamo dzieci w wyniku aborcji straciło życie.\nProjektowane przepisy uderzają w podstawowe prawo każdego\nczłowieka, są całkowicie nieakceptowalne i powinny\nbyć odrzucone już w pierwszym czytaniu. (Oklaski)",
         "True",
         "['Conversation_Killer' 'Appeal_to_Hypocrisy' 'Appeal_to_Values']",
         "train",
         "[]",
         "[]",
         "['Tytuł projektu Lewicy sugeruje, że aborcja może być bezpieczna, tymczasem sami projektodawcy w uzasadnieniu projektu podają, że od dnia wydania wyroku Trybunału Konstytucyjnego w 2020 r. tylko jedna z organizacji proaborcyjnych pomagała w aborcji w przypadku 125 tys. kobiet, co oznacza, że co najmniej tyle samo dzieci w wyniku aborcji straciło życie']",
         "['są całkowicie nieakceptowalne i powinny być odrzucone już w pierwszym czytaniu']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Projektowane przepisy uderzają w podstawowe prawo każdego człowieka']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/False_Dilemma-No_Choice",
         "False_Dilemma-No_Choice",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "0",
         "No, the False Dilemma-No Choice technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not present a false dilemma or an either-or situation. It discusses the implications of a proposed project regarding abortion without limiting the options to just two. Therefore, the technique was not used.\",\\n  \"updated_definition\": \"\"\\n}']",
         "[None]",
         "['The input text does not present a false dilemma or an either-or situation. It discusses the implications of a proposed project regarding abortion without limiting the options to just two. Therefore, the technique was not used.']",
         "[ True]",
         "[None]",
         "[None]",
         "[None]",
         "['']",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/False_Dilemma-No_Choice/train/pl/train-pl-part_0002.parquet",
         "[None]",
         "[None]",
         "train",
         "{\"description\": \"The input text does not present a false dilemma or an either-or situation. It discusses the implications of a proposed project regarding abortion without limiting the options to just two. Therefore, the technique was not used.\", \"verdict\": false}"
        ],
        [
         "46",
         "pl_abortion_11_04_2024_n06.txt",
         "7874",
         "8360",
         "PL",
         "Jeszcze żaden zakaz aborcji nie zlikwidował aborcji.\nTa debata, szanowni państwo, nie jest o waszych\nsumieniach, jest o nas, o kobietach, o naszym zdrowiu,\no naszym życiu, o naszej godności. Więc proszę\nwas, abyście nie kazali nam być zakładnikami waszej\nwiary albo jej braku, waszych sumień i waszych poglądów.\nProszę was o to, abyście nam, kobietom, po\nprostu zaufali. Uwierzcie, że jesteśmy mądre, że\nmożemy podejmować decyzje i że te decyzje są najlepsze dla nas. Dziękuję. (Oklaski",
         "True",
         "['Conversation_Killer' 'Flag_Waving' 'Appeal_to_Pity']",
         "train",
         "[]",
         "[]",
         "[]",
         "['Jeszcze żaden zakaz aborcji nie zlikwidował aborcji']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Ta debata, szanowni państwo, nie jest o waszych sumieniach, jest o nas, o kobietach, o naszym zdrowiu, o naszym życiu, o naszej godności'\n 'Proszę was o to, abyście nam, kobietom, po prostu zaufali. Uwierzcie, że jesteśmy mądre, że możemy podejmować decyzje i że te decyzje są najlepsze dla nas']",
         "[]",
         "[]",
         "['Więc proszę was, abyście nie kazali nam być zakładnikami waszej wiary albo jej braku, waszych sumień i waszych poglądów']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/False_Dilemma-No_Choice",
         "False_Dilemma-No_Choice",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "0",
         "No, the False Dilemma-No Choice technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not present a false dilemma or limit the options available to the audience. Instead, it emphasizes the importance of trusting women to make their own decisions, suggesting that there are multiple perspectives and choices rather than just two opposing options.\",\\n  \"updated_definition\": \"\"\\n}']",
         "[None]",
         "['The input text does not present a false dilemma or limit the options available to the audience. Instead, it emphasizes the importance of trusting women to make their own decisions, suggesting that there are multiple perspectives and choices rather than just two opposing options.']",
         "[ True]",
         "[None]",
         "[None]",
         "[None]",
         "['']",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/False_Dilemma-No_Choice/train/pl/train-pl-part_0002.parquet",
         "[None]",
         "[None]",
         "train",
         "{\"description\": \"The input text does not present a false dilemma or limit the options available to the audience. Instead, it emphasizes the importance of trusting women to make their own decisions, suggesting that there are multiple perspectives and choices rather than just two opposing options.\", \"verdict\": false}"
        ],
        [
         "47",
         "pl_current_affairs_09_01_2025_n01.txt",
         "4848",
         "5376",
         "PL",
         "Dzięki zastosowaniu automatycznego programowania od startu programu do końca grudnia 2024 r.\nrozpatrzono ponad 80% wniosków złożonych w tym\nokresie, pomimo że w październiku, co było naturalne, doszło do spiętrzenia wpływu wniosków z uwagi\nna to, że złożyli je rodzice dzieci z trzech roczników:\n2021–2023. W okresie od 1 października do 31 grudnia ZUS wypłacił łącznie 558 685 świadczeń na kwotę 670 279 596,83 zł. Nadal trwa rozpatrywanie wniosków z okresu, w którym konieczne jest przeprowadzenie postępowania wyjaśniającego.",
         "False",
         "[]",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/False_Dilemma-No_Choice",
         "False_Dilemma-No_Choice",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "0",
         "No, the False Dilemma-No Choice technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not present a false dilemma or no choice scenario, as it discusses the processing of applications without limiting the options available to the audience. There are no indications of presenting only two alternatives or depicting one as a no-go option.\",\\n  \"updated_definition\": \"\"\\n}']",
         "[None]",
         "['The input text does not present a false dilemma or no choice scenario, as it discusses the processing of applications without limiting the options available to the audience. There are no indications of presenting only two alternatives or depicting one as a no-go option.']",
         "[ True]",
         "[None]",
         "[None]",
         "[None]",
         "['']",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/False_Dilemma-No_Choice/train/pl/train-pl-part_0002.parquet",
         "[None]",
         "[None]",
         "train",
         "{\"description\": \"The input text does not present a false dilemma or no choice scenario, as it discusses the processing of applications without limiting the options available to the audience. There are no indications of presenting only two alternatives or depicting one as a no-go option.\", \"verdict\": false}"
        ],
        [
         "48",
         "pl_abortion_11_04_2024_n08.txt",
         "290",
         "1251",
         "PL",
         "Poseł Roman Fritz:\nGrupa feministek pomagająca mordować\nnienarodzone dzieci, Aborcyjny Dream Team, pochwaliła\nsię mniej więcej 2 lata temu, że pomogła zabić\ndziecko gotowe do porodu. Jego matka była w 37. tygodniu\nciąży. Feministki przyznają, że pomaganie w\naborcjach jest ich życiową pasją i misją, a za cel obrały\nsobie promowanie pozytywnego przekazu\ndotyczącego aborcji. Za pośrednictwem mediów\nspołecznościowych co jakiś czas Aborcyjny Dream Team chwali się\nswoimi morderczymi osiągnięciami. Uruchomiona\nprzez nich infolinia umożliwia konsultacje aborcyjne\ni zamawianie tabletek poronnych oraz umawianie\nwyjazdów na zabicie dziecka za granicami Polski.\nAborcjonistki przyznały również, że preferowaną metodą\nzabicia dziecka w tak zaawansowanym stadium\nrozwoju jest rozszerzenie szyjki macicy umożliwiające\nwydobycie go narzędziami, a wcześniej podanie\nbezbronnemu dziecku morderczego zastrzyku, który\nzatrzymuje akcję serca.\n(Poseł Krzysztof Bosak: Hańba!)",
         "True",
         "['Loaded_Language' 'Slogans' 'Questioning_the_Reputation'\n 'Name_Calling-Labeling' 'Appeal_to_Fear-Prejudice']",
         "train",
         "['Grupa feministek pomagająca mordować nienarodzone dzieci, Aborcyjny Dream Team, pochwaliła się mniej więcej 2 lata temu, że pomogła zabić dziecko gotowe do porodu'\n 'Feministki przyznają, że pomaganie w aborcjach jest ich życiową pasją i misją, a za cel obrały sobie promowanie pozytywnego przekazu dotyczącego aborcji'\n 'Aborcyjny Dream Team chwali się swoimi morderczymi osiągnięciami']",
         "['Aborcyjny Dream Team' 'Aborcyjny Dream Team' 'morderczymi']",
         "[]",
         "[]",
         "['pomagająca mordować nienarodzone dzieci' 'pomogła zabić dziecko'\n 'jest ich życiową pasją i misją' 'zabicie dziecka' 'zabicia'\n 'morderczego']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Hańba!)']",
         "['preferowaną metodą zabicia dziecka w tak zaawansowanym stadium rozwoju jest rozszerzenie szyjki macicy umożliwiające wydobycie go narzędziami, a wcześniej podanie bezbronnemu dziecku morderczego zastrzyku, który zatrzymuje akcję serca']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/False_Dilemma-No_Choice",
         "False_Dilemma-No_Choice",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "0",
         "No, the False Dilemma-No Choice technique is not used in the input.",
         "\"\"",
         "[None]",
         "[None]",
         "[None]",
         "[ True]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/False_Dilemma-No_Choice/train/pl/train-pl-part_0002.parquet",
         "[{'code': 'content_filter', 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': True, 'severity': 'high'}, 'jailbreak': {'detected': False, 'filtered': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}, 'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'param': 'prompt', 'status': 400.0, 'type': None}]",
         "['no validation']",
         "train",
         "{\"description\": null, \"verdict\": false}"
        ],
        [
         "49",
         "pl_defence_22_05_2024_n02.txt",
         "1681",
         "1905",
         "PL",
         "Nie mamy też rezerw. Armia polska jest\nmobilizowana na czas wojny. Niestety nie mamy kogo\nmobilizować. Przeciętny wiek polskiego rezerwisty wynosi 50 lat.\nZanim pośle się żołnierza do wojny...\n(Poseł Piotr Kaleta: Na wojnę.)",
         "True",
         "['Doubt']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Nie mamy też rezerw. Armia polska jest mobilizowana na czas wojny. Niestety nie mamy kogo mobilizować. Przeciętny wiek polskiego rezerwisty wynosi 50 lat']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/False_Dilemma-No_Choice",
         "False_Dilemma-No_Choice",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "0",
         "No, the False Dilemma-No Choice technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not present a false dilemma or an either-or situation. It discusses the state of the Polish army and the age of reservists without limiting the options available or suggesting that there are only two choices. Therefore, the technique is not used.\",\\n  \"updated_definition\": \"\"\\n}']",
         "[None]",
         "['The input text does not present a false dilemma or an either-or situation. It discusses the state of the Polish army and the age of reservists without limiting the options available or suggesting that there are only two choices. Therefore, the technique is not used.']",
         "[ True]",
         "[None]",
         "[None]",
         "[None]",
         "['']",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/False_Dilemma-No_Choice/train/pl/train-pl-part_0002.parquet",
         "[None]",
         "[None]",
         "train",
         "{\"description\": \"The input text does not present a false dilemma or an either-or situation. It discusses the state of the Polish army and the age of reservists without limiting the options available or suggesting that there are only two choices. Therefore, the technique is not used.\", \"verdict\": false}"
        ],
        [
         "130",
         "RU_discrediting_the_west_10.txt",
         "2217",
         "2286",
         "RU",
         "ивации воевать за Родину… Так не должно быть.",
         "True",
         "['Conversation_Killer']",
         "train",
         "[]",
         "[]",
         "[]",
         "['Так не должно быть']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/False_Dilemma-No_Choice",
         "False_Dilemma-No_Choice",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "0",
         "No, the False Dilemma-No Choice technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not present a situation where only two options are given, nor does it eliminate other possible choices. Therefore, the False Dilemma or No Choice technique is not used.\",\\n  \"updated_definition\": \"\"\\n}']",
         "[None]",
         "['The input text does not present a situation where only two options are given, nor does it eliminate other possible choices. Therefore, the False Dilemma or No Choice technique is not used.']",
         "[ True]",
         "[None]",
         "[None]",
         "[None]",
         "['']",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/False_Dilemma-No_Choice/train/ru/train-ru-part_0008.parquet",
         "[None]",
         "[None]",
         "train",
         "{\"description\": \"The input text does not present a situation where only two options are given, nor does it eliminate other possible choices. Therefore, the False Dilemma or No Choice technique is not used.\", \"verdict\": false}"
        ],
        [
         "131",
         "RU_discrediting_the_west_19.txt",
         "0",
         "26",
         "RU",
         "Объединённая Европа в шоке",
         "True",
         "['Exaggeration-Minimisation']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Объединённая Европа в шоке']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/False_Dilemma-No_Choice",
         "False_Dilemma-No_Choice",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "0",
         "No, the False Dilemma-No Choice technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not present a false dilemma as it does not limit the options available to the audience or suggest that there are only two choices. There are no excerpts indicating the use of this technique.\",\\n  \"updated_definition\": \"\"\\n}']",
         "[None]",
         "['The input text does not present a false dilemma as it does not limit the options available to the audience or suggest that there are only two choices. There are no excerpts indicating the use of this technique.']",
         "[ True]",
         "[None]",
         "[None]",
         "[None]",
         "['']",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/False_Dilemma-No_Choice/train/ru/train-ru-part_0008.parquet",
         "[None]",
         "[None]",
         "train",
         "{\"description\": \"The input text does not present a false dilemma as it does not limit the options available to the audience or suggest that there are only two choices. There are no excerpts indicating the use of this technique.\", \"verdict\": false}"
        ],
        [
         "132",
         "RU_discrediting_the_west_2.txt",
         "1076",
         "1412",
         "RU",
         "Несмотря на сильное давление со стороны Вашингтона и Брюсселя, недавно приняты законы также в Венгрии и Киргизии.\nСейчас законодательные инициативы об ограничении иностранного влияния рассматриваются не только в Грузии, но и во Франции. Только в Париже в отличие от Тбилиси — ни уличных протестов, ни окриков со стороны США и Евросоюза.",
         "True",
         "['Appeal_to_Popularity']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Несмотря на сильное давление со стороны Вашингтона и Брюсселя, недавно приняты законы также в Венгрии и Киргизии. Сейчас законодательные инициативы об ограничении иностранного влияния рассматриваются не только в Грузии, но и во Франции']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/False_Dilemma-No_Choice",
         "False_Dilemma-No_Choice",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "0",
         "No, the False Dilemma-No Choice technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not present a false dilemma as it does not limit the options to only two choices or depict one option as a no-go. It discusses legislative initiatives in various countries without suggesting that there are only two possible actions or outcomes.\",\\n  \"updated_definition\": \"\"\\n}']",
         "[None]",
         "['The input text does not present a false dilemma as it does not limit the options to only two choices or depict one option as a no-go. It discusses legislative initiatives in various countries without suggesting that there are only two possible actions or outcomes.']",
         "[ True]",
         "[None]",
         "[None]",
         "[None]",
         "['']",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/False_Dilemma-No_Choice/train/ru/train-ru-part_0008.parquet",
         "[None]",
         "[None]",
         "train",
         "{\"description\": \"The input text does not present a false dilemma as it does not limit the options to only two choices or depict one option as a no-go. It discusses legislative initiatives in various countries without suggesting that there are only two possible actions or outcomes.\", \"verdict\": false}"
        ],
        [
         "133",
         "RU_discrediting_the_west_2.txt",
         "422",
         "533",
         "RU",
         "Выступающие против принятия закона действуют однозначно в интересах другого государства, не своей страны точно.",
         "False",
         "[]",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/False_Dilemma-No_Choice",
         "False_Dilemma-No_Choice",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "0",
         "No, the False Dilemma-No Choice technique is not used in the input.",
         "\"\"",
         "[None]",
         "[None]",
         "[None]",
         "[ True]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/False_Dilemma-No_Choice/train/ru/train-ru-part_0008.parquet",
         "[{'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-12-01-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit. For Free Account customers, upgrade to Pay as you Go here: https://aka.ms/429TrialUpgrade.'}]",
         "['no validation']",
         "train",
         "{\"description\": null, \"verdict\": false}"
        ],
        [
         "134",
         "RU_discrediting_the_west_2.txt",
         "1959",
         "2185",
         "RU",
         "Такая истерика вокруг закона об иноагентах может говорить только о том, что есть решения Вашингтона и Брюсселя по свержению действующей грузинской власти и деньги на это уже выделены, а принятие закона может эти планы сорвать.",
         "False",
         "[]",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/False_Dilemma-No_Choice",
         "False_Dilemma-No_Choice",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "0",
         "No, the False Dilemma-No Choice technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not present a false dilemma as it does not limit the options to only two choices or depict one as a no-go option. Instead, it discusses potential actions and implications without forcing a binary choice.\",\\n  \"updated_definition\": \"\"\\n}']",
         "[None]",
         "['The input text does not present a false dilemma as it does not limit the options to only two choices or depict one as a no-go option. Instead, it discusses potential actions and implications without forcing a binary choice.']",
         "[ True]",
         "[None]",
         "[None]",
         "[None]",
         "['']",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/False_Dilemma-No_Choice/train/ru/train-ru-part_0008.parquet",
         "[None]",
         "[None]",
         "train",
         "{\"description\": \"The input text does not present a false dilemma as it does not limit the options to only two choices or depict one as a no-go option. Instead, it discusses potential actions and implications without forcing a binary choice.\", \"verdict\": false}"
        ],
        [
         "135",
         "RU_discrediting_the_west_3.txt",
         "450",
         "887",
         "RU",
         "2. Язык.\nНа Украине запрещается язык, на котором говорит большинство населения страны. Изымаются учебники русского языка и литературы, из образовательной программы исключены русские писатели.\nВместо того, чтобы дать людям возможность говорить на родном, Зеленский навязывает им чуждый язык. Внес законопроект, который наделяет английский статусом языка «международного общения» на Украине. Обязал руководителей разного уровня владеть им.",
         "True",
         "['Causal_Oversimplification' 'Red_Herring']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Внес законопроект, который наделяет английский статусом языка «международного общения» на Украине']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Вместо того, чтобы дать людям возможность говорить на родном, Зеленский навязывает им чуждый язык']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/False_Dilemma-No_Choice",
         "False_Dilemma-No_Choice",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "0",
         "No, the False Dilemma-No Choice technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not present a false dilemma or no choice scenario. It discusses language policies in Ukraine without limiting the options to only two alternatives or depicting one as a no-go option. Therefore, the expert\\'s verdict that the technique is not used is accurate.\",\\n  \"updated_definition\": \"\"\\n}']",
         "[None]",
         "[\"The input text does not present a false dilemma or no choice scenario. It discusses language policies in Ukraine without limiting the options to only two alternatives or depicting one as a no-go option. Therefore, the expert's verdict that the technique is not used is accurate.\"]",
         "[ True]",
         "[None]",
         "[None]",
         "[None]",
         "['']",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/False_Dilemma-No_Choice/train/ru/train-ru-part_0008.parquet",
         "[None]",
         "[None]",
         "train",
         "{\"description\": \"The input text does not present a false dilemma or no choice scenario. It discusses language policies in Ukraine without limiting the options to only two alternatives or depicting one as a no-go option. Therefore, the expert's verdict that the technique is not used is accurate.\", \"verdict\": false}"
        ],
        [
         "136",
         "RU_discrediting_the_west_1.txt",
         "1468",
         "1612",
         "RU",
         "Подобные проявления только сначала выглядят игрой и шуткой.\nЗа этим скрывается серьезная программа отказа от человечности и всего человеческого.",
         "False",
         "[]",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/False_Dilemma-No_Choice",
         "False_Dilemma-No_Choice",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "0",
         "No, the False Dilemma-No Choice technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not present a false dilemma as it does not limit the options to only two choices or depict one as a no-go option. It discusses a serious issue without forcing a binary choice.\",\\n  \"updated_definition\": \"\"\\n}']",
         "[None]",
         "['The input text does not present a false dilemma as it does not limit the options to only two choices or depict one as a no-go option. It discusses a serious issue without forcing a binary choice.']",
         "[ True]",
         "[None]",
         "[None]",
         "[None]",
         "['']",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/False_Dilemma-No_Choice/train/ru/train-ru-part_0008.parquet",
         "[None]",
         "[None]",
         "train",
         "{\"description\": \"The input text does not present a false dilemma as it does not limit the options to only two choices or depict one as a no-go option. It discusses a serious issue without forcing a binary choice.\", \"verdict\": false}"
        ],
        [
         "137",
         "RU_discrediting_the_west_1.txt",
         "28",
         "207",
         "RU",
         "США и страны Запада всегда были одержимы идеей мирового господства. Долгое время им удавалось сохранять гегемонию за счёт грабежа, насилия, колониальной и захватнической политики.",
         "True",
         "['Name_Calling-Labeling']",
         "train",
         "[]",
         "['США и страны Запада всегда были одержимы идеей мирового господства'\n 'сохранять гегемонию за счёт грабежа, насилия, колониальной и захватнической политики']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/False_Dilemma-No_Choice",
         "False_Dilemma-No_Choice",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "0",
         "No, the False Dilemma-No Choice technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not present a false dilemma as it does not limit the options to only two choices or depict one as a no-go option. It discusses the actions of the USA and Western countries without suggesting that there are only two possible perspectives or actions.\",\\n  \"updated_definition\": \"\"\\n}']",
         "[None]",
         "['The input text does not present a false dilemma as it does not limit the options to only two choices or depict one as a no-go option. It discusses the actions of the USA and Western countries without suggesting that there are only two possible perspectives or actions.']",
         "[ True]",
         "[None]",
         "[None]",
         "[None]",
         "['']",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/False_Dilemma-No_Choice/train/ru/train-ru-part_0008.parquet",
         "[None]",
         "[None]",
         "train",
         "{\"description\": \"The input text does not present a false dilemma as it does not limit the options to only two choices or depict one as a no-go option. It discusses the actions of the USA and Western countries without suggesting that there are only two possible perspectives or actions.\", \"verdict\": false}"
        ],
        [
         "138",
         "RU_URW_4.txt",
         "1256",
         "1715",
         "RU",
         "Что касается вообще вариантов договориться с Украиной, то, что мертво, умереть не может. Там не с кем вести диалог и любые соглашения будут нарушены в любой момент в силу любых обстоятельств, включая внутреполитические, британские интересы или европейские. Хотелось, чтобы наша сторона это понимала и не забывала \"Минск\" 1,2, Нормандский формат, Стамбульские договоренности, Зерновую сделку и нынешнее одобрение \"отказа от ударов по объектам энергоструктуры\".",
         "True",
         "['Exaggeration-Minimisation' 'Loaded_Language'\n 'Obfuscation-Vagueness-Confusion']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Что касается вообще вариантов договориться с Украиной, то, что мертво, умереть не может']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Там не с кем вести диалог и любые соглашения будут нарушены в любой момент в силу любых обстоятельств, включая внутреполитические, британские интересы или европейские']",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Хотелось, чтобы наша сторона это понимала и не забывала \"Минск\" 1,2, Нормандский формат, Стамбульские договоренности, Зерновую сделку и нынешнее одобрение \"отказа от ударов по объектам энергоструктуры\"']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/False_Dilemma-No_Choice",
         "False_Dilemma-No_Choice",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "0",
         "No, the False Dilemma-No Choice technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not present a false dilemma as it does not limit the options to only two choices. Instead, it discusses the complexities of negotiating with Ukraine and acknowledges multiple factors that influence the situation, indicating that there are more than just two sides to consider.\",\\n  \"updated_definition\": \"\"\\n}']",
         "[None]",
         "['The input text does not present a false dilemma as it does not limit the options to only two choices. Instead, it discusses the complexities of negotiating with Ukraine and acknowledges multiple factors that influence the situation, indicating that there are more than just two sides to consider.']",
         "[ True]",
         "[None]",
         "[None]",
         "[None]",
         "['']",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/False_Dilemma-No_Choice/train/ru/train-ru-part_0008.parquet",
         "[None]",
         "[None]",
         "train",
         "{\"description\": \"The input text does not present a false dilemma as it does not limit the options to only two choices. Instead, it discusses the complexities of negotiating with Ukraine and acknowledges multiple factors that influence the situation, indicating that there are more than just two sides to consider.\", \"verdict\": false}"
        ],
        [
         "139",
         "RU_discrediting_the_west_11.txt",
         "598",
         "703",
         "RU",
         "т генерал Попов он особо опасен. Он же голос имеет, он же многое знает, он же умный и проницательный.\n\nДе",
         "False",
         "[]",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/False_Dilemma-No_Choice",
         "False_Dilemma-No_Choice",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "0",
         "No, the False Dilemma-No Choice technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not present a false dilemma as it does not limit the options to only two choices or depict one option as a no-go. Instead, it discusses the characteristics of General Popov without suggesting that there are only two alternatives or actions to take.\",\\n  \"updated_definition\": \"\"\\n}']",
         "[None]",
         "['The input text does not present a false dilemma as it does not limit the options to only two choices or depict one option as a no-go. Instead, it discusses the characteristics of General Popov without suggesting that there are only two alternatives or actions to take.']",
         "[ True]",
         "[None]",
         "[None]",
         "[None]",
         "['']",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/False_Dilemma-No_Choice/train/ru/train-ru-part_0008.parquet",
         "[None]",
         "[None]",
         "train",
         "{\"description\": \"The input text does not present a false dilemma as it does not limit the options to only two choices or depict one option as a no-go. Instead, it discusses the characteristics of General Popov without suggesting that there are only two alternatives or actions to take.\", \"verdict\": false}"
        ],
        [
         "140",
         "RU_discrediting_the_west_5.txt",
         "949",
         "1079",
         "RU",
         "Не вызывало вопросов у Парижа и открытое поощрение в «Твиттере» русофобии, призывов убивать россиян и «отменять» русскую культуру.",
         "True",
         "['Appeal_to_Hypocrisy']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/False_Dilemma-No_Choice",
         "False_Dilemma-No_Choice",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "0",
         "No, the False Dilemma-No Choice technique is not used in the input.",
         "\"\"",
         "[None]",
         "[None]",
         "[None]",
         "[ True]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/False_Dilemma-No_Choice/train/ru/train-ru-part_0009.parquet",
         "[{'code': 'content_filter', 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': True, 'severity': 'medium'}, 'jailbreak': {'detected': False, 'filtered': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'low'}}}, 'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'param': 'prompt', 'status': 400.0, 'type': None}]",
         "['no validation']",
         "train",
         "{\"description\": null, \"verdict\": false}"
        ],
        [
         "141",
         "RU_discrediting_the_west_7.txt",
         "1655",
         "1890",
         "RU",
         "Задержание основателя Telegram Павла Дурова 24 августа во Франции ещё раз продемонстрировало, что России нужен полный цифровой суверенитет. Полумеры, например, в виде торможения Youtube, воспринимаются обществом как непоследовательные.",
         "True",
         "['False_Dilemma-No_Choice']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Задержание основателя Telegram Павла Дурова 24 августа во Франции ещё раз продемонстрировало, что России нужен полный цифровой суверенитет']",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/False_Dilemma-No_Choice",
         "False_Dilemma-No_Choice",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "1",
         "Yes, the False Dilemma-No Choice technique is used in the input.",
         "\"Задержание основателя Telegram Павла Дурова 24 августа во Франции ещё раз продемонстрировало, что России нужен полный цифровой суверенитет\"",
         "['{\\n  \"explanation\": \"The input text presents a false dilemma by suggesting that Russia must choose between complete digital sovereignty and ineffective measures like merely slowing down YouTube. The excerpt implies that without full sovereignty, the alternative is inadequate, thus framing the situation as a binary choice.\",\\n  \"updated_definition\": \"\"\\n}']",
         "[None]",
         "['The input text presents a false dilemma by suggesting that Russia must choose between complete digital sovereignty and ineffective measures like merely slowing down YouTube. The excerpt implies that without full sovereignty, the alternative is inadequate, thus framing the situation as a binary choice.']",
         "[ True]",
         "[None]",
         "[None]",
         "[None]",
         "['']",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/False_Dilemma-No_Choice/train/ru/train-ru-part_0009.parquet",
         "[None]",
         "[None]",
         "train",
         "{\"description\": \"The input text presents a false dilemma by suggesting that Russia must choose between complete digital sovereignty and ineffective measures like merely slowing down YouTube. The excerpt implies that without full sovereignty, the alternative is inadequate, thus framing the situation as a binary choice.\", \"verdict\": true}"
        ],
        [
         "142",
         "RU_discrediting_the_west_19.txt",
         "1442",
         "1692",
         "RU",
         "В принципе те, кто в Брюсселе поумнее, понимают, что эта война уже идёт, ЕС конец, приходит время возвращения к власти в Европе национальных элит. А вот генсек НАТО - молодец, первым переобулся в воздухе, присягнул Трампу и поддержал Вэнса в Мюнхене.",
         "True",
         "['Exaggeration-Minimisation' 'Name_Calling-Labeling']",
         "train",
         "[]",
         "['А вот генсек НАТО - молодец, первым переобулся в воздухе, присягнул Трампу и поддержал Вэнса в Мюнхене']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['В принципе те, кто в Брюсселе поумнее, понимают, что эта война уже идёт, ЕС конец, приходит время возвращения к власти в Европе национальных элит']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/False_Dilemma-No_Choice",
         "False_Dilemma-No_Choice",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "0",
         "No, the False Dilemma-No Choice technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not present a false dilemma or an either-or situation. It discusses the political situation in Europe without limiting the options to just two, thus not employing the False Dilemma or No Choice technique.\",\\n  \"updated_definition\": \"\"\\n}']",
         "[None]",
         "['The input text does not present a false dilemma or an either-or situation. It discusses the political situation in Europe without limiting the options to just two, thus not employing the False Dilemma or No Choice technique.']",
         "[ True]",
         "[None]",
         "[None]",
         "[None]",
         "['']",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/False_Dilemma-No_Choice/train/ru/train-ru-part_0009.parquet",
         "[None]",
         "[None]",
         "train",
         "{\"description\": \"The input text does not present a false dilemma or an either-or situation. It discusses the political situation in Europe without limiting the options to just two, thus not employing the False Dilemma or No Choice technique.\", \"verdict\": false}"
        ],
        [
         "143",
         "RU_discrediting_the_west_21.txt",
         "82",
         "249",
         "RU",
         "умеется, самая массовая британская газета Daily Mail просто не могла обойти стороной версию о \"русском следе\" в сегодняшнем пожаре на подстанции в аэропорту Хитроу.\n\n\n",
         "False",
         "[]",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/False_Dilemma-No_Choice",
         "False_Dilemma-No_Choice",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "0",
         "No, the False Dilemma-No Choice technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not present a false dilemma or limit the options available to the audience. It discusses a specific event without suggesting that there are only two choices or outcomes.\",\\n  \"updated_definition\": \"\"\\n}']",
         "[None]",
         "['The input text does not present a false dilemma or limit the options available to the audience. It discusses a specific event without suggesting that there are only two choices or outcomes.']",
         "[ True]",
         "[None]",
         "[None]",
         "[None]",
         "['']",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/False_Dilemma-No_Choice/train/ru/train-ru-part_0009.parquet",
         "[None]",
         "[None]",
         "train",
         "{\"description\": \"The input text does not present a false dilemma or limit the options available to the audience. It discusses a specific event without suggesting that there are only two choices or outcomes.\", \"verdict\": false}"
        ],
        [
         "144",
         "RU_migrants_4.txt",
         "0",
         "315",
         "RU",
         "Сегодня важный день с точки зрения политики в отношении мигрантов, так как вступают в силу ужесточения, которые дадут положительный результат. С 5 февраля 2025 года действует режим спецвысылки, штрафы за нарушения при въезде и оказание услуг нелегальным мигрантам, а также вводится статус нежелательного пребывания.",
         "True",
         "['Loaded_Language']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "['которые дадут положительный результат']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/False_Dilemma-No_Choice",
         "False_Dilemma-No_Choice",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "0",
         "No, the False Dilemma-No Choice technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text discusses new policies regarding migrants without presenting only two options or sides. It does not depict one alternative as a no-go option, nor does it eliminate other possible choices, which aligns with the expert\\'s verdict that the False Dilemma or No Choice technique is not used.\",\\n  \"updated_definition\": \"\"\\n}']",
         "[None]",
         "[\"The input text discusses new policies regarding migrants without presenting only two options or sides. It does not depict one alternative as a no-go option, nor does it eliminate other possible choices, which aligns with the expert's verdict that the False Dilemma or No Choice technique is not used.\"]",
         "[ True]",
         "[None]",
         "[None]",
         "[None]",
         "['']",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/False_Dilemma-No_Choice/train/ru/train-ru-part_0009.parquet",
         "[None]",
         "[None]",
         "train",
         "{\"description\": \"The input text discusses new policies regarding migrants without presenting only two options or sides. It does not depict one alternative as a no-go option, nor does it eliminate other possible choices, which aligns with the expert's verdict that the False Dilemma or No Choice technique is not used.\", \"verdict\": false}"
        ],
        [
         "145",
         "RU_demography_2.txt",
         "0",
         "280",
         "RU",
         "Сегодняшнюю ситуацию с рождаемостью специалисты называют \"демографическая зима\". В условиях специальной военной операции и других серьёзных геополитических вызовов, на которые вынуждена отвечать наша страна, вопрос повышения рождаемости становится стратегическим и принципиальным.",
         "True",
         "['Exaggeration-Minimisation']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['вопрос повышения рождаемости становится стратегическим и принципиальным']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/False_Dilemma-No_Choice",
         "False_Dilemma-No_Choice",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "0",
         "No, the False Dilemma-No Choice technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not present a false dilemma as it does not limit the options to only two choices or depict one option as a no-go. It discusses the situation regarding birth rates without suggesting that there are only two possible actions or outcomes.\",\\n  \"updated_definition\": \"\"\\n}']",
         "[None]",
         "['The input text does not present a false dilemma as it does not limit the options to only two choices or depict one option as a no-go. It discusses the situation regarding birth rates without suggesting that there are only two possible actions or outcomes.']",
         "[ True]",
         "[None]",
         "[None]",
         "[None]",
         "['']",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/False_Dilemma-No_Choice/train/ru/train-ru-part_0009.parquet",
         "[None]",
         "[None]",
         "train",
         "{\"description\": \"The input text does not present a false dilemma as it does not limit the options to only two choices or depict one option as a no-go. It discusses the situation regarding birth rates without suggesting that there are only two possible actions or outcomes.\", \"verdict\": false}"
        ],
        [
         "146",
         "RU_URW_2.txt",
         "102",
         "417",
         "RU",
         "Два года назад на аналогичных чтениях Святейший Патриарх Московский и всея Руси Кирилл призвал мобилизовать прихожан, духовенство и всю Русскую православную церковь для сбора помощи участникам СВО: «Ищите возможности, собирайте деньги, отправляйте посылки, по возможности сами поезжайте, поддержите военнослужащих».",
         "False",
         "[]",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/False_Dilemma-No_Choice",
         "False_Dilemma-No_Choice",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "0",
         "No, the False Dilemma-No Choice technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not present a false dilemma or no choice scenario. It does not limit the options available to the audience, nor does it depict one alternative as a no-go option. Instead, it encourages various forms of support without excluding other possibilities.\",\\n  \"updated_definition\": \"\"\\n}']",
         "[None]",
         "['The input text does not present a false dilemma or no choice scenario. It does not limit the options available to the audience, nor does it depict one alternative as a no-go option. Instead, it encourages various forms of support without excluding other possibilities.']",
         "[ True]",
         "[None]",
         "[None]",
         "[None]",
         "['']",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/False_Dilemma-No_Choice/train/ru/train-ru-part_0009.parquet",
         "[None]",
         "[None]",
         "train",
         "{\"description\": \"The input text does not present a false dilemma or no choice scenario. It does not limit the options available to the audience, nor does it depict one alternative as a no-go option. Instead, it encourages various forms of support without excluding other possibilities.\", \"verdict\": false}"
        ],
        [
         "147",
         "RU_discrediting_the_west_19.txt",
         "28",
         "203",
         "RU",
         "Мюнхенская конференция по безопасности стала своеобразной лакмусовой бумажкой борьбы национальных элит против посаженных править космополитичных менеджеров элит глобалистских.",
         "False",
         "[]",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/False_Dilemma-No_Choice",
         "False_Dilemma-No_Choice",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "0",
         "No, the False Dilemma-No Choice technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not present a false dilemma as it does not limit the options to only two choices or depict one option as a no-go. Instead, it discusses a broader context of national elites versus globalist managers without forcing a binary choice.\",\\n  \"updated_definition\": \"\"\\n}']",
         "[None]",
         "['The input text does not present a false dilemma as it does not limit the options to only two choices or depict one option as a no-go. Instead, it discusses a broader context of national elites versus globalist managers without forcing a binary choice.']",
         "[ True]",
         "[None]",
         "[None]",
         "[None]",
         "['']",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/False_Dilemma-No_Choice/train/ru/train-ru-part_0009.parquet",
         "[None]",
         "[None]",
         "train",
         "{\"description\": \"The input text does not present a false dilemma as it does not limit the options to only two choices or depict one option as a no-go. Instead, it discusses a broader context of national elites versus globalist managers without forcing a binary choice.\", \"verdict\": false}"
        ],
        [
         "148",
         "RU_migrants_1.txt",
         "0",
         "333",
         "RU",
         "Мы как-то привыкли к тому что все новостные ленты заполнены в первую очередь заграницей - Трампом, Зеленским который резко возжелал переговоров с Россией на фоне того что наши парни ломят по всему фронту, особенно на Донецком направлении, Орбаном, какими - то рассуждениями о том, украдут ли США российские ЗВР, или уже украли и т.п.",
         "False",
         "[]",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/False_Dilemma-No_Choice",
         "False_Dilemma-No_Choice",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "0",
         "No, the False Dilemma-No Choice technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not present a false dilemma or restrict the audience to only two options. It discusses various international figures and events without implying that there are only two choices or outcomes. Therefore, the technique is not used.\",\\n  \"updated_definition\": \"\"\\n}']",
         "[None]",
         "['The input text does not present a false dilemma or restrict the audience to only two options. It discusses various international figures and events without implying that there are only two choices or outcomes. Therefore, the technique is not used.']",
         "[ True]",
         "[None]",
         "[None]",
         "[None]",
         "['']",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/False_Dilemma-No_Choice/train/ru/train-ru-part_0009.parquet",
         "[None]",
         "[None]",
         "train",
         "{\"description\": \"The input text does not present a false dilemma or restrict the audience to only two options. It discusses various international figures and events without implying that there are only two choices or outcomes. Therefore, the technique is not used.\", \"verdict\": false}"
        ],
        [
         "149",
         "RU_discrediting_the_west_21.txt",
         "477",
         "742",
         "RU",
         "явления? Неясно. Газета приводит лишь мнения таких же журналистов да экспертов по безопасности, но те впрямую Россию не обвиняют. И лишь говорят, что будь они русскими, то непременно \"сосредоточились\" бы на британской инфраструктуре. Ну, кто бы сомневался.\n\n\nТо ест",
         "True",
         "['Obfuscation-Vagueness-Confusion']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Что за заявления? Неясно']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/False_Dilemma-No_Choice",
         "False_Dilemma-No_Choice",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "0",
         "No, the False Dilemma-No Choice technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not present a false dilemma or an either-or situation. It discusses opinions without limiting the choices to just two options, thus not employing the False Dilemma or No Choice technique.\",\\n  \"updated_definition\": \"\"\\n}']",
         "[None]",
         "['The input text does not present a false dilemma or an either-or situation. It discusses opinions without limiting the choices to just two options, thus not employing the False Dilemma or No Choice technique.']",
         "[ True]",
         "[None]",
         "[None]",
         "[None]",
         "['']",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/False_Dilemma-No_Choice/train/ru/train-ru-part_0009.parquet",
         "[None]",
         "[None]",
         "train",
         "{\"description\": \"The input text does not present a false dilemma or an either-or situation. It discusses opinions without limiting the choices to just two options, thus not employing the False Dilemma or No Choice technique.\", \"verdict\": false}"
        ],
        [
         "150",
         "RU_discrediting_the_west_12.txt",
         "2311",
         "2457",
         "RU",
         "чные случаи. Сверху рисуют план по набору на контракт, регионы берут под козырек и привлекают людей выплатами, мошенники зарабатывают.\n\nПрофит у в",
         "True",
         "['Causal_Oversimplification' 'Exaggeration-Minimisation']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Это не единичные случаи']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Сверху рисуют план по набору на контракт, регионы берут под козырек и привлекают людей выплатами, мошенники зарабатывают']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/False_Dilemma-No_Choice",
         "False_Dilemma-No_Choice",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "0",
         "No, the False Dilemma-No Choice technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not present a situation where only two options are provided, nor does it eliminate other possible choices. Therefore, the False Dilemma or No Choice technique is not used.\",\\n  \"updated_definition\": \"\"\\n}']",
         "[None]",
         "['The input text does not present a situation where only two options are provided, nor does it eliminate other possible choices. Therefore, the False Dilemma or No Choice technique is not used.']",
         "[ True]",
         "[None]",
         "[None]",
         "[None]",
         "['']",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/False_Dilemma-No_Choice/train/ru/train-ru-part_0000.parquet",
         "[None]",
         "[None]",
         "train",
         "{\"description\": \"The input text does not present a situation where only two options are provided, nor does it eliminate other possible choices. Therefore, the False Dilemma or No Choice technique is not used.\", \"verdict\": false}"
        ],
        [
         "151",
         "RU_URW_4.txt",
         "507",
         "751",
         "RU",
         "Собственно, данная тактика себя оправдала во время \"Минского формата\", когда подписанное обязана была соблюдать только Россия, которая тогда вообще не была стороной конфликта, но все равно оставалась виноватой. Так зачем ломать \"рабочую\" схему.",
         "True",
         "['Causal_Oversimplification']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Собственно, данная тактика себя оправдала во время \"Минского формата\", когда подписанное обязана была соблюдать только Россия, которая тогда вообще не была стороной конфликта, но все равно оставалась виноватой']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/False_Dilemma-No_Choice",
         "False_Dilemma-No_Choice",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "0",
         "No, the False Dilemma-No Choice technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not present a false dilemma as it does not limit the options to only two choices or depict one option as a no-go. Instead, it discusses the situation without forcing a binary choice upon the audience.\",\\n  \"updated_definition\": \"\"\\n}']",
         "[None]",
         "['The input text does not present a false dilemma as it does not limit the options to only two choices or depict one option as a no-go. Instead, it discusses the situation without forcing a binary choice upon the audience.']",
         "[ True]",
         "[None]",
         "[None]",
         "[None]",
         "['']",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/False_Dilemma-No_Choice/train/ru/train-ru-part_0000.parquet",
         "[None]",
         "[None]",
         "train",
         "{\"description\": \"The input text does not present a false dilemma as it does not limit the options to only two choices or depict one option as a no-go. Instead, it discusses the situation without forcing a binary choice upon the audience.\", \"verdict\": false}"
        ],
        [
         "152",
         "RU_migrants_4.txt",
         "1955",
         "2137",
         "RU",
         "Будем надеяться, что ужесточение законодательства ударит и по адептам нетрадиционного Ислама и религиозного экстремизма, а также по распространителям наркотиков на территории России.",
         "True",
         "['Straw_Man']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Будем надеяться, что ужесточение законодательства ударит и по адептам нетрадиционного Ислама и религиозного экстремизма, а также по распространителям наркотиков на территории России']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/False_Dilemma-No_Choice",
         "False_Dilemma-No_Choice",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "0",
         "No, the False Dilemma-No Choice technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not present a false dilemma as it does not limit the options to only two choices or depict one as a no-go option. It discusses the hope that stricter legislation will impact multiple groups without suggesting that these are the only groups affected or that there are no other alternatives.\",\\n  \"updated_definition\": \"\"\\n}']",
         "[None]",
         "['The input text does not present a false dilemma as it does not limit the options to only two choices or depict one as a no-go option. It discusses the hope that stricter legislation will impact multiple groups without suggesting that these are the only groups affected or that there are no other alternatives.']",
         "[ True]",
         "[None]",
         "[None]",
         "[None]",
         "['']",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/False_Dilemma-No_Choice/train/ru/train-ru-part_0000.parquet",
         "[None]",
         "[None]",
         "train",
         "{\"description\": \"The input text does not present a false dilemma as it does not limit the options to only two choices or depict one as a no-go option. It discusses the hope that stricter legislation will impact multiple groups without suggesting that these are the only groups affected or that there are no other alternatives.\", \"verdict\": false}"
        ],
        [
         "153",
         "RU_demography_1.txt",
         "1283",
         "1609",
         "RU",
         "Русские, как народ, нация, культура, могут исчезнуть. Если русские утратят волю к жизни, инстинкт самосохранения и продолжения рода, так и будет. И случится всё вполне в течение текущего столетия. Во второй его половине. Просто в силу сокращения, размывания новых поколений русских, их вытеснения и замещения другими народами.",
         "True",
         "['Appeal_to_Fear-Prejudice']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Русские, как народ, нация, культура, могут исчезнуть. Если русские утратят волю к жизни, инстинкт самосохранения и продолжения рода, так и будет']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/False_Dilemma-No_Choice",
         "False_Dilemma-No_Choice",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "0",
         "No, the False Dilemma-No Choice technique is not used in the input.",
         "\"\"",
         "[None]",
         "[None]",
         "[None]",
         "[ True]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/False_Dilemma-No_Choice/train/ru/train-ru-part_0000.parquet",
         "[{'code': 'content_filter', 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': True, 'severity': 'medium'}, 'jailbreak': {'detected': False, 'filtered': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}, 'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'param': 'prompt', 'status': 400.0, 'type': None}]",
         "['no validation']",
         "train",
         "{\"description\": null, \"verdict\": false}"
        ],
        [
         "154",
         "RU_discrediting_the_west_12.txt",
         "717",
         "969",
         "RU",
         "имер, родная для меня Самарская область отличилась. Выплаты за подписание контракта подняли до 4 млн, тысяч 30 выплачивают по акции \"приведи друга\", и в целом, стахановскими темпами идёт вербовка контрактников, молодцы! Ещё бы на качество смотрели.\n\nНе",
         "True",
         "['Doubt']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Например, родная для меня Самарская область отличилась. Выплаты за подписание контракта подняли до 4 млн, тысяч 30 выплачивают по акции \"приведи друга\", и в целом, стахановскими темпами идёт вербовка контрактников, молодцы!']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/False_Dilemma-No_Choice",
         "False_Dilemma-No_Choice",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "0",
         "No, the False Dilemma-No Choice technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not present a false dilemma or an either-or situation. It discusses the positive aspects of contract signing and recruitment without limiting the options available to the audience.\",\\n  \"updated_definition\": \"\"\\n}']",
         "[None]",
         "['The input text does not present a false dilemma or an either-or situation. It discusses the positive aspects of contract signing and recruitment without limiting the options available to the audience.']",
         "[ True]",
         "[None]",
         "[None]",
         "[None]",
         "['']",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/False_Dilemma-No_Choice/train/ru/train-ru-part_0000.parquet",
         "[None]",
         "[None]",
         "train",
         "{\"description\": \"The input text does not present a false dilemma or an either-or situation. It discusses the positive aspects of contract signing and recruitment without limiting the options available to the audience.\", \"verdict\": false}"
        ],
        [
         "155",
         "RU_Trump_1.txt",
         "1302",
         "1987",
         "RU",
         "мпа стратегия «only business», то есть экономическая выгода для США, у Путина стратегия «realpolitik» - прагматизм в интересах общества, но с элементами нравственности. А вот стратегия Зеленского - сохранить не Украину, а себя. У него цугцванг- любой ход ведет к проигрышу. Сделка - продажа Украины, отказ от сделки - разрушение государства. А договориться он не смог, так как человек недалекий. И, вероятно, Зеленский не думал, что будут вопросы к нему по поводу махинаций с выделяемыми средствами из бюджета США, что сумеет проскочить и Трампу он выгоден, но Трамп хочет полного контроля над ресурсами Украины и полного подчинения Зеленского - такова цена военной помощи.\n\nЛишившись ",
         "True",
         "['False_Dilemma-No_Choice' 'Name_Calling-Labeling' 'Straw_Man' 'Doubt']",
         "train",
         "[]",
         "['так как человек недалекий']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['А вот стратегия Зеленского - сохранить не Украину, а себя. У него цугцванг- любой ход ведет к проигрышу']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['И, вероятно, Зеленский не думал, что будут вопросы к нему по поводу махинаций с выделяемыми средствами из бюджета США, что сумеет проскочить и Трампу он выгоден, но Трамп хочет полного контроля над ресурсами Украины и полного подчинения Зеленского - такова цена военной помощи']",
         "[]",
         "[]",
         "[]",
         "[]",
         "['А вот стратегия Зеленского - сохранить не Украину, а себя'\n 'Сделка - продажа Украины, отказ от сделки - разрушение государства']",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/False_Dilemma-No_Choice",
         "False_Dilemma-No_Choice",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "1",
         "Yes, the False Dilemma-No Choice technique is used in the input.",
         "\"А вот стратегия Зеленского - сохранить не Украину, а себя Сделка - продажа Украины, отказ от сделки - разрушение государства\"",
         "['{\\n  \"explanation\": \"The False Dilemma technique is explicitly used in the input text by presenting only two options regarding Zelensky\\'s strategy: either he sells Ukraine or he faces the destruction of the state. This aligns with the definition, as it limits the choices to these two extremes, ignoring any other possible alternatives.\",\\n  \"updated_definition\": \"\"\\n}']",
         "[None]",
         "[\"The False Dilemma technique is explicitly used in the input text by presenting only two options regarding Zelensky's strategy: either he sells Ukraine or he faces the destruction of the state. This aligns with the definition, as it limits the choices to these two extremes, ignoring any other possible alternatives.\"]",
         "[ True]",
         "[None]",
         "[None]",
         "[None]",
         "['']",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/False_Dilemma-No_Choice/train/ru/train-ru-part_0000.parquet",
         "[None]",
         "[None]",
         "train",
         "{\"description\": \"The False Dilemma technique is explicitly used in the input text by presenting only two options regarding Zelensky's strategy: either he sells Ukraine or he faces the destruction of the state. This aligns with the definition, as it limits the choices to these two extremes, ignoring any other possible alternatives.\", \"verdict\": true}"
        ],
        [
         "156",
         "RU_discrediting_the_west_6.txt",
         "1132",
         "1580",
         "RU",
         "За два с половиной года нет ни одной публичной адекватной версии произошедшего. Три отдельных расследования диверсии были инициированы и прекращены, а европейцев кормят сказками об украинском водолазе «Володимире З.», который чуть ли не в одиночку спустил несколько тонн оборудования и взорвал защищённую энергоинфраструктуру на дне Балтийского моря. Хотя разрушительную террористическую сущность «Володимиров З.» не стоит недооценивать, но всё же.",
         "True",
         "['Causal_Oversimplification' 'Loaded_Language']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Три отдельных расследования диверсии были инициированы и прекращены, а европейцев кормят сказками об украинском водолазе «Володимире З.», который чуть ли не в одиночку спустил несколько тонн оборудования и взорвал защищённую энергоинфраструктуру на дне Балтийского моря'\n 'кормят сказками']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['За два с половиной года нет ни одной публичной адекватной версии произошедшего']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/False_Dilemma-No_Choice",
         "False_Dilemma-No_Choice",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "0",
         "No, the False Dilemma-No Choice technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not present a false dilemma or an either-or situation. It discusses the lack of adequate public versions of events and mentions investigations without limiting the options to just two. Therefore, the technique is not used.\",\\n  \"updated_definition\": \"\"\\n}']",
         "[None]",
         "['The input text does not present a false dilemma or an either-or situation. It discusses the lack of adequate public versions of events and mentions investigations without limiting the options to just two. Therefore, the technique is not used.']",
         "[ True]",
         "[None]",
         "[None]",
         "[None]",
         "['']",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/False_Dilemma-No_Choice/train/ru/train-ru-part_0000.parquet",
         "[None]",
         "[None]",
         "train",
         "{\"description\": \"The input text does not present a false dilemma or an either-or situation. It discusses the lack of adequate public versions of events and mentions investigations without limiting the options to just two. Therefore, the technique is not used.\", \"verdict\": false}"
        ],
        [
         "157",
         "RU_discrediting_the_west_2.txt",
         "1414",
         "1566",
         "RU",
         "Всё из-за политики Вашингтона, в основе которой принцип собственной исключительности, превосходства американцев над другими, а также двойных стандартов.",
         "True",
         "['Appeal_to_Hypocrisy']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/False_Dilemma-No_Choice",
         "False_Dilemma-No_Choice",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "0",
         "No, the False Dilemma-No Choice technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not present a false dilemma as it does not limit the options to only two choices or depict one option as a no-go. It discusses a political principle without forcing a binary choice.\",\\n  \"updated_definition\": \"\"\\n}']",
         "[None]",
         "['The input text does not present a false dilemma as it does not limit the options to only two choices or depict one option as a no-go. It discusses a political principle without forcing a binary choice.']",
         "[ True]",
         "[None]",
         "[None]",
         "[None]",
         "['']",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/False_Dilemma-No_Choice/train/ru/train-ru-part_0000.parquet",
         "[None]",
         "[None]",
         "train",
         "{\"description\": \"The input text does not present a false dilemma as it does not limit the options to only two choices or depict one option as a no-go. It discusses a political principle without forcing a binary choice.\", \"verdict\": false}"
        ],
        [
         "158",
         "RU_discrediting_the_west_6.txt",
         "1060",
         "1130",
         "RU",
         "Что это за надругательство над здравым смыслом уходящей администрации?",
         "True",
         "['Conversation_Killer' 'Loaded_Language']",
         "train",
         "[]",
         "[]",
         "[]",
         "['Что это за надругательство над здравым смыслом уходящей администрации?']",
         "['надругательство над здравым смыслом']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/False_Dilemma-No_Choice",
         "False_Dilemma-No_Choice",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "0",
         "No, the False Dilemma-No Choice technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not present a false dilemma as it does not limit the options to only two choices or depict one option as unacceptable. It raises a question without forcing a binary choice.\",\\n  \"updated_definition\": \"\"\\n}']",
         "[None]",
         "['The input text does not present a false dilemma as it does not limit the options to only two choices or depict one option as unacceptable. It raises a question without forcing a binary choice.']",
         "[ True]",
         "[None]",
         "[None]",
         "[None]",
         "['']",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/False_Dilemma-No_Choice/train/ru/train-ru-part_0000.parquet",
         "[None]",
         "[None]",
         "train",
         "{\"description\": \"The input text does not present a false dilemma as it does not limit the options to only two choices or depict one option as unacceptable. It raises a question without forcing a binary choice.\", \"verdict\": false}"
        ],
        [
         "159",
         "RU_URW_4.txt",
         "753",
         "934",
         "RU",
         "Как видим, от администрации Трампа тоже не слышно слов возмущения по поводу атаки на нашу нефтебазу, молчит Европа, молчат все. Но как только Россия ответит, то молчание закончится.",
         "True",
         "['Causal_Oversimplification' 'Appeal_to_Authority']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Как видим, от администрации Трампа тоже не слышно слов возмущения по поводу атаки на нашу нефтебазу, молчит Европа, молчат все']",
         "['Но как только Россия ответит, то молчание закончится']",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41_MINI/v001/False_Dilemma-No_Choice",
         "False_Dilemma-No_Choice",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1-mini",
         "chat",
         "0",
         "No, the False Dilemma-No Choice technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not present a false dilemma as it does not limit the options to only two choices or depict one as a no-go option. It discusses the silence of various parties without suggesting that there are only two possible responses or actions.\",\\n  \"updated_definition\": \"\"\\n}']",
         "[None]",
         "['The input text does not present a false dilemma as it does not limit the options to only two choices or depict one as a no-go option. It discusses the silence of various parties without suggesting that there are only two possible responses or actions.']",
         "[ True]",
         "[None]",
         "[None]",
         "[None]",
         "['']",
         "data/llm_output/persuasion/explain/GPT_41_MINI/v001/False_Dilemma-No_Choice/train/ru/train-ru-part_0000.parquet",
         "[None]",
         "[None]",
         "train",
         "{\"description\": \"The input text does not present a false dilemma as it does not limit the options to only two choices or depict one as a no-go option. It discusses the silence of various parties without suggesting that there are only two possible responses or actions.\", \"verdict\": false}"
        ]
       ],
       "shape": {
        "columns": 60,
        "rows": 1226
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>text_lang</th>\n",
       "      <th>text</th>\n",
       "      <th>label_bin</th>\n",
       "      <th>label_multi</th>\n",
       "      <th>base_split</th>\n",
       "      <th>Questioning_the_Reputation</th>\n",
       "      <th>Name_Calling-Labeling</th>\n",
       "      <th>...</th>\n",
       "      <th>is_valid</th>\n",
       "      <th>illegal_value</th>\n",
       "      <th>think_content</th>\n",
       "      <th>extra_content</th>\n",
       "      <th>updated_definition</th>\n",
       "      <th>source_file</th>\n",
       "      <th>error</th>\n",
       "      <th>status</th>\n",
       "      <th>split</th>\n",
       "      <th>expected_output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>pl_abortion_11_04_2024_n07.txt</td>\n",
       "      <td>3811</td>\n",
       "      <td>4153</td>\n",
       "      <td>PL</td>\n",
       "      <td>My, kobiety i mężczyźni broniący prawa do życi...</td>\n",
       "      <td>True</td>\n",
       "      <td>[Appeal_to_Values]</td>\n",
       "      <td>train</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[]</td>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41_MINI...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>train</td>\n",
       "      <td>{\"description\": \"The input text discusses the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>pl_abortion_11_04_2024_n08.txt</td>\n",
       "      <td>3138</td>\n",
       "      <td>3188</td>\n",
       "      <td>PL</td>\n",
       "      <td>(Poseł Joanna Scheuring-Wielgus: Zejdź z mówni...</td>\n",
       "      <td>True</td>\n",
       "      <td>[Loaded_Language]</td>\n",
       "      <td>train</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[]</td>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41_MINI...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>train</td>\n",
       "      <td>{\"description\": \"The input text does not prese...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>pl_current_affairs_09_01_2025_n02.txt</td>\n",
       "      <td>8069</td>\n",
       "      <td>9438</td>\n",
       "      <td>PL</td>\n",
       "      <td>W decyzji generalny dyrektor ochrony środowisk...</td>\n",
       "      <td>True</td>\n",
       "      <td>[Appeal_to_Authority, Appeal_to_Values]</td>\n",
       "      <td>train</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41_MINI...</td>\n",
       "      <td>[{'code': '429', 'message': 'Requests to the C...</td>\n",
       "      <td>[no validation]</td>\n",
       "      <td>train</td>\n",
       "      <td>{\"description\": null, \"verdict\": false}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>pl_eu_12_06_2024_n02.txt</td>\n",
       "      <td>5000</td>\n",
       "      <td>5586</td>\n",
       "      <td>PL</td>\n",
       "      <td>Poseł Marcin Porzucek:\\nPanie Marszałku! Wysok...</td>\n",
       "      <td>True</td>\n",
       "      <td>[Questioning_the_Reputation]</td>\n",
       "      <td>train</td>\n",
       "      <td>[podejmowaliśmy stosowne działania, państwo na...</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[]</td>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41_MINI...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>train</td>\n",
       "      <td>{\"description\": \"The input text does not prese...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>pl_eu_12_06_2024_n01.txt</td>\n",
       "      <td>2653</td>\n",
       "      <td>3161</td>\n",
       "      <td>PL</td>\n",
       "      <td>Po prezentacji przez ministrów uzasadnienia pr...</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>train</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[]</td>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41_MINI...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>train</td>\n",
       "      <td>{\"description\": \"The input text does not prese...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6547</th>\n",
       "      <td>trail_raw_BG_7.txt</td>\n",
       "      <td>2179</td>\n",
       "      <td>2221</td>\n",
       "      <td>BG</td>\n",
       "      <td>АНЕ, от място): Я пак!\\n\\nИСКРЕН МИТЕВ: Това</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>train</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[]</td>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41/v001...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>train</td>\n",
       "      <td>{\"description\": \"The input text does not conta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6548</th>\n",
       "      <td>20240704_URW_BG_30.txt</td>\n",
       "      <td>5823</td>\n",
       "      <td>6119</td>\n",
       "      <td>BG</td>\n",
       "      <td>заседанието, което ще бъде абсолютно безсмисле...</td>\n",
       "      <td>True</td>\n",
       "      <td>[Consequential_Oversimplification, Exaggeratio...</td>\n",
       "      <td>train</td>\n",
       "      <td>[]</td>\n",
       "      <td>[абсолютно безсмислено]</td>\n",
       "      <td>...</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[This technique consists in making an impressi...</td>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41/v001...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>train</td>\n",
       "      <td>{\"description\": \"The input text does not emplo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6549</th>\n",
       "      <td>trail_raw_BG_7.txt</td>\n",
       "      <td>2225</td>\n",
       "      <td>2773</td>\n",
       "      <td>BG</td>\n",
       "      <td>итат от Мария Захарова, която е директно предс...</td>\n",
       "      <td>True</td>\n",
       "      <td>[Exaggeration-Minimisation, Name_Calling-Label...</td>\n",
       "      <td>train</td>\n",
       "      <td>[]</td>\n",
       "      <td>[проруска партия, проруска партия]</td>\n",
       "      <td>...</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[]</td>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41/v001...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>train</td>\n",
       "      <td>{\"description\": \"The input text does not emplo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6550</th>\n",
       "      <td>20240229_URW_BG_67.txt</td>\n",
       "      <td>4167</td>\n",
       "      <td>4219</td>\n",
       "      <td>BG</td>\n",
       "      <td>ПРЕДСЕДАТЕЛ РОСЕН ЖЕЛЯЗКОВ: Времето, госпожо Н...</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>train</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[]</td>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41/v001...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>train</td>\n",
       "      <td>{\"description\": \"The input text does not conta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6551</th>\n",
       "      <td>20240229_URW_BG_67.txt</td>\n",
       "      <td>766</td>\n",
       "      <td>1302</td>\n",
       "      <td>BG</td>\n",
       "      <td>Запитан дали изпращането на западни войски в У...</td>\n",
       "      <td>True</td>\n",
       "      <td>[Appeal_to_Authority]</td>\n",
       "      <td>train</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[]</td>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41/v001...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>train</td>\n",
       "      <td>{\"description\": \"The input text does not emplo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1226 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   filename  start   end text_lang  \\\n",
       "30           pl_abortion_11_04_2024_n07.txt   3811  4153        PL   \n",
       "31           pl_abortion_11_04_2024_n08.txt   3138  3188        PL   \n",
       "32    pl_current_affairs_09_01_2025_n02.txt   8069  9438        PL   \n",
       "33                 pl_eu_12_06_2024_n02.txt   5000  5586        PL   \n",
       "34                 pl_eu_12_06_2024_n01.txt   2653  3161        PL   \n",
       "...                                     ...    ...   ...       ...   \n",
       "6547                     trail_raw_BG_7.txt   2179  2221        BG   \n",
       "6548                 20240704_URW_BG_30.txt   5823  6119        BG   \n",
       "6549                     trail_raw_BG_7.txt   2225  2773        BG   \n",
       "6550                 20240229_URW_BG_67.txt   4167  4219        BG   \n",
       "6551                 20240229_URW_BG_67.txt    766  1302        BG   \n",
       "\n",
       "                                                   text  label_bin  \\\n",
       "30    My, kobiety i mężczyźni broniący prawa do życi...       True   \n",
       "31    (Poseł Joanna Scheuring-Wielgus: Zejdź z mówni...       True   \n",
       "32    W decyzji generalny dyrektor ochrony środowisk...       True   \n",
       "33    Poseł Marcin Porzucek:\\nPanie Marszałku! Wysok...       True   \n",
       "34    Po prezentacji przez ministrów uzasadnienia pr...      False   \n",
       "...                                                 ...        ...   \n",
       "6547       АНЕ, от място): Я пак!\\n\\nИСКРЕН МИТЕВ: Това      False   \n",
       "6548  заседанието, което ще бъде абсолютно безсмисле...       True   \n",
       "6549  итат от Мария Захарова, която е директно предс...       True   \n",
       "6550  ПРЕДСЕДАТЕЛ РОСЕН ЖЕЛЯЗКОВ: Времето, госпожо Н...      False   \n",
       "6551  Запитан дали изпращането на западни войски в У...       True   \n",
       "\n",
       "                                            label_multi base_split  \\\n",
       "30                                   [Appeal_to_Values]      train   \n",
       "31                                    [Loaded_Language]      train   \n",
       "32              [Appeal_to_Authority, Appeal_to_Values]      train   \n",
       "33                         [Questioning_the_Reputation]      train   \n",
       "34                                                   []      train   \n",
       "...                                                 ...        ...   \n",
       "6547                                                 []      train   \n",
       "6548  [Consequential_Oversimplification, Exaggeratio...      train   \n",
       "6549  [Exaggeration-Minimisation, Name_Calling-Label...      train   \n",
       "6550                                                 []      train   \n",
       "6551                              [Appeal_to_Authority]      train   \n",
       "\n",
       "                             Questioning_the_Reputation  \\\n",
       "30                                                   []   \n",
       "31                                                   []   \n",
       "32                                                   []   \n",
       "33    [podejmowaliśmy stosowne działania, państwo na...   \n",
       "34                                                   []   \n",
       "...                                                 ...   \n",
       "6547                                                 []   \n",
       "6548                                                 []   \n",
       "6549                                                 []   \n",
       "6550                                                 []   \n",
       "6551                                                 []   \n",
       "\n",
       "                   Name_Calling-Labeling  ... is_valid illegal_value  \\\n",
       "30                                    []  ...   [True]        [None]   \n",
       "31                                    []  ...   [True]        [None]   \n",
       "32                                    []  ...   [True]        [None]   \n",
       "33                                    []  ...   [True]        [None]   \n",
       "34                                    []  ...   [True]        [None]   \n",
       "...                                  ...  ...      ...           ...   \n",
       "6547                                  []  ...   [True]        [None]   \n",
       "6548             [абсолютно безсмислено]  ...   [True]        [None]   \n",
       "6549  [проруска партия, проруска партия]  ...   [True]        [None]   \n",
       "6550                                  []  ...   [True]        [None]   \n",
       "6551                                  []  ...   [True]        [None]   \n",
       "\n",
       "     think_content extra_content  \\\n",
       "30          [None]        [None]   \n",
       "31          [None]        [None]   \n",
       "32          [None]        [None]   \n",
       "33          [None]        [None]   \n",
       "34          [None]        [None]   \n",
       "...            ...           ...   \n",
       "6547        [None]        [None]   \n",
       "6548        [None]        [None]   \n",
       "6549        [None]        [None]   \n",
       "6550        [None]        [None]   \n",
       "6551        [None]        [None]   \n",
       "\n",
       "                                     updated_definition  \\\n",
       "30                                                   []   \n",
       "31                                                   []   \n",
       "32                                               [None]   \n",
       "33                                                   []   \n",
       "34                                                   []   \n",
       "...                                                 ...   \n",
       "6547                                                 []   \n",
       "6548  [This technique consists in making an impressi...   \n",
       "6549                                                 []   \n",
       "6550                                                 []   \n",
       "6551                                                 []   \n",
       "\n",
       "                                            source_file  \\\n",
       "30    data/llm_output/persuasion/explain/GPT_41_MINI...   \n",
       "31    data/llm_output/persuasion/explain/GPT_41_MINI...   \n",
       "32    data/llm_output/persuasion/explain/GPT_41_MINI...   \n",
       "33    data/llm_output/persuasion/explain/GPT_41_MINI...   \n",
       "34    data/llm_output/persuasion/explain/GPT_41_MINI...   \n",
       "...                                                 ...   \n",
       "6547  data/llm_output/persuasion/explain/GPT_41/v001...   \n",
       "6548  data/llm_output/persuasion/explain/GPT_41/v001...   \n",
       "6549  data/llm_output/persuasion/explain/GPT_41/v001...   \n",
       "6550  data/llm_output/persuasion/explain/GPT_41/v001...   \n",
       "6551  data/llm_output/persuasion/explain/GPT_41/v001...   \n",
       "\n",
       "                                                  error           status  \\\n",
       "30                                               [None]           [None]   \n",
       "31                                               [None]           [None]   \n",
       "32    [{'code': '429', 'message': 'Requests to the C...  [no validation]   \n",
       "33                                               [None]           [None]   \n",
       "34                                               [None]           [None]   \n",
       "...                                                 ...              ...   \n",
       "6547                                             [None]           [None]   \n",
       "6548                                             [None]           [None]   \n",
       "6549                                             [None]           [None]   \n",
       "6550                                             [None]           [None]   \n",
       "6551                                             [None]           [None]   \n",
       "\n",
       "      split                                    expected_output  \n",
       "30    train  {\"description\": \"The input text discusses the ...  \n",
       "31    train  {\"description\": \"The input text does not prese...  \n",
       "32    train            {\"description\": null, \"verdict\": false}  \n",
       "33    train  {\"description\": \"The input text does not prese...  \n",
       "34    train  {\"description\": \"The input text does not prese...  \n",
       "...     ...                                                ...  \n",
       "6547  train  {\"description\": \"The input text does not conta...  \n",
       "6548  train  {\"description\": \"The input text does not emplo...  \n",
       "6549  train  {\"description\": \"The input text does not emplo...  \n",
       "6550  train  {\"description\": \"The input text does not conta...  \n",
       "6551  train  {\"description\": \"The input text does not emplo...  \n",
       "\n",
       "[1226 rows x 60 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[~df.error.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32362a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['raw'].apply(lambda x: isinstance(x, np.ndarray) and None in x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895c8920",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[~df.error.isna()].value_counts('source_file')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

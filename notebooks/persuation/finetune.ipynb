{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5bb4b26b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bc303d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wd = '/mnt/openfact/users/msawinski/factue-task2'\n",
    "wd = '/Users/marcinsawinski/Documents/GitHub/factue-task2'\n",
    "import sys, os\n",
    "os.chdir(wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "baa931db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Name_Calling-Labeling\"\n",
      "\"Guilt_by_Association\"\n",
      "\"Doubt\"\n",
      "\"Appeal_to_Hypocrisy\"\n",
      "\"Questioning_the_Reputation\"\n",
      "\"Flag_Waving\"\n",
      "\"Appeal_to_Authority\"\n",
      "\"Appeal_to_Popularity\"\n",
      "\"Appeal_to_Values\"\n",
      "\"Appeal_to_Fear-Prejudice\"\n",
      "\"Straw_Man\"\n",
      "\"Red_Herring\"\n",
      "\"Whataboutism\"\n",
      "\"Appeal_to_Pity\"\n",
      "\"Causal_Oversimplification\"\n",
      "\"False_Dilemma-No_Choice\"\n",
      "\"Consequential_Oversimplification\"\n",
      "\"False_Equivalence\"\n",
      "\"Slogans\"\n",
      "\"Conversation_Killer\"\n",
      "\"Appeal_to_Time\"\n",
      "\"Loaded_Language\"\n",
      "\"Obfuscation-Vagueness-Confusion\"\n",
      "\"Exaggeration-Minimisation\"\n",
      "\"Repetition\"\n"
     ]
    }
   ],
   "source": [
    "from factue.methods.llm_calls import load_template_list, load_template_parts\n",
    "for x in load_template_list(job='persuasion', step=\"explain\", prompt_version='v001').keys():\n",
    "    print(f'\"{x}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "babd803f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "filename",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "start",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "end",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "text_lang",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "text",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "label_bin",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "label_multi",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "base_split",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Questioning_the_Reputation",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Name_Calling-Labeling",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Appeal_to_Hypocrisy",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Conversation_Killer",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Loaded_Language",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Repetition",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Appeal_to_Popularity",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Doubt",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Red_Herring",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Flag_Waving",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Exaggeration-Minimisation",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Consequential_Oversimplification",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Appeal_to_Pity",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Appeal_to_Time",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Appeal_to_Values",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Obfuscation-Vagueness-Confusion",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Straw_Man",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Slogans",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Appeal_to_Fear-Prejudice",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Causal_Oversimplification",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Appeal_to_Authority",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "False_Dilemma-No_Choice",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Whataboutism",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "False_Equivalence",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Guilt_by_Association",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "alt_split",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "output_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "prompt_name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "prompt_version",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "job",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "step",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "max_iterations",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "temperature",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "model_provider",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "model_name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "model_mode",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "gold",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "gold_text",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "spans",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "raw",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "updated_definition",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "extra_properties",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "extra_content",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "explanation",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "illegal_value",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "think_content",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "is_valid",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "source_file",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "error",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "status",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "split",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "expected_output",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "ad16a9ec-d2f6-4cd0-9569-e14796d8103f",
       "rows": [
        [
         "0",
         "pl_eu_12_06_2024_n01.txt",
         "0",
         "135",
         "PL",
         "Wicemarszałek Włodzimierz Czarzasty:\nBardzo proszę panią poseł Danutę Jazłowiecką\no przedstawienie sprawozdania komisji.\nBardzo proszę.",
         "False",
         "[]",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Hypocrisy",
         "Appeal_to_Hypocrisy",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Appeal to Hypocrisy technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not contain any elements that attack the reputation of an individual by charging them with hypocrisy or inconsistency. There are no contradictions or past actions referenced that would indicate the use of the Appeal to Hypocrisy technique.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "['The input text does not contain any elements that attack the reputation of an individual by charging them with hypocrisy or inconsistency. There are no contradictions or past actions referenced that would indicate the use of the Appeal to Hypocrisy technique.']",
         "[None]",
         "[None]",
         "[ True]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/pl/train-pl-part_0005.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text does not contain any elements that attack the reputation of an individual by charging them with hypocrisy or inconsistency. There are no contradictions or past actions referenced that would indicate the use of the Appeal to Hypocrisy technique.\", \"verdict\": false}"
        ],
        [
         "1",
         "pl_defence_22_05_2024_n01.txt",
         "3608",
         "3857",
         "PL",
         "Pan wspominał o ABCS – Integrated Battle Command System. Ten program ja miałem zaszczyt nabyć w marcu 2018 r. (Oklaski) razem z umową dotyczącą dwóch baterii Patriot. A tę umowę przygotowywał mój poprzednik pan minister Antoni Macierewicz. (Oklaski)",
         "False",
         "[]",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Hypocrisy",
         "Appeal_to_Hypocrisy",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Appeal to Hypocrisy technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. There are no explicit or implicit references to contradictions between positions or actions, nor is there any mention of someone criticizing another for actions they themselves have taken in the past.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "['The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. There are no explicit or implicit references to contradictions between positions or actions, nor is there any mention of someone criticizing another for actions they themselves have taken in the past.']",
         "[None]",
         "[None]",
         "[ True]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/pl/train-pl-part_0005.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. There are no explicit or implicit references to contradictions between positions or actions, nor is there any mention of someone criticizing another for actions they themselves have taken in the past.\", \"verdict\": false}"
        ],
        [
         "2",
         "pl_current_affairs_09_01_2025_n03.txt",
         "1808",
         "1984",
         "PL",
         "(Poseł Anna Gembicka: Decyzja została zmieniona. Proszę słuchać uważnie.)\nTo jest nieprawda, ten raport nie został poprawiony.\n(Poseł Anna Gembicka: Decyzja została zmieniona.)",
         "True",
         "['Repetition']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Decyzja została zmieniona' 'Decyzja została zmieniona.)']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Hypocrisy",
         "Appeal_to_Hypocrisy",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Appeal to Hypocrisy technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The Appeal to Hypocrisy technique was not used in the input text as there are no attacks on reputation through charges of hypocrisy or inconsistency. The statements made do not highlight any contradictions or past actions that would indicate hypocrisy.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "['The Appeal to Hypocrisy technique was not used in the input text as there are no attacks on reputation through charges of hypocrisy or inconsistency. The statements made do not highlight any contradictions or past actions that would indicate hypocrisy.']",
         "[None]",
         "[None]",
         "[ True]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/pl/train-pl-part_0005.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The Appeal to Hypocrisy technique was not used in the input text as there are no attacks on reputation through charges of hypocrisy or inconsistency. The statements made do not highlight any contradictions or past actions that would indicate hypocrisy.\", \"verdict\": false}"
        ],
        [
         "3",
         "pl_abortion_11_04_2024_n08.txt",
         "2952",
         "3136",
         "PL",
         "Czy czas najwyższy, by w końcu dopuścić\ndekryminalizację kradzieży i pomocnictwa w kradzieżach\nz włamaniem? Dlaczego tak nie lubicie dzieci?\nDlaczego chcecie pozwolić na ich zabijanie?",
         "True",
         "['False_Equivalence' 'Loaded_Language' 'Whataboutism' 'Straw_Man']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "['zabijanie?']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Czy czas najwyższy, by w końcu dopuścić dekryminalizację kradzieży i pomocnictwa w kradzieżach z włamaniem?']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Dlaczego tak nie lubicie dzieci?']",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Hypocrisy",
         "Appeal_to_Hypocrisy",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Appeal to Hypocrisy technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. There are no explicit or implicit references to contradictions between positions or actions, which is necessary for the Appeal to Hypocrisy technique to be present.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "['The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. There are no explicit or implicit references to contradictions between positions or actions, which is necessary for the Appeal to Hypocrisy technique to be present.']",
         "[None]",
         "[None]",
         "[ True]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/pl/train-pl-part_0005.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. There are no explicit or implicit references to contradictions between positions or actions, which is necessary for the Appeal to Hypocrisy technique to be present.\", \"verdict\": false}"
        ],
        [
         "4",
         "pl_eu_12_06_2024_n01.txt",
         "1277",
         "2304",
         "PL",
         "Prezentowany na posiedzeniu projekt ustawy, opracowany w celu wzmocnienia bezpieczeństwa podczas\nprzebiegu najważniejszych wydarzeń, które odbędą\nsię w Polsce w czasie trwania polskiej prezydencji,\nwyznacza zadania i ich realizację przez poszczególne\nsłużby i organy administracji publicznej. Spośród\nrozwiązań szczegółowych wyszczególnione zostały\nm.in.: koordynacja działań podejmowanych w zakresie zapewnienia bezpieczeństwa, plan zapewnienia\nbezpieczeństwa i porządku publicznego, przetwarzanie informacji, w tym danych osobowych, przez Policję, sprawdzenie przez służby osób lub podmiotów\nwspółpracujących przy organizacji wydarzeń, zawieranie porozumień z instytucjami unijnymi, wzmacnianie personelu Stałego Przedstawicielstwa Rzeczypospolitej Polskiej przy Unii Europejskiej, zasady\nudzielania i realizacji zamówień, zasady przedłużania czasu pracy służb, funkcjonariuszy. Minister\nzwrócił uwagę na czasowy charakter ustawy, obejmujący okres przygotowania, przeprowadzenia i rozliczenia prezydencji w Unii Europejskiej.",
         "False",
         "[]",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Hypocrisy",
         "Appeal_to_Hypocrisy",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Appeal to Hypocrisy technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text discusses a proposed law aimed at enhancing security during significant events in Poland. It outlines various measures and responsibilities without attacking anyone\\'s reputation or highlighting hypocrisy. Therefore, the Appeal to Hypocrisy technique is not present.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "[\"The input text discusses a proposed law aimed at enhancing security during significant events in Poland. It outlines various measures and responsibilities without attacking anyone's reputation or highlighting hypocrisy. Therefore, the Appeal to Hypocrisy technique is not present.\"]",
         "[None]",
         "[None]",
         "[ True]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/pl/train-pl-part_0005.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text discusses a proposed law aimed at enhancing security during significant events in Poland. It outlines various measures and responsibilities without attacking anyone's reputation or highlighting hypocrisy. Therefore, the Appeal to Hypocrisy technique is not present.\", \"verdict\": false}"
        ],
        [
         "5",
         "pl_abortion_11_04_2024_n06.txt",
         "1965",
         "2258",
         "PL",
         "Wicemarszałek Włodzimierz Czarzasty:\nPrzepraszam, pani posłanko, przepraszam bardzo.\n(Poseł Krystyna Skowrońska: Proszę zwrócić uwagę.)\nAle zaraz, proszę państwa, proszę państwa…\n(Wypowiedź poza mikrofonem)\n(Poseł Krystyna Skowrońska: Ale nie zagłusza…)\n(Poseł Mariusz Krystian: A wy możecie?)",
         "False",
         "[]",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Hypocrisy",
         "Appeal_to_Hypocrisy",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Appeal to Hypocrisy technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. There are no explicit or implicit references to contradictions between positions or actions, nor is there any mention of someone criticizing another for actions they themselves have taken. Therefore, the Appeal to Hypocrisy technique is not used.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "['The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. There are no explicit or implicit references to contradictions between positions or actions, nor is there any mention of someone criticizing another for actions they themselves have taken. Therefore, the Appeal to Hypocrisy technique is not used.']",
         "[None]",
         "[None]",
         "[ True]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/pl/train-pl-part_0005.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. There are no explicit or implicit references to contradictions between positions or actions, nor is there any mention of someone criticizing another for actions they themselves have taken. Therefore, the Appeal to Hypocrisy technique is not used.\", \"verdict\": false}"
        ],
        [
         "6",
         "pl_defence_22_05_2024_n02.txt",
         "1907",
         "2635",
         "PL",
         "...do walki, musi on przejść długie szkolenie.\nRosjanie, zanim puszczą żołnierza na front, ćwiczą go\n12 miesięcy, a u nas można przejść do rezerwy po\nzaledwie miesięcznym szkoleniu w ramach\ndobrowolnej zasadniczej służby wojskowej. Nawet Niemcy na\npoczątku 1945 r., kiedy front całkowicie im się\nposypał, wydali rozkaz zabraniający puszczania do walki\nżołnierzy poniżej 8 tygodni szkolenia, ponieważ jest\nto bezsensowne marnowanie ich życia bez istotnej\nkorzyści dla wojska. Kiedy my wreszcie zaczniemy\nmasowo szkolić rezerwy? Czy jak Rosja nas już zaatakuje,\nładnie poprosimy Putina, żeby zaczekali jeszcze\nrok, bo musimy się przygotować do tej wojny, czy też\nwyślemy na pewną śmierć nieprzygotowanych,\nnieprzeszkolonych ludzi?",
         "True",
         "['Doubt' 'Appeal_to_Fear-Prejudice']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Rosjanie, zanim puszczą żołnierza na front, ćwiczą go 12 miesięcy, a u nas można przejść do rezerwy po zaledwie miesięcznym szkoleniu w ramach dobrowolnej zasadniczej służby wojskowej'\n 'u nas można przejść do rezerwy po zaledwie miesięcznym szkoleniu w ramach dobrowolnej zasadniczej służby wojskowej. Nawet Niemcy na początku 1945 r., kiedy front całkowicie im się posypał, wydali rozkaz zabraniający puszczania do walki żołnierzy poniżej 8 tygodni szkolenia, ponieważ jest to bezsensowne marnowanie ich życia bez istotnej korzyści dla wojska']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Czy jak Rosja nas już zaatakuje, ładnie poprosimy Putina, żeby zaczekali jeszcze rok, bo musimy się przygotować do tej wojny, czy też wyślemy na pewną śmierć nieprzygotowanych, nieprzeszkolonych ludzi?']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Hypocrisy",
         "Appeal_to_Hypocrisy",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Appeal to Hypocrisy technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not contain any instances of the Appeal to Hypocrisy technique, as it does not attack the reputation of any target by charging them with hypocrisy or inconsistency. Instead, it discusses military training practices without referencing any contradictions or past actions of critics.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "['The input text does not contain any instances of the Appeal to Hypocrisy technique, as it does not attack the reputation of any target by charging them with hypocrisy or inconsistency. Instead, it discusses military training practices without referencing any contradictions or past actions of critics.']",
         "[None]",
         "[None]",
         "[ True]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/pl/train-pl-part_0005.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text does not contain any instances of the Appeal to Hypocrisy technique, as it does not attack the reputation of any target by charging them with hypocrisy or inconsistency. Instead, it discusses military training practices without referencing any contradictions or past actions of critics.\", \"verdict\": false}"
        ],
        [
         "7",
         "pl_abortion_11_04_2024_n03.txt",
         "10068",
         "10611",
         "PL",
         "Państwo polskie zaoszczędziło na zdrowiu i życiu\nPolek 49 mln przez ostatnie 8 lat. Na aborcje\nwykonywane u kobiet z Polski składają się wszystkie inne\npaństwa, takie jak Holandia, Francja czy Belgia, ale\nteż prywatni darczyńcy. Każdego dnia dzięki pieniądzom\notrzymanym z organizacji kobiecych około\nsiedmiu kobiet wyjeżdża do Holandii na zabieg\naborcji w drugim trymestrze ciąży. Wiele z nich\npotrzebuje wsparcia finansowego. To są często ciąże chciane,\nto są często ciąże wyczekane, ale te kobiety nie\nmogą otrzymać pomocy w swoim państwie.",
         "True",
         "['Flag_Waving' 'Questioning_the_Reputation' 'Appeal_to_Popularity']",
         "train",
         "['Państwo polskie zaoszczędziło na zdrowiu i życiu Polek 49 mln przez ostatnie 8 lat']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Na aborcje wykonywane u kobiet z Polski składają się wszystkie inne państwa, takie jak Holandia, Francja czy Belgia, ale też prywatni darczyńcy. Każdego dnia dzięki pieniądzom otrzymanym z organizacji kobiecych około siedmiu kobiet wyjeżdża do Holandii na zabieg aborcji w drugim trymestrze ciąży']",
         "[]",
         "[]",
         "['te kobiety nie mogą otrzymać pomocy w swoim państwie']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Hypocrisy",
         "Appeal_to_Hypocrisy",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Appeal to Hypocrisy technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text discusses the financial implications of abortion services in Poland and the reliance on other countries for these services. It does not attack any individual\\'s reputation by charging them with hypocrisy or inconsistency, nor does it highlight contradictions in positions or actions. Therefore, the Appeal to Hypocrisy technique is not present.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "[\"The input text discusses the financial implications of abortion services in Poland and the reliance on other countries for these services. It does not attack any individual's reputation by charging them with hypocrisy or inconsistency, nor does it highlight contradictions in positions or actions. Therefore, the Appeal to Hypocrisy technique is not present.\"]",
         "[None]",
         "[None]",
         "[ True]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/pl/train-pl-part_0005.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text discusses the financial implications of abortion services in Poland and the reliance on other countries for these services. It does not attack any individual's reputation by charging them with hypocrisy or inconsistency, nor does it highlight contradictions in positions or actions. Therefore, the Appeal to Hypocrisy technique is not present.\", \"verdict\": false}"
        ],
        [
         "8",
         "pl_defence_22_05_2024_n01.txt",
         "3494",
         "3606",
         "PL",
         "A więc trzeba za to wszystko przeprosić i potem\nrealizować program Prawa i Sprawiedliwości, bo to\ndobry program.",
         "True",
         "['Slogans' 'False_Dilemma-No_Choice']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['bo to dobry program']",
         "[]",
         "[]",
         "[]",
         "['A więc trzeba za to wszystko przeprosić i potem realizować program Prawa i Sprawiedliwości, bo to dobry program']",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Hypocrisy",
         "Appeal_to_Hypocrisy",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Appeal to Hypocrisy technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. There are no explicit or implicit references to contradictions between positions or actions, nor is there any mention of someone criticizing another for something they themselves have done.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "['The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. There are no explicit or implicit references to contradictions between positions or actions, nor is there any mention of someone criticizing another for something they themselves have done.']",
         "[None]",
         "[None]",
         "[ True]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/pl/train-pl-part_0005.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. There are no explicit or implicit references to contradictions between positions or actions, nor is there any mention of someone criticizing another for something they themselves have done.\", \"verdict\": false}"
        ],
        [
         "9",
         "pl_abortion_11_04_2024_n03.txt",
         "6145",
         "6687",
         "PL",
         "W szpitalach na Podlasiu i Podkarpaciu nawet ten\npseudokompromis nie działał, bo żadna, ale to żadna,\nkobieta od lat, nawet w przypadku zagrożenia\nzdrowia i życia, nie mogła tam otrzymać pomocy i była\nodsyłana z kwitkiem, chociaż w zasadzie raczej bez\nkwitka, bo lekarze odmawiali aborcji, zasłaniając się\nklauzulą sumienia. I chociaż łamali w ten sposób prawo,\nnie wyznaczali podmiotu leczniczego, w którym\nkobieta mogłaby przerwać ciążę, i nie dokumentowali\ntej odmowy na piśmie. Łamanie praw pacjentek?\nKto by tam się przejmował kobietami.",
         "True",
         "['Loaded_Language' 'Appeal_to_Hypocrisy' 'Questioning_the_Reputation'\n 'Appeal_to_Values' 'Repetition']",
         "train",
         "['I chociaż łamali w ten sposób prawo, nie wyznaczali podmiotu leczniczego, w którym kobieta mogłaby przerwać ciążę, i nie dokumentowali tej odmowy na piśmie']",
         "[]",
         "['lekarze odmawiali aborcji, zasłaniając się klauzulą sumienia']",
         "[]",
         "['pseudokompromis' 'była odsyłana z kwitkiem' 'Kto by tam się przejmował']",
         "['żadna' 'żadna']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['bo lekarze odmawiali aborcji, zasłaniając się klauzulą sumienia'\n 'Łamanie praw pacjentek? Kto by tam się przejmował kobietami']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Hypocrisy",
         "Appeal_to_Hypocrisy",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "1",
         "Yes, the Appeal to Hypocrisy technique is used in the input.",
         "\"lekarze odmawiali aborcji, zasłaniając się klauzulą sumienia\"",
         "['{\\n  \"explanation\": \"The Appeal to Hypocrisy technique is used in the input text by highlighting the inconsistency of doctors who refuse to perform abortions citing the conscience clause, while simultaneously violating the law and neglecting women\\'s rights. This points to a hypocrisy in their actions versus their claimed moral stance.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "[\"The Appeal to Hypocrisy technique is used in the input text by highlighting the inconsistency of doctors who refuse to perform abortions citing the conscience clause, while simultaneously violating the law and neglecting women's rights. This points to a hypocrisy in their actions versus their claimed moral stance.\"]",
         "[None]",
         "[None]",
         "[ True]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/pl/train-pl-part_0005.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The Appeal to Hypocrisy technique is used in the input text by highlighting the inconsistency of doctors who refuse to perform abortions citing the conscience clause, while simultaneously violating the law and neglecting women's rights. This points to a hypocrisy in their actions versus their claimed moral stance.\", \"verdict\": true}"
        ],
        [
         "10",
         "pl_abortion_11_04_2024_n06.txt",
         "3465",
         "3708",
         "PL",
         "Poseł Monika Rosa:\nPanie Pośle! Pan nigdy nie był w ciąży i pan nie\nwie, co to znaczy nosić dziecko i się bać. A więc proszę\nnie wychodzić mi z jakimiś moralnymi według pana\ni etycznymi komentarzami. (Oklaski)\n(Poseł Piotr Kaleta: Ojej, ojej…)",
         "True",
         "['Loaded_Language' 'Questioning_the_Reputation' 'Straw_Man']",
         "train",
         "['Pan nigdy nie był w ciąży i pan nie wie, co to znaczy nosić dziecko i się bać. A więc proszę nie wychodzić mi z jakimiś moralnymi według pana i etycznymi komentarzami']",
         "[]",
         "[]",
         "[]",
         "['nie wychodzić mi']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Pan nigdy nie był w ciąży i pan nie wie, co to znaczy nosić dziecko i się bać. A więc proszę nie wychodzić mi z jakimiś moralnymi według pana i etycznymi komentarzami']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Hypocrisy",
         "Appeal_to_Hypocrisy",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Appeal to Hypocrisy technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not contain any elements that attack the reputation of the target by charging them with hypocrisy or inconsistency. Monika Rosa\\'s statement focuses on the personal experience of pregnancy and does not reference any past actions or positions of the other individual that would indicate hypocrisy.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "[\"The input text does not contain any elements that attack the reputation of the target by charging them with hypocrisy or inconsistency. Monika Rosa's statement focuses on the personal experience of pregnancy and does not reference any past actions or positions of the other individual that would indicate hypocrisy.\"]",
         "[None]",
         "[None]",
         "[ True]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/pl/train-pl-part_0004.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text does not contain any elements that attack the reputation of the target by charging them with hypocrisy or inconsistency. Monika Rosa's statement focuses on the personal experience of pregnancy and does not reference any past actions or positions of the other individual that would indicate hypocrisy.\", \"verdict\": false}"
        ],
        [
         "11",
         "pl_abortion_11_04_2024_n01.txt",
         "4660",
         "5608",
         "PL",
         "Musimy się zgodzić na to, żeby ta pomoc nie groziła\ntym, że rozdziela się rodziny, rozdziela się ojców i\ndzieci, rozdziela się babcie oraz ciocie czy też przyjaciółki\nrodziny. Ogólnodostępne dane zawierające informacje\no treści wyroków polskich sądów pokazują, że w\nostatnich latach za pomoc kobiecie w aborcji zostali skazani\nm.in.: ojciec, który przekazał córce pieniądze na\npokrycie kosztów jej zabiegu aborcji w klinice w Holandii;\nmatka, która pomogła córce wyjechać na zabieg aborcji\ndo kliniki w Holandii i która opłaciła córce koszty\nprzejazdu i samego zabiegu; kolejna matka, matka kobiety,\nżyjącej kobiety, która zorganizowała swojej córce\nwyjazd na zabieg aborcji i również opłaciła jej środek\ntransportu; następna matka – to samo, dokładnie taki\nsam przypadek. Tych wyroków jest w Polsce dużo.\nPaństwo może sobie nie zdają z tego sprawy, bo być może\nto jest takie podejście: nie interesujemy się, niech sobie\nkobiety to załatwiają same.",
         "True",
         "['Appeal_to_Pity' 'Appeal_to_Values' 'False_Dilemma-No_Choice' 'Doubt']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['bo być może to jest takie podejście: nie interesujemy się, niech sobie kobiety to załatwiają same']",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Ogólnodostępne dane zawierające informacje o treści wyroków polskich sądów pokazują, że w ostatnich latach za pomoc kobiecie w aborcji zostali skazani m.in.: ojciec, który przekazał córce pieniądze na pokrycie kosztów jej zabiegu aborcji w klinice w Holandii; matka, która pomogła córce wyjechać na zabieg aborcji do kliniki w Holandii i która opłaciła córce koszty przejazdu i samego zabiegu; kolejna matka, matka kobiety, żyjącej kobiety, która zorganizowała swojej córce wyjazd na zabieg aborcji i również opłaciła jej środek transportu; następna matka – to samo, dokładnie taki sam przypadek']",
         "[]",
         "['Musimy się zgodzić na to, żeby ta pomoc nie groziła tym, że rozdziela się rodziny, rozdziela się ojców i dzieci, rozdziela się babcie oraz ciocie czy też przyjaciółki rodziny']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Musimy się zgodzić na to, żeby ta pomoc nie groziła tym, że rozdziela się rodziny, rozdziela się ojców i dzieci, rozdziela się babcie oraz ciocie czy też przyjaciółki rodziny']",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Hypocrisy",
         "Appeal_to_Hypocrisy",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Appeal to Hypocrisy technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text discusses the consequences of legal actions related to abortion assistance without attacking the reputation of any individual or group by charging them with hypocrisy. There are no explicit or implicit contradictions highlighted that would constitute an Appeal to Hypocrisy.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "['The input text discusses the consequences of legal actions related to abortion assistance without attacking the reputation of any individual or group by charging them with hypocrisy. There are no explicit or implicit contradictions highlighted that would constitute an Appeal to Hypocrisy.']",
         "[None]",
         "[None]",
         "[ True]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/pl/train-pl-part_0004.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text discusses the consequences of legal actions related to abortion assistance without attacking the reputation of any individual or group by charging them with hypocrisy. There are no explicit or implicit contradictions highlighted that would constitute an Appeal to Hypocrisy.\", \"verdict\": false}"
        ],
        [
         "12",
         "pl_eu_12_06_2024_n02.txt",
         "2901",
         "3285",
         "PL",
         "Niewątpliwie priorytetem będzie kwestia poprawy obronności. Cieszę się, że rząd Donalda Tuska po\nzmianie, po 15 października przejął stery naszej dyplomacji, bo to jest gwarancja tego, że wykorzystamy\nten czas jak najlepiej (Dzwonek) dla zapewnienia i realizacji interesów Polski, m.in. poprzez poprawę bezpieczeństwa i zaangażowania w tę kwestię członków\nUnii Europejskiej. Dziękuję.",
         "True",
         "['Consequential_Oversimplification' 'Flag_Waving']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['dla zapewnienia i realizacji interesów Polski']",
         "[]",
         "['rząd Donalda Tuska po zmianie, po 15 października przejął stery naszej dyplomacji, bo to jest gwarancja tego, że wykorzystamy ten czas jak najlepiej']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Hypocrisy",
         "Appeal_to_Hypocrisy",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Appeal to Hypocrisy technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. There are no explicit or implicit references to contradictions between positions or actions, nor is there any mention of someone criticizing another for something they themselves have done. Therefore, the Appeal to Hypocrisy technique is not used.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "['The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. There are no explicit or implicit references to contradictions between positions or actions, nor is there any mention of someone criticizing another for something they themselves have done. Therefore, the Appeal to Hypocrisy technique is not used.']",
         "[None]",
         "[None]",
         "[ True]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/pl/train-pl-part_0004.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. There are no explicit or implicit references to contradictions between positions or actions, nor is there any mention of someone criticizing another for something they themselves have done. Therefore, the Appeal to Hypocrisy technique is not used.\", \"verdict\": false}"
        ],
        [
         "13",
         "pl_abortion_11_04_2024_n04.txt",
         "4214",
         "4856",
         "PL",
         "Poseł Agnieszka Buczyńska:\nPanie Marszałku! Wysoka Izbo! Czy polskie\nkobiety oczekują od nas, polityczek i polityków, kłótni\ni krzyków z mównicy, wewnętrznych wojen i obrażania?\nA może raczej umiejętności dyskusji i szukania\nwspólnego rozwiązania? Uspokojenia, empatii,\nwrażliwości, bo i tak w samym społeczeństwie ten temat\nwywołuje potężne emocje. Jesienią 2020 r. tysiące\nkobiet i nierzadko mężczyzn wyszło na ulice\nprotestować przeciwko skandalicznej decyzji Trybunału\nKonstytucyjnego Przyłębskiej, który w swoim\nbezpodstawnym orzeczeniu zmusił kobiety do heroizmu,\ndo rodzenia dzieci z ciężkimi wadami płodu,\ndo narażania własnego życia.",
         "True",
         "['Exaggeration-Minimisation' 'Appeal_to_Values' 'Name_Calling-Labeling'\n 'Straw_Man' 'Repetition']",
         "train",
         "[]",
         "['skandalicznej decyzji Trybunału Konstytucyjnego'\n 'bezpodstawnym orzeczeniu']",
         "[]",
         "[]",
         "[]",
         "['zmusił kobiety do heroizmu']",
         "[]",
         "[]",
         "[]",
         "[]",
         "['zmusił kobiety do heroizmu']",
         "[]",
         "[]",
         "[]",
         "['Czy polskie kobiety oczekują od nas, polityczek i polityków, kłótni i krzyków z mównicy, wewnętrznych wojen i obrażania?'\n 'A może raczej umiejętności dyskusji i szukania wspólnego rozwiązania?'\n 'Uspokojenia, empatii, wrażliwości, bo i tak w samym społeczeństwie ten temat wywołuje potężne emocje'\n 'narażania własnego życia']",
         "[]",
         "['Czy polskie kobiety oczekują od nas, polityczek i polityków, kłótni i krzyków z mównicy, wewnętrznych wojen i obrażania?']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Hypocrisy",
         "Appeal_to_Hypocrisy",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Appeal to Hypocrisy technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. There are no explicit or implicit references to contradictions between different positions or actions held by the speaker or others, which is necessary for the Appeal to Hypocrisy technique to be present.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "['The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. There are no explicit or implicit references to contradictions between different positions or actions held by the speaker or others, which is necessary for the Appeal to Hypocrisy technique to be present.']",
         "[None]",
         "[None]",
         "[ True]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/pl/train-pl-part_0004.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. There are no explicit or implicit references to contradictions between different positions or actions held by the speaker or others, which is necessary for the Appeal to Hypocrisy technique to be present.\", \"verdict\": false}"
        ],
        [
         "14",
         "pl_eu_12_06_2024_n01.txt",
         "6832",
         "7189",
         "PL",
         "Projektodawca jest również niekonsekwentny.\nZ jednej strony ogłasza plan likwidacji CBA, z drugiej, w art. 9 nakazuje zamawiającym zgłaszać zamówienia realizowane poza reżimem Prawa zamówień\npublicznych właśnie dokąd? Do CBA. Zasadny jest\nwięc wniosek mniejszości, by wykreślić art. 8 i powiązany z nim art. 9 projektu ustawy. Będziemy popierać ten wniosek.",
         "True",
         "['Appeal_to_Hypocrisy' 'Doubt']",
         "train",
         "[]",
         "[]",
         "['Z jednej strony ogłasza plan likwidacji CBA, z drugiej, w art. 9 nakazuje zamawiającym zgłaszać zamówienia realizowane poza reżimem Prawa zamówień publicznych właśnie dokąd? Do CBA']",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Projektodawca jest również niekonsekwentny']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Hypocrisy",
         "Appeal_to_Hypocrisy",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "1",
         "Yes, the Appeal to Hypocrisy technique is used in the input.",
         "\"Z jednej strony ogłasza plan likwidacji CBA, z drugiej, w art. 9 nakazuje zamawiającym zgłaszać zamówienia realizowane poza reżimem Prawa zamówień publicznych właśnie dokąd? Do CBA\"",
         "['{\\n  \"explanation\": \"The Appeal to Hypocrisy technique is used in the input text by highlighting the inconsistency in the actions of the project proposer. The text points out that while the proposer announces a plan to liquidate the CBA, they simultaneously require submissions to be made to the CBA, showcasing a contradiction in their stance.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "['The Appeal to Hypocrisy technique is used in the input text by highlighting the inconsistency in the actions of the project proposer. The text points out that while the proposer announces a plan to liquidate the CBA, they simultaneously require submissions to be made to the CBA, showcasing a contradiction in their stance.']",
         "[None]",
         "[None]",
         "[ True]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/pl/train-pl-part_0004.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The Appeal to Hypocrisy technique is used in the input text by highlighting the inconsistency in the actions of the project proposer. The text points out that while the proposer announces a plan to liquidate the CBA, they simultaneously require submissions to be made to the CBA, showcasing a contradiction in their stance.\", \"verdict\": true}"
        ],
        [
         "15",
         "pl_abortion_11_04_2024_n01.txt",
         "3417",
         "3907",
         "PL",
         "Rozmawiamy o życiu. Rozmawiajmy o życiu\nkobiet, jak to życie jest niszczone przez to, że mąż\nkobiety, która przerwała ciążę – podkreślam, miała\nprawo to zrobić – idzie do więzienia. Czy to jest\nnormalne? Czy to nie jest niszczenie życia rodzin?\nWiększość kobiet, które przerywają ciążę, już ma dzieci,\njedno lub więcej, i w tym momencie członek rodziny\n– czasem tata tych dzieci, czasem babcia, czasem\nciocia – ryzykuje tym, że trafi na 3 lata do więzienia.\nTo się musi zmienić natychmiast.",
         "True",
         "['Appeal_to_Time' 'Appeal_to_Pity' 'Appeal_to_Values' 'Repetition' 'Doubt']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Rozmawiamy o życiu' 'Rozmawiajmy o życiu kobiet']",
         "[]",
         "['Czy to jest normalne?']",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Rozmawiajmy o życiu kobiet, jak to życie jest niszczone przez to, że mąż kobiety, która przerwała ciążę – podkreślam, miała prawo to zrobić – idzie do więzienia. Czy to jest normalne? Czy to nie jest niszczenie życia rodzin?'\n 'Większość kobiet, które przerywają ciążę, już ma dzieci, jedno lub więcej, i w tym momencie członek rodziny – czasem tata tych dzieci, czasem babcia, czasem ciocia – ryzykuje tym, że trafi na 3 lata do więzienia']",
         "['To się musi zmienić natychmiast']",
         "['Rozmawiamy o życiu'\n 'Rozmawiajmy o życiu kobiet, jak to życie jest niszczone przez to, że mąż kobiety, która przerwała ciążę – podkreślam, miała prawo to zrobić – idzie do więzienia'\n 'Czy to nie jest niszczenie życia rodzin?']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Hypocrisy",
         "Appeal_to_Hypocrisy",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Appeal to Hypocrisy technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text discusses the impact of legal consequences on women and their families regarding abortion, but it does not attack anyone\\'s reputation by charging them with hypocrisy or inconsistency. There are no explicit or implicit references to contradictions in positions or actions that would constitute an Appeal to Hypocrisy.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "[\"The input text discusses the impact of legal consequences on women and their families regarding abortion, but it does not attack anyone's reputation by charging them with hypocrisy or inconsistency. There are no explicit or implicit references to contradictions in positions or actions that would constitute an Appeal to Hypocrisy.\"]",
         "[None]",
         "[None]",
         "[ True]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/pl/train-pl-part_0004.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text discusses the impact of legal consequences on women and their families regarding abortion, but it does not attack anyone's reputation by charging them with hypocrisy or inconsistency. There are no explicit or implicit references to contradictions in positions or actions that would constitute an Appeal to Hypocrisy.\", \"verdict\": false}"
        ],
        [
         "16",
         "pl_abortion_11_04_2024_n04.txt",
         "7452",
         "7724",
         "PL",
         "Wicemarszałek Włodzimierz Czarzasty:\nDziękuję bardzo.\nZanim poproszę panią poseł, chcę przeprosić, bo\nnie wiem, czy jeszcze jest grupa młodzieży z Jędrzejowa.\nJesteście jeszcze państwo? Są, jesteście.\nWitam was serdecznie. (Oklaski)\n(Poseł Urszula Pasławska: Pozdrawiamy.)",
         "False",
         "[]",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Hypocrisy",
         "Appeal_to_Hypocrisy",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Appeal to Hypocrisy technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. There are no explicit or implicit references to contradictions or past actions that would qualify as an Appeal to Hypocrisy.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "['The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. There are no explicit or implicit references to contradictions or past actions that would qualify as an Appeal to Hypocrisy.']",
         "[None]",
         "[None]",
         "[ True]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/pl/train-pl-part_0004.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. There are no explicit or implicit references to contradictions or past actions that would qualify as an Appeal to Hypocrisy.\", \"verdict\": false}"
        ],
        [
         "17",
         "pl_abortion_11_04_2024_n04.txt",
         "2549",
         "2890",
         "PL",
         "Dziś z tego miejsca chciałabym, by jeszcze raz\nwybrzmiało, że aborcja to prawa człowieka, to\npodstawowe prawo kobiety do podjęcia decyzji o swoim\nciele, zdrowiu i życiu. Aborcje były, są i będą tak długo,\njak będą potrzebne. Aborcja jest jednym z najczęściej\nstosowanych zabiegów medycznych na świecie i\nnajczęstszym zabiegiem w ginekologii.",
         "True",
         "['Conversation_Killer' 'Appeal_to_Values' 'Appeal_to_Popularity']",
         "train",
         "[]",
         "[]",
         "[]",
         "['Aborcje były, są i będą']",
         "[]",
         "[]",
         "['Aborcja jest jednym z najczęściej stosowanych zabiegów medycznych na świecie i najczęstszym zabiegiem w ginekologii']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Dziś z tego miejsca chciałabym, by jeszcze raz wybrzmiało, że aborcja to prawa człowieka, to podstawowe prawo kobiety do podjęcia decyzji o swoim ciele, zdrowiu i życiu']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Hypocrisy",
         "Appeal_to_Hypocrisy",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Appeal to Hypocrisy technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. It focuses on the rights related to abortion without referencing any contradictions or past actions of critics.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "['The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. It focuses on the rights related to abortion without referencing any contradictions or past actions of critics.']",
         "[None]",
         "[None]",
         "[ True]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/pl/train-pl-part_0004.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. It focuses on the rights related to abortion without referencing any contradictions or past actions of critics.\", \"verdict\": false}"
        ],
        [
         "18",
         "pl_defence_22_05_2024_n02.txt",
         "3985",
         "4869",
         "PL",
         "Trzeba zwiększyć polskie zdolności produkcyjne,\nzamawiać dużo sprzętu w polskich firmach, zarówno\nprywatnych, jak i publicznych, trzeba też im płacić\nza utrzymanie zdolności produkcyjnych na czas\nwojny oraz wycofać się z konwencji ottawskiej o zakazie\nużywania min przeciwpiechotnych. Nie są stroną tej\nkonwencji Rosja, Stany Zjednoczone, Chiny, Indie,\nIzrael, Egipt. Ukraina, gdyby nie miny\nprzeciwpiechotne, nie broniłaby się skutecznie przed Rosją.\nMusimy jak najszybciej wypowiedzieć tę konwencję.\nNie jesteśmy w tym momencie gotowi do wojny.\nJedni i drudzy rządziliście Polską od 20 lat i nie\nprzygotowaliście nas do obrony na czas wojny. PiS\nprzygotowywał się tylko do wojny z Platformą, Platforma\nprzygotowywała się do wojny z PiS-em, a Polska nie\njest gotowa. Nasze Siły Zbrojne pod kątem liczby\nrezerw, liczby czołgów czy też liczby\nsprzętu są najsłabsze od 80 lat. (Oklaski)",
         "True",
         "['Causal_Oversimplification' 'Exaggeration-Minimisation' 'Appeal_to_Time'\n 'Questioning_the_Reputation' 'Whataboutism' 'Doubt'\n 'Appeal_to_Fear-Prejudice']",
         "train",
         "['Jedni i drudzy rządziliście Polską od 20 lat i nie przygotowaliście nas do obrony na czas wojny']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Nasze Siły Zbrojne pod kątem liczby rezerw, liczby czołgów czy też liczby sprzętu są najsłabsze od 80 lat']",
         "[]",
         "[]",
         "['PiS przygotowywał się tylko do wojny z Platformą, Platforma przygotowywała się do wojny z PiS-em, a Polska nie jest gotowa']",
         "[]",
         "[]",
         "['Musimy jak najszybciej wypowiedzieć tę konwencję']",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Nie jesteśmy w tym momencie gotowi do wojny'\n 'Jedni i drudzy rządziliście Polską od 20 lat i nie przygotowaliście nas do obrony na czas wojny']",
         "['Ukraina, gdyby nie miny przeciwpiechotne, nie broniłaby się skutecznie przed Rosją']",
         "[]",
         "[]",
         "['PiS przygotowywał się tylko do wojny z Platformą, Platforma przygotowywała się do wojny z PiS-em, a Polska nie jest gotowa']",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Hypocrisy",
         "Appeal_to_Hypocrisy",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Appeal to Hypocrisy technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not explicitly attack the reputation of any individual or group by charging them with hypocrisy or inconsistency. While it criticizes the political parties for their lack of preparation for war, it does not point out any past actions or positions that contradict their current stance, which is necessary for the Appeal to Hypocrisy technique to be applicable.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "['The input text does not explicitly attack the reputation of any individual or group by charging them with hypocrisy or inconsistency. While it criticizes the political parties for their lack of preparation for war, it does not point out any past actions or positions that contradict their current stance, which is necessary for the Appeal to Hypocrisy technique to be applicable.']",
         "[None]",
         "[None]",
         "[ True]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/pl/train-pl-part_0004.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text does not explicitly attack the reputation of any individual or group by charging them with hypocrisy or inconsistency. While it criticizes the political parties for their lack of preparation for war, it does not point out any past actions or positions that contradict their current stance, which is necessary for the Appeal to Hypocrisy technique to be applicable.\", \"verdict\": false}"
        ],
        [
         "19",
         "pl_abortion_11_04_2024_n02.txt",
         "2916",
         "3709",
         "PL",
         "Ale to nie koniec. Art. 152, jak wiemy, jest\nprzyczyną tragedii także w polskich szpitalach, bo od\n30 lat aborcja jest traktowana nie jak zabieg\nmedyczny, tylko jak przestępstwo. To sprawia, że lekarze nie\nuczą się o tym, jak przeprowadzać aborcję, nie mają\npraktyki, nie wiedzą, jak to się robi, i kiedy stają\nwobec takiej sytuacji, że mają przerwać ciążę, to się\nboją, próbują tego uniknąć. Nawet wtedy, kiedy ta\ndecyzja zagraża życiu i zdrowiu pacjentki.\nBo brakuje im kompetencji, bo boją się o swoją karierę.\nI właśnie to spychanie aborcji do sfery świata\nkryminalnego doprowadziło do śmierci Izy z Pszczyny,\ndoprowadziło do śmierci Doroty z Nowego Targu i innych\nmłodych kobiet, które miały przed sobą całe życie,\nktóre miały małe dzieci, które mogły dalej\nżyć i wychowywać swoje dzieci.",
         "True",
         "['Causal_Oversimplification' 'Loaded_Language'\n 'Questioning_the_Reputation' 'Appeal_to_Values' 'Doubt']",
         "train",
         "['bo boją się o swoją karierę']",
         "[]",
         "[]",
         "[]",
         "['spychanie aborcji do sfery świata kryminalnego']",
         "[]",
         "[]",
         "['Art. 152, jak wiemy, jest przyczyną tragedii także w polskich szpitalach, bo od 30 lat aborcja jest traktowana nie jak zabieg medyczny, tylko jak przestępstwo'\n 'Bo brakuje im kompetencji']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Nawet wtedy, kiedy ta decyzja zagraża życiu i zdrowiu pacjentki'\n 'które miały przed sobą całe życie, które miały małe dzieci, które mogły dalej żyć i wychowywać swoje dzieci']",
         "[]",
         "[]",
         "[]",
         "[]",
         "['To sprawia, że lekarze nie uczą się o tym, jak przeprowadzać aborcję, nie mają praktyki, nie wiedzą, jak to się robi, i kiedy stają wobec takiej sytuacji, że mają przerwać ciążę, to się boją, próbują tego uniknąć'\n 'I właśnie to spychanie aborcji do sfery świata kryminalnego doprowadziło do śmierci Izy z Pszczyny, doprowadziło do śmierci Doroty z Nowego Targu i innych młodych kobiet, które miały przed sobą całe życie, które miały małe dzieci, które mogły dalej żyć i wychowywać swoje dzieci']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Hypocrisy",
         "Appeal_to_Hypocrisy",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Appeal to Hypocrisy technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text discusses the consequences of treating abortion as a criminal act and highlights the lack of medical training and the resulting tragedies. However, it does not attack anyone\\'s reputation by charging them with hypocrisy or inconsistency, nor does it point out contradictions in their positions or actions. Therefore, the Appeal to Hypocrisy technique is not used.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "[\"The input text discusses the consequences of treating abortion as a criminal act and highlights the lack of medical training and the resulting tragedies. However, it does not attack anyone's reputation by charging them with hypocrisy or inconsistency, nor does it point out contradictions in their positions or actions. Therefore, the Appeal to Hypocrisy technique is not used.\"]",
         "[None]",
         "[None]",
         "[ True]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/pl/train-pl-part_0004.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text discusses the consequences of treating abortion as a criminal act and highlights the lack of medical training and the resulting tragedies. However, it does not attack anyone's reputation by charging them with hypocrisy or inconsistency, nor does it point out contradictions in their positions or actions. Therefore, the Appeal to Hypocrisy technique is not used.\", \"verdict\": false}"
        ],
        [
         "20",
         "pl_defence_22_05_2024_n01.txt",
         "1828",
         "2081",
         "PL",
         "Wicemarszałek Piotr Zgorzelski:\nPanie pośle, proszę zachować powagę, bo jest\ndebata.\n(Głos z sali: No właśnie to jest powaga.)\n(Głos z sali: Dokumentujemy powagę, panie marszałku.)\nJest debata, proszę zachować powagę.\n(Głos z sali: Gdzie jest Hołownia?)",
         "False",
         "[]",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Hypocrisy",
         "Appeal_to_Hypocrisy",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Appeal to Hypocrisy technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. There are no explicit or implicit references to contradictions between positions or actions, nor is there any mention of someone criticizing another for something they themselves have done. Therefore, the Appeal to Hypocrisy technique is not used.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "['The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. There are no explicit or implicit references to contradictions between positions or actions, nor is there any mention of someone criticizing another for something they themselves have done. Therefore, the Appeal to Hypocrisy technique is not used.']",
         "[None]",
         "[None]",
         "[ True]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/pl/train-pl-part_0006.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. There are no explicit or implicit references to contradictions between positions or actions, nor is there any mention of someone criticizing another for something they themselves have done. Therefore, the Appeal to Hypocrisy technique is not used.\", \"verdict\": false}"
        ],
        [
         "21",
         "pl_abortion_11_04_2024_n03.txt",
         "9280",
         "9741",
         "PL",
         "Zakaz aborcji zabija i nie likwiduje aborcji. Zakaz\naborcji powoduje, że w polskich szpitalach nie ma\ndzisiaj bezpiecznej aborcji. Ale od 30 lat te aborcje się\ndzieją tylko dlatego, że poszczególne osoby znajdują\nsposób na to, żeby je zrobić. Ostatnie lata to zasługa\ngrup nieformalnych i aktywistek działających\nw Polsce – to Aborcyjny Dream Team czy Aborcja bez Granic.\nWiem, że jesteście, pozdrawiam was bardzo serdecznie\ni dziękuję za waszą pracę. (Oklaski)",
         "True",
         "['Consequential_Oversimplification' 'Causal_Oversimplification'\n 'Loaded_Language' 'Flag_Waving' 'Appeal_to_Popularity' 'Doubt'\n 'Appeal_to_Fear-Prejudice']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "['zabija']",
         "[]",
         "['Ostatnie lata to zasługa grup nieformalnych i aktywistek działających w Polsce – to Aborcyjny Dream Team czy Aborcja bez Granic']",
         "['Zakaz aborcji zabija i nie likwiduje aborcji']",
         "[]",
         "['Wiem, że jesteście, pozdrawiam']",
         "[]",
         "['Zakaz aborcji zabija i nie likwiduje aborcji']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Zakaz aborcji zabija']",
         "['Zakaz aborcji powoduje, że w polskich szpitalach nie ma dzisiaj bezpiecznej aborcji']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Hypocrisy",
         "Appeal_to_Hypocrisy",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Appeal to Hypocrisy technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. It discusses the issue of abortion and acknowledges the efforts of activists without calling out any hypocrisy.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "['The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. It discusses the issue of abortion and acknowledges the efforts of activists without calling out any hypocrisy.']",
         "[None]",
         "[None]",
         "[ True]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/pl/train-pl-part_0006.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. It discusses the issue of abortion and acknowledges the efforts of activists without calling out any hypocrisy.\", \"verdict\": false}"
        ],
        [
         "22",
         "pl_abortion_11_04_2024_n04.txt",
         "7809",
         "7883",
         "PL",
         "Bardzo proszę panią poseł Urszulę Pasławską o zabranie głosu.\nProszę, Ula.",
         "False",
         "[]",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Hypocrisy",
         "Appeal_to_Hypocrisy",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Appeal to Hypocrisy technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not contain any elements that attack the reputation of an individual by charging them with hypocrisy or inconsistency. There are no references to past actions or positions that would indicate a contradiction, which is necessary for the Appeal to Hypocrisy technique to be present.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "['The input text does not contain any elements that attack the reputation of an individual by charging them with hypocrisy or inconsistency. There are no references to past actions or positions that would indicate a contradiction, which is necessary for the Appeal to Hypocrisy technique to be present.']",
         "[None]",
         "[None]",
         "[ True]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/pl/train-pl-part_0006.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text does not contain any elements that attack the reputation of an individual by charging them with hypocrisy or inconsistency. There are no references to past actions or positions that would indicate a contradiction, which is necessary for the Appeal to Hypocrisy technique to be present.\", \"verdict\": false}"
        ],
        [
         "23",
         "pl_current_affairs_09_01_2025_n03.txt",
         "4738",
         "4973",
         "PL",
         "…a za rządów Jarosława Kaczyńskiego, Mateusza\nMorawieckiego i ministra Gróbarczyka odpowiedzialnego za zabezpieczenie przeciwpowodziowe – 303 km.\n1732 km versus 303 km. Myślę, że na podsumowanie\nto wystarczy. Dziękuję bardzo. (Oklaski)",
         "True",
         "['Conversation_Killer' 'Doubt']",
         "train",
         "[]",
         "[]",
         "[]",
         "['Myślę, że na podsumowanie to wystarczy']",
         "[]",
         "[]",
         "[]",
         "['…a za rządów Jarosława Kaczyńskiego, Mateusza Morawieckiego i ministra Gróbarczyka odpowiedzialnego za zabezpieczenie przeciwpowodziowe – 303 km. 1732 km versus 303 km']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Hypocrisy",
         "Appeal_to_Hypocrisy",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Appeal to Hypocrisy technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. There are no explicit or implicit references to contradictions between positions or actions, nor is there any mention of someone criticizing another for something they themselves have done.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "['The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. There are no explicit or implicit references to contradictions between positions or actions, nor is there any mention of someone criticizing another for something they themselves have done.']",
         "[None]",
         "[None]",
         "[ True]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/pl/train-pl-part_0006.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. There are no explicit or implicit references to contradictions between positions or actions, nor is there any mention of someone criticizing another for something they themselves have done.\", \"verdict\": false}"
        ],
        [
         "24",
         "pl_eu_12_06_2024_n02.txt",
         "1851",
         "1921",
         "PL",
         "Wicemarszałek Włodzimierz Czarzasty:\nDziękuję serdecznie, panie pośle.",
         "False",
         "[]",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Hypocrisy",
         "Appeal_to_Hypocrisy",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Appeal to Hypocrisy technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. There are no explicit or implicit references to contradictions or past actions that would qualify as an Appeal to Hypocrisy.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "['The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. There are no explicit or implicit references to contradictions or past actions that would qualify as an Appeal to Hypocrisy.']",
         "[None]",
         "[None]",
         "[ True]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/pl/train-pl-part_0006.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. There are no explicit or implicit references to contradictions or past actions that would qualify as an Appeal to Hypocrisy.\", \"verdict\": false}"
        ],
        [
         "25",
         "pl_eu_12_06_2024_n01.txt",
         "3163",
         "3547",
         "PL",
         "Po rozpatrzeniu całości projektu ustawy członkowie obu komisji, 51 posłanek i posłów, 32 głosami za,\n2 przeciw i 17 wstrzymującymi przyjęli projekt ustawy o szczególnych rozwiązaniach w związku z przygotowywaniem i sprawowaniem przez Rzeczpospolitą Polską przewodnictwa w Radzie Unii Europejskiej\nw I połowie 2025 roku, druk nr 347, rekomendując\ngo Wysokiej Izbie. Dziękuję. (Oklaski)",
         "False",
         "[]",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Hypocrisy",
         "Appeal_to_Hypocrisy",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Appeal to Hypocrisy technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. There are no explicit or implicit references to contradictions or past actions that would qualify as an Appeal to Hypocrisy.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "['The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. There are no explicit or implicit references to contradictions or past actions that would qualify as an Appeal to Hypocrisy.']",
         "[None]",
         "[None]",
         "[ True]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/pl/train-pl-part_0006.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. There are no explicit or implicit references to contradictions or past actions that would qualify as an Appeal to Hypocrisy.\", \"verdict\": false}"
        ],
        [
         "26",
         "pl_eu_12_06_2024_n02.txt",
         "5845",
         "5961",
         "PL",
         "Wicemarszałek Włodzimierz Czarzasty:\nDziękuję.\nPan poseł Janusz Kowalski, Klub Parlamentarny\nPrawo i Sprawiedliwość.",
         "False",
         "[]",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Hypocrisy",
         "Appeal_to_Hypocrisy",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Appeal to Hypocrisy technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The Appeal to Hypocrisy technique was not used in the input text as there are no attacks on reputation or charges of hypocrisy present. The text consists of a simple acknowledgment without any reference to contradictions or past actions.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "['The Appeal to Hypocrisy technique was not used in the input text as there are no attacks on reputation or charges of hypocrisy present. The text consists of a simple acknowledgment without any reference to contradictions or past actions.']",
         "[None]",
         "[None]",
         "[ True]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/pl/train-pl-part_0006.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The Appeal to Hypocrisy technique was not used in the input text as there are no attacks on reputation or charges of hypocrisy present. The text consists of a simple acknowledgment without any reference to contradictions or past actions.\", \"verdict\": false}"
        ],
        [
         "27",
         "pl_abortion_11_04_2024_n01.txt",
         "268",
         "371",
         "PL",
         "Panowie, halo, szanujmy wszystkich gości.\nDziękujemy wam bardzo za przybycie.\nSuper, bardzo dziękujemy.",
         "False",
         "[]",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Hypocrisy",
         "Appeal_to_Hypocrisy",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Appeal to Hypocrisy technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. There are no contradictions or criticisms present that would indicate the use of the Appeal to Hypocrisy technique.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "['The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. There are no contradictions or criticisms present that would indicate the use of the Appeal to Hypocrisy technique.']",
         "[None]",
         "[None]",
         "[ True]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/pl/train-pl-part_0006.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. There are no contradictions or criticisms present that would indicate the use of the Appeal to Hypocrisy technique.\", \"verdict\": false}"
        ],
        [
         "28",
         "pl_abortion_11_04_2024_n03.txt",
         "0",
         "175",
         "PL",
         "Wicemarszałek Włodzimierz Czarzasty:\nDziękuję serdecznie.\nBardzo proszę panią posłankę Katarzynę Kotulę\no przedstawienie uzasadnienia projektu ustawy\nzawartego w druku nr 177.",
         "False",
         "[]",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Hypocrisy",
         "Appeal_to_Hypocrisy",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Appeal to Hypocrisy technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. There are no explicit or implicit references to contradictions or past actions that would qualify as an Appeal to Hypocrisy.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "['The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. There are no explicit or implicit references to contradictions or past actions that would qualify as an Appeal to Hypocrisy.']",
         "[None]",
         "[None]",
         "[ True]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/pl/train-pl-part_0006.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. There are no explicit or implicit references to contradictions or past actions that would qualify as an Appeal to Hypocrisy.\", \"verdict\": false}"
        ],
        [
         "29",
         "pl_defence_22_05_2024_n02.txt",
         "807",
         "993",
         "PL",
         "Ustawa o ochronie Ojczyzny obowiązuje już od\nponad 2 lat, a do tej pory nie ma do niej wydanych\n12 niezbędnych rozporządzeń, w wyniku czego\nWojsko Polskie nawet nie może się mobilizować.",
         "False",
         "[]",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Hypocrisy",
         "Appeal_to_Hypocrisy",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Appeal to Hypocrisy technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text discusses the lack of necessary regulations related to a law and its impact on the military\\'s ability to mobilize. There is no attack on someone\\'s reputation by charging them with hypocrisy or inconsistency, nor is there any mention of past actions or positions that would indicate hypocrisy. Therefore, the Appeal to Hypocrisy technique is not used.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "[\"The input text discusses the lack of necessary regulations related to a law and its impact on the military's ability to mobilize. There is no attack on someone's reputation by charging them with hypocrisy or inconsistency, nor is there any mention of past actions or positions that would indicate hypocrisy. Therefore, the Appeal to Hypocrisy technique is not used.\"]",
         "[None]",
         "[None]",
         "[ True]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/pl/train-pl-part_0006.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text discusses the lack of necessary regulations related to a law and its impact on the military's ability to mobilize. There is no attack on someone's reputation by charging them with hypocrisy or inconsistency, nor is there any mention of past actions or positions that would indicate hypocrisy. Therefore, the Appeal to Hypocrisy technique is not used.\", \"verdict\": false}"
        ],
        [
         "30",
         "pl_abortion_11_04_2024_n07.txt",
         "3811",
         "4153",
         "PL",
         "My, kobiety i mężczyźni broniący prawa do życia\nchcemy poważnego traktowania kobiet i ich potrzeb,\nkiedy zachodzą w ciążę, kiedy stają się matkami,\nlepszej jakości i dostępności opieki zdrowotnej, wsparcia\npsychologicznego oraz pomocy w zakresie opieki nad\ndzieckiem, szczególnie gdy okaże się, że może być\nniepełnosprawne lub poważnie chore.",
         "True",
         "['Appeal_to_Values']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['chcemy poważnego traktowania kobiet i ich potrzeb, kiedy zachodzą w ciążę, kiedy stają się matkami, lepszej jakości i dostępności opieki zdrowotnej, wsparcia psychologicznego oraz pomocy w zakresie opieki nad dzieckiem']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Hypocrisy",
         "Appeal_to_Hypocrisy",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Appeal to Hypocrisy technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. It focuses on advocating for women\\'s rights and healthcare without referencing any contradictions or past actions of others.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "[\"The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. It focuses on advocating for women's rights and healthcare without referencing any contradictions or past actions of others.\"]",
         "[None]",
         "[None]",
         "[ True]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/pl/train-pl-part_0007.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. It focuses on advocating for women's rights and healthcare without referencing any contradictions or past actions of others.\", \"verdict\": false}"
        ],
        [
         "31",
         "pl_abortion_11_04_2024_n08.txt",
         "3138",
         "3188",
         "PL",
         "(Poseł Joanna Scheuring-Wielgus: Zejdź z mównicy.)",
         "True",
         "['Loaded_Language']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Zejdź z mównicy']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Hypocrisy",
         "Appeal_to_Hypocrisy",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Appeal to Hypocrisy technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. There are no explicit or implicit references to contradictions or past actions that would qualify as an Appeal to Hypocrisy.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "['The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. There are no explicit or implicit references to contradictions or past actions that would qualify as an Appeal to Hypocrisy.']",
         "[None]",
         "[None]",
         "[ True]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/pl/train-pl-part_0007.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. There are no explicit or implicit references to contradictions or past actions that would qualify as an Appeal to Hypocrisy.\", \"verdict\": false}"
        ],
        [
         "32",
         "pl_current_affairs_09_01_2025_n02.txt",
         "8069",
         "9438",
         "PL",
         "W decyzji generalny dyrektor ochrony środowiska\npodkreśla, że poważne ustawowe braki w raporcie\no oddziaływaniu na środowisko nie pozwalały na wydanie takiej decyzji. Po pierwsze, zabrakło tam wariantowania przedsięwzięcia. Raport nie zawierał ustawowo wymaganej analizy wariantowej z uwzględnieniem opisu oddziaływania poszczególnych wariantów\nna środowisko. W oparciu o informacje zawarte w raporcie nie można było wskazać, który wariant jest\nnajkorzystniejszy dla środowiska i czy istnieją w ogóle przesłanki wyboru innego wariantu niż ten wskazany do realizacji przez inwestora. Inwestor nie przeanalizował innych działań w zakresie możliwości\nosiągnięcia celu środowiskowego środkami mniej\ndolegliwymi dla środowiska i nie udowodnił, że ten\ncel nie może być za ich pomocą osiągnięty. Raport nie\nzawierał również opisu oddziaływania przedsięwzięcia na obszary Natura 2000, na rezerwaty przyrody\nczy opisu działań mających na celu jakąkolwiek minimalizację, kompensację negatywnych oddziaływań\nprzedsięwzięcia w tym zakresie. Na podstawie informacji znajdujących się w raporcie nie można było\nwykluczyć w żaden sposób, że to przedsięwzięcie nie\nbędzie znacząco negatywnie oddziaływać na obszary\nNatura 2000 typu Włocławska Dolina Wisły, Nieszawska Dolina Wisły, Dolina Dolnej Wisły, Dolny\nDunajec, Dorzecze Górnego Sanu, Wisłoka z dopływami, rezerwat przyrody Kulin.",
         "True",
         "['Appeal_to_Authority' 'Appeal_to_Values']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Na podstawie informacji znajdujących się w raporcie nie można było wykluczyć w żaden sposób, że to przedsięwzięcie nie będzie znacząco negatywnie oddziaływać na obszary Natura 2000 typu Włocławska Dolina Wisły, Nieszawska Dolina Wisły, Dolina Dolnej Wisły, Dolny Dunajec, Dorzecze Górnego Sanu, Wisłoka z dopływami, rezerwat przyrody Kulin']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['W decyzji generalny dyrektor ochrony środowiska podkreśla, że poważne ustawowe braki w raporcie o oddziaływaniu na środowisko nie pozwalały na wydanie takiej decyzji']",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Hypocrisy",
         "Appeal_to_Hypocrisy",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Appeal to Hypocrisy technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text discusses the deficiencies in an environmental report and does not attack the reputation of any individual or entity by charging them with hypocrisy or inconsistency. There are no explicit or implicit references to contradictions in positions or actions, which is necessary for the Appeal to Hypocrisy technique to be applicable.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "['The input text discusses the deficiencies in an environmental report and does not attack the reputation of any individual or entity by charging them with hypocrisy or inconsistency. There are no explicit or implicit references to contradictions in positions or actions, which is necessary for the Appeal to Hypocrisy technique to be applicable.']",
         "[None]",
         "[None]",
         "[ True]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/pl/train-pl-part_0007.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text discusses the deficiencies in an environmental report and does not attack the reputation of any individual or entity by charging them with hypocrisy or inconsistency. There are no explicit or implicit references to contradictions in positions or actions, which is necessary for the Appeal to Hypocrisy technique to be applicable.\", \"verdict\": false}"
        ],
        [
         "33",
         "pl_eu_12_06_2024_n02.txt",
         "5000",
         "5586",
         "PL",
         "Poseł Marcin Porzucek:\nPanie Marszałku! Wysoka Izbo! Szanowni Państwo! W okresie COVID-u, gdy sytuacje pandemiczne\npojawiały się w ciągu nie roku, nie miesięcy, nie tygodnia, ale wręcz dni, i podejmowaliśmy stosowne\ndziałania, państwo nas krytykowaliście. Gdy Rosja\nnapadała pełnoskalowo na Ukrainę, było podobnie.\nSytuacja wojny hybrydowej na granicy polsko-białoruskiej, podobnie. A dzisiaj państwo macie jeszcze\ntyle czasu, chociaż zmarnowaliście ostatnie pół roku,\nproponujecie rozwiązania ekstraordynaryjne, choć\nmożna to w wielu aspektach zrobić tradycyjnie. To\njest jedna sprawa.",
         "True",
         "['Questioning_the_Reputation']",
         "train",
         "['podejmowaliśmy stosowne działania, państwo nas krytykowaliście'\n 'Gdy Rosja napadała pełnoskalowo na Ukrainę, było podobnie. Sytuacja wojny hybrydowej na granicy polsko-białoruskiej, podobnie'\n 'zmarnowaliście ostatnie pół roku']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Hypocrisy",
         "Appeal_to_Hypocrisy",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Appeal to Hypocrisy technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not explicitly attack the reputation of the critics by charging them with hypocrisy or inconsistency. While the speaker mentions past criticisms from the opposing side during crises, there is no direct accusation of hypocrisy or inconsistency in their actions or positions. Therefore, the Appeal to Hypocrisy technique is not used.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "['The input text does not explicitly attack the reputation of the critics by charging them with hypocrisy or inconsistency. While the speaker mentions past criticisms from the opposing side during crises, there is no direct accusation of hypocrisy or inconsistency in their actions or positions. Therefore, the Appeal to Hypocrisy technique is not used.']",
         "[None]",
         "[None]",
         "[ True]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/pl/train-pl-part_0007.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text does not explicitly attack the reputation of the critics by charging them with hypocrisy or inconsistency. While the speaker mentions past criticisms from the opposing side during crises, there is no direct accusation of hypocrisy or inconsistency in their actions or positions. Therefore, the Appeal to Hypocrisy technique is not used.\", \"verdict\": false}"
        ],
        [
         "34",
         "pl_eu_12_06_2024_n01.txt",
         "2653",
         "3161",
         "PL",
         "Po prezentacji przez ministrów uzasadnienia projektu ustawy odbyła się krótka debata. Po niej członkowie obu komisji przystąpili do analizy poszczególnych artykułów. W trakcie Biuro Legislacyjne zaproponowało wprowadzenie 20 poprawek redakcyjnych\ni legislacyjnych, które zarówno przez ministerstwo,\njak i członków obu komisji zostały przyjęte. W trakcie\nrozpatrywania poszczególnych artykułów poseł Sebastian Kaleta złożył wniosek mniejszości z propozycją skreślenia art. 8. dotyczącego zamówień publicznych.",
         "False",
         "[]",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Hypocrisy",
         "Appeal_to_Hypocrisy",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Appeal to Hypocrisy technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. There are no explicit or implicit references to contradictions between positions or actions, which are necessary for the Appeal to Hypocrisy technique to be present.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "['The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. There are no explicit or implicit references to contradictions between positions or actions, which are necessary for the Appeal to Hypocrisy technique to be present.']",
         "[None]",
         "[None]",
         "[ True]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/pl/train-pl-part_0007.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. There are no explicit or implicit references to contradictions between positions or actions, which are necessary for the Appeal to Hypocrisy technique to be present.\", \"verdict\": false}"
        ],
        [
         "35",
         "pl_abortion_11_04_2024_n05.txt",
         "9681",
         "10556",
         "PL",
         "Dziś jesteśmy w demograficznym kryzysie. Polki\nnie chcą rodzić dzieci w Polsce, która nie jest dla nich\nbezpieczna pod żadnym względem. Mówią: boję się\nbyć w ciąży, bo dziewczyny w moim wieku umierają.\nUmarły pan Iza, pani Agnieszka, pani Marta, pani\nDorota. Dlatego Koalicja Obywatelska przygotowała\ni przedstawia projekt ustawy o świadomym rodzicielstwie.\nZakaz aborcji w Polsce to restrykcyjne prawo,\nktóre zagraża zdrowiu, życiu i bezpieczeństwu kobiet,\na nasz projekt, projekt Koalicji Obywatelskiej,\nprzywraca kobietom wolność wyboru, przywraca kobietom\ngodność, przywraca kobietom podmiotowość. Zakłada\nmożliwość bezpiecznego i bezpłatnego przerywania\nciąży do 12 tygodnia jej trwania oraz po 12 tygodniu\nw określonych okolicznościach. Aborcja musi być\nbezpieczna, aborcja musi być legalna. Aborcja musi być\ndostępna, a kobieta musi być bezpieczna.\nDziękuję. (Oklaski)",
         "True",
         "['Conversation_Killer' 'Causal_Oversimplification' 'Slogans'\n 'Whataboutism' 'Appeal_to_Values' 'Repetition' 'Appeal_to_Fear-Prejudice']",
         "train",
         "[]",
         "[]",
         "[]",
         "['aborcja musi być legalna' 'Aborcja musi być dostępna']",
         "[]",
         "['przywraca kobietom wolność wyboru' 'przywraca kobietom godność'\n 'przywraca kobietom podmiotowość']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['zagraża zdrowiu, życiu i bezpieczeństwu kobiet']",
         "[]",
         "[]",
         "['Aborcja musi być bezpieczna, aborcja musi być legalna'\n 'Aborcja musi być dostępna, a kobieta musi być bezpieczna']",
         "['Mówią: boję się być w ciąży, bo dziewczyny w moim wieku umierają. Umarły pan Iza, pani Agnieszka, pani Marta, pani Dorota'\n 'Zakaz aborcji w Polsce to restrykcyjne prawo, które zagraża zdrowiu, życiu i bezpieczeństwu kobiet']",
         "['Polki nie chcą rodzić dzieci w Polsce, która nie jest dla nich bezpieczna pod żadnym względem']",
         "[]",
         "[]",
         "['Dziś jesteśmy w demograficznym kryzysie']",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Hypocrisy",
         "Appeal_to_Hypocrisy",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Appeal to Hypocrisy technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text discusses the issue of abortion and women\\'s rights without attacking the reputation of any specific individual or group by charging them with hypocrisy. It focuses on presenting a legislative proposal and the reasons behind it, rather than highlighting contradictions in the positions or actions of others.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "[\"The input text discusses the issue of abortion and women's rights without attacking the reputation of any specific individual or group by charging them with hypocrisy. It focuses on presenting a legislative proposal and the reasons behind it, rather than highlighting contradictions in the positions or actions of others.\"]",
         "[None]",
         "[None]",
         "[ True]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/pl/train-pl-part_0007.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text discusses the issue of abortion and women's rights without attacking the reputation of any specific individual or group by charging them with hypocrisy. It focuses on presenting a legislative proposal and the reasons behind it, rather than highlighting contradictions in the positions or actions of others.\", \"verdict\": false}"
        ],
        [
         "36",
         "pl_abortion_11_04_2024_n04.txt",
         "6500",
         "6777",
         "PL",
         "Natomiast trzecim elementem jest referendum.\nTego chcą Polki i Polacy, ponad 66%. Jest to rozwiązanie\nskuteczne. To jest rozwiązanie, do którego\nmusi zastosować się prezydent. To rozwiązanie\nzagwarantuje nam także pokój, bo to decyzja\nobywatelek i obywateli ma najgłębszy sens.",
         "True",
         "['Conversation_Killer' 'Appeal_to_Values' 'Appeal_to_Popularity']",
         "train",
         "[]",
         "[]",
         "[]",
         "['Jest to rozwiązanie skuteczne'\n 'To jest rozwiązanie, do którego musi zastosować się prezydent']",
         "[]",
         "[]",
         "['Natomiast trzecim elementem jest referendum. Tego chcą Polki i Polacy, ponad 66%. Jest to rozwiązanie skuteczne']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['To rozwiązanie zagwarantuje nam także pokój, bo to decyzja obywatelek i obywateli ma najgłębszy sens']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Hypocrisy",
         "Appeal_to_Hypocrisy",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Appeal to Hypocrisy technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. It focuses on the importance of a referendum without referencing any contradictions or past actions of individuals.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "['The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. It focuses on the importance of a referendum without referencing any contradictions or past actions of individuals.']",
         "[None]",
         "[None]",
         "[ True]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/pl/train-pl-part_0007.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. It focuses on the importance of a referendum without referencing any contradictions or past actions of individuals.\", \"verdict\": false}"
        ],
        [
         "37",
         "pl_current_affairs_09_01_2025_n02.txt",
         "7617",
         "7814",
         "PL",
         "Dzisiaj generalny dyrektor ochrony środowiska\nde facto powtórzył te argumenty, które były argumentami niepozostawiającymi żadnych wątpliwości.\n(Poseł Joanna Borowiak: Dlatego przegrał pan\nKurtyka.)",
         "True",
         "['Conversation_Killer' 'Appeal_to_Authority']",
         "train",
         "[]",
         "[]",
         "[]",
         "['które były argumentami niepozostawiającymi żadnych wątpliwości']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Dzisiaj generalny dyrektor ochrony środowiska de facto powtórzył te argumenty, które były argumentami niepozostawiającymi żadnych wątpliwości']",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Hypocrisy",
         "Appeal_to_Hypocrisy",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Appeal to Hypocrisy technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. There are no explicit or implicit references to contradictions between positions or actions, nor is there any mention of someone criticizing another for something they themselves have done.\",\\n  \"updated_definition\": \"The target of the technique is attacked on its reputation by charging them with hypocrisy or inconsistency, either explicitly by calling out hypocrisy directly, or implicitly by highlighting contradictions between different positions or actions. This includes instances where someone criticizes another for a behavior they themselves have exhibited.\"\\n}']",
         "['The target of the technique is attacked on its reputation by charging them with hypocrisy or inconsistency, either explicitly by calling out hypocrisy directly, or implicitly by highlighting contradictions between different positions or actions. This includes instances where someone criticizes another for a behavior they themselves have exhibited.']",
         "[None]",
         "[None]",
         "['The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. There are no explicit or implicit references to contradictions between positions or actions, nor is there any mention of someone criticizing another for something they themselves have done.']",
         "[None]",
         "[None]",
         "[ True]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/pl/train-pl-part_0007.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. There are no explicit or implicit references to contradictions between positions or actions, nor is there any mention of someone criticizing another for something they themselves have done.\", \"verdict\": false}"
        ],
        [
         "38",
         "pl_abortion_11_04_2024_n05.txt",
         "0",
         "364",
         "PL",
         "Poseł Urszula Pasławska:\nSzanowny Panie Marszałku! Wysoka Izbo! Polacy\n15 października zagłosowali na nas, prosili nas o to,\nżebyśmy rządzili skutecznie. Dlatego dzisiaj jako\nTrzecia Droga przedstawiamy projekt ustawy, który\nskutecznie rozwiąże problem terminacji ciąży,\nponieważ jako jedyny ma szansę zarówno na poparcie\nprawej strony, jak i na podpis prezydenta.",
         "True",
         "['Appeal_to_Authority']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['jako jedyny ma szansę zarówno na poparcie prawej strony, jak i na podpis prezydenta']",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Hypocrisy",
         "Appeal_to_Hypocrisy",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Appeal to Hypocrisy technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. There are no explicit or implicit references to contradictions between positions or actions, nor is there any mention of someone criticizing another for something they themselves have done. Therefore, the Appeal to Hypocrisy technique is not used.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "['The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. There are no explicit or implicit references to contradictions between positions or actions, nor is there any mention of someone criticizing another for something they themselves have done. Therefore, the Appeal to Hypocrisy technique is not used.']",
         "[None]",
         "[None]",
         "[ True]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/pl/train-pl-part_0007.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. There are no explicit or implicit references to contradictions between positions or actions, nor is there any mention of someone criticizing another for something they themselves have done. Therefore, the Appeal to Hypocrisy technique is not used.\", \"verdict\": false}"
        ],
        [
         "39",
         "pl_abortion_11_04_2024_n05.txt",
         "7984",
         "9130",
         "PL",
         "I jeszcze heroizm. Obowiązujące prawo w Polsce\nzmusza kobiety do heroizmu. Dziś w Polsce ciążę\nprowadzą prokurator, polityk i ksiądz. Dziś ciążę w\nPolsce prowadzą ideologia, zabobony i religia. W 2016 r.\nJarosław Kaczyński zapowiedział, że będą dążyli do\ntego, by nawet przypadki ciąż bardzo trudnych,\nkiedy dziecko jest skazane na śmierć, mocno\nzdeformowane, kończyły się jednak porodem, by to dziecko\nmogło być ochrzczone, pochowane, miało imię i było\nokrutnym początkiem. Czarę goryczy przelał wyrok\nTrybunału Konstytucyjnego Julii Przyłębskiej. I to,\nco się wydarzyło, jest czarnym scenariuszem, który\nwłaśnie się cały czas realizuje. To był impuls do\ndziałania polityków PiS-u, Konfederacji i\nultrakonserwatywnych fundamentalistów, dla których\nnajważniejsze to urodzić. Nieważne, czy dziecko z gwałtu, czy\ndziecko z niepełnosprawnością, która zakończy jego\nżycie w cierpieniach, nie ważne, czy płód jest martwy\ni czy przy okazji trudnego porodu umrze matka.\nNajważniejsze to urodzić. Scenariusz, o którym mówię\njest scenariuszem dramatycznego filmu opartego na\nfaktach, w którym dochodzi do rzeczywistych\ntragedii, bo umierają młode kobiety.",
         "True",
         "['Exaggeration-Minimisation' 'Loaded_Language' 'Appeal_to_Pity'\n 'Name_Calling-Labeling' 'Straw_Man' 'Repetition'\n 'Appeal_to_Fear-Prejudice']",
         "train",
         "[]",
         "['ultrakonserwatywnych fundamentalistów']",
         "[]",
         "[]",
         "['skazane na śmierć' 'mocno zdeformowane' 'okrutnym' 'Czarę goryczy'\n 'czarnym scenariuszem']",
         "['Dziś w Polsce ciążę prowadzą' 'Dziś ciążę w Polsce prowadzą']",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Obowiązujące prawo w Polsce zmusza kobiety do heroizmu'\n 'Dziś w Polsce ciążę prowadzą prokurator, polityk i ksiądz'\n 'Dziś ciążę w Polsce prowadzą ideologia, zabobony i religia'\n 'I to, co się wydarzyło, jest czarnym scenariuszem, który właśnie się cały czas realizuje']",
         "[]",
         "['Nieważne, czy dziecko z gwałtu, czy dziecko z niepełnosprawnością, która zakończy jego życie w cierpieniach, nie ważne, czy płód jest martwy i czy przy okazji trudnego porodu umrze matka']",
         "[]",
         "[]",
         "[]",
         "['To był impuls do działania polityków PiS-u, Konfederacji i ultrakonserwatywnych fundamentalistów, dla których najważniejsze to urodzić'\n 'Najważniejsze to urodzić']",
         "[]",
         "['by nawet przypadki ciąż bardzo trudnych, kiedy dziecko jest skazane na śmierć, mocno zdeformowane, kończyły się jednak porodem'\n 'przy okazji trudnego porodu umrze matka'\n 'dochodzi do rzeczywistych tragedii, bo umierają młode kobiety']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Hypocrisy",
         "Appeal_to_Hypocrisy",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Appeal to Hypocrisy technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text discusses the harsh realities of pregnancy laws in Poland and criticizes the positions of certain political figures and ideologies. However, it does not explicitly attack the reputation of any individual by charging them with hypocrisy or inconsistency. There are no instances where the author points out contradictions between past actions or positions of the critics, which is a key aspect of the Appeal to Hypocrisy technique.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "['The input text discusses the harsh realities of pregnancy laws in Poland and criticizes the positions of certain political figures and ideologies. However, it does not explicitly attack the reputation of any individual by charging them with hypocrisy or inconsistency. There are no instances where the author points out contradictions between past actions or positions of the critics, which is a key aspect of the Appeal to Hypocrisy technique.']",
         "[None]",
         "[None]",
         "[ True]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/pl/train-pl-part_0007.parquet",
         null,
         null,
         "train",
         "{\"description\": \"The input text discusses the harsh realities of pregnancy laws in Poland and criticizes the positions of certain political figures and ideologies. However, it does not explicitly attack the reputation of any individual by charging them with hypocrisy or inconsistency. There are no instances where the author points out contradictions between past actions or positions of the critics, which is a key aspect of the Appeal to Hypocrisy technique.\", \"verdict\": false}"
        ],
        [
         "40",
         "pl_abortion_11_04_2024_n08.txt",
         "150",
         "288",
         "PL",
         "Wicemarszałek Monika Wielichowska:\nSam pan wywołał reakcję pań, które znajdują się na\ngalerii. Proszę kontynuować. (Gwar na sali, dzwonek)",
         "True",
         "['Questioning_the_Reputation']",
         "train",
         "['Sam pan wywołał reakcję pań, które znajdują się na galerii']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Hypocrisy",
         "Appeal_to_Hypocrisy",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Appeal to Hypocrisy technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. There are no explicit or implicit references to contradictions or past actions that would qualify as an Appeal to Hypocrisy.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "['The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. There are no explicit or implicit references to contradictions or past actions that would qualify as an Appeal to Hypocrisy.']",
         "[None]",
         "[None]",
         "[ True]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/pl/train-pl-part_0002.parquet",
         "[None]",
         "[None]",
         "train",
         "{\"description\": \"The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. There are no explicit or implicit references to contradictions or past actions that would qualify as an Appeal to Hypocrisy.\", \"verdict\": false}"
        ],
        [
         "41",
         "pl_abortion_11_04_2024_n04.txt",
         "1320",
         "1701",
         "PL",
         "Zakaz aborcji w Polsce nie działa i wiedzą o tym\ndoskonale pomagające w aborcjach aktywistki i\nprzedstawicielki organizacji pozarządowych, które są tutaj\ndziś z nami. Nie wiem, czy wszystkie, bo nie wszystkie\notrzymały dziś rano zgodę od marszałka Hołowni\nna wejście na galerię. Podobno powodem są jakieś\nlimity, limity w otwartości i w uśmiechu.\nPierwsze słyszę, ale się zdarzyło.",
         "True",
         "['Conversation_Killer' 'Appeal_to_Pity' 'Repetition']",
         "train",
         "[]",
         "[]",
         "[]",
         "['Zakaz aborcji w Polsce nie działa']",
         "[]",
         "['Zakaz aborcji w Polsce nie działa']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Podobno powodem są jakieś limity, limity w otwartości i w uśmiechu']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Hypocrisy",
         "Appeal_to_Hypocrisy",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Appeal to Hypocrisy technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. There are no explicit or implicit references to contradictions between positions or actions that would qualify as an Appeal to Hypocrisy.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "['The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. There are no explicit or implicit references to contradictions between positions or actions that would qualify as an Appeal to Hypocrisy.']",
         "[None]",
         "[None]",
         "[ True]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/pl/train-pl-part_0002.parquet",
         "[None]",
         "[None]",
         "train",
         "{\"description\": \"The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. There are no explicit or implicit references to contradictions between positions or actions that would qualify as an Appeal to Hypocrisy.\", \"verdict\": false}"
        ],
        [
         "42",
         "pl_defence_22_05_2024_n01.txt",
         "8339",
         "10002",
         "PL",
         "Proszę państwa, jeśli chodzi o te zakupy, to one\nwszystkie były konsultowane, były wynikiem naszych rozmów w Radzie Modernizacji Technicznej\nz przeważającym, decydującym głosem Sztabu Generalnego Wojska Polskiego. Zmieniłem sposób zamawiania sprzętu wojskowego dla polskiego wojska,\nbo on był sprzeczny wewnętrznie. To była sytuacja,\nw której nie można było pójść naprzód, więc udrożniłem te procesy. Potem, kiedy przyszedł rok 2022,\nkiedy po raz kolejny Rosja napadła na Ukrainę, nawiązałem relacje z Koreą Południową. Dlaczego to\nzrobiłem? Dlatego że Korea Południowa posiada olbrzymi potencjał produkcyjny, jeśli chodzi o przemysł\nzbrojeniowy. Uważam za jeden z naszych sukcesów\nto, że w tak krótkim czasie doprowadziliśmy do tego,\nże w Wojsku Polskim już są czołgi K2, że obok\nHIMARS-ów, o których powiedziałem, są Chunmoo,\nczyli artyleria rakietowa o zasięgu do 300 km, że są\nsamoloty szkolno-bojowe FA-50. Pan powiedział, że\npiloci tak dużo zarabiają. Trzeba szkolić pilotów.\nFA-50 zostały zaprojektowane przez Lockheed Martin, a więc są taką mniejszą, to prawda, wersją\nF-16. W Wojsku Polskim, kiedy przyszliśmy do\nwładzy, w zasadzie tylko F-16 stanowiły jakąś siłę\nbojową. Pozostały sprzęt wojskowy był postsowiecki,\nbył zużyty. To był obraz nędzy i rozpaczy, a my doprowadziliśmy do tego, że dziś Wojsko Polskie liczy\nponad 200 tys. żołnierzy. Tylko jeszcze cele… Też\npan o tym nie wspomniał. Co najmniej 300 tys. żołnierzy. Można powiedzieć, że 300 tys. żołnierzy wojsk\noperacyjnych i 50 tys. żołnierzy Wojsk Obrony Terytorialnej – to powinien być nasz wspólny cel, mówię\no państwie polskim (Oklaski), bo w ten sposób możemy realnie odstraszyć agresora.",
         "True",
         "['Loaded_Language' 'Flag_Waving' 'Obfuscation-Vagueness-Confusion'\n 'Appeal_to_Authority' 'Name_Calling-Labeling' 'Red_Herring'\n 'Appeal_to_Fear-Prejudice']",
         "train",
         "[]",
         "['postsowiecki']",
         "[]",
         "[]",
         "['obraz nędzy i rozpaczy']",
         "[]",
         "[]",
         "[]",
         "['Pan powiedział, że piloci tak dużo zarabiają']",
         "['mówię o państwie polskim']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['To była sytuacja, w której nie można było pójść naprzód, więc udrożniłem te procesy']",
         "[]",
         "[]",
         "['realnie odstraszyć agresora']",
         "[]",
         "['jeśli chodzi o te zakupy, to one wszystkie były konsultowane, były wynikiem naszych rozmów w Radzie Modernizacji Technicznej z przeważającym, decydującym głosem Sztabu Generalnego Wojska Polskiego']",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Hypocrisy",
         "Appeal_to_Hypocrisy",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Appeal to Hypocrisy technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not contain any instances of attacking the reputation of a target by charging them with hypocrisy or inconsistency. There are no explicit or implicit references to contradictions in positions or actions that would qualify as an Appeal to Hypocrisy.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "['The input text does not contain any instances of attacking the reputation of a target by charging them with hypocrisy or inconsistency. There are no explicit or implicit references to contradictions in positions or actions that would qualify as an Appeal to Hypocrisy.']",
         "[None]",
         "[None]",
         "[ True]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/pl/train-pl-part_0002.parquet",
         "[None]",
         "[None]",
         "train",
         "{\"description\": \"The input text does not contain any instances of attacking the reputation of a target by charging them with hypocrisy or inconsistency. There are no explicit or implicit references to contradictions in positions or actions that would qualify as an Appeal to Hypocrisy.\", \"verdict\": false}"
        ],
        [
         "43",
         "pl_abortion_11_04_2024_n03.txt",
         "1839",
         "2256",
         "PL",
         "Mam dzisiaj zaszczyt i przyjemność jako posłanka\nklubu parlamentarnego Lewicy i wnioskodawczyni\nprojektu o bezpiecznym przerywaniu ciąży\nprzedstawić państwu projekt, który jest oparty na trosce i\nempatii w stosunku do kobiet, które po 30 latach\nobowiązywania zakazu aborcji muszą w końcu odzyskać\nodebrane im wiele lat temu prawo do podejmowania\nsamodzielnych decyzji w sprawie macierzyństwa,\nswojego zdrowia i życia.",
         "True",
         "['Appeal_to_Time' 'Appeal_to_Pity' 'Appeal_to_Values']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['po 30 latach obowiązywania zakazu aborcji muszą w końcu odzyskać odebrane im wiele lat temu prawo do podejmowania samodzielnych decyzji w sprawie macierzyństwa, swojego zdrowia i życia']",
         "['po 30 latach obowiązywania zakazu aborcji muszą w końcu odzyskać odebrane im wiele lat temu prawo']",
         "['który jest oparty na trosce i empatii w stosunku do kobiet'\n 'muszą w końcu odzyskać odebrane im wiele lat temu prawo do podejmowania samodzielnych decyzji w sprawie macierzyństwa, swojego zdrowia i życia']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Hypocrisy",
         "Appeal_to_Hypocrisy",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Appeal to Hypocrisy technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. It focuses on advocating for women\\'s rights without referencing any contradictions or past actions of others.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "[\"The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. It focuses on advocating for women's rights without referencing any contradictions or past actions of others.\"]",
         "[None]",
         "[None]",
         "[ True]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/pl/train-pl-part_0002.parquet",
         "[None]",
         "[None]",
         "train",
         "{\"description\": \"The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. It focuses on advocating for women's rights without referencing any contradictions or past actions of others.\", \"verdict\": false}"
        ],
        [
         "44",
         "pl_current_affairs_09_01_2025_n01.txt",
         "1187",
         "2227",
         "PL",
         "Poseł Maria Koc:\nDziękuję, panie marszałku.\nSzanowny Panie Marszałku! Szanowna Pani Minister! Wysoka Izbo! Jedną ze sztandarowych obietnic złożonych w trakcie kampanii wyborczej w 2023 r.\nprzez Koalicję Obywatelską, przez pana Donalda\nTuska była obietnica wprowadzenia w ciągu pierwszych 100 dni rządów tzw. świadczenia babciowego.\nTo pieniądze dla rodziców na zapewnienie opieki nad\nmałymi dziećmi, po to aby ci rodzice mogli wrócić na\nrynek pracy. Nie udało się koalicji rządzącej wprowadzić tego świadczenia w życie w ciągu pierwszych\n100 dni rządów, ale jesienią ta ustawa weszła w życie.\nOd 1 października 2024 r. rodzice mogli już składać\nwnioski do ZUS-u i wielu rodziców takie wnioski złożyło. Były opóźnienia w wypłatach, rodzice komunikowali się z ZUS-em, ZUS zapewniał, że wszystkie\nświadczenia, łącznie z wyrównaniami od 1 października, zostaną wypłacone rodzicom do dnia 20 grudnia. Niestety mamy rok 2025 i media ogólnopolskie\ndonoszą, że wielu rodziców nadal nie otrzymało tego\nświadczenia, mimo że składali wnioski w 2024 r.",
         "True",
         "['Doubt']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Niestety mamy rok 2025 i media ogólnopolskie donoszą, że wielu rodziców nadal nie otrzymało tego świadczenia, mimo że składali wnioski w 2024 r']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Hypocrisy",
         "Appeal_to_Hypocrisy",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Appeal to Hypocrisy technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. There are no explicit or implicit references to contradictions between past actions or positions held by the individuals mentioned. Therefore, the Appeal to Hypocrisy technique is not used.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "['The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. There are no explicit or implicit references to contradictions between past actions or positions held by the individuals mentioned. Therefore, the Appeal to Hypocrisy technique is not used.']",
         "[None]",
         "[None]",
         "[ True]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/pl/train-pl-part_0002.parquet",
         "[None]",
         "[None]",
         "train",
         "{\"description\": \"The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. There are no explicit or implicit references to contradictions between past actions or positions held by the individuals mentioned. Therefore, the Appeal to Hypocrisy technique is not used.\", \"verdict\": false}"
        ],
        [
         "45",
         "pl_abortion_11_04_2024_n07.txt",
         "7843",
         "8354",
         "PL",
         "Tytuł projektu Lewicy sugeruje, że aborcja może być\nbezpieczna, tymczasem sami projektodawcy w\nuzasadnieniu projektu podają, że od dnia wydania wyroku\nTrybunału Konstytucyjnego w 2020 r. tylko jedna z\norganizacji proaborcyjnych pomagała w aborcji w\nprzypadku 125 tys. kobiet, co oznacza, że co najmniej tyle\nsamo dzieci w wyniku aborcji straciło życie.\nProjektowane przepisy uderzają w podstawowe prawo każdego\nczłowieka, są całkowicie nieakceptowalne i powinny\nbyć odrzucone już w pierwszym czytaniu. (Oklaski)",
         "True",
         "['Conversation_Killer' 'Appeal_to_Hypocrisy' 'Appeal_to_Values']",
         "train",
         "[]",
         "[]",
         "['Tytuł projektu Lewicy sugeruje, że aborcja może być bezpieczna, tymczasem sami projektodawcy w uzasadnieniu projektu podają, że od dnia wydania wyroku Trybunału Konstytucyjnego w 2020 r. tylko jedna z organizacji proaborcyjnych pomagała w aborcji w przypadku 125 tys. kobiet, co oznacza, że co najmniej tyle samo dzieci w wyniku aborcji straciło życie']",
         "['są całkowicie nieakceptowalne i powinny być odrzucone już w pierwszym czytaniu']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Projektowane przepisy uderzają w podstawowe prawo każdego człowieka']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Hypocrisy",
         "Appeal_to_Hypocrisy",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "1",
         "Yes, the Appeal to Hypocrisy technique is used in the input.",
         "\"Tytuł projektu Lewicy sugeruje, że aborcja może być bezpieczna, tymczasem sami projektodawcy w uzasadnieniu projektu podają, że od dnia wydania wyroku Trybunału Konstytucyjnego w 2020 r. tylko jedna z organizacji proaborcyjnych pomagała w aborcji w przypadku 125 tys. kobiet, co oznacza, że co najmniej tyle samo dzieci w wyniku aborcji straciło życie\"",
         "['{\\n  \"explanation\": \"The Appeal to Hypocrisy technique is used in the input text by highlighting the inconsistency between the claim that abortion can be safe and the evidence presented that only one organization has helped a limited number of women, implying that the proponents of the project are not acting in accordance with their stated beliefs. This directly points out the hypocrisy in their position.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "['The Appeal to Hypocrisy technique is used in the input text by highlighting the inconsistency between the claim that abortion can be safe and the evidence presented that only one organization has helped a limited number of women, implying that the proponents of the project are not acting in accordance with their stated beliefs. This directly points out the hypocrisy in their position.']",
         "[None]",
         "[None]",
         "[ True]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/pl/train-pl-part_0002.parquet",
         "[None]",
         "[None]",
         "train",
         "{\"description\": \"The Appeal to Hypocrisy technique is used in the input text by highlighting the inconsistency between the claim that abortion can be safe and the evidence presented that only one organization has helped a limited number of women, implying that the proponents of the project are not acting in accordance with their stated beliefs. This directly points out the hypocrisy in their position.\", \"verdict\": true}"
        ],
        [
         "46",
         "pl_abortion_11_04_2024_n06.txt",
         "7874",
         "8360",
         "PL",
         "Jeszcze żaden zakaz aborcji nie zlikwidował aborcji.\nTa debata, szanowni państwo, nie jest o waszych\nsumieniach, jest o nas, o kobietach, o naszym zdrowiu,\no naszym życiu, o naszej godności. Więc proszę\nwas, abyście nie kazali nam być zakładnikami waszej\nwiary albo jej braku, waszych sumień i waszych poglądów.\nProszę was o to, abyście nam, kobietom, po\nprostu zaufali. Uwierzcie, że jesteśmy mądre, że\nmożemy podejmować decyzje i że te decyzje są najlepsze dla nas. Dziękuję. (Oklaski",
         "True",
         "['Conversation_Killer' 'Flag_Waving' 'Appeal_to_Pity']",
         "train",
         "[]",
         "[]",
         "[]",
         "['Jeszcze żaden zakaz aborcji nie zlikwidował aborcji']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Ta debata, szanowni państwo, nie jest o waszych sumieniach, jest o nas, o kobietach, o naszym zdrowiu, o naszym życiu, o naszej godności'\n 'Proszę was o to, abyście nam, kobietom, po prostu zaufali. Uwierzcie, że jesteśmy mądre, że możemy podejmować decyzje i że te decyzje są najlepsze dla nas']",
         "[]",
         "[]",
         "['Więc proszę was, abyście nie kazali nam być zakładnikami waszej wiary albo jej braku, waszych sumień i waszych poglądów']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Hypocrisy",
         "Appeal_to_Hypocrisy",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Appeal to Hypocrisy technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not contain any elements that attack the reputation of the audience by charging them with hypocrisy or inconsistency. It focuses on advocating for women\\'s rights and autonomy without referencing any past actions or positions of the audience that would imply hypocrisy.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "[\"The input text does not contain any elements that attack the reputation of the audience by charging them with hypocrisy or inconsistency. It focuses on advocating for women's rights and autonomy without referencing any past actions or positions of the audience that would imply hypocrisy.\"]",
         "[None]",
         "[None]",
         "[ True]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/pl/train-pl-part_0002.parquet",
         "[None]",
         "[None]",
         "train",
         "{\"description\": \"The input text does not contain any elements that attack the reputation of the audience by charging them with hypocrisy or inconsistency. It focuses on advocating for women's rights and autonomy without referencing any past actions or positions of the audience that would imply hypocrisy.\", \"verdict\": false}"
        ],
        [
         "47",
         "pl_current_affairs_09_01_2025_n01.txt",
         "4848",
         "5376",
         "PL",
         "Dzięki zastosowaniu automatycznego programowania od startu programu do końca grudnia 2024 r.\nrozpatrzono ponad 80% wniosków złożonych w tym\nokresie, pomimo że w październiku, co było naturalne, doszło do spiętrzenia wpływu wniosków z uwagi\nna to, że złożyli je rodzice dzieci z trzech roczników:\n2021–2023. W okresie od 1 października do 31 grudnia ZUS wypłacił łącznie 558 685 świadczeń na kwotę 670 279 596,83 zł. Nadal trwa rozpatrywanie wniosków z okresu, w którym konieczne jest przeprowadzenie postępowania wyjaśniającego.",
         "False",
         "[]",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Hypocrisy",
         "Appeal_to_Hypocrisy",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Appeal to Hypocrisy technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. There are no explicit or implicit references to contradictions between positions or actions, nor is there any mention of someone criticizing another for actions they themselves have taken in the past.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "['The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. There are no explicit or implicit references to contradictions between positions or actions, nor is there any mention of someone criticizing another for actions they themselves have taken in the past.']",
         "[None]",
         "[None]",
         "[ True]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/pl/train-pl-part_0002.parquet",
         "[None]",
         "[None]",
         "train",
         "{\"description\": \"The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. There are no explicit or implicit references to contradictions between positions or actions, nor is there any mention of someone criticizing another for actions they themselves have taken in the past.\", \"verdict\": false}"
        ],
        [
         "48",
         "pl_abortion_11_04_2024_n08.txt",
         "290",
         "1251",
         "PL",
         "Poseł Roman Fritz:\nGrupa feministek pomagająca mordować\nnienarodzone dzieci, Aborcyjny Dream Team, pochwaliła\nsię mniej więcej 2 lata temu, że pomogła zabić\ndziecko gotowe do porodu. Jego matka była w 37. tygodniu\nciąży. Feministki przyznają, że pomaganie w\naborcjach jest ich życiową pasją i misją, a za cel obrały\nsobie promowanie pozytywnego przekazu\ndotyczącego aborcji. Za pośrednictwem mediów\nspołecznościowych co jakiś czas Aborcyjny Dream Team chwali się\nswoimi morderczymi osiągnięciami. Uruchomiona\nprzez nich infolinia umożliwia konsultacje aborcyjne\ni zamawianie tabletek poronnych oraz umawianie\nwyjazdów na zabicie dziecka za granicami Polski.\nAborcjonistki przyznały również, że preferowaną metodą\nzabicia dziecka w tak zaawansowanym stadium\nrozwoju jest rozszerzenie szyjki macicy umożliwiające\nwydobycie go narzędziami, a wcześniej podanie\nbezbronnemu dziecku morderczego zastrzyku, który\nzatrzymuje akcję serca.\n(Poseł Krzysztof Bosak: Hańba!)",
         "True",
         "['Loaded_Language' 'Slogans' 'Questioning_the_Reputation'\n 'Name_Calling-Labeling' 'Appeal_to_Fear-Prejudice']",
         "train",
         "['Grupa feministek pomagająca mordować nienarodzone dzieci, Aborcyjny Dream Team, pochwaliła się mniej więcej 2 lata temu, że pomogła zabić dziecko gotowe do porodu'\n 'Feministki przyznają, że pomaganie w aborcjach jest ich życiową pasją i misją, a za cel obrały sobie promowanie pozytywnego przekazu dotyczącego aborcji'\n 'Aborcyjny Dream Team chwali się swoimi morderczymi osiągnięciami']",
         "['Aborcyjny Dream Team' 'Aborcyjny Dream Team' 'morderczymi']",
         "[]",
         "[]",
         "['pomagająca mordować nienarodzone dzieci' 'pomogła zabić dziecko'\n 'jest ich życiową pasją i misją' 'zabicie dziecka' 'zabicia'\n 'morderczego']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Hańba!)']",
         "['preferowaną metodą zabicia dziecka w tak zaawansowanym stadium rozwoju jest rozszerzenie szyjki macicy umożliwiające wydobycie go narzędziami, a wcześniej podanie bezbronnemu dziecku morderczego zastrzyku, który zatrzymuje akcję serca']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Hypocrisy",
         "Appeal_to_Hypocrisy",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Appeal to Hypocrisy technique is not used in the input.",
         "\"\"",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[ True]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/pl/train-pl-part_0002.parquet",
         "[{'code': 'content_filter', 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': True, 'severity': 'high'}, 'jailbreak': {'detected': False, 'filtered': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}, 'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'param': 'prompt', 'status': 400.0, 'type': None}]",
         "['no validation']",
         "train",
         "{\"description\": null, \"verdict\": false}"
        ],
        [
         "49",
         "pl_defence_22_05_2024_n02.txt",
         "1681",
         "1905",
         "PL",
         "Nie mamy też rezerw. Armia polska jest\nmobilizowana na czas wojny. Niestety nie mamy kogo\nmobilizować. Przeciętny wiek polskiego rezerwisty wynosi 50 lat.\nZanim pośle się żołnierza do wojny...\n(Poseł Piotr Kaleta: Na wojnę.)",
         "True",
         "['Doubt']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Nie mamy też rezerw. Armia polska jest mobilizowana na czas wojny. Niestety nie mamy kogo mobilizować. Przeciętny wiek polskiego rezerwisty wynosi 50 lat']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Hypocrisy",
         "Appeal_to_Hypocrisy",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Appeal to Hypocrisy technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. There are no explicit or implicit references to contradictions between positions or actions, nor is there any mention of someone criticizing another for a past action they themselves have done.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "['The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. There are no explicit or implicit references to contradictions between positions or actions, nor is there any mention of someone criticizing another for a past action they themselves have done.']",
         "[None]",
         "[None]",
         "[ True]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/pl/train-pl-part_0002.parquet",
         "[None]",
         "[None]",
         "train",
         "{\"description\": \"The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. There are no explicit or implicit references to contradictions between positions or actions, nor is there any mention of someone criticizing another for a past action they themselves have done.\", \"verdict\": false}"
        ]
       ],
       "shape": {
        "columns": 60,
        "rows": 1880
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>text_lang</th>\n",
       "      <th>text</th>\n",
       "      <th>label_bin</th>\n",
       "      <th>label_multi</th>\n",
       "      <th>base_split</th>\n",
       "      <th>Questioning_the_Reputation</th>\n",
       "      <th>Name_Calling-Labeling</th>\n",
       "      <th>...</th>\n",
       "      <th>extra_content</th>\n",
       "      <th>explanation</th>\n",
       "      <th>illegal_value</th>\n",
       "      <th>think_content</th>\n",
       "      <th>is_valid</th>\n",
       "      <th>source_file</th>\n",
       "      <th>error</th>\n",
       "      <th>status</th>\n",
       "      <th>split</th>\n",
       "      <th>expected_output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pl_eu_12_06_2024_n01.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>135</td>\n",
       "      <td>PL</td>\n",
       "      <td>Wicemarszałek Włodzimierz Czarzasty:\\nBardzo p...</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>train</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[The input text does not contain any elements ...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[True]</td>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41/v001...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "      <td>{\"description\": \"The input text does not conta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pl_defence_22_05_2024_n01.txt</td>\n",
       "      <td>3608</td>\n",
       "      <td>3857</td>\n",
       "      <td>PL</td>\n",
       "      <td>Pan wspominał o ABCS – Integrated Battle Comma...</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>train</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[The input text does not contain any elements ...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[True]</td>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41/v001...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "      <td>{\"description\": \"The input text does not conta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pl_current_affairs_09_01_2025_n03.txt</td>\n",
       "      <td>1808</td>\n",
       "      <td>1984</td>\n",
       "      <td>PL</td>\n",
       "      <td>(Poseł Anna Gembicka: Decyzja została zmienion...</td>\n",
       "      <td>True</td>\n",
       "      <td>[Repetition]</td>\n",
       "      <td>train</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[The Appeal to Hypocrisy technique was not use...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[True]</td>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41/v001...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "      <td>{\"description\": \"The Appeal to Hypocrisy techn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pl_abortion_11_04_2024_n08.txt</td>\n",
       "      <td>2952</td>\n",
       "      <td>3136</td>\n",
       "      <td>PL</td>\n",
       "      <td>Czy czas najwyższy, by w końcu dopuścić\\ndekry...</td>\n",
       "      <td>True</td>\n",
       "      <td>[False_Equivalence, Loaded_Language, Whatabout...</td>\n",
       "      <td>train</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[The input text does not contain any elements ...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[True]</td>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41/v001...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "      <td>{\"description\": \"The input text does not conta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pl_eu_12_06_2024_n01.txt</td>\n",
       "      <td>1277</td>\n",
       "      <td>2304</td>\n",
       "      <td>PL</td>\n",
       "      <td>Prezentowany na posiedzeniu projekt ustawy, op...</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>train</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[The input text discusses a proposed law aimed...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[True]</td>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41/v001...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "      <td>{\"description\": \"The input text discusses a pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1875</th>\n",
       "      <td>20231208_URW_BG_71.txt</td>\n",
       "      <td>3950</td>\n",
       "      <td>3965</td>\n",
       "      <td>BG</td>\n",
       "      <td>Има ли реплика?</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>train</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[The input text does not contain any elements ...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[True]</td>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41/v001...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "      <td>{\"description\": \"The input text does not conta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1876</th>\n",
       "      <td>20231208_URW_BG_76.txt</td>\n",
       "      <td>1541</td>\n",
       "      <td>1938</td>\n",
       "      <td>BG</td>\n",
       "      <td>Най-интересното е, че в т. 7 пише, цитирам, че...</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>train</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[The input text does not employ the Casting Do...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[True]</td>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41/v001...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "      <td>{\"description\": \"The input text does not emplo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1877</th>\n",
       "      <td>20240704_URW_BG_25.txt</td>\n",
       "      <td>4841</td>\n",
       "      <td>5237</td>\n",
       "      <td>BG</td>\n",
       "      <td>и, предлагам това заседание, госпожо Председат...</td>\n",
       "      <td>True</td>\n",
       "      <td>[Appeal_to_Hypocrisy, Loaded_Language]</td>\n",
       "      <td>train</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[The input text does not contain any elements ...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[True]</td>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41/v001...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "      <td>{\"description\": \"The input text does not conta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1878</th>\n",
       "      <td>20240704_URW_BG_25.txt</td>\n",
       "      <td>1179</td>\n",
       "      <td>1237</td>\n",
       "      <td>BG</td>\n",
       "      <td>АВ РИБАРСКИ (ПП-ДБ): Благодаря, госпожо Предсе...</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>train</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[The input text does not contain any elements ...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[True]</td>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41/v001...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "      <td>{\"description\": \"The input text does not conta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1879</th>\n",
       "      <td>trail_raw_BG_7.txt</td>\n",
       "      <td>51</td>\n",
       "      <td>113</td>\n",
       "      <td>BG</td>\n",
       "      <td>АНИСЛАВ БАЛАБАНОВ (ИТН): Господин Председател,...</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>train</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[The input text does not contain any elements ...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[True]</td>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41/v001...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "      <td>{\"description\": \"The input text does not conta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1880 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   filename  start   end text_lang  \\\n",
       "0                  pl_eu_12_06_2024_n01.txt      0   135        PL   \n",
       "1             pl_defence_22_05_2024_n01.txt   3608  3857        PL   \n",
       "2     pl_current_affairs_09_01_2025_n03.txt   1808  1984        PL   \n",
       "3            pl_abortion_11_04_2024_n08.txt   2952  3136        PL   \n",
       "4                  pl_eu_12_06_2024_n01.txt   1277  2304        PL   \n",
       "...                                     ...    ...   ...       ...   \n",
       "1875                 20231208_URW_BG_71.txt   3950  3965        BG   \n",
       "1876                 20231208_URW_BG_76.txt   1541  1938        BG   \n",
       "1877                 20240704_URW_BG_25.txt   4841  5237        BG   \n",
       "1878                 20240704_URW_BG_25.txt   1179  1237        BG   \n",
       "1879                     trail_raw_BG_7.txt     51   113        BG   \n",
       "\n",
       "                                                   text  label_bin  \\\n",
       "0     Wicemarszałek Włodzimierz Czarzasty:\\nBardzo p...      False   \n",
       "1     Pan wspominał o ABCS – Integrated Battle Comma...      False   \n",
       "2     (Poseł Anna Gembicka: Decyzja została zmienion...       True   \n",
       "3     Czy czas najwyższy, by w końcu dopuścić\\ndekry...       True   \n",
       "4     Prezentowany na posiedzeniu projekt ustawy, op...      False   \n",
       "...                                                 ...        ...   \n",
       "1875                                    Има ли реплика?      False   \n",
       "1876  Най-интересното е, че в т. 7 пише, цитирам, че...      False   \n",
       "1877  и, предлагам това заседание, госпожо Председат...       True   \n",
       "1878  АВ РИБАРСКИ (ПП-ДБ): Благодаря, госпожо Предсе...      False   \n",
       "1879  АНИСЛАВ БАЛАБАНОВ (ИТН): Господин Председател,...      False   \n",
       "\n",
       "                                            label_multi base_split  \\\n",
       "0                                                    []      train   \n",
       "1                                                    []      train   \n",
       "2                                          [Repetition]      train   \n",
       "3     [False_Equivalence, Loaded_Language, Whatabout...      train   \n",
       "4                                                    []      train   \n",
       "...                                                 ...        ...   \n",
       "1875                                                 []      train   \n",
       "1876                                                 []      train   \n",
       "1877             [Appeal_to_Hypocrisy, Loaded_Language]      train   \n",
       "1878                                                 []      train   \n",
       "1879                                                 []      train   \n",
       "\n",
       "     Questioning_the_Reputation Name_Calling-Labeling  ... extra_content  \\\n",
       "0                            []                    []  ...        [None]   \n",
       "1                            []                    []  ...        [None]   \n",
       "2                            []                    []  ...        [None]   \n",
       "3                            []                    []  ...        [None]   \n",
       "4                            []                    []  ...        [None]   \n",
       "...                         ...                   ...  ...           ...   \n",
       "1875                         []                    []  ...        [None]   \n",
       "1876                         []                    []  ...        [None]   \n",
       "1877                         []                    []  ...        [None]   \n",
       "1878                         []                    []  ...        [None]   \n",
       "1879                         []                    []  ...        [None]   \n",
       "\n",
       "                                            explanation illegal_value  \\\n",
       "0     [The input text does not contain any elements ...        [None]   \n",
       "1     [The input text does not contain any elements ...        [None]   \n",
       "2     [The Appeal to Hypocrisy technique was not use...        [None]   \n",
       "3     [The input text does not contain any elements ...        [None]   \n",
       "4     [The input text discusses a proposed law aimed...        [None]   \n",
       "...                                                 ...           ...   \n",
       "1875  [The input text does not contain any elements ...        [None]   \n",
       "1876  [The input text does not employ the Casting Do...        [None]   \n",
       "1877  [The input text does not contain any elements ...        [None]   \n",
       "1878  [The input text does not contain any elements ...        [None]   \n",
       "1879  [The input text does not contain any elements ...        [None]   \n",
       "\n",
       "     think_content is_valid  \\\n",
       "0           [None]   [True]   \n",
       "1           [None]   [True]   \n",
       "2           [None]   [True]   \n",
       "3           [None]   [True]   \n",
       "4           [None]   [True]   \n",
       "...            ...      ...   \n",
       "1875        [None]   [True]   \n",
       "1876        [None]   [True]   \n",
       "1877        [None]   [True]   \n",
       "1878        [None]   [True]   \n",
       "1879        [None]   [True]   \n",
       "\n",
       "                                            source_file error status  split  \\\n",
       "0     data/llm_output/persuasion/explain/GPT_41/v001...   NaN    NaN  train   \n",
       "1     data/llm_output/persuasion/explain/GPT_41/v001...   NaN    NaN  train   \n",
       "2     data/llm_output/persuasion/explain/GPT_41/v001...   NaN    NaN  train   \n",
       "3     data/llm_output/persuasion/explain/GPT_41/v001...   NaN    NaN  train   \n",
       "4     data/llm_output/persuasion/explain/GPT_41/v001...   NaN    NaN  train   \n",
       "...                                                 ...   ...    ...    ...   \n",
       "1875  data/llm_output/persuasion/explain/GPT_41/v001...   NaN    NaN  train   \n",
       "1876  data/llm_output/persuasion/explain/GPT_41/v001...   NaN    NaN  train   \n",
       "1877  data/llm_output/persuasion/explain/GPT_41/v001...   NaN    NaN  train   \n",
       "1878  data/llm_output/persuasion/explain/GPT_41/v001...   NaN    NaN  train   \n",
       "1879  data/llm_output/persuasion/explain/GPT_41/v001...   NaN    NaN  train   \n",
       "\n",
       "                                        expected_output  \n",
       "0     {\"description\": \"The input text does not conta...  \n",
       "1     {\"description\": \"The input text does not conta...  \n",
       "2     {\"description\": \"The Appeal to Hypocrisy techn...  \n",
       "3     {\"description\": \"The input text does not conta...  \n",
       "4     {\"description\": \"The input text discusses a pr...  \n",
       "...                                                 ...  \n",
       "1875  {\"description\": \"The input text does not conta...  \n",
       "1876  {\"description\": \"The input text does not emplo...  \n",
       "1877  {\"description\": \"The input text does not conta...  \n",
       "1878  {\"description\": \"The input text does not conta...  \n",
       "1879  {\"description\": \"The input text does not conta...  \n",
       "\n",
       "[1880 rows x 60 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os\n",
    "import json \n",
    "import numpy as np\n",
    "\n",
    "root = Path(\"data/llm_output/persuasion/explain\")\n",
    "# Example path template\n",
    "files = root.rglob(\"*/*.parquet\")\n",
    "\n",
    "# Read all files and add file path as a column\n",
    "df_list = []\n",
    "for f in files:\n",
    "    df_part = pd.read_parquet(f)\n",
    "    df_part['source_file'] = f  # add the file path\n",
    "    df_list.append(df_part)\n",
    "\n",
    "# Combine into one DataFrame\n",
    "df = pd.concat(df_list, ignore_index=True)\n",
    "df['split'] = df.source_file.astype(str).str.split('/',expand=True)[7]\n",
    "\n",
    "def safe_description(data):\n",
    "    if isinstance(data, (list,np.ndarray)):\n",
    "        return data[-1]\n",
    "    else:\n",
    "        return None  # or \"\", depending on what you prefer\n",
    "    \n",
    "df['expected_output'] = df.apply(lambda row: json.dumps({\n",
    "    'description': safe_description(row['explanation']),\n",
    "    'verdict': bool(row['gold'])\n",
    "}), axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e3668470",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "filename",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "start",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "end",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "text_lang",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "text",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "label_bin",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "label_multi",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "base_split",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Questioning_the_Reputation",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Name_Calling-Labeling",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Appeal_to_Hypocrisy",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Conversation_Killer",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Loaded_Language",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Repetition",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Appeal_to_Popularity",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Doubt",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Red_Herring",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Flag_Waving",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Exaggeration-Minimisation",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Consequential_Oversimplification",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Appeal_to_Pity",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Appeal_to_Time",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Appeal_to_Values",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Obfuscation-Vagueness-Confusion",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Straw_Man",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Slogans",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Appeal_to_Fear-Prejudice",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Causal_Oversimplification",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Appeal_to_Authority",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "False_Dilemma-No_Choice",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Whataboutism",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "False_Equivalence",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Guilt_by_Association",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "alt_split",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "output_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "prompt_name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "prompt_version",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "job",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "step",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "max_iterations",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "temperature",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "model_provider",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "model_name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "model_mode",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "gold",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "gold_text",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "spans",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "raw",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "updated_definition",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "extra_properties",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "extra_content",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "explanation",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "illegal_value",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "think_content",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "is_valid",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "source_file",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "error",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "status",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "split",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "expected_output",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "0f175945-50d3-4d9d-8d03-fea4cbb9205e",
       "rows": [
        [
         "90",
         "pl_abortion_11_04_2024_n03.txt",
         "4168",
         "5204",
         "PL",
         "W latach 90., które już bardzo dobrze pamiętam,\nmiały miejsce kolejne próby zaostrzenia prawa\naborcyjnego. Najpierw efektem tego było prawo aborcyjne\noparte na czterech przesłankach, w tym przesłance\nekonomiczno-społecznej, a finalnie, po wyroku\nTrybunału Konstytucyjnego w 1997 r. zakończyło się to\nwprowadzeniem zakazu aborcji opartego na trzech\nwąskich przesłankach, dla niepoznaki i czystych\nsumień konserwatywnych polityków i duchownych\nKościoła katolickiego zwanego kompromisem aborcyjnym.\nNikt nie pytał wtedy kobiet o zdanie w sprawie\nplanowania rodziny, ochrony płodu ludzkiego i\nwarunków dopuszczalności przerywania ciąży – tak\nnazywała się ta ustawa. Nie pytano kobiet, bo ta ustawa\nbyła początkiem wymazywania kobiet z debaty o aborcji.\nCzęść polityków miała czyste ręce i czyste sumienia.\nPrawo zabraniało kobiecie przerywania ciąży,\nlekarze przestali wykonywać aborcję, ale tylko w\npublicznych szpitalach. Według rządowych statystyk\nciążę przerywało 600–1000 kobiet rocznie, a w rze-\nczywistości miała ją co trzecia Polka.",
         "True",
         "['Appeal_to_Hypocrisy' 'Loaded_Language' 'Questioning_the_Reputation'\n 'Appeal_to_Popularity' 'Repetition']",
         "train",
         "['ustawa była początkiem wymazywania kobiet z debaty o aborcji'\n 'Część polityków miała czyste ręce i czyste sumienia']",
         "[]",
         "['zakazu aborcji opartego na trzech wąskich przesłankach, dla niepoznaki i czystych sumień konserwatywnych polityków i duchownych Kościoła katolickiego zwanego kompromisem aborcyjnym']",
         "[]",
         "['wymazywania kobiet' 'wymazywania']",
         "['Nikt nie pytał wtedy kobiet' 'Nie pytano kobiet']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Hypocrisy",
         "Appeal_to_Hypocrisy",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "1",
         "Yes, the Appeal to Hypocrisy technique is used in the input.",
         "\"zakazu aborcji opartego na trzech wąskich przesłankach, dla niepoznaki i czystych sumień konserwatywnych polityków i duchownych Kościoła katolickiego zwanego kompromisem aborcyjnym\"",
         "['{\\n  \"explanation\": \"The Appeal to Hypocrisy technique is used in the input text by highlighting the inconsistency of conservative politicians and Catholic clergy who, while advocating for strict abortion laws, are described as having \\'czyste sumienia\\' (clean consciences). This implies that they are hypocritical for imposing restrictions on women\\'s rights while not considering their opinions, thus attacking their reputation by pointing out this hypocrisy.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[False]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/pl/train-pl-part_0000.parquet",
         null,
         null,
         "train",
         "{\"description\": null, \"verdict\": true}"
        ],
        [
         "201",
         "SI_interpelation_interior_12.txt",
         "4448",
         "7979",
         "SI",
         "Najlepša hvala za besedo. Najprej hvala gospod minister za odgovor. Vi in vaši sodelavci ste se potrudili. Je pa res, da niste postregli s številkami, ki bi demantirale številke, ki smo jih predstavili poslanke in poslanci, ki smo se podpisali pod interpelacijo. V tem delu imate problem. Ampak pojdimo k številkam, kot sem rekla, ki ne lažejo. Brez patetike, brez in sumi insinuacij, kot je bilo danes rečeno, ampak prva trditev, gospod minister, policija dela dobro. Da, strinjam se z vami. Policistke in policisti na terenu delajo dobro, človek bi rekel, presenetljivo dobro glede na vodstvo policije, ki že dve leti to policijo razkraja. Hvaležna sem jim kot Novomeščanka, kajti ko je kjerkoli kaj narobe, posebno seveda v romskem naselju, o katerem bom govorila kasneje, so prvi na kraju policistke in policisti. Vendar, se opravičujem, še enkrat, bom prebrala najbolj pomembne številke, ki kažejo, gospod minister, da statistika, ki je popolnoma sveža letošnja in zajema tudi lansko obdobje kaže, da je v vašem obdobju se je zmanjšalo število odkritih kaznivih dejanj za 43,5 procentov. Torej vi ne morete vplivati verjetno ne na število kriminalcev, ki hodijo po naši državi, lahko pa vplivate na število odkritih kaznivih dejanj, torej z dobrim, učinkovitim vodenjem in s preventivnim delovanjem policije. Povečalo se je število kaznivih dejanj gospodarske kriminalitete za 18 procentov in mladoletniške za. 9,4, in tisto kar nas res boli in so nekateri, ki so ime, ki so pisali odzive poslanskih skupin slabo prebrali, našo interpelacijo, je porast kriminalitete v družinah, na področju nasilja v družini se je ta povečala za 18 procentov in pri odvzetih mladoletniških osebah, kar spet mislim na moje dolenjske mladoletne Rome, se je povečala za 65,7 procenta, ta kriminaliteta. Torej Slovenija je varna država, vendar je delo policije neučinkovito in če bo to delo trajalo še dolgo, hvala bogu, da ta Vlada ne bo zelo dolgo, bomo prišli res na zaskrbljujoče številke in nekaj o mladoletnikih, kar nas dejansko tudi skrbi, posebno v Novi Sloveniji in na kar smo dejansko opozarjali, da se je povečalo število nasilništva med mladoletniki. In ko smo vas prosili, spoštovana in draga koalicija, da ukrepate v zvezi z romsko problematiko, ste samo obljubljali, nekateri z gnusom zavrnili naše zakone in številke so vas vzele, izdale. Niste učinkoviti in nikoli ne boste vedeli kako učinkoviti bi bili, če bi pred enim letom in pol sprejeli zakone, ki so jih napisali župani. Takrat ste rekli, prav ena poslanka iz Svobode, da Vida Čadonič Špelič, njen župan in tudi ostali župani Dolenjske lažejo in zavajajo, številke govorijo drugače. Torej, spoštovani gospod minister, tisti, ki vam je pisal odgovore na našo interpelacijo je spregledal te številke. Drugo, rekli ste, da policija dela dobro, vendar ste v isti sapi povedali, da niste zadovoljni z delom CVZ. Spoštovani minister, saj vi ja dobro veste, da je CVZ del policije. In zdaj, ko se pogovarjamo o CVZ je prav, da povemo nekaj, česar se verjetno poslanke in poslanci ne zavedamo. Tudi policistke in policisti, ki so del naše službe, našega varovanja tukaj, ki nas tako prijetno pozdravijo, ko vstopimo v ta Državni zbor in najbolj prijetno je, ko zvečer pozno odhajajo, nam pomahajo v slovo in zaželijo srečno pot. Tudi oni so del CVZ, ne, oni ne delajo slabo, vsi ne delajo slabo. Dela pa slabo očitno vodstvo CVZ, ki ga vaš direktor, zdaj že bivši, ki je častno odstopil, ni uspel urediti. Šele danes ali včeraj, kdaj je to bilo, je tudi CVZ dobila novo vodstvo.",
         "True",
         "['Consequential_Oversimplification' 'Exaggeration-Minimisation'\n 'Loaded_Language' 'Appeal_to_Hypocrisy' 'Appeal_to_Pity'\n 'Appeal_to_Authority' 'Questioning_the_Reputation'\n 'False_Dilemma-No_Choice' 'Red_Herring' 'Repetition' 'Doubt'\n 'Appeal_to_Fear-Prejudice']",
         "train",
         "['tisti, ki vam je pisal odgovore na našo interpelacijo je spregledal te številke']",
         "[]",
         "['Drugo, rekli ste, da policija dela dobro, vendar ste v isti sapi povedali, da niste zadovoljni z delom CVZ']",
         "[]",
         "['posebno seveda v romskem naselju'\n 'kriminalcev, ki hodijo po naši državi' 'moje dolenjske mladoletne Rome'\n 'gnusom']",
         "['k številkam, kot sem rekla, ki ne lažejo' 'številke' 'številke'\n 'vsi ne delajo slabo']",
         "[]",
         "['Policistke in policisti na terenu delajo dobro, človek bi rekel, presenetljivo dobro glede na vodstvo policije, ki že dve leti to policijo razkraja'\n 'Niste učinkoviti in nikoli ne boste vedeli kako učinkoviti bi bili, če bi pred enim letom in pol sprejeli zakone, ki so jih napisali župani']",
         "['kot Novomeščanka'\n 'Tudi policistke in policisti, ki so del naše službe, našega varovanja tukaj, ki nas tako prijetno pozdravijo, ko vstopimo v ta Državni zbor in najbolj prijetno je, ko zvečer pozno odhajajo, nam pomahajo v slovo in zaželijo srečno pot']",
         "[]",
         "['Niste učinkoviti in nikoli ne boste vedeli kako učinkoviti bi bili']",
         "['vendar je delo policije neučinkovito in če bo to delo trajalo še dolgo, hvala bogu, da ta Vlada ne bo zelo dolgo, bomo prišli res na zaskrbljujoče številke']",
         "['Hvaležna sem jim kot Novomeščanka'\n 'Tudi policistke in policisti, ki so del naše službe, našega varovanja tukaj, ki nas tako prijetno pozdravijo, ko vstopimo v ta Državni zbor in najbolj prijetno je, ko zvečer pozno odhajajo, nam pomahajo v slovo in zaželijo srečno pot']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Povečalo se je število kaznivih dejanj gospodarske kriminalitete za 18 procentov in mladoletniške za. 9,4, in tisto kar nas res boli in so nekateri, ki so ime, ki so pisali odzive poslanskih skupin slabo prebrali, našo interpelacijo, je porast kriminalitete v družinah, na področju nasilja v družini se je ta povečala za 18 procentov in pri odvzetih mladoletniških osebah, kar spet mislim na moje dolenjske mladoletne Rome, se je povečala za 65,7 procenta, ta kriminaliteta'\n 'Torej Slovenija je varna država, vendar je delo policije neučinkovito in če bo to delo trajalo še dolgo, hvala bogu, da ta Vlada ne bo zelo dolgo, bomo prišli res na zaskrbljujoče številke in nekaj o mladoletnikih, kar nas dejansko tudi skrbi, posebno v Novi Sloveniji in na kar smo dejansko opozarjali, da se je povečalo število nasilništva med mladoletniki']",
         "[]",
         "['k številkam, kot sem rekla, ki ne lažejo'\n 'Hvaležna sem jim kot Novomeščanka, kajti ko je kjerkoli kaj narobe, posebno seveda v romskem naselju, o katerem bom govorila kasneje, so prvi na kraju policistke in policisti'\n 'številke so vas vzele, izdale']",
         "['Niste učinkoviti in nikoli ne boste vedeli kako učinkoviti bi bili, če bi pred enim letom in pol sprejeli zakone, ki so jih napisali župani']",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Hypocrisy",
         "Appeal_to_Hypocrisy",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "1",
         "Yes, the Appeal to Hypocrisy technique is used in the input.",
         "\"Drugo, rekli ste, da policija dela dobro, vendar ste v isti sapi povedali, da niste zadovoljni z delom CVZ\"",
         "['{\\n  \"explanation\": \"The Appeal to Hypocrisy technique is used in the input text when the speaker points out the contradiction in the minister\\'s statements. The minister claims that the police are doing well, yet simultaneously expresses dissatisfaction with the work of CVZ, which is part of the police. This highlights the inconsistency in the minister\\'s position, effectively attacking his credibility by showing hypocrisy.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[False]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/si/train-si-part_0004.parquet",
         null,
         null,
         "train",
         "{\"description\": null, \"verdict\": true}"
        ],
        [
         "209",
         "SI_interpelation_interior_7.txt",
         "2598",
         "5288",
         "SI",
         "Policisti prav tako dobijo navodila, naj ne spoštujejo zakonov, kajti policisti, ko primejo osebo, ki je ilegalno vstopila v Slovenijo, so dolžni preveriti vse okoliščine takega dejanja in morajo osebi zavrniti vstop v državo, če za to obstajajo zakoniti razlogi. Če je dejansko nesporno, da je oseba ilegalno vstopila v Slovenijo iz Hrvaške, ki je varna država, mora policist tako osebo vrniti v državo iz katere je prišla, torej s sosednjo Hrvaško. Tega policisti več ne preverjajo, kot so to prej, ampak postanejo le še zgolj taksisti, ki na državne stroške ilegalne migrante prevažajo v azilni dom v Ljubljano. Ti po nekaj dnevih azilni dom zapustijo, in če jih policisti na poti proti Avstriji ali Italiji ustavijo, imajo nalogo, da jim ponudijo ponovno možnost podajo vloge za azil ali mednarodno zaščito in ponovno nastanitev v azilnem domu, česar pa prej ni bilo. Taka navodila policistom seveda preprečujejo ostalo zakonodajo, delati ostalo zakonodajo, kar prav tako doprinaša k razpadanju sistema delovanja policije. V času bivanja v Sloveniji, se nekateri ilegalni migranti prosto gibajo po glavnem mestu in povzročajo številna kazniva dejanja, kradejo, napadajo policiste in paznike, ki jih pri tem zalotijo, posiljujejo, prekupčujejo z drogo in se pretepajo. Včasih katerega najdejo tudi utopljenega v Ljubljanici, med tem policija zadevo prikriva. Namesto ustreznega ukrepanja policija na podhodu železniške postaje v Ljubljani namesti nalepke z napisom: Če ste sami žrtev spolnega napada ali veste za ta primer, ga takoj prijavite policiji in ljudem svetuje, seveda mora biti žrtev posilstva, naj poskušajo s storilcem, naj se poskušajo s storilcem pogovoriti in vzbuditi občutek razumevanja ter sočutja. Zelo zanimivo. Ljudi, predvsem pa žensk, je ponoči strah hoditi po Ljubljani. Prodaja solzivcev se v Ljubljani poveča za kar 1000 odstotkov. Katastrofalne postanejo razmere tudi v centru za varnost in zaščito. Na to javnost opozori tožilka Mateja Gončin, ki se izpove o številnih nepravilnostih, zlorabah in celo naklepnih kaznivih dejanjih varnostnikov, zlasti pa vodstva omenjenega centra pri njenem varovanju. Prav tako naj bi varnostniki celo zbirali podatke o naši predsednici Državnega zbora zaradi morebitne kasnejše diskreditacije, iz Civilne centra za varstvo in zaščito naj bi informacije tudi odtekale kriminalcem. Čeprav je z nepravilnostmi večkrat seznanila tako nezakonitega generalnega direktorja policije Jušića, kot notranjega ministra Poklukarja, se na tem področju ni zgodilo nič. V CVZ se tudi nadpovprečno obremenjuje varnostnike, ki tudi več dni zaporedoma nimajo zagotovljenega minimalnega dnevnega počitka, nepravilno se obračunavajo delovne ure.",
         "True",
         "['Consequential_Oversimplification' 'Exaggeration-Minimisation'\n 'Loaded_Language' 'Appeal_to_Hypocrisy' 'Appeal_to_Pity'\n 'Questioning_the_Reputation' 'Appeal_to_Authority' 'Red_Herring' 'Doubt'\n 'Appeal_to_Fear-Prejudice']",
         "train",
         "['Taka navodila policistom seveda preprečujejo ostalo zakonodajo, delati ostalo zakonodajo, kar prav tako doprinaša k razpadanju sistema delovanja policije']",
         "[]",
         "['Čeprav je z nepravilnostmi večkrat seznanila tako nezakonitega generalnega direktorja policije Jušića, kot notranjega ministra Poklukarja, se na tem področju ni zgodilo nič']",
         "[]",
         "['le še zgolj taksisti' 'državne stroške']",
         "[]",
         "[]",
         "['Policisti prav tako dobijo navodila, naj ne spoštujejo zakonov'\n 'Včasih katerega najdejo tudi utopljenega v Ljubljanici, med tem policija zadevo prikriva']",
         "['V CVZ se tudi nadpovprečno obremenjuje varnostnike, ki tudi več dni zaporedoma nimajo zagotovljenega minimalnega dnevnega počitka, nepravilno se obračunavajo delovne ure']",
         "[]",
         "['številna kazniva dejanja'\n 'Katastrofalne postanejo razmere tudi v centru za varnost in zaščito']",
         "['Namesto ustreznega ukrepanja policija na podhodu železniške postaje v Ljubljani namesti nalepke z napisom: Če ste sami žrtev spolnega napada ali veste za ta primer, ga takoj prijavite policiji in ljudem svetuje, seveda mora biti žrtev posilstva, naj poskušajo s storilcem, naj se poskušajo s storilcem pogovoriti in vzbuditi občutek razumevanja ter sočutja'\n 'Prodaja solzivcev se v Ljubljani poveča za kar 1000 odstotkov']",
         "['nadpovprečno obremenjuje varnostnike, ki tudi več dni zaporedoma nimajo zagotovljenega minimalnega dnevnega počitka']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['V času bivanja v Sloveniji, se nekateri ilegalni migranti prosto gibajo po glavnem mestu in povzročajo številna kazniva dejanja, kradejo, napadajo policiste in paznike, ki jih pri tem zalotijo, posiljujejo, prekupčujejo z drogo in se pretepajo'\n 'Ljudi, predvsem pa žensk, je ponoči strah hoditi po Ljubljani'\n 'Prav tako naj bi varnostniki celo zbirali podatke o naši predsednici Državnega zbora zaradi morebitne kasnejše diskreditacije, iz Civilne centra za varstvo in zaščito naj bi informacije tudi odtekale kriminalcem']",
         "[]",
         "['tožilka Mateja Gončin']",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Hypocrisy",
         "Appeal_to_Hypocrisy",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "1",
         "Yes, the Appeal to Hypocrisy technique is used in the input.",
         "\"Čeprav je z nepravilnostmi večkrat seznanila tako nezakonitega generalnega direktorja policije Jušića, kot notranjega ministra Poklukarja, se na tem področju ni zgodilo nič\"",
         "['{\\n  \"explanation\": \"The Appeal to Hypocrisy technique is used in the input text by highlighting the inaction of the general director of police and the interior minister despite being informed of irregularities. This implies hypocrisy, as they are expected to uphold the law and address issues but fail to do so, thus attacking their reputation for inconsistency.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[False]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/si/train-si-part_0004.parquet",
         null,
         null,
         "train",
         "{\"description\": null, \"verdict\": true}"
        ],
        [
         "227",
         "SI_interpelation_interior_7.txt",
         "839",
         "2596",
         "SI",
         "Naslednji primer: žena pomočnika generalnega direktorja policije, ki na policiji opravlja piar službo, se prevaža s protokolarnim vozilom, ki je namenjeno za prevoze varovanih oseb in ne uslužbencev policije. Ko policijska voznica v poročilu navede, koga je prevažala, mora po navodilu pomočnika generalnega direktorja policije, ki je mož te osebe, poročilo popraviti. Prav tako je kasneje s strani vodstva šikanirana. Namestnik generalnega direktorja policije, torej mož piarovke, si za službeno vozilo prilasti novo toyoto, ostalim pa v uporabo nameni stara vozila. Zoper svetovalca generalnega direktorja, zdaj že bivšega generalnega direktorja za področje gospodarske in korupcijske kriminalitete, bi pa naj bilo podanih kar več kaznivih ovadb. Da je stanje v policiji slabo, dokazuje tudi poročilo iz prvega polletja leta 2023, iz katerega je razvidno, da se je število kaznivih dejanj znatno povečalo, število preiskanosti in odkritosti z lastno dejavnostjo pa znatno zmanjšalo. Povečala se je uporaba prisilnih sredstev in izdanih plačilnih nalogov, število opozoril se je zmanjšalo, prav tako se v deželici z imenom Slovenija v časih golobistov prične na meji odstranjevati ograja. S tem se ilegalnim migrantom sporoči, da je prehod preko Slovenije lažji, zato se prične znatno povečevati število ilegalnih prehodov meje. Migranti se tako množično gibajo po naseljih ob hrvaški meji, kar povzročajo, povzroča strah in nelagodje tamkajšnjim prebivalcem. Število je že tako veliko, da kapacitete v azilnih domovih več ne zadoščajo, zato vlada sklene, da bo v Obrežju in v Središču ob Dravi uredila izpostave azilnega doma, ne da bi se o tem predhodno posvetovala z lokalno skupnostjo. To seveda povzroči nestrinjanje in upor tamkajšnjega prebivalstva.",
         "True",
         "['Causal_Oversimplification' 'Exaggeration-Minimisation'\n 'Appeal_to_Hypocrisy' 'Loaded_Language' 'Appeal_to_Pity'\n 'Obfuscation-Vagueness-Confusion' 'Questioning_the_Reputation'\n 'Name_Calling-Labeling' 'Doubt' 'Repetition' 'Appeal_to_Fear-Prejudice']",
         "train",
         "['mora po navodilu pomočnika generalnega direktorja policije, ki je mož te osebe, poročilo popraviti']",
         "['golobistov']",
         "['žena pomočnika generalnega direktorja policije, ki na policiji opravlja piar službo, se prevaža s protokolarnim vozilom, ki je namenjeno za prevoze varovanih oseb in ne uslužbencev policije'\n 'Namestnik generalnega direktorja policije, torej mož piarovke, si za službeno vozilo prilasti novo toyoto, ostalim pa v uporabo nameni stara vozila'\n 'Zoper svetovalca generalnega direktorja, zdaj že bivšega generalnega direktorja za področje gospodarske in korupcijske kriminalitete, bi pa naj bilo podanih kar več kaznivih ovadb']",
         "[]",
         "['šikanirana' 'ilegalnim migrantom']",
         "['golobistov']",
         "[]",
         "['s strani vodstva šikanirana']",
         "[]",
         "[]",
         "['stara vozila' 'množično gibajo po naseljih ob hrvaški meji']",
         "[]",
         "['s strani vodstva šikanirana']",
         "[]",
         "[]",
         "['prisilnih sredstev']",
         "[]",
         "[]",
         "['zato se prične znatno povečevati število ilegalnih prehodov meje'\n 'Migranti se tako množično gibajo po naseljih ob hrvaški meji, kar povzročajo, povzroča strah in nelagodje tamkajšnjim prebivalcem']",
         "['S tem se ilegalnim migrantom sporoči, da je prehod preko Slovenije lažji, zato se prične znatno povečevati število ilegalnih prehodov meje']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Hypocrisy",
         "Appeal_to_Hypocrisy",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "1",
         "Yes, the Appeal to Hypocrisy technique is used in the input.",
         "\"žena pomočnika generalnega direktorja policije, ki na policiji opravlja piar službo, se prevaža s protokolarnim vozilom, ki je namenjeno za prevoze varovanih oseb in ne uslužbencev policije Namestnik generalnega direktorja policije, torej mož piarovke, si za službeno vozilo prilasti novo toyoto, ostalim pa v uporabo nameni stara vozila Zoper svetovalca generalnega direktorja, zdaj že bivšega generalnega direktorja za področje gospodarske in korupcijske kriminalitete, bi pa naj bilo podanih kar več kaznivih ovadb\"",
         "['{\\n  \"explanation\": \"The Appeal to Hypocrisy technique is used in the input text by highlighting the inconsistency in the actions of the deputy director of the police and his wife, who is in a public relations role. The text points out that while she uses a vehicle meant for protected individuals, her husband, the deputy director, appropriates a new vehicle for himself while providing older vehicles to others. This contradiction illustrates hypocrisy in their actions, as they are in positions of authority yet act in self-serving ways, which undermines their credibility.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[False]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/si/train-si-part_0006.parquet",
         null,
         null,
         "train",
         "{\"description\": null, \"verdict\": true}"
        ],
        [
         "234",
         "SI_interpelation_interior_6.txt",
         "270",
         "7305",
         "SI",
         "Na eni izmed sej Odbora za notranje zadeve mi je predsednica odbora dejala, da sem pravljičar, zato mi spoštovani kolegi in kolegice dovolite, da vam v imenu Poslanske skupine Slovenske demokratske stranke povem zgodbo, ki morda ni pravljica in se glasi takole. Tam, na sončni strani Alp, so v deželici z imenom Slovenija nedolgo nazaj vladali janšisti. Prišel je čas volitev in oblast so prevzeli golobisti. Tik pred prevzemom oblasti njihov vodja k sebi pokliče novo ministrico za notranje zadeve in novega vršilca dolžnosti generalnega direktorja policije in jima naroči: Imata eno samo nalogo in to je, da policijo očistita janšistov. Oba vestno pričneta z opravljanjem ukazane naloge in na vodilnih položajih policije zamenjujeta osebe, ki naj bi bili janšisti. Še posebej direktorja, tam na mojem koncu, kot je dejal njihov vodja, in direktor Nacionalnega preiskovalnega urada, kajti prav ta urad preiskuje vodjo golobistov, zaradi ukradene identitete v Romuniji in kup denarja na tamkajšnjem računu, nakazila novinarki Vesni Vuković za neznane usluge in balkanskim poslovanjem denarja. Pri svojem delu pa naletita na težavo, kdo je janšist in kdo ne, saj so določene osebe, menita, da zamenjava ni potrebna. To povzroči nezadovoljstvo pri vodji in zato vršilca dolžnosti generalnega direktorja policije vrže čez ramo in ga noče imenovati za generalnega direktorja policije. Temu se ministrica upre in odstopi. Praznino v vodenju notranjega ministrstva izkoristi človek iz ozadja, ki sicer deluje na drugem ministrstvu in vodji predlaga osebo, ki bo pa poslušna. In tako minister za notranje zadeve postane Boštjan Poklukar. No, in novi minister Boštjan Poklukar prične z delom, seveda s poslušnim delom. Najprej o tem, kako naj bi delovalo policija in ministrstvo sicer ne posvetuje z ustreznimi strokovnjaki, ampak pogovor opravi z Jašo Jenulom, torej osebo, ki je bila v času vodenja janšistov večkrat kaznovana, ker je pozival k neprijavljenim protestom. Nato kljub temu, da je znotraj policije na desetine visoko izobraženih ter usposobljenih kadrov, na željo vodje golobistov za vršilca dolžnosti generalnega direktorja policije imenuje Senada Jušića, ki seveda nima vodstvenih izkušenj, saj je v preteklosti deloval zgolj kot pomočnik vodje na lokalnem nivoju. Imenovanje za vršilca dolžnosti generalnega direktorja policije pa naj bi bilo celo nezakonito, saj se ob njegovi premestitvi ne bi opravilo varnostno preverjanje, kar je sicer vedno obvezno o premestitvi na višje delovno mesto. Senad Jušić je tako nezakonito imenovan kasneje za generalnega direktorja Policije, saj Uradniški svet pri sklepu o izpolnitvi pogojev upošteva neke interne akte policije in za to poda tudi pomanjkljivo obrazložitev, ker seveda nimajo kaj obrazložiti. Ker bivši vršilec dolžnosti generalnega direktorja policije to ve, poda tožbo na Upravno sodišče, ki seveda razsodi, da je sklep natečajne komisije nezakonit, tako da je tudi imenovanje Senada Jušića za generalnega direktorja Policije nezakonito. Vodja golobistov, generalni direktor Policije, kakor tudi minister Poklukar se sprenevedajo, zanemarjajo sistem pravne države in ne spoštujejo sodbe. Jušića varujejo pred očitki, tako daleč, da se mora v to dogajanje vključiti sam striček iz ozadja in po 83 dneh Senad Jušić odstopi. Seveda v času vodenja policije s strani Senada Jušića postajajo razmere na policiji iz dneva v dan bolj kritične in dosežejo najnižjo točko v sistem delovanja policije v zgodovini Slovenije. Nestrokovni vodje svojo nestrokovnost prenašajo na policiste in policiste. Na njih izvajajo pritiske. Policisti in policistke več ne vedo kako naj delajo, kako naj postopajo, da bo prav in da zoper njih ne bodo uvedene sankcije. Strah jih je, delajo več nadur in tako dalje. Tako se policisti raje umaknejo, kot bi posredovali v eni izmed garažnih hiš v Ljubljani, kjer so policijsko patruljo ob posredovanju obkrožili zbrani mladostniki in preprečevali vožnjo. Policista se z vozilom umakneta. Prav tako se v Ljubljani zbere množica ljudi, ki z avtomobili hupa, drifta s strelnim orožjem strelja v zrak in na eno izmed policijskih vozil celo namesti albansko zastavo. Na jugovzhodnem delu te deželice se pojavijo težave, saj policija ni več kos kaznivim dejanjem, tamkajšnjim živečim Romom, ki kršijo prometne predpise, izvajajo tatvine, ustrahujejo, pretepajo, uporabljajo strelno orožje in tako dalje. Slovenija postane tudi raj za hudodelske združbe, ki med sabo obračunavajo kar sredi dneva, izvajajo likvidacije, umore, in to kar pred očmi otrok. Prav tako umorijo skesanca, ki ga policija ne zaščiti kljub opozorilom o njegovi likvidaciji. V priljubljenem velenjskem lokalu ob pretepu poseduje lastnik tega lokala, ki pa je med najbolj iskanimi osebami v Evropi na Interpolovi tiralici, zaradi sodelovanja v kriminalni združbi v Bosni in Hercegovini. Kljub obsodbi na leto in pol zapora brez težav torej opravlja ta lokal, se svobodno giba po Sloveniji, saj ga policija ne aretira. Varnost v državi se iz leta v leto slabša, kar dokazuje podatek globalnega indeksa miru, ker je Slovenija iz četrtega mesta v letu 2020 v lanskem letu 2024 zdrsnila na deveto mesto. Policisti in policistke tako množično zapuščajo policijske vrste: bodisi se upokojijo ali pa si poiščejo boljšo zaposlitev in podajo odpoved. Novih zaposlitev ni. Zdesetkana, policija ne zmore več opravljati nalog, ki jih je dolžna izvajati. V času janšistov, torej v letu 2020 in 2021 je bilo kar 164 odstotkov več prihodov kot odhodov. V času golobistov, v letu 2022 in vaju 24 je pa bilo 60 odstotkov več. Torej, manj prihodov kot odhodov. Od tega v času ministrovanja Boštjana Poklukarja, torej v letu 23 in 24 za 51 odstotkov manj prihodov kot odhodov. Kljub temu, da je denarja v davčni blagajni rekordno veliko se za promocijo poklica policist, policijska ne namenjajo namenska finančna sredstva, ki bi imela v proračunu svojo postavko, kot jo ima to na primer vojska. Poslabšanje organizacijske klime v policiji dokazuje tudi raziskava odbora za integriteto in etiko v policiji, saj so se rezultati pod vodstvom Boštjana Poklukarja znatno poslabšali. Medtem se v vodstvenih vrstah izvajajo različne mahinacije, kot so naslednji; minister Poklukar podpiše novo sistemizacijo delovnih mest na Policijski upravi Maribor, kjer se omogoči zaposlitev izbrane osebe za pomočnika direktorja Policijske uprave. Njihovo namero na žalost tik pred iztekom roka razpise prekine poslanec iz naše poslanske skupine, ki na to temo poda pisno poslansko vprašanje. Tako v istem dnevu razpis prekličejo, zamenjajo priloge te sistemizacije in razpišejo novo delovno mesto, in sicer za policijskega svetnika na Policijski upravi. Ta oseba se na ta razpis prijavi in se tudi zaposli. V odgovoru na pisno poslansko vprašanje poslanca naše poslanske skupine se pa minister zlaže, da je zaposlitev policijskega svetnika na PU Maribor potrebna zaradi povečanega števila kaznivih dejanj Romov iz Hrvaške na območju Policijske postaje Ormož in Gorišnica in zaradi povečanega števila migracij na tem območju.",
         "True",
         "['Loaded_Language' 'Obfuscation-Vagueness-Confusion'\n 'Name_Calling-Labeling' 'Red_Herring' 'Guilt_by_Association' 'Doubt'\n 'Causal_Oversimplification' 'Exaggeration-Minimisation'\n 'Questioning_the_Reputation' 'Appeal_to_Authority' 'Appeal_to_Values'\n 'False_Dilemma-No_Choice' 'Repetition' 'Appeal_to_Fear-Prejudice']",
         "train",
         "['Še posebej direktorja, tam na mojem koncu, kot je dejal njihov vodja, in direktor Nacionalnega preiskovalnega urada, kajti prav ta urad preiskuje vodjo golobistov, zaradi ukradene identitete v Romuniji in kup denarja na tamkajšnjem računu, nakazila novinarki Vesni Vuković za neznane usluge in balkanskim poslovanjem denarja'\n 'Praznino v vodenju notranjega ministrstva izkoristi človek iz ozadja, ki sicer deluje na drugem ministrstvu in vodji predlaga osebo, ki bo pa poslušna'\n 'minister zlaže']",
         "['golobisti' 'janšistov' 'janšisti' 'janšistov' 'golobistov' 'golobistov'\n 'janšistov' 'golobistov']",
         "[]",
         "[]",
         "['janšisti' 'golobisti' 'janšist' 'vrže čez ramo' 'striček iz ozadja'\n 'deželice' 'hudodelske združbe' 'Zdesetkana' 'mahinacije']",
         "['janšisti' 'janšist' 'janšistov' 'golobistov' 'nezakonito' 'golobistov'\n 'janšistov' 'golobistov']",
         "[]",
         "['seveda s poslušnim delom'\n 'Nato kljub temu, da je znotraj policije na desetine visoko izobraženih ter usposobljenih kadrov, na željo vodje golobistov za vršilca dolžnosti generalnega direktorja policije imenuje Senada Jušića, ki seveda nima vodstvenih izkušenj, saj je v preteklosti deloval zgolj kot pomočnik vodje na lokalnem nivoju'\n 'Senad Jušić je tako nezakonito imenovan kasneje za generalnega direktorja Policije']",
         "['Na eni izmed sej Odbora za notranje zadeve mi je predsednica odbora dejala, da sem pravljičar, zato mi spoštovani kolegi in kolegice dovolite, da vam v imenu Poslanske skupine Slovenske demokratske stranke povem zgodbo, ki morda ni pravljica in se glasi takole'\n 'Tam, na sončni strani Alp, so v deželici z imenom Slovenija nedolgo nazaj vladali janšisti. Prišel je čas volitev in oblast so prevzeli golobisti. Tik pred prevzemom oblasti njihov vodja k sebi pokliče novo ministrico za notranje zadeve in novega vršilca dolžnosti generalnega direktorja policije in jima naroči: Imata eno samo nalogo in to je, da policijo očistita janšistov'\n 'Oba vestno pričneta z opravljanjem ukazane naloge in na vodilnih položajih policije zamenjujeta osebe, ki naj bi bili janšisti. Še posebej direktorja, tam na mojem koncu, kot je dejal njihov vodja, in direktor Nacionalnega preiskovalnega urada, kajti prav ta urad preiskuje vodjo golobistov, zaradi ukradene identitete v Romuniji in kup denarja na tamkajšnjem računu, nakazila novinarki Vesni Vuković za neznane usluge in balkanskim poslovanjem denarja. Pri svojem delu pa naletita na težavo, kdo je janšist in kdo ne, saj so določene osebe, menita, da zamenjava ni potrebna. To povzroči nezadovoljstvo pri vodji in zato vršilca dolžnosti generalnega direktorja policije vrže čez ramo in ga noče imenovati za generalnega direktorja policije. Temu se ministrica upre in odstopi. Praznino v vodenju notranjega ministrstva izkoristi človek iz ozadja, ki sicer deluje na drugem ministrstvu in vodji predlaga osebo, ki bo pa poslušna']",
         "[]",
         "['eno samo nalogo' 'zgolj kot pomočnik vodje na lokalnem nivoju'\n 'iz dneva v dan bolj kritične in dosežejo najnižjo točko v sistem delovanja policije v zgodovini Slovenije'\n 'Slovenija postane tudi raj za hudodelske združbe, ki med sabo obračunavajo kar sredi dneva, izvajajo likvidacije, umore, in to kar pred očmi otrok'\n 'najbolj iskanimi osebami v Evropi na Interpolovi tiralici' 'množično'\n 'V času janšistov, torej v letu 2020 in 2021 je bilo kar 164 odstotkov več prihodov kot odhodov'\n 'rekordno veliko' 'znatno poslabšali']",
         "[]",
         "[]",
         "[]",
         "['nezakonito' 'nezakonito'\n 'Vodja golobistov, generalni direktor Policije, kakor tudi minister Poklukar se sprenevedajo, zanemarjajo sistem pravne države in ne spoštujejo sodbe'\n 'Nestrokovni vodje svojo nestrokovnost prenašajo na policiste in policiste']",
         "['človek iz ozadja' 'neke interne akte policije' 'uvedene sankcije']",
         "[]",
         "[]",
         "['očistita janšistov'\n 'Nestrokovni vodje svojo nestrokovnost prenašajo na policiste in policiste. Na njih izvajajo pritiske'\n 'Policisti in policistke več ne vedo kako naj delajo, kako naj postopajo, da bo prav in da zoper njih ne bodo uvedene sankcije. Strah jih je, delajo več nadur in tako dalje'\n 'Prav tako se v Ljubljani zbere množica ljudi, ki z avtomobili hupa, drifta s strelnim orožjem strelja v zrak in na eno izmed policijskih vozil celo namesti albansko zastavo'\n 'Na jugovzhodnem delu te deželice se pojavijo težave, saj policija ni več kos kaznivim dejanjem, tamkajšnjim živečim Romom, ki kršijo prometne predpise, izvajajo tatvine, ustrahujejo, pretepajo, uporabljajo strelno orožje in tako dalje'\n 'Slovenija postane tudi raj za hudodelske združbe, ki med sabo obračunavajo kar sredi dneva, izvajajo likvidacije, umore, in to kar pred očmi otrok'\n 'Prav tako umorijo skesanca, ki ga policija ne zaščiti kljub opozorilom o njegovi likvidaciji'\n 'V priljubljenem velenjskem lokalu ob pretepu poseduje lastnik tega lokala, ki pa je med najbolj iskanimi osebami v Evropi na Interpolovi tiralici, zaradi sodelovanja v kriminalni združbi v Bosni in Hercegovini'\n 'Kljub obsodbi na leto in pol zapora brez težav torej opravlja ta lokal, se svobodno giba po Sloveniji, saj ga policija ne aretira'\n 'povečanega števila kaznivih dejanj Romov']",
         "['Varnost v državi se iz leta v leto slabša, kar dokazuje podatek globalnega indeksa miru, ker je Slovenija iz četrtega mesta v letu 2020 v lanskem letu 2024 zdrsnila na deveto mesto'\n 'Od tega v času ministrovanja Boštjana Poklukarja, torej v letu 23 in 24 za 51 odstotkov manj prihodov kot odhodov']",
         "['Nato kljub temu, da je znotraj policije na desetine visoko izobraženih ter usposobljenih kadrov'\n 'odbora za integriteto in etiko v policiji']",
         "['bodisi se upokojijo ali pa si poiščejo boljšo zaposlitev in podajo odpoved']",
         "[]",
         "[]",
         "['sicer ne posvetuje z ustreznimi strokovnjaki, ampak pogovor opravi z Jašo Jenulom, torej osebo, ki je bila v času vodenja janšistov večkrat kaznovana, ker je pozival k neprijavljenim protestom']",
         "train",
         "GPT_41/v001/Appeal_to_Hypocrisy",
         "Appeal_to_Hypocrisy",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Appeal to Hypocrisy technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not contain any explicit or implicit attacks on the reputation of a target by charging them with hypocrisy or inconsistency. There are no instances where the speaker calls out hypocrisy directly or highlights contradictions between different positions or actions. Therefore, the Appeal to Hypocrisy technique is not used.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[False]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/si/train-si-part_0006.parquet",
         null,
         null,
         "train",
         "{\"description\": null, \"verdict\": false}"
        ],
        [
         "256",
         "SI_interpelation_interior_11.txt",
         "2427",
         "2780",
         "SI",
         "Vse te stvari bomo uredili s sprejetjem novele Zakona o nalogah in pooblastilih policije, ki bo bolje urejala ukrep prepovedi približevanja. To so in bi morale biti družbene prioritete, ki bi si zaslužile obravnavo na sejah teles parlamenta, ne pa razne tendencioznosti, temelječe na napihovanju bojda slabe varnostne situacije, kot sem opisala uvodoma.",
         "True",
         "['Consequential_Oversimplification' 'Loaded_Language' 'Appeal_to_Values'\n 'Red_Herring']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "['tendencioznosti, temelječe na napihovanju bojda slabe varnostne situacije']",
         "[]",
         "[]",
         "[]",
         "['Vse te stvari bomo uredili s sprejetjem novele Zakona o nalogah in pooblastilih policije, ki bo bolje urejala ukrep prepovedi približevanja']",
         "[]",
         "[]",
         "['Vse te stvari bomo uredili s sprejetjem novele Zakona o nalogah in pooblastilih policije, ki bo bolje urejala ukrep prepovedi približevanja']",
         "[]",
         "[]",
         "['To so in bi morale biti družbene prioritete']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Hypocrisy",
         "Appeal_to_Hypocrisy",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Appeal to Hypocrisy technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. There are no explicit or implicit references to contradictions between positions or actions, which is essential for the Appeal to Hypocrisy technique.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[False]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/si/train-si-part_0000.parquet",
         null,
         null,
         "train",
         "{\"description\": null, \"verdict\": false}"
        ],
        [
         "259",
         "SI_interpelation_interior_1.txt",
         "0",
         "1089",
         "SI",
         "Tožilka se je zaradi nezaupanja v policijo varovanju odpovedala, saj je posumila, da je prišlo do nezakonitega vpogleda v nadzorno kamero, nameščeno na njeni hiši. Naj spomnim na znameniti stavek predsednika Vlade: \"Namesto, da bi bila varovana, je bila nadzorovana.\" Javno je priznal napake generalnega direktorja policije in ministra Poklukarja, toda ni ukrepal. In pri odstopu gospoda Jušića sta oba, tako predsednik vlade kot minister Poklukar, rekla, da je Jušić delal dobro in da je njegov odstop časten. Kaj je častnega v takšnem delu, kot sem ga zdaj predstavila? Na SVZ so razmere še zdaj nerešene in pred kratkim smo slišali, da mnenje, ali je potrebno ali ni potrebno varovanje tožilke in ostalih, ki delajo v pravnem sistemu, menjajo na SVZ hitreje kot mnenja, mnenje predsednik Vlade oziroma stališče o recimo omrežninah. Saj veste, v parih urah so rekli, da, potem pa ne. In kaj smo danes slišali? Da je bila v obdobju, ko SVZ ni varoval tožilke Gončinove, velika verjetnost, da je bil v Sloveniji morilec Satka Zovka, tako imenovani Cezar. In hvala bogu, tožilka je še živa.",
         "True",
         "['Appeal_to_Hypocrisy' 'Questioning_the_Reputation'\n 'Appeal_to_Fear-Prejudice']",
         "train",
         "['Kaj je častnega v takšnem delu, kot sem ga zdaj predstavila?']",
         "[]",
         "['Javno je priznal napake generalnega direktorja policije in ministra Poklukarja, toda ni ukrepal']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Da je bila v obdobju, ko SVZ ni varoval tožilke Gončinove, velika verjetnost, da je bil v Sloveniji morilec Satka Zovka, tako imenovani Cezar']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Hypocrisy",
         "Appeal_to_Hypocrisy",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "1",
         "Yes, the Appeal to Hypocrisy technique is used in the input.",
         "\"Javno je priznal napake generalnega direktorja policije in ministra Poklukarja, toda ni ukrepal\"",
         "['{\\n  \"explanation\": \"The Appeal to Hypocrisy technique is used in the input text by highlighting the inconsistency of the Prime Minister\\'s public acknowledgment of mistakes made by the police leadership while failing to take any action. This contradiction points to hypocrisy, as the Prime Minister criticizes the situation but does not follow through with necessary measures, thus undermining his credibility.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[False]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/si/train-si-part_0000.parquet",
         null,
         null,
         "train",
         "{\"description\": null, \"verdict\": true}"
        ],
        [
         "260",
         "SI_interpelation_interior_0.txt",
         "1825",
         "2018",
         "SI",
         "Glasujemo. Ravno sem bila obveščena, da je očitno prišlo do tehničnih težav s sistemom in da bi bilo treba za 15 minut prekiniti sejo, da bomo te tehnične težave rešili. Se iskreno opravičujem.",
         "False",
         "[]",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Hypocrisy",
         "Appeal_to_Hypocrisy",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Appeal to Hypocrisy technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. There are no explicit or implicit references to contradictions or past actions that would qualify as an Appeal to Hypocrisy.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[False]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/si/train-si-part_0000.parquet",
         null,
         null,
         "train",
         "{\"description\": null, \"verdict\": false}"
        ],
        [
         "263",
         "SI_interpelation_interior_0.txt",
         "3170",
         "3956",
         "SI",
         "Danes bomo govorili o delu ministra za notranje zadeve in o razlogih za njegovo razrešitev, v resnici pa bomo predstavljali tudi bistvo zgrešenih potez predsednika Vlade. On je namreč obljubljal eno, delal je popolnoma drugače. In kaj je pravzaprav največja napaka predsednika vlade? Da napak ne priznava. Dela in odloča se po navdihu. Kljub temu, da tako predsednik vlade kot v Svobodi ne priznavajo napak, sem prepričana, da globoko v sebi vedo, da je bila odstranitev Tatjane Bobnar in Boštjana Lindava napaka. Zaradi te napake je posledično prišlo do politizacije policije, krize vodenja razkroja institucij in zaradi velike ubogljivosti in želje ugajati šefu je stanje na področju varnosti slabo. Tako čutijo ljudje, tako govorijo ankete in tako vam bom zdaj dokazala s številkami.",
         "True",
         "['Consequential_Oversimplification' 'Appeal_to_Hypocrisy'\n 'Appeal_to_Popularity']",
         "train",
         "[]",
         "[]",
         "['Danes bomo govorili o delu ministra za notranje zadeve in o razlogih za njegovo razrešitev, v resnici pa bomo predstavljali tudi bistvo zgrešenih potez predsednika Vlade'\n 'On je namreč obljubljal eno, delal je popolnoma drugače'\n 'Kljub temu, da tako predsednik vlade kot v Svobodi ne priznavajo napak, sem prepričana, da globoko v sebi vedo, da je bila odstranitev Tatjane Bobnar in Boštjana Lindava napaka']",
         "[]",
         "[]",
         "[]",
         "['Tako čutijo ljudje, tako govorijo ankete']",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Zaradi te napake je posledično prišlo do politizacije policije, krize vodenja razkroja institucij in zaradi velike ubogljivosti in želje ugajati šefu je stanje na področju varnosti slabo']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Hypocrisy",
         "Appeal_to_Hypocrisy",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "1",
         "Yes, the Appeal to Hypocrisy technique is used in the input.",
         "\"Danes bomo govorili o delu ministra za notranje zadeve in o razlogih za njegovo razrešitev, v resnici pa bomo predstavljali tudi bistvo zgrešenih potez predsednika Vlade On je namreč obljubljal eno, delal je popolnoma drugače Kljub temu, da tako predsednik vlade kot v Svobodi ne priznavajo napak, sem prepričana, da globoko v sebi vedo, da je bila odstranitev Tatjane Bobnar in Boštjana Lindava napaka\"",
         "['{\\n  \"explanation\": \"The Appeal to Hypocrisy technique is used in the input text by highlighting the inconsistency between the Prime Minister\\'s promises and his actions. The speaker points out that the Prime Minister promised one thing but acted in a completely different manner, which directly attacks his credibility and reputation. This aligns with the definition of the technique, as it calls out the hypocrisy of the Prime Minister not acknowledging his mistakes while implying that he is aware of them.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[False]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/si/train-si-part_0000.parquet",
         null,
         null,
         "train",
         "{\"description\": null, \"verdict\": true}"
        ],
        [
         "265",
         "SI_interpelation_interior_2.txt",
         "3786",
         "5640",
         "SI",
         "Dovolite, da se referiram še na eno vašo značajsko lastnost, ki jo izpostavljate v odgovoru na interpelacijo. Zapišete: Visoka stopnja politične kulture bo vedno eno izmed mojih temeljnih vodil pri opravljanju funkcije. Pa se zato za zaključek dotaknimo še nezakonitega imenovanja direktorja policije. V odgovoru na interpelacijo zapišete: Nezakonitosti imenovanja magistra senata Jušića za generalnega direktorja policije. Posledično Upravno sodišče torej sploh ni moglo ugotoviti in je tudi ni ugotovilo. O nezakonitem imenovanju zato ne moremo in ne smemo govoriti. Spoštovani minister, pravnik doktor Pirnat, si je vendarle drznil govoriti. Rekel je: Če je akt posebne natečajne komisije uradniškega sveta nezakonit, potem je gotovo nezakonito tudi imenovanje generalnega direktorja. Tako nazadnje veleva tudi zdrav razum. Na dan sodbe Upravnega sodišča je potekel rok za odstop generalnega direktorja policije. Kajti, gospod Poklukar, če ste res pošten in iskren politik, potem se morava strinjati, da za nezakonito imenovan direktor ne more opravljati svoje funkcije niti en dan. Kakšen vtis v javnosti pa daje policija, če jo vodi nezakonito imenovan direktor, medtem ko v vseh ostalih zahteva zakonitost delovanja? In naprej, z vsakim dnem, ko je po odločitvi sodišča generalni direktor Policije vztrajal na svojem mestu, vi, gospod Poklukar, pa ga niste pozvali k odstopu, je minil dan strmoglavljenja politične kulture te vlade. In vi ste več kot dva meseca branili to stanje. Če ste torej pošten in iskren politik, katerega, kot sami pravite, visoka stopnja politične kulture bo vedno eno izmed temeljnih vodil pri opravljanju funkcije ministra, potem preprosto morate odstopiti, ker ste predolgo tolerirali nekaj, kar ni moč tolerirati, sploh ne na vrhu represivnega organa, ki bi moral biti vsem državljankam in državljanom za vzgled. Hvala.",
         "True",
         "['Exaggeration-Minimisation' 'Loaded_Language' 'Appeal_to_Hypocrisy'\n 'Appeal_to_Authority' 'Appeal_to_Values' 'Repetition']",
         "train",
         "[]",
         "[]",
         "['Kakšen vtis v javnosti pa daje policija, če jo vodi nezakonito imenovan direktor, medtem ko v vseh ostalih zahteva zakonitost delovanja?']",
         "[]",
         "['drznil govoriti']",
         "['pošten in iskren politik' 'pošten in iskren politik']",
         "[]",
         "[]",
         "[]",
         "[]",
         "['je minil dan strmoglavljenja politične kulture te vlade']",
         "[]",
         "[]",
         "[]",
         "['Če ste torej pošten in iskren politik, katerega, kot sami pravite, visoka stopnja politične kulture bo vedno eno izmed temeljnih vodil pri opravljanju funkcije ministra, potem preprosto morate odstopiti, ker ste predolgo tolerirali nekaj, kar ni moč tolerirati, sploh ne na vrhu represivnega organa, ki bi moral biti vsem državljankam in državljanom za vzgled']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['pravnik doktor Pirnat']",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Hypocrisy",
         "Appeal_to_Hypocrisy",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "1",
         "Yes, the Appeal to Hypocrisy technique is used in the input.",
         "\"Kakšen vtis v javnosti pa daje policija, če jo vodi nezakonito imenovan direktor, medtem ko v vseh ostalih zahteva zakonitost delovanja?\"",
         "['{\\n  \"explanation\": \"The Appeal to Hypocrisy technique is used in the input text by highlighting the inconsistency in the minister\\'s stance on legality. The speaker points out that while the minister demands legality in other areas, he tolerates an illegally appointed police director, thus attacking the minister\\'s reputation for being a principled politician. This aligns with the definition, as it calls out the hypocrisy of the minister\\'s actions compared to his stated values.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[False]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/si/train-si-part_0000.parquet",
         null,
         null,
         "train",
         "{\"description\": null, \"verdict\": true}"
        ],
        [
         "266",
         "SI_interpelation_interior_9.txt",
         "3480",
         "4437",
         "SI",
         "Spoštovani minister Poklukar! Državljanov ne zanimajo obljube o reorganizaciji, zanima jih, kdo in zakaj se je spravil na tožilko v zadevi Kavaški klan, kdaj bodo spisane in vložene ovadbe, kdaj se bodo začeli kazenski in predkazenski postopki glede tega, to nas zanima. Že 15 mesecev je minilo, odkar je tožilka vse odgovorne seznanila z nepravilnostmi, ko je šlo za varovanje predsednika vlade Goloba, se je zadeva rešila v treh mesecih. ko je šlo za varovanje predsednika vlade Goloba, se je zadeva rešila v treh mesecih. Ali vam je, minister Poklukar, pomembno samo varovanje predsednika vlade, za druge se pa ne sekirate, tudi za tiste, ki preganjajo mafijone, za predsednika vlade posebno varnostno službo, za ostale pa, kaj? Ne varnostno službo? Še veliko tega imam za povedati, ampak tudi kolegice in kolegi iz Poslanske skupine Nove Slovenije bodo kasneje v razpravi, kot tudi predlagateljica, ki je odlično uvedla zadevo, bodo kasneje še povedali.",
         "True",
         "['Appeal_to_Hypocrisy' 'Questioning_the_Reputation'\n 'Name_Calling-Labeling' 'Appeal_to_Popularity' 'Repetition']",
         "train",
         "['Ali vam je, minister Poklukar, pomembno samo varovanje predsednika vlade, za druge se pa ne sekirate, tudi za tiste, ki preganjajo mafijone, za predsednika vlade posebno varnostno službo, za ostale pa, kaj? Ne varnostno službo?']",
         "['mafijone']",
         "['Že 15 mesecev je minilo, odkar je tožilka vse odgovorne seznanila z nepravilnostmi, ko je šlo za varovanje predsednika vlade Goloba, se je zadeva rešila v treh mesecih. ko je šlo za varovanje predsednika vlade Goloba, se je zadeva rešila v treh mesecih']",
         "[]",
         "[]",
         "['to nas zanima'\n 'ko je šlo za varovanje predsednika vlade Goloba, se je zadeva rešila v treh mesecih']",
         "['Državljanov ne zanimajo obljube o reorganizaciji, zanima jih, kdo in zakaj se je spravil na tožilko v zadevi Kavaški klan, kdaj bodo spisane in vložene ovadbe, kdaj se bodo začeli kazenski in predkazenski postopki glede tega, to nas zanima']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Hypocrisy",
         "Appeal_to_Hypocrisy",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "1",
         "Yes, the Appeal to Hypocrisy technique is used in the input.",
         "\"Že 15 mesecev je minilo, odkar je tožilka vse odgovorne seznanila z nepravilnostmi, ko je šlo za varovanje predsednika vlade Goloba, se je zadeva rešila v treh mesecih. ko je šlo za varovanje predsednika vlade Goloba, se je zadeva rešila v treh mesecih\"",
         "['{\\n  \"explanation\": \"The Appeal to Hypocrisy technique is used in the input text by highlighting the inconsistency in the minister\\'s actions regarding the protection of the Prime Minister compared to the lack of action for others. The speaker points out that while issues concerning the Prime Minister were resolved quickly, similar issues affecting others have not been addressed, thus calling out the hypocrisy in prioritizing one over the other.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[False]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/si/train-si-part_0001.parquet",
         null,
         null,
         "train",
         "{\"description\": null, \"verdict\": true}"
        ],
        [
         "271",
         "SI_interpelation_interior_2.txt",
         "5869",
         "5947",
         "SI",
         "Spoštovana gospa predsednica Državnega zbora! Spoštovane poslanke in poslanci!",
         "False",
         "[]",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Hypocrisy",
         "Appeal_to_Hypocrisy",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Appeal to Hypocrisy technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. There are no explicit or implicit references to contradictions or past actions that would qualify as an Appeal to Hypocrisy.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[False]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/si/train-si-part_0001.parquet",
         null,
         null,
         "train",
         "{\"description\": null, \"verdict\": false}"
        ],
        [
         "272",
         "SI_interpelation_interior_4.txt",
         "3163",
         "7586",
         "SI",
         "V javnosti najodmevnejši očitek, ki so ga seveda prevzeli tudi predlagatelji, je očitek glede delovanja Centra za varovanje in zaščito. Situacija v zvezi z delovanjem in organizacijo Centra za varovanje in zaščito je bistveno bolj kompleksna, kot jo sicer nekateri radi prikazujejo in je trenutno v fazi preiskave morebitnih sumov storitve kaznivih dejanj pripadnikov te enote, ki jo vodi specializirano državno tožilstvo. Naj povem, da je Center za varovanje in zaščito vseeno zelo profesionalna enota policije z dolgoletno tradicijo in je sposobna brezhibno izvesti tudi najzahtevnejša varovanja, vključno z zagotavljanjem najvišje stopnje varovanja svetovnim voditeljem, ki so izpostavljeni visokim varnostnim tveganjem in grožnjam. Pri osebnem varovanju je ključno vzpostaviti zaupanje med varnostniki in varovano osebo. Iz lastnih izkušenj že drugič kot varovana oseba lahko potrdim, da policisti varnostniki svoje naloge opravljajo profesionalno in dosledno. Naj pa jasno povem, da je bil zadnji izredni nadzor nad Centrom za varovanje in zaščito uveden leta 2010 s strani takratne ministrice za notranje zadeve, zaradi tako imenovane afere katarske ure, in ponovni nadzor nad enoto leta 2012 s strani takratnega notranjega ministra. Dejstvo je tudi, da v vsem tem času direktorat za policijo in druge varnostne naloge ministrstva v obravnavo ni prejel nobene pritožbe zoper dela policistov varnostnikov centra za varovanje in zaščito. Nekdanji generalni direktor Policije magister Senad Jušić je takoj po nastopu funkcije leta 2023 aktivno pričel z različnimi aktivnostmi in ukrepi za izboljšanje stanja v Centru za varovanje in zaščito. Zaradi določenih nepravilnosti in napak v enoti je večkrat odredil notranje varnostne postopke, ki pa so v izključni pristojnosti generalnega direktorja policije in ne ministra za notranje zadeve. Kot minister za notranje zadeve sem na podlagi nekaterih medijskih objav o nepravilnostih v Centru za varovanje in zaščito 28. februarja lani v skladu s svojo zakonsko pristojnostjo direktoratu za policijo in druge varnostne naloge Ministrstva za notranje zadeve odredil izredni strokovni nadzor nad izvajanjem policijskih nalog in pooblastil v Centru za varovanje in zaščito, ki sta ga izvedla nadzornika direktorata. Po zaključnem nadzoru sta nadzornika direktorata konec avgusta leta 2024 zaključila poročilo o izrednem nadzoru v centru za varovanje in zaščito, ki je pod oznako stopnje zaupnosti interno. V samem izrednem strokovnem nadzoru so bile ugotovljene nepravilnosti in napake, ki so zapisane v poročilu izrednega nadzora. Na podlagi teh ugotovitev sem generalnemu direktorju policije z usmeritvami in obveznimi navodili ministra naložil ukrepe za izboljšanje stanja v Centru za varovanje in zaščito. Policija je takoj pristopila k odpravljanju nepravilnosti in pripravila načrt za odpravo ugotovljenih nepravilnosti in pomanjkljivosti na podlagi mojih usmeritev in obveznih navodil in ga začela tudi izvajati. V oddaji TV Slovenija Tarča lani decembra, so bile razkrite operativne informacije o varovanju varovanih oseb, izpostavljene so bile nepravilnosti in podani morebitni sumi storitve kaznivih dejanj v Centru za varovanje in zaščito na podlagi razkritih odklonov sem naslednji dan generalnemu direktorju policije izdal usmeritev in obvezno navodilo za reorganizacijo centra za varovanje in zaščito do 1. aprila letos. Prav tako sem zaradi javnega dvoma v zakonitost in transparentnost postopka javnega naročanja izdal sklep o izvedbi notranje revizije uporabe nastanitvenih kapacitet za potrebe Centra za varovanje in zaščito. Na podlagi medijskih očitkov in nekaterih neresničnih informacij ter predvsem zaradi velikega interesa javnosti, je bila delno umaknjena stopnja zaupnosti sporočila izrednega nadzora, ki ga je na tiskovni konferenci predstavil direktor direktorata za policijo in druge varnostne naloge, prav tako pa so ga prejeli nekateri mediji po dostopu do informacij javnega značaja in ga tudi javno objavili. Prav tako sem z elektronskim sporočilom zaprosil generalno državno tožilko, da v skladu s svojimi pristojnostmi naredi vse, da se čim prej preiščejo sumi morebitnih kaznivih dejanj v Centru za varovanje in zaščito. Njen odgovor je bil, da je preiskava že uvedena po uradni dolžnosti. Naj še dodam, da je Specializirano državno tožilstvo zahtevalo celotno poročilo o izrednem nadzoru, ki ga je Ministrstvo za notranje zadeve tudi predal.",
         "True",
         "['Exaggeration-Minimisation' 'Loaded_Language'\n 'Obfuscation-Vagueness-Confusion' 'Appeal_to_Authority'\n 'Appeal_to_Values' 'Appeal_to_Popularity' 'Doubt']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "['seveda'\n 'vseeno zelo profesionalna enota policije z dolgoletno tradicijo'\n 'brezhibno izvesti tudi najzahtevnejša varovanja, vključno z zagotavljanjem najvišje stopnje varovanja'\n 'operativne informacije']",
         "[]",
         "['ni prejel nobene pritožbe']",
         "['nekaterih neresničnih informacij']",
         "[]",
         "[]",
         "['V javnosti najodmevnejši očitek' 'aktivno pričel']",
         "[]",
         "[]",
         "[]",
         "['javnega dvoma v zakonitost in transparentnost postopka javnega naročanja']",
         "['bolj kompleksna, kot jo sicer nekateri radi prikazujejo'\n 'različnimi aktivnostmi in ukrepi' 'določenih nepravilnosti in napak'\n 'operativne informacije' 'nepravilnosti'\n 'morebitni sumi storitve kaznivih dejanj' 'javnega dvoma']",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Naj povem, da je Center za varovanje in zaščito vseeno zelo profesionalna enota policije z dolgoletno tradicijo in je sposobna brezhibno izvesti tudi najzahtevnejša varovanja, vključno z zagotavljanjem najvišje stopnje varovanja svetovnim voditeljem, ki so izpostavljeni visokim varnostnim tveganjem in grožnjam'\n 'kot varovana oseba lahko potrdim' 'Kot minister za notranje zadeve'\n 'v skladu s svojo zakonsko pristojnostjo' 'nadzornika direktorata'\n 'izrednem strokovnem nadzoru']",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Hypocrisy",
         "Appeal_to_Hypocrisy",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Appeal to Hypocrisy technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not contain any instances of the Appeal to Hypocrisy technique, as it does not attack the reputation of any individual by charging them with hypocrisy or inconsistency. The text focuses on the operations and oversight of the Center for Protection and Security without making any comparisons to past actions or positions that would indicate hypocrisy.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[False]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/si/train-si-part_0001.parquet",
         null,
         null,
         "train",
         "{\"description\": null, \"verdict\": false}"
        ],
        [
         "275",
         "SI_interpelation_interior_10.txt",
         "554",
         "2314",
         "SI",
         "Na tem mestu Socialni demokrati opozarjamo, da se je v razmerju do vodstvenih kadrov v policiji doslej že bistveno prevečkrat pozabljalo na potrebo po ohranjanju zakonskih določb, gospod Jušić je položaj obdržal kljub ugotovitvam upravnega sodišča in po zaslugi intervenciji politike, zato zahtevamo, da minister in koalicija opravita nujen razmislek o spremembi načina imenovanja generalnega direktorja policije na način, ki v največji možni meri politično izključi iz postopkov imenovanja in izbire. Pred navedenim pa so se odprli tudi očitki zoper strokovnost ministra, ki izhaja iz katastrofalnega stanja v Centru za varovanje in zaščito. Specializirana tožilka, gospa Gončin, je pričala o napakah v okviru njenega varovanja in CVZ očita, da naj bi nepooblaščeno zbirali njene zasebne podatke. Sama je celo izjavila, da je izgubila zaupanje v policijo. Sporne okoliščine se pojavljajo tudi v razmerju zaposlitve člana osebnega varovanja tožilke. Specializirana tožilka Gončin je proti zaposlenemu v centru spisala tudi kazensko ovadbo, in sicer zaradi nepooblaščenega vstopa v videonadzorni sistem, ki je namenjen njenemu varovanju. Članu njenega varovanja očitno kaznivo dejanje zlorabe pooblastil. Kljub navedenemu pa je pod ministrom in nekdanjim generalnim direktorjem v okviru CVZ celo napredoval. Dejstvo je, da je stanje na CVZ odgovornost ministra za notranje zadeve, saj ima na podlagi določb Zakona o organiziranosti in delu v policiji vsa pooblastila, ki mu preko podajanja usmeritev omogočajo, da stanje posredno z intervencijo v vodstvo policije odpravi. Zato je nesprejemljivo, da takšno stanje na CVZ vlada že kar 14 mesecev. Navsezadnje pa gre za odgovornost ministra tudi zato, ker je na vodilno mesto v policiji imenovan neprimeren kader.",
         "True",
         "['Loaded_Language' 'Appeal_to_Hypocrisy' 'Questioning_the_Reputation'\n 'Appeal_to_Authority' 'Doubt' 'Appeal_to_Fear-Prejudice']",
         "train",
         "['opozarjamo, da se je v razmerju do vodstvenih kadrov v policiji doslej že bistveno prevečkrat pozabljalo na potrebo po ohranjanju zakonskih določb, gospod Jušić je položaj obdržal kljub ugotovitvam upravnega sodišča in po zaslugi intervenciji politike'\n 'očitki zoper strokovnost ministra'\n 'Kljub navedenemu pa je pod ministrom in nekdanjim generalnim direktorjem v okviru CVZ celo napredoval']",
         "[]",
         "['Kljub navedenemu pa je pod ministrom in nekdanjim generalnim direktorjem v okviru CVZ celo napredoval']",
         "[]",
         "['katastrofalnega stanja']",
         "[]",
         "[]",
         "['Navsezadnje pa gre za odgovornost ministra tudi zato, ker je na vodilno mesto v policiji imenovan neprimeren kader']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['zaradi nepooblaščenega vstopa v videonadzorni sistem, ki je namenjen njenemu varovanju']",
         "[]",
         "['Sama je celo izjavila, da je izgubila zaupanje v policijo']",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Hypocrisy",
         "Appeal_to_Hypocrisy",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "1",
         "Yes, the Appeal to Hypocrisy technique is used in the input.",
         "\"Kljub navedenemu pa je pod ministrom in nekdanjim generalnim direktorjem v okviru CVZ celo napredoval\"",
         "['{\\n  \"explanation\": \"The Appeal to Hypocrisy technique is used in the input text by highlighting the inconsistency in the minister\\'s actions. The excerpt points out that despite the problematic situation in the CVZ, a member of the security team has advanced under the minister\\'s leadership, suggesting hypocrisy in the minister\\'s ability to manage the situation while allowing such advancements.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[False]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/si/train-si-part_0001.parquet",
         null,
         null,
         "train",
         "{\"description\": null, \"verdict\": true}"
        ],
        [
         "286",
         "20231208_URW_BG_72.txt",
         "3279",
         "3627",
         "BG",
         "Аз обаче не взех репликата за това, а взех репликата, господин Гуцанов, за да Ви кажа, че не само лъжете в това Ваше изказване, но и от 29 септември, когато излязохте на тази трибуна да ни кажете, че бензинът става 4 лв., измина доста време, а вече той е със 17 стотинки надолу от деня, в който Вие го казахте, и нямат нищо общо с 4 лв. Благодаря. ",
         "True",
         "['Appeal_to_Hypocrisy' 'Red_Herring']",
         "train",
         "[]",
         "[]",
         "['Аз обаче не взех репликата за това, а взех репликата, господин Гуцанов, за да Ви кажа, че не само лъжете в това Ваше изказване, но и от 29 септември, когато излязохте на тази трибуна да ни кажете, че бензинът става 4 лв., измина доста време, а вече той е със 17 стотинки надолу от деня, в който Вие го казахте, и нямат нищо общо с 4 лв']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Аз обаче не взех репликата за това, а взех репликата, господин Гуцанов, за да Ви кажа, че не само лъжете в това Ваше изказване, но и от 29 септември, когато излязохте на тази трибуна да ни кажете, че бензинът става 4 лв., измина доста време, а вече той е със 17 стотинки надолу от деня, в който Вие го казахте, и нямат нищо общо с 4 лв']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Hypocrisy",
         "Appeal_to_Hypocrisy",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "1",
         "Yes, the Appeal to Hypocrisy technique is used in the input.",
         "\"Аз обаче не взех репликата за това, а взех репликата, господин Гуцанов, за да Ви кажа, че не само лъжете в това Ваше изказване, но и от 29 септември, когато излязохте на тази трибуна да ни кажете, че бензинът става 4 лв., измина доста време, а вече той е със 17 стотинки надолу от деня, в който Вие го казахте, и нямат нищо общо с 4 лв\"",
         "['{\\n  \"explanation\": \"The Appeal to Hypocrisy technique is used in the input text as the speaker accuses Mr. Gutsanov of lying about the price of gasoline, highlighting the inconsistency between his previous statement and the current price. This directly attacks Gutsanov\\'s credibility by pointing out his past claim that gasoline would rise to 4 BGN, which is now proven false.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[False]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/bg/train-bg-part_0009.parquet",
         "[None]",
         "[None]",
         "train",
         "{\"description\": null, \"verdict\": true}"
        ],
        [
         "332",
         "20231208_URW_BG_73.txt",
         "5323",
         "5459",
         "BG",
         "КОСТАДИН КОСТАДИНОВ (ВЪЗРАЖДАНЕ, от място): А докато беше в БСП до миналата година, дали беше проруска партия?! (Реплики от ВЪЗРАЖДАНЕ.)",
         "True",
         "['Appeal_to_Hypocrisy']",
         "train",
         "[]",
         "[]",
         "['А докато беше в БСП до миналата година, дали беше проруска партия?!']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Hypocrisy",
         "Appeal_to_Hypocrisy",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "1",
         "Yes, the Appeal to Hypocrisy technique is used in the input.",
         "\"А докато беше в БСП до миналата година, дали беше проруска партия?!\"",
         "['{\\n  \"explanation\": \"The Appeal to Hypocrisy technique is used in the input text as it directly calls out the hypocrisy of the target by questioning their past affiliation with the BСП (Bulgarian Socialist Party) and implying that they were a pro-Russian party at that time. This highlights a contradiction between their past actions and their current stance.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[False]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/bg/train-bg-part_0002.parquet",
         null,
         null,
         "train",
         "{\"description\": null, \"verdict\": true}"
        ],
        [
         "376",
         "pl_eu_12_06_2024_n01.txt",
         "0",
         "135",
         "PL",
         "Wicemarszałek Włodzimierz Czarzasty:\nBardzo proszę panią poseł Danutę Jazłowiecką\no przedstawienie sprawozdania komisji.\nBardzo proszę.",
         "False",
         "[]",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Questioning_the_Reputation",
         "Questioning_the_Reputation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Questioning the Reputation technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not contain any elements that attack or undermine the reputation of any individual. It is a straightforward request for a report without any negative claims or implications about the character or moral stature of the individuals involved.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[False]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/pl/train-pl-part_0005.parquet",
         null,
         null,
         "train",
         "{\"description\": null, \"verdict\": false}"
        ],
        [
         "379",
         "pl_abortion_11_04_2024_n08.txt",
         "2952",
         "3136",
         "PL",
         "Czy czas najwyższy, by w końcu dopuścić\ndekryminalizację kradzieży i pomocnictwa w kradzieżach\nz włamaniem? Dlaczego tak nie lubicie dzieci?\nDlaczego chcecie pozwolić na ich zabijanie?",
         "True",
         "['False_Equivalence' 'Loaded_Language' 'Whataboutism' 'Straw_Man']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "['zabijanie?']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Czy czas najwyższy, by w końcu dopuścić dekryminalizację kradzieży i pomocnictwa w kradzieżach z włamaniem?']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Dlaczego tak nie lubicie dzieci?']",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Questioning_the_Reputation",
         "Questioning_the_Reputation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Questioning the Reputation technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not contain any explicit attacks on the reputation or character of a target. It poses questions about policies and expresses concern for children, but does not undermine anyone\\'s moral stature or credibility, which is essential for the Questioning the Reputation technique.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[False]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/pl/train-pl-part_0005.parquet",
         null,
         null,
         "train",
         "{\"description\": null, \"verdict\": false}"
        ],
        [
         "381",
         "pl_abortion_11_04_2024_n06.txt",
         "1965",
         "2258",
         "PL",
         "Wicemarszałek Włodzimierz Czarzasty:\nPrzepraszam, pani posłanko, przepraszam bardzo.\n(Poseł Krystyna Skowrońska: Proszę zwrócić uwagę.)\nAle zaraz, proszę państwa, proszę państwa…\n(Wypowiedź poza mikrofonem)\n(Poseł Krystyna Skowrońska: Ale nie zagłusza…)\n(Poseł Mariusz Krystian: A wy możecie?)",
         "False",
         "[]",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Questioning_the_Reputation",
         "Questioning_the_Reputation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Questioning the Reputation technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not contain any elements that attack the reputation of a target or make negative claims about their character or moral stature. There are no instances of undermining reputation or credibility, which aligns with the expert\\'s verdict that the Questioning the Reputation technique is not used.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[False]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/pl/train-pl-part_0005.parquet",
         null,
         null,
         "train",
         "{\"description\": null, \"verdict\": false}"
        ],
        [
         "383",
         "pl_abortion_11_04_2024_n03.txt",
         "10068",
         "10611",
         "PL",
         "Państwo polskie zaoszczędziło na zdrowiu i życiu\nPolek 49 mln przez ostatnie 8 lat. Na aborcje\nwykonywane u kobiet z Polski składają się wszystkie inne\npaństwa, takie jak Holandia, Francja czy Belgia, ale\nteż prywatni darczyńcy. Każdego dnia dzięki pieniądzom\notrzymanym z organizacji kobiecych około\nsiedmiu kobiet wyjeżdża do Holandii na zabieg\naborcji w drugim trymestrze ciąży. Wiele z nich\npotrzebuje wsparcia finansowego. To są często ciąże chciane,\nto są często ciąże wyczekane, ale te kobiety nie\nmogą otrzymać pomocy w swoim państwie.",
         "True",
         "['Flag_Waving' 'Questioning_the_Reputation' 'Appeal_to_Popularity']",
         "train",
         "['Państwo polskie zaoszczędziło na zdrowiu i życiu Polek 49 mln przez ostatnie 8 lat']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Na aborcje wykonywane u kobiet z Polski składają się wszystkie inne państwa, takie jak Holandia, Francja czy Belgia, ale też prywatni darczyńcy. Każdego dnia dzięki pieniądzom otrzymanym z organizacji kobiecych około siedmiu kobiet wyjeżdża do Holandii na zabieg aborcji w drugim trymestrze ciąży']",
         "[]",
         "[]",
         "['te kobiety nie mogą otrzymać pomocy w swoim państwie']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Questioning_the_Reputation",
         "Questioning_the_Reputation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "1",
         "Yes, the Questioning the Reputation technique is used in the input.",
         "\"Państwo polskie zaoszczędziło na zdrowiu i życiu Polek 49 mln przez ostatnie 8 lat\"",
         "['{\\n  \"explanation\": \"The technique of Questioning the Reputation is explicitly used in the input text by making a strong negative claim about the Polish state, stating that it has \\'saved\\' money at the expense of the health and lives of women. This undermines the reputation and moral standing of the state, suggesting negligence or a lack of care for its citizens, which aligns with the definition of the technique.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[False]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/pl/train-pl-part_0005.parquet",
         null,
         null,
         "train",
         "{\"description\": null, \"verdict\": true}"
        ],
        [
         "384",
         "pl_defence_22_05_2024_n01.txt",
         "3494",
         "3606",
         "PL",
         "A więc trzeba za to wszystko przeprosić i potem\nrealizować program Prawa i Sprawiedliwości, bo to\ndobry program.",
         "True",
         "['Slogans' 'False_Dilemma-No_Choice']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['bo to dobry program']",
         "[]",
         "[]",
         "[]",
         "['A więc trzeba za to wszystko przeprosić i potem realizować program Prawa i Sprawiedliwości, bo to dobry program']",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Questioning_the_Reputation",
         "Questioning_the_Reputation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Questioning the Reputation technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not contain any elements that attack the reputation of a target or make negative claims about it. It focuses on the need to apologize and implement a program, which does not align with the definition of Questioning the Reputation.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[False]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/pl/train-pl-part_0005.parquet",
         null,
         null,
         "train",
         "{\"description\": null, \"verdict\": false}"
        ],
        [
         "385",
         "pl_abortion_11_04_2024_n03.txt",
         "6145",
         "6687",
         "PL",
         "W szpitalach na Podlasiu i Podkarpaciu nawet ten\npseudokompromis nie działał, bo żadna, ale to żadna,\nkobieta od lat, nawet w przypadku zagrożenia\nzdrowia i życia, nie mogła tam otrzymać pomocy i była\nodsyłana z kwitkiem, chociaż w zasadzie raczej bez\nkwitka, bo lekarze odmawiali aborcji, zasłaniając się\nklauzulą sumienia. I chociaż łamali w ten sposób prawo,\nnie wyznaczali podmiotu leczniczego, w którym\nkobieta mogłaby przerwać ciążę, i nie dokumentowali\ntej odmowy na piśmie. Łamanie praw pacjentek?\nKto by tam się przejmował kobietami.",
         "True",
         "['Loaded_Language' 'Appeal_to_Hypocrisy' 'Questioning_the_Reputation'\n 'Appeal_to_Values' 'Repetition']",
         "train",
         "['I chociaż łamali w ten sposób prawo, nie wyznaczali podmiotu leczniczego, w którym kobieta mogłaby przerwać ciążę, i nie dokumentowali tej odmowy na piśmie']",
         "[]",
         "['lekarze odmawiali aborcji, zasłaniając się klauzulą sumienia']",
         "[]",
         "['pseudokompromis' 'była odsyłana z kwitkiem' 'Kto by tam się przejmował']",
         "['żadna' 'żadna']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['bo lekarze odmawiali aborcji, zasłaniając się klauzulą sumienia'\n 'Łamanie praw pacjentek? Kto by tam się przejmował kobietami']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Questioning_the_Reputation",
         "Questioning_the_Reputation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "1",
         "Yes, the Questioning the Reputation technique is used in the input.",
         "\"I chociaż łamali w ten sposób prawo, nie wyznaczali podmiotu leczniczego, w którym kobieta mogłaby przerwać ciążę, i nie dokumentowali tej odmowy na piśmie\"",
         "['{\\n  \"explanation\": \"The Questioning the Reputation technique is used in the input text by making strong negative claims about the behavior of doctors who refuse to provide necessary medical assistance, thereby undermining their moral stature and credibility. The excerpt highlights their illegal actions and lack of accountability, which attacks their reputation as healthcare providers.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[False]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/pl/train-pl-part_0005.parquet",
         null,
         null,
         "train",
         "{\"description\": null, \"verdict\": true}"
        ],
        [
         "386",
         "pl_abortion_11_04_2024_n06.txt",
         "3465",
         "3708",
         "PL",
         "Poseł Monika Rosa:\nPanie Pośle! Pan nigdy nie był w ciąży i pan nie\nwie, co to znaczy nosić dziecko i się bać. A więc proszę\nnie wychodzić mi z jakimiś moralnymi według pana\ni etycznymi komentarzami. (Oklaski)\n(Poseł Piotr Kaleta: Ojej, ojej…)",
         "True",
         "['Loaded_Language' 'Questioning_the_Reputation' 'Straw_Man']",
         "train",
         "['Pan nigdy nie był w ciąży i pan nie wie, co to znaczy nosić dziecko i się bać. A więc proszę nie wychodzić mi z jakimiś moralnymi według pana i etycznymi komentarzami']",
         "[]",
         "[]",
         "[]",
         "['nie wychodzić mi']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Pan nigdy nie był w ciąży i pan nie wie, co to znaczy nosić dziecko i się bać. A więc proszę nie wychodzić mi z jakimiś moralnymi według pana i etycznymi komentarzami']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Questioning_the_Reputation",
         "Questioning_the_Reputation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "1",
         "Yes, the Questioning the Reputation technique is used in the input.",
         "\"Pan nigdy nie był w ciąży i pan nie wie, co to znaczy nosić dziecko i się bać. A więc proszę nie wychodzić mi z jakimiś moralnymi według pana i etycznymi komentarzami\"",
         "['{\\n  \"explanation\": \"The Questioning the Reputation technique is explicitly used in the input text as the speaker attacks the reputation of the opponent by stating that he has never been pregnant and therefore cannot understand the associated fears. This undermines his moral authority to make ethical comments on the subject, aligning with the technique\\'s definition of attacking character and moral stature.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[False]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/pl/train-pl-part_0004.parquet",
         null,
         null,
         "train",
         "{\"description\": null, \"verdict\": true}"
        ],
        [
         "387",
         "pl_abortion_11_04_2024_n01.txt",
         "4660",
         "5608",
         "PL",
         "Musimy się zgodzić na to, żeby ta pomoc nie groziła\ntym, że rozdziela się rodziny, rozdziela się ojców i\ndzieci, rozdziela się babcie oraz ciocie czy też przyjaciółki\nrodziny. Ogólnodostępne dane zawierające informacje\no treści wyroków polskich sądów pokazują, że w\nostatnich latach za pomoc kobiecie w aborcji zostali skazani\nm.in.: ojciec, który przekazał córce pieniądze na\npokrycie kosztów jej zabiegu aborcji w klinice w Holandii;\nmatka, która pomogła córce wyjechać na zabieg aborcji\ndo kliniki w Holandii i która opłaciła córce koszty\nprzejazdu i samego zabiegu; kolejna matka, matka kobiety,\nżyjącej kobiety, która zorganizowała swojej córce\nwyjazd na zabieg aborcji i również opłaciła jej środek\ntransportu; następna matka – to samo, dokładnie taki\nsam przypadek. Tych wyroków jest w Polsce dużo.\nPaństwo może sobie nie zdają z tego sprawy, bo być może\nto jest takie podejście: nie interesujemy się, niech sobie\nkobiety to załatwiają same.",
         "True",
         "['Appeal_to_Pity' 'Appeal_to_Values' 'False_Dilemma-No_Choice' 'Doubt']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['bo być może to jest takie podejście: nie interesujemy się, niech sobie kobiety to załatwiają same']",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Ogólnodostępne dane zawierające informacje o treści wyroków polskich sądów pokazują, że w ostatnich latach za pomoc kobiecie w aborcji zostali skazani m.in.: ojciec, który przekazał córce pieniądze na pokrycie kosztów jej zabiegu aborcji w klinice w Holandii; matka, która pomogła córce wyjechać na zabieg aborcji do kliniki w Holandii i która opłaciła córce koszty przejazdu i samego zabiegu; kolejna matka, matka kobiety, żyjącej kobiety, która zorganizowała swojej córce wyjazd na zabieg aborcji i również opłaciła jej środek transportu; następna matka – to samo, dokładnie taki sam przypadek']",
         "[]",
         "['Musimy się zgodzić na to, żeby ta pomoc nie groziła tym, że rozdziela się rodziny, rozdziela się ojców i dzieci, rozdziela się babcie oraz ciocie czy też przyjaciółki rodziny']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Musimy się zgodzić na to, żeby ta pomoc nie groziła tym, że rozdziela się rodziny, rozdziela się ojców i dzieci, rozdziela się babcie oraz ciocie czy też przyjaciółki rodziny']",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Questioning_the_Reputation",
         "Questioning_the_Reputation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Questioning the Reputation technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not contain any strong negative claims aimed at undermining the reputation or moral stature of any individual or group. It discusses the consequences of legal actions related to abortion without attacking the character of those involved. Therefore, the Questioning the Reputation technique is not used.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[False]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/pl/train-pl-part_0004.parquet",
         null,
         null,
         "train",
         "{\"description\": null, \"verdict\": false}"
        ],
        [
         "388",
         "pl_eu_12_06_2024_n02.txt",
         "2901",
         "3285",
         "PL",
         "Niewątpliwie priorytetem będzie kwestia poprawy obronności. Cieszę się, że rząd Donalda Tuska po\nzmianie, po 15 października przejął stery naszej dyplomacji, bo to jest gwarancja tego, że wykorzystamy\nten czas jak najlepiej (Dzwonek) dla zapewnienia i realizacji interesów Polski, m.in. poprzez poprawę bezpieczeństwa i zaangażowania w tę kwestię członków\nUnii Europejskiej. Dziękuję.",
         "True",
         "['Consequential_Oversimplification' 'Flag_Waving']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['dla zapewnienia i realizacji interesów Polski']",
         "[]",
         "['rząd Donalda Tuska po zmianie, po 15 października przejął stery naszej dyplomacji, bo to jest gwarancja tego, że wykorzystamy ten czas jak najlepiej']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Questioning_the_Reputation",
         "Questioning_the_Reputation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Questioning the Reputation technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not contain any elements that attack or undermine the reputation of any individual or group. It focuses on positive statements regarding the government\\'s actions and priorities without making negative claims about any opponents or their character.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[False]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/pl/train-pl-part_0004.parquet",
         null,
         null,
         "train",
         "{\"description\": null, \"verdict\": false}"
        ],
        [
         "392",
         "pl_abortion_11_04_2024_n04.txt",
         "7452",
         "7724",
         "PL",
         "Wicemarszałek Włodzimierz Czarzasty:\nDziękuję bardzo.\nZanim poproszę panią poseł, chcę przeprosić, bo\nnie wiem, czy jeszcze jest grupa młodzieży z Jędrzejowa.\nJesteście jeszcze państwo? Są, jesteście.\nWitam was serdecznie. (Oklaski)\n(Poseł Urszula Pasławska: Pozdrawiamy.)",
         "False",
         "[]",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Questioning_the_Reputation",
         "Questioning_the_Reputation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Questioning the Reputation technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not contain any elements that attack or undermine the reputation of any individual. It is a polite greeting and does not include any negative claims or implications about character or moral stature, which are essential for the use of the Questioning the Reputation technique.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[False]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/pl/train-pl-part_0004.parquet",
         null,
         null,
         "train",
         "{\"description\": null, \"verdict\": false}"
        ],
        [
         "394",
         "pl_defence_22_05_2024_n02.txt",
         "3985",
         "4869",
         "PL",
         "Trzeba zwiększyć polskie zdolności produkcyjne,\nzamawiać dużo sprzętu w polskich firmach, zarówno\nprywatnych, jak i publicznych, trzeba też im płacić\nza utrzymanie zdolności produkcyjnych na czas\nwojny oraz wycofać się z konwencji ottawskiej o zakazie\nużywania min przeciwpiechotnych. Nie są stroną tej\nkonwencji Rosja, Stany Zjednoczone, Chiny, Indie,\nIzrael, Egipt. Ukraina, gdyby nie miny\nprzeciwpiechotne, nie broniłaby się skutecznie przed Rosją.\nMusimy jak najszybciej wypowiedzieć tę konwencję.\nNie jesteśmy w tym momencie gotowi do wojny.\nJedni i drudzy rządziliście Polską od 20 lat i nie\nprzygotowaliście nas do obrony na czas wojny. PiS\nprzygotowywał się tylko do wojny z Platformą, Platforma\nprzygotowywała się do wojny z PiS-em, a Polska nie\njest gotowa. Nasze Siły Zbrojne pod kątem liczby\nrezerw, liczby czołgów czy też liczby\nsprzętu są najsłabsze od 80 lat. (Oklaski)",
         "True",
         "['Causal_Oversimplification' 'Exaggeration-Minimisation' 'Appeal_to_Time'\n 'Questioning_the_Reputation' 'Whataboutism' 'Doubt'\n 'Appeal_to_Fear-Prejudice']",
         "train",
         "['Jedni i drudzy rządziliście Polską od 20 lat i nie przygotowaliście nas do obrony na czas wojny']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Nasze Siły Zbrojne pod kątem liczby rezerw, liczby czołgów czy też liczby sprzętu są najsłabsze od 80 lat']",
         "[]",
         "[]",
         "['PiS przygotowywał się tylko do wojny z Platformą, Platforma przygotowywała się do wojny z PiS-em, a Polska nie jest gotowa']",
         "[]",
         "[]",
         "['Musimy jak najszybciej wypowiedzieć tę konwencję']",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Nie jesteśmy w tym momencie gotowi do wojny'\n 'Jedni i drudzy rządziliście Polską od 20 lat i nie przygotowaliście nas do obrony na czas wojny']",
         "['Ukraina, gdyby nie miny przeciwpiechotne, nie broniłaby się skutecznie przed Rosją']",
         "[]",
         "[]",
         "['PiS przygotowywał się tylko do wojny z Platformą, Platforma przygotowywała się do wojny z PiS-em, a Polska nie jest gotowa']",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Questioning_the_Reputation",
         "Questioning_the_Reputation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "1",
         "Yes, the Questioning the Reputation technique is used in the input.",
         "\"Jedni i drudzy rządziliście Polską od 20 lat i nie przygotowaliście nas do obrony na czas wojny\"",
         "['{\\n  \"explanation\": \"The Questioning the Reputation technique is explicitly used in the input text through the statement that criticizes both political parties for their failure to prepare Poland for defense over the past 20 years. This attack on their competence and moral responsibility undermines their reputation, aligning with the technique\\'s definition of making strong negative claims to damage the target\\'s character and moral stature.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[False]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/pl/train-pl-part_0004.parquet",
         null,
         null,
         "train",
         "{\"description\": null, \"verdict\": true}"
        ],
        [
         "395",
         "pl_abortion_11_04_2024_n02.txt",
         "2916",
         "3709",
         "PL",
         "Ale to nie koniec. Art. 152, jak wiemy, jest\nprzyczyną tragedii także w polskich szpitalach, bo od\n30 lat aborcja jest traktowana nie jak zabieg\nmedyczny, tylko jak przestępstwo. To sprawia, że lekarze nie\nuczą się o tym, jak przeprowadzać aborcję, nie mają\npraktyki, nie wiedzą, jak to się robi, i kiedy stają\nwobec takiej sytuacji, że mają przerwać ciążę, to się\nboją, próbują tego uniknąć. Nawet wtedy, kiedy ta\ndecyzja zagraża życiu i zdrowiu pacjentki.\nBo brakuje im kompetencji, bo boją się o swoją karierę.\nI właśnie to spychanie aborcji do sfery świata\nkryminalnego doprowadziło do śmierci Izy z Pszczyny,\ndoprowadziło do śmierci Doroty z Nowego Targu i innych\nmłodych kobiet, które miały przed sobą całe życie,\nktóre miały małe dzieci, które mogły dalej\nżyć i wychowywać swoje dzieci.",
         "True",
         "['Causal_Oversimplification' 'Loaded_Language'\n 'Questioning_the_Reputation' 'Appeal_to_Values' 'Doubt']",
         "train",
         "['bo boją się o swoją karierę']",
         "[]",
         "[]",
         "[]",
         "['spychanie aborcji do sfery świata kryminalnego']",
         "[]",
         "[]",
         "['Art. 152, jak wiemy, jest przyczyną tragedii także w polskich szpitalach, bo od 30 lat aborcja jest traktowana nie jak zabieg medyczny, tylko jak przestępstwo'\n 'Bo brakuje im kompetencji']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Nawet wtedy, kiedy ta decyzja zagraża życiu i zdrowiu pacjentki'\n 'które miały przed sobą całe życie, które miały małe dzieci, które mogły dalej żyć i wychowywać swoje dzieci']",
         "[]",
         "[]",
         "[]",
         "[]",
         "['To sprawia, że lekarze nie uczą się o tym, jak przeprowadzać aborcję, nie mają praktyki, nie wiedzą, jak to się robi, i kiedy stają wobec takiej sytuacji, że mają przerwać ciążę, to się boją, próbują tego uniknąć'\n 'I właśnie to spychanie aborcji do sfery świata kryminalnego doprowadziło do śmierci Izy z Pszczyny, doprowadziło do śmierci Doroty z Nowego Targu i innych młodych kobiet, które miały przed sobą całe życie, które miały małe dzieci, które mogły dalej żyć i wychowywać swoje dzieci']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Questioning_the_Reputation",
         "Questioning_the_Reputation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "1",
         "Yes, the Questioning the Reputation technique is used in the input.",
         "\"bo boją się o swoją karierę\"",
         "['{\\n  \"explanation\": \"The Questioning the Reputation technique is used in the input text by implying that doctors are fearful of their careers due to the criminalization of abortion, which undermines their professional integrity and moral character. This suggests that their reputation is at risk, thus attacking their credibility and moral stature in the context of performing abortions.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[False]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/pl/train-pl-part_0004.parquet",
         null,
         null,
         "train",
         "{\"description\": null, \"verdict\": true}"
        ],
        [
         "397",
         "pl_abortion_11_04_2024_n03.txt",
         "9280",
         "9741",
         "PL",
         "Zakaz aborcji zabija i nie likwiduje aborcji. Zakaz\naborcji powoduje, że w polskich szpitalach nie ma\ndzisiaj bezpiecznej aborcji. Ale od 30 lat te aborcje się\ndzieją tylko dlatego, że poszczególne osoby znajdują\nsposób na to, żeby je zrobić. Ostatnie lata to zasługa\ngrup nieformalnych i aktywistek działających\nw Polsce – to Aborcyjny Dream Team czy Aborcja bez Granic.\nWiem, że jesteście, pozdrawiam was bardzo serdecznie\ni dziękuję za waszą pracę. (Oklaski)",
         "True",
         "['Consequential_Oversimplification' 'Causal_Oversimplification'\n 'Loaded_Language' 'Flag_Waving' 'Appeal_to_Popularity' 'Doubt'\n 'Appeal_to_Fear-Prejudice']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "['zabija']",
         "[]",
         "['Ostatnie lata to zasługa grup nieformalnych i aktywistek działających w Polsce – to Aborcyjny Dream Team czy Aborcja bez Granic']",
         "['Zakaz aborcji zabija i nie likwiduje aborcji']",
         "[]",
         "['Wiem, że jesteście, pozdrawiam']",
         "[]",
         "['Zakaz aborcji zabija i nie likwiduje aborcji']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Zakaz aborcji zabija']",
         "['Zakaz aborcji powoduje, że w polskich szpitalach nie ma dzisiaj bezpiecznej aborcji']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Questioning_the_Reputation",
         "Questioning_the_Reputation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Questioning the Reputation technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not contain any elements that attack the reputation of a target or make strong negative claims about it. It focuses on discussing the issue of abortion and acknowledges the efforts of certain groups without undermining their character or moral stature.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[False]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/pl/train-pl-part_0006.parquet",
         null,
         null,
         "train",
         "{\"description\": null, \"verdict\": false}"
        ],
        [
         "398",
         "pl_abortion_11_04_2024_n04.txt",
         "7809",
         "7883",
         "PL",
         "Bardzo proszę panią poseł Urszulę Pasławską o zabranie głosu.\nProszę, Ula.",
         "False",
         "[]",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Questioning_the_Reputation",
         "Questioning_the_Reputation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Questioning the Reputation technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not contain any elements that attack or undermine the reputation of an individual. It simply requests a member of parliament to speak, without making any negative claims about her character or moral stature.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[False]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/pl/train-pl-part_0006.parquet",
         null,
         null,
         "train",
         "{\"description\": null, \"verdict\": false}"
        ],
        [
         "401",
         "pl_eu_12_06_2024_n01.txt",
         "3163",
         "3547",
         "PL",
         "Po rozpatrzeniu całości projektu ustawy członkowie obu komisji, 51 posłanek i posłów, 32 głosami za,\n2 przeciw i 17 wstrzymującymi przyjęli projekt ustawy o szczególnych rozwiązaniach w związku z przygotowywaniem i sprawowaniem przez Rzeczpospolitą Polską przewodnictwa w Radzie Unii Europejskiej\nw I połowie 2025 roku, druk nr 347, rekomendując\ngo Wysokiej Izbie. Dziękuję. (Oklaski)",
         "False",
         "[]",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Questioning_the_Reputation",
         "Questioning_the_Reputation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Questioning the Reputation technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not contain any elements that attack the reputation of a target or make negative claims about it. It simply discusses the approval of a legislative project without undermining anyone\\'s character or moral stature.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[False]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/pl/train-pl-part_0006.parquet",
         null,
         null,
         "train",
         "{\"description\": null, \"verdict\": false}"
        ],
        [
         "402",
         "pl_eu_12_06_2024_n02.txt",
         "5845",
         "5961",
         "PL",
         "Wicemarszałek Włodzimierz Czarzasty:\nDziękuję.\nPan poseł Janusz Kowalski, Klub Parlamentarny\nPrawo i Sprawiedliwość.",
         "False",
         "[]",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Questioning_the_Reputation",
         "Questioning_the_Reputation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Questioning the Reputation technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not contain any elements that attack or undermine the reputation of any individual. There are no strong negative claims made about anyone\\'s character or moral stature, which aligns with the expert\\'s verdict that the Questioning the Reputation technique is not used.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[False]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/pl/train-pl-part_0006.parquet",
         null,
         null,
         "train",
         "{\"description\": null, \"verdict\": false}"
        ],
        [
         "403",
         "pl_abortion_11_04_2024_n01.txt",
         "268",
         "371",
         "PL",
         "Panowie, halo, szanujmy wszystkich gości.\nDziękujemy wam bardzo za przybycie.\nSuper, bardzo dziękujemy.",
         "False",
         "[]",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Questioning_the_Reputation",
         "Questioning_the_Reputation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Questioning the Reputation technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not contain any elements that attack or undermine the reputation of any individual or group. It is a polite acknowledgment of guests and does not make any negative claims about anyone\\'s character or moral stature.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[False]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/pl/train-pl-part_0006.parquet",
         null,
         null,
         "train",
         "{\"description\": null, \"verdict\": false}"
        ],
        [
         "404",
         "pl_abortion_11_04_2024_n03.txt",
         "0",
         "175",
         "PL",
         "Wicemarszałek Włodzimierz Czarzasty:\nDziękuję serdecznie.\nBardzo proszę panią posłankę Katarzynę Kotulę\no przedstawienie uzasadnienia projektu ustawy\nzawartego w druku nr 177.",
         "False",
         "[]",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Questioning_the_Reputation",
         "Questioning_the_Reputation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Questioning the Reputation technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not contain any elements that attack the reputation of an individual or make negative claims about their character or moral stature. It is a straightforward request for justification of a legislative proposal, lacking any derogatory or reputational questioning.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[False]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/pl/train-pl-part_0006.parquet",
         null,
         null,
         "train",
         "{\"description\": null, \"verdict\": false}"
        ],
        [
         "405",
         "pl_defence_22_05_2024_n02.txt",
         "807",
         "993",
         "PL",
         "Ustawa o ochronie Ojczyzny obowiązuje już od\nponad 2 lat, a do tej pory nie ma do niej wydanych\n12 niezbędnych rozporządzeń, w wyniku czego\nWojsko Polskie nawet nie może się mobilizować.",
         "False",
         "[]",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Questioning_the_Reputation",
         "Questioning_the_Reputation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Questioning the Reputation technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text discusses the lack of necessary regulations related to the law on the protection of the homeland and its impact on the Polish Army\\'s mobilization. It does not make any negative claims about the character or moral stature of any individual or group, which is required for the Questioning the Reputation technique. Therefore, the technique is not used.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[False]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/pl/train-pl-part_0006.parquet",
         null,
         null,
         "train",
         "{\"description\": null, \"verdict\": false}"
        ],
        [
         "407",
         "pl_abortion_11_04_2024_n08.txt",
         "3138",
         "3188",
         "PL",
         "(Poseł Joanna Scheuring-Wielgus: Zejdź z mównicy.)",
         "True",
         "['Loaded_Language']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Zejdź z mównicy']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Questioning_the_Reputation",
         "Questioning_the_Reputation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Questioning the Reputation technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not contain any elements that attack the reputation of a target or make negative claims about their character or moral stature. Therefore, the Questioning the Reputation technique is not used.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[False]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/pl/train-pl-part_0007.parquet",
         null,
         null,
         "train",
         "{\"description\": null, \"verdict\": false}"
        ],
        [
         "409",
         "pl_eu_12_06_2024_n02.txt",
         "5000",
         "5586",
         "PL",
         "Poseł Marcin Porzucek:\nPanie Marszałku! Wysoka Izbo! Szanowni Państwo! W okresie COVID-u, gdy sytuacje pandemiczne\npojawiały się w ciągu nie roku, nie miesięcy, nie tygodnia, ale wręcz dni, i podejmowaliśmy stosowne\ndziałania, państwo nas krytykowaliście. Gdy Rosja\nnapadała pełnoskalowo na Ukrainę, było podobnie.\nSytuacja wojny hybrydowej na granicy polsko-białoruskiej, podobnie. A dzisiaj państwo macie jeszcze\ntyle czasu, chociaż zmarnowaliście ostatnie pół roku,\nproponujecie rozwiązania ekstraordynaryjne, choć\nmożna to w wielu aspektach zrobić tradycyjnie. To\njest jedna sprawa.",
         "True",
         "['Questioning_the_Reputation']",
         "train",
         "['podejmowaliśmy stosowne działania, państwo nas krytykowaliście'\n 'Gdy Rosja napadała pełnoskalowo na Ukrainę, było podobnie. Sytuacja wojny hybrydowej na granicy polsko-białoruskiej, podobnie'\n 'zmarnowaliście ostatnie pół roku']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Questioning_the_Reputation",
         "Questioning_the_Reputation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "1",
         "Yes, the Questioning the Reputation technique is used in the input.",
         "\"podejmowaliśmy stosowne działania, państwo nas krytykowaliście Gdy Rosja napadała pełnoskalowo na Ukrainę, było podobnie. Sytuacja wojny hybrydowej na granicy polsko-białoruskiej, podobnie zmarnowaliście ostatnie pół roku\"",
         "['{\\n  \"explanation\": \"The input text uses the Questioning the Reputation technique by criticizing the actions of the opposing party during critical situations, such as the COVID pandemic and the war in Ukraine. The speaker implies that the opposition has failed to act appropriately (\\'państwo nas krytykowaliście\\' and \\'zmarnowaliście ostatnie pół roku\\'), which attacks their reputation and moral standing rather than addressing the topic directly.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[False]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/pl/train-pl-part_0007.parquet",
         null,
         null,
         "train",
         "{\"description\": null, \"verdict\": true}"
        ],
        [
         "411",
         "pl_abortion_11_04_2024_n05.txt",
         "9681",
         "10556",
         "PL",
         "Dziś jesteśmy w demograficznym kryzysie. Polki\nnie chcą rodzić dzieci w Polsce, która nie jest dla nich\nbezpieczna pod żadnym względem. Mówią: boję się\nbyć w ciąży, bo dziewczyny w moim wieku umierają.\nUmarły pan Iza, pani Agnieszka, pani Marta, pani\nDorota. Dlatego Koalicja Obywatelska przygotowała\ni przedstawia projekt ustawy o świadomym rodzicielstwie.\nZakaz aborcji w Polsce to restrykcyjne prawo,\nktóre zagraża zdrowiu, życiu i bezpieczeństwu kobiet,\na nasz projekt, projekt Koalicji Obywatelskiej,\nprzywraca kobietom wolność wyboru, przywraca kobietom\ngodność, przywraca kobietom podmiotowość. Zakłada\nmożliwość bezpiecznego i bezpłatnego przerywania\nciąży do 12 tygodnia jej trwania oraz po 12 tygodniu\nw określonych okolicznościach. Aborcja musi być\nbezpieczna, aborcja musi być legalna. Aborcja musi być\ndostępna, a kobieta musi być bezpieczna.\nDziękuję. (Oklaski)",
         "True",
         "['Conversation_Killer' 'Causal_Oversimplification' 'Slogans'\n 'Whataboutism' 'Appeal_to_Values' 'Repetition' 'Appeal_to_Fear-Prejudice']",
         "train",
         "[]",
         "[]",
         "[]",
         "['aborcja musi być legalna' 'Aborcja musi być dostępna']",
         "[]",
         "['przywraca kobietom wolność wyboru' 'przywraca kobietom godność'\n 'przywraca kobietom podmiotowość']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['zagraża zdrowiu, życiu i bezpieczeństwu kobiet']",
         "[]",
         "[]",
         "['Aborcja musi być bezpieczna, aborcja musi być legalna'\n 'Aborcja musi być dostępna, a kobieta musi być bezpieczna']",
         "['Mówią: boję się być w ciąży, bo dziewczyny w moim wieku umierają. Umarły pan Iza, pani Agnieszka, pani Marta, pani Dorota'\n 'Zakaz aborcji w Polsce to restrykcyjne prawo, które zagraża zdrowiu, życiu i bezpieczeństwu kobiet']",
         "['Polki nie chcą rodzić dzieci w Polsce, która nie jest dla nich bezpieczna pod żadnym względem']",
         "[]",
         "[]",
         "['Dziś jesteśmy w demograficznym kryzysie']",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Questioning_the_Reputation",
         "Questioning_the_Reputation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Questioning the Reputation technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not contain any elements that attack the reputation of a target or make strong negative claims about it. It focuses on discussing the issue of abortion and women\\'s rights without undermining the character or moral stature of any individual or group. Therefore, the Questioning the Reputation technique is not used.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[False]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/pl/train-pl-part_0007.parquet",
         null,
         null,
         "train",
         "{\"description\": null, \"verdict\": false}"
        ],
        [
         "416",
         "pl_abortion_11_04_2024_n08.txt",
         "150",
         "288",
         "PL",
         "Wicemarszałek Monika Wielichowska:\nSam pan wywołał reakcję pań, które znajdują się na\ngalerii. Proszę kontynuować. (Gwar na sali, dzwonek)",
         "True",
         "['Questioning_the_Reputation']",
         "train",
         "['Sam pan wywołał reakcję pań, które znajdują się na galerii']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Questioning_the_Reputation",
         "Questioning_the_Reputation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "1",
         "Yes, the Questioning the Reputation technique is used in the input.",
         "\"Sam pan wywołał reakcję pań, które znajdują się na galerii\"",
         "['{\\n  \"explanation\": \"The technique of Questioning the Reputation is used in the input text as the speaker, Wicemarszałek Monika Wielichowska, implies that the person addressed has provoked a negative reaction from the women in the gallery. This statement attacks the character of the individual by suggesting they are responsible for inciting a disturbance, thereby undermining their reputation without addressing the actual topic at hand.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[False]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/pl/train-pl-part_0002.parquet",
         "[None]",
         "[None]",
         "train",
         "{\"description\": null, \"verdict\": true}"
        ],
        [
         "418",
         "pl_defence_22_05_2024_n01.txt",
         "8339",
         "10002",
         "PL",
         "Proszę państwa, jeśli chodzi o te zakupy, to one\nwszystkie były konsultowane, były wynikiem naszych rozmów w Radzie Modernizacji Technicznej\nz przeważającym, decydującym głosem Sztabu Generalnego Wojska Polskiego. Zmieniłem sposób zamawiania sprzętu wojskowego dla polskiego wojska,\nbo on był sprzeczny wewnętrznie. To była sytuacja,\nw której nie można było pójść naprzód, więc udrożniłem te procesy. Potem, kiedy przyszedł rok 2022,\nkiedy po raz kolejny Rosja napadła na Ukrainę, nawiązałem relacje z Koreą Południową. Dlaczego to\nzrobiłem? Dlatego że Korea Południowa posiada olbrzymi potencjał produkcyjny, jeśli chodzi o przemysł\nzbrojeniowy. Uważam za jeden z naszych sukcesów\nto, że w tak krótkim czasie doprowadziliśmy do tego,\nże w Wojsku Polskim już są czołgi K2, że obok\nHIMARS-ów, o których powiedziałem, są Chunmoo,\nczyli artyleria rakietowa o zasięgu do 300 km, że są\nsamoloty szkolno-bojowe FA-50. Pan powiedział, że\npiloci tak dużo zarabiają. Trzeba szkolić pilotów.\nFA-50 zostały zaprojektowane przez Lockheed Martin, a więc są taką mniejszą, to prawda, wersją\nF-16. W Wojsku Polskim, kiedy przyszliśmy do\nwładzy, w zasadzie tylko F-16 stanowiły jakąś siłę\nbojową. Pozostały sprzęt wojskowy był postsowiecki,\nbył zużyty. To był obraz nędzy i rozpaczy, a my doprowadziliśmy do tego, że dziś Wojsko Polskie liczy\nponad 200 tys. żołnierzy. Tylko jeszcze cele… Też\npan o tym nie wspomniał. Co najmniej 300 tys. żołnierzy. Można powiedzieć, że 300 tys. żołnierzy wojsk\noperacyjnych i 50 tys. żołnierzy Wojsk Obrony Terytorialnej – to powinien być nasz wspólny cel, mówię\no państwie polskim (Oklaski), bo w ten sposób możemy realnie odstraszyć agresora.",
         "True",
         "['Loaded_Language' 'Flag_Waving' 'Obfuscation-Vagueness-Confusion'\n 'Appeal_to_Authority' 'Name_Calling-Labeling' 'Red_Herring'\n 'Appeal_to_Fear-Prejudice']",
         "train",
         "[]",
         "['postsowiecki']",
         "[]",
         "[]",
         "['obraz nędzy i rozpaczy']",
         "[]",
         "[]",
         "[]",
         "['Pan powiedział, że piloci tak dużo zarabiają']",
         "['mówię o państwie polskim']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['To była sytuacja, w której nie można było pójść naprzód, więc udrożniłem te procesy']",
         "[]",
         "[]",
         "['realnie odstraszyć agresora']",
         "[]",
         "['jeśli chodzi o te zakupy, to one wszystkie były konsultowane, były wynikiem naszych rozmów w Radzie Modernizacji Technicznej z przeważającym, decydującym głosem Sztabu Generalnego Wojska Polskiego']",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Questioning_the_Reputation",
         "Questioning_the_Reputation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Questioning the Reputation technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not contain any elements that attack the reputation of a target or make strong negative claims about it. The speaker focuses on achievements and improvements in the military rather than undermining anyone\\'s character or moral stature.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[False]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/pl/train-pl-part_0002.parquet",
         "[None]",
         "[None]",
         "train",
         "{\"description\": null, \"verdict\": false}"
        ],
        [
         "421",
         "pl_abortion_11_04_2024_n07.txt",
         "7843",
         "8354",
         "PL",
         "Tytuł projektu Lewicy sugeruje, że aborcja może być\nbezpieczna, tymczasem sami projektodawcy w\nuzasadnieniu projektu podają, że od dnia wydania wyroku\nTrybunału Konstytucyjnego w 2020 r. tylko jedna z\norganizacji proaborcyjnych pomagała w aborcji w\nprzypadku 125 tys. kobiet, co oznacza, że co najmniej tyle\nsamo dzieci w wyniku aborcji straciło życie.\nProjektowane przepisy uderzają w podstawowe prawo każdego\nczłowieka, są całkowicie nieakceptowalne i powinny\nbyć odrzucone już w pierwszym czytaniu. (Oklaski)",
         "True",
         "['Conversation_Killer' 'Appeal_to_Hypocrisy' 'Appeal_to_Values']",
         "train",
         "[]",
         "[]",
         "['Tytuł projektu Lewicy sugeruje, że aborcja może być bezpieczna, tymczasem sami projektodawcy w uzasadnieniu projektu podają, że od dnia wydania wyroku Trybunału Konstytucyjnego w 2020 r. tylko jedna z organizacji proaborcyjnych pomagała w aborcji w przypadku 125 tys. kobiet, co oznacza, że co najmniej tyle samo dzieci w wyniku aborcji straciło życie']",
         "['są całkowicie nieakceptowalne i powinny być odrzucone już w pierwszym czytaniu']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Projektowane przepisy uderzają w podstawowe prawo każdego człowieka']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Questioning_the_Reputation",
         "Questioning_the_Reputation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Questioning the Reputation technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not contain any explicit attacks on the reputation or moral character of the project proponents. It focuses on presenting factual information and expressing opposition to the proposed legislation without undermining the character of the individuals involved.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[False]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/pl/train-pl-part_0002.parquet",
         "[None]",
         "[None]",
         "train",
         "{\"description\": null, \"verdict\": false}"
        ],
        [
         "423",
         "pl_current_affairs_09_01_2025_n01.txt",
         "4848",
         "5376",
         "PL",
         "Dzięki zastosowaniu automatycznego programowania od startu programu do końca grudnia 2024 r.\nrozpatrzono ponad 80% wniosków złożonych w tym\nokresie, pomimo że w październiku, co było naturalne, doszło do spiętrzenia wpływu wniosków z uwagi\nna to, że złożyli je rodzice dzieci z trzech roczników:\n2021–2023. W okresie od 1 października do 31 grudnia ZUS wypłacił łącznie 558 685 świadczeń na kwotę 670 279 596,83 zł. Nadal trwa rozpatrywanie wniosków z okresu, w którym konieczne jest przeprowadzenie postępowania wyjaśniającego.",
         "False",
         "[]",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Questioning_the_Reputation",
         "Questioning_the_Reputation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Questioning the Reputation technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not contain any elements that attack or undermine the reputation of any individual or entity. It focuses on factual information regarding the processing of applications and financial disbursements without making negative claims about anyone\\'s character or moral stature.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[False]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/pl/train-pl-part_0002.parquet",
         "[None]",
         "[None]",
         "train",
         "{\"description\": null, \"verdict\": false}"
        ],
        [
         "426",
         "pl_current_affairs_09_01_2025_n03.txt",
         "3170",
         "3937",
         "PL",
         "Przypomnę również rok 2020. Powstało coś takiego jak specustawa suszowa, projekt. To kolejny projekt ministra odpowiedzialnego za gospodarkę wodną, w tym za zabezpieczenie przeciwsuszowe i przeciwpowodziowe w Polsce przez 8 lat. Projekt powstał\n4 lata po gigantycznej suszy, która nawiedziła Polskę\nw 2015 r., 2016 r. Dopiero 4 lata po niej. Zawierał\ngłównie plan budowy ok. 500 budowli hydrotechnicznych, z których wiele, podobnie jak w przypadku\nplanu zapory w Siarzewie, nie gwarantowało zabezpieczenia przeciwpowodziowego i przeciwsuszowego.\nByło to tylko de facto przykrywką dla zupełnie innych planów, planów żeglugowych. I z tego znany był\nwtedy wasz minister za to odpowiadający.\n(Poseł Anna Gembicka: No to chyba dobrze, że\nchciał, żeby można było żeglować?)",
         "True",
         "['Appeal_to_Hypocrisy' 'Questioning_the_Reputation' 'Red_Herring' 'Doubt']",
         "train",
         "['I z tego znany był wtedy wasz minister za to odpowiadający']",
         "[]",
         "['Było to tylko de facto przykrywką dla zupełnie innych planów, planów żeglugowych']",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Powstało coś takiego jak specustawa suszowa, projekt. To kolejny projekt ministra odpowiedzialnego za gospodarkę wodną, w tym za zabezpieczenie przeciwsuszowe i przeciwpowodziowe w Polsce przez 8 lat. Projekt powstał 4 lata po gigantycznej suszy, która nawiedziła Polskę w 2015 r., 2016 r. Dopiero 4 lata po niej. Zawierał głównie plan budowy ok. 500 budowli hydrotechnicznych, z których wiele, podobnie jak w przypadku planu zapory w Siarzewie, nie gwarantowało zabezpieczenia przeciwpowodziowego i przeciwsuszowego. Było to tylko de facto przykrywką dla zupełnie innych planów, planów żeglugowych. I z tego znany był wtedy wasz minister za to odpowiadający']",
         "['No to chyba dobrze, że chciał, żeby można było żeglować?)']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Questioning_the_Reputation",
         "Questioning_the_Reputation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "1",
         "Yes, the Questioning the Reputation technique is used in the input.",
         "\"I z tego znany był wtedy wasz minister za to odpowiadający\"",
         "['{\\n  \"explanation\": \"The Questioning the Reputation technique is explicitly used in the input text by making a strong negative claim about the minister\\'s reputation. The excerpt \\'I z tego znany był wtedy wasz minister za to odpowiadający\\' implies that the minister is known for something negative, which undermines his character and moral stature, aligning with the definition of the technique.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[False]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/pl/train-pl-part_0003.parquet",
         null,
         null,
         "train",
         "{\"description\": null, \"verdict\": true}"
        ],
        [
         "430",
         "pl_current_affairs_09_01_2025_n02.txt",
         "9440",
         "9898",
         "PL",
         "Wreszcie raport nie zawierał analizy wpływu na\njakość wód. Nie przeprowadzono dokładnej oceny, jak\nbudowa stopnia wodnego wpłynie na jakość wody\nw Wiśle, w jej dopływach czy na wyznaczone dla niej\ncele środowiskowe. Warto podkreślić, że inwestor\nw całym tym bardzo długim procesie od 2017 r. był\nwielokrotnie wzywany do przedłożenia i uzupełnienia raportu w zakresie braków ustawowych, które\nw tym raporcie były, jednak nie uzupełnił go zgodnie\nz wezwaniami.",
         "True",
         "['Doubt']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Warto podkreślić, że inwestor w całym tym bardzo długim procesie od 2017 r. był wielokrotnie wzywany do przedłożenia i uzupełnienia raportu w zakresie braków ustawowych, które w tym raporcie były, jednak nie uzupełnił go zgodnie z wezwaniami']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Questioning_the_Reputation",
         "Questioning_the_Reputation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Questioning the Reputation technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not contain any strong negative claims aimed at undermining the reputation or moral stature of any individual or entity. It focuses on the lack of analysis in a report and the investor\\'s failure to comply with requests, which does not align with the definition of Questioning the Reputation.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[False]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/pl/train-pl-part_0003.parquet",
         null,
         null,
         "train",
         "{\"description\": null, \"verdict\": false}"
        ],
        [
         "432",
         "pl_defence_22_05_2024_n02.txt",
         "520",
         "805",
         "PL",
         "Przede wszystkim mamy olbrzymi bałagan w dowodzeniu.\nSystem kierowania i dowodzenia Siłami\nZbrojnymi był kilkanaście razy zmieniany od czasu\nupadku PRL-u. Jest skomplikowany, jest niejasny,\na generalny dowódca rodzajów Sił Zbrojnych do tej\npory dowodził co najwyżej pułkiem specjalnym.",
         "True",
         "['Doubt']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['System kierowania i dowodzenia Siłami Zbrojnymi był kilkanaście razy zmieniany od czasu upadku PRL-u. Jest skomplikowany, jest niejasny, a generalny dowódca rodzajów Sił Zbrojnych do tej pory dowodził co najwyżej pułkiem specjalnym']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Questioning_the_Reputation",
         "Questioning_the_Reputation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Questioning the Reputation technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text discusses issues related to the command system of the armed forces, highlighting confusion and changes over time. However, it does not make any strong negative claims about an individual\\'s character or moral stature, nor does it undermine the reputation of a specific target. Therefore, the Questioning the Reputation technique is not used.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[False]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/pl/train-pl-part_0003.parquet",
         null,
         null,
         "train",
         "{\"description\": null, \"verdict\": false}"
        ],
        [
         "434",
         "pl_current_affairs_09_01_2025_n02.txt",
         "9900",
         "10562",
         "PL",
         "Więc podsumowując, państwo próbowaliście zrobić tę inwestycję na rympał, ignorując prawo. Wasz\nwłasny minister klimatu i środowiska w 2021 r. wam\no tym powiedział i odmówił wydania decyzji o środowiskowych uwarunkowaniach. Dzisiejszy minister,\ngłówny dyrektor ochrony środowiska potwierdził\njego argumenty. Tak że nie wiem, jak to jeszcze państwu przekazać. Mogę tylko w tym miejscu przypomnieć, że również pod nadzorem tego samego ministra odpowiedzialnego za gospodarkę wodną i tego\nsamego rządu kilka innych inwestycji w obszarze\ngospodarki wodnej było przygotowane z równą dbałością o jakość i przestrzeganie prawa, czyli bez dbałości o przestrzeganie prawa.",
         "True",
         "['Loaded_Language' 'Appeal_to_Authority' 'Questioning_the_Reputation'\n 'Appeal_to_Values' 'Doubt']",
         "train",
         "['kilka innych inwestycji w obszarze gospodarki wodnej było przygotowane z równą dbałością o jakość i przestrzeganie prawa, czyli bez dbałości o przestrzeganie prawa']",
         "[]",
         "[]",
         "[]",
         "['na rympał']",
         "[]",
         "[]",
         "['Więc podsumowując, państwo próbowaliście zrobić tę inwestycję na rympał, ignorując prawo']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['państwo próbowaliście zrobić tę inwestycję na rympał, ignorując prawo'\n 'kilka innych inwestycji w obszarze gospodarki wodnej było przygotowane z równą dbałością o jakość i przestrzeganie prawa, czyli bez dbałości o przestrzeganie prawa']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Wasz własny minister klimatu i środowiska w 2021 r. wam o tym powiedział i odmówił wydania decyzji o środowiskowych uwarunkowaniach'\n 'Dzisiejszy minister, główny dyrektor ochrony środowiska potwierdził jego argumenty']",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Questioning_the_Reputation",
         "Questioning_the_Reputation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "1",
         "Yes, the Questioning the Reputation technique is used in the input.",
         "\"kilka innych inwestycji w obszarze gospodarki wodnej było przygotowane z równą dbałością o jakość i przestrzeganie prawa, czyli bez dbałości o przestrzeganie prawa\"",
         "['{\\n  \"explanation\": \"The input text uses the Questioning the Reputation technique by implying that the actions of the government and its ministers regarding water management investments were negligent and lacked legal adherence. The excerpt suggests that multiple investments were prepared without proper care for legal compliance, thereby undermining the reputation and moral standing of the officials involved.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[False]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/pl/train-pl-part_0003.parquet",
         null,
         null,
         "train",
         "{\"description\": null, \"verdict\": true}"
        ],
        [
         "435",
         "pl_abortion_11_04_2024_n06.txt",
         "3082",
         "3129",
         "PL",
         "Panie pośle, na podstawie… (Poruszenie na sali)",
         "False",
         "[]",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Questioning_the_Reputation",
         "Questioning_the_Reputation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Questioning the Reputation technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not contain any elements that attack the reputation of a target or make negative claims about it. Therefore, the Questioning the Reputation technique is not used.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[False]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/pl/train-pl-part_0003.parquet",
         null,
         null,
         "train",
         "{\"description\": null, \"verdict\": false}"
        ],
        [
         "438",
         "pl_current_affairs_09_01_2025_n02.txt",
         "10564",
         "11076",
         "PL",
         "Przypomnę tylko, że 23 czerwca 2017 r. na pochylni Wulkan Nowy w Szczecińskim Parku Przemysłowym odbyło się położenie stępki pod budowę promu\npasażersko-samochodowego. Obecny na tej ceremonii pan minister Marek Gróbarczyk podkreślił znaczenie projektu w procesie odbudowy pozycji polskich\nstoczni. W 2023 r., kilka lat później, okazało się, że\njeśli chodzi o dokapitalizowanie spółek zaangażowanych w ten projekt, w projekt „Batory”, zainwestowano 1 mld zł z publicznych pieniędzy – 1 mld zł strat\ni zero promów.",
         "True",
         "['Questioning_the_Reputation']",
         "train",
         "['W 2023 r., kilka lat później, okazało się, że jeśli chodzi o dokapitalizowanie spółek zaangażowanych w ten projekt, w projekt „Batory”, zainwestowano 1 mld zł z publicznych pieniędzy – 1 mld zł strat i zero promów']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Questioning_the_Reputation",
         "Questioning_the_Reputation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "1",
         "Yes, the Questioning the Reputation technique is used in the input.",
         "\"W 2023 r., kilka lat później, okazało się, że jeśli chodzi o dokapitalizowanie spółek zaangażowanych w ten projekt, w projekt „Batory”, zainwestowano 1 mld zł z publicznych pieniędzy – 1 mld zł strat i zero promów\"",
         "['{\\n  \"explanation\": \"The input text uses the Questioning the Reputation technique by highlighting the financial losses and lack of results from the project \\'Batory\\', which undermines the credibility and moral standing of those involved, particularly the minister who previously supported the project. This aligns with the technique\\'s definition of attacking reputation through negative claims.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[False]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/pl/train-pl-part_0001.parquet",
         null,
         null,
         "train",
         "{\"description\": null, \"verdict\": true}"
        ],
        [
         "439",
         "pl_abortion_11_04_2024_n06.txt",
         "3223",
         "3463",
         "PL",
         "Panie pośle, na podstawie art. 175 ust. 3 regulaminu\nSejmu przywołuję pana do porządku.\nRozumiem, że pan wyłączył urządzenie. Rozumiem, że pan zrozumiał.\n(Poseł Dariusz Matecki: Wyłączyłem bicie serca dziecka.)\nPani posłanko, bardzo proszę.",
         "True",
         "['Obfuscation-Vagueness-Confusion']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Wyłączyłem bicie serca dziecka']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Questioning_the_Reputation",
         "Questioning_the_Reputation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Questioning the Reputation technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not contain any elements that attack the reputation of a target or make strong negative claims about it. There are no attempts to undermine character or moral stature, which are key aspects of the Questioning the Reputation technique. Therefore, the expert\\'s verdict that this technique was not used is accurate.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[False]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/pl/train-pl-part_0001.parquet",
         null,
         null,
         "train",
         "{\"description\": null, \"verdict\": false}"
        ],
        [
         "443",
         "pl_current_affairs_09_01_2025_n02.txt",
         "1271",
         "1380",
         "PL",
         "(Poseł Joanna Borowiak: A kto to?)\nNie wiem, ale to mili ludzie, uśmiechnięci, z otwartymi sercami. (Oklaski)",
         "False",
         "[]",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Questioning_the_Reputation",
         "Questioning_the_Reputation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Questioning the Reputation technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not contain any elements that attack or undermine the reputation of a target. It instead describes people in a positive light, which does not align with the definition of the Questioning the Reputation technique.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[False]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/pl/train-pl-part_0001.parquet",
         null,
         null,
         "train",
         "{\"description\": null, \"verdict\": false}"
        ]
       ],
       "shape": {
        "columns": 60,
        "rows": 241
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>text_lang</th>\n",
       "      <th>text</th>\n",
       "      <th>label_bin</th>\n",
       "      <th>label_multi</th>\n",
       "      <th>base_split</th>\n",
       "      <th>Questioning_the_Reputation</th>\n",
       "      <th>Name_Calling-Labeling</th>\n",
       "      <th>...</th>\n",
       "      <th>extra_content</th>\n",
       "      <th>explanation</th>\n",
       "      <th>illegal_value</th>\n",
       "      <th>think_content</th>\n",
       "      <th>is_valid</th>\n",
       "      <th>source_file</th>\n",
       "      <th>error</th>\n",
       "      <th>status</th>\n",
       "      <th>split</th>\n",
       "      <th>expected_output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>pl_abortion_11_04_2024_n03.txt</td>\n",
       "      <td>4168</td>\n",
       "      <td>5204</td>\n",
       "      <td>PL</td>\n",
       "      <td>W latach 90., które już bardzo dobrze pamiętam...</td>\n",
       "      <td>True</td>\n",
       "      <td>[Appeal_to_Hypocrisy, Loaded_Language, Questio...</td>\n",
       "      <td>train</td>\n",
       "      <td>[ustawa była początkiem wymazywania kobiet z d...</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[False]</td>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41/v001...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "      <td>{\"description\": null, \"verdict\": true}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>SI_interpelation_interior_12.txt</td>\n",
       "      <td>4448</td>\n",
       "      <td>7979</td>\n",
       "      <td>SI</td>\n",
       "      <td>Najlepša hvala za besedo. Najprej hvala gospod...</td>\n",
       "      <td>True</td>\n",
       "      <td>[Consequential_Oversimplification, Exaggeratio...</td>\n",
       "      <td>train</td>\n",
       "      <td>[tisti, ki vam je pisal odgovore na našo inter...</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[False]</td>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41/v001...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "      <td>{\"description\": null, \"verdict\": true}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>SI_interpelation_interior_7.txt</td>\n",
       "      <td>2598</td>\n",
       "      <td>5288</td>\n",
       "      <td>SI</td>\n",
       "      <td>Policisti prav tako dobijo navodila, naj ne sp...</td>\n",
       "      <td>True</td>\n",
       "      <td>[Consequential_Oversimplification, Exaggeratio...</td>\n",
       "      <td>train</td>\n",
       "      <td>[Taka navodila policistom seveda preprečujejo ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[False]</td>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41/v001...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "      <td>{\"description\": null, \"verdict\": true}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>SI_interpelation_interior_7.txt</td>\n",
       "      <td>839</td>\n",
       "      <td>2596</td>\n",
       "      <td>SI</td>\n",
       "      <td>Naslednji primer: žena pomočnika generalnega d...</td>\n",
       "      <td>True</td>\n",
       "      <td>[Causal_Oversimplification, Exaggeration-Minim...</td>\n",
       "      <td>train</td>\n",
       "      <td>[mora po navodilu pomočnika generalnega direkt...</td>\n",
       "      <td>[golobistov]</td>\n",
       "      <td>...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[False]</td>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41/v001...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "      <td>{\"description\": null, \"verdict\": true}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>SI_interpelation_interior_6.txt</td>\n",
       "      <td>270</td>\n",
       "      <td>7305</td>\n",
       "      <td>SI</td>\n",
       "      <td>Na eni izmed sej Odbora za notranje zadeve mi ...</td>\n",
       "      <td>True</td>\n",
       "      <td>[Loaded_Language, Obfuscation-Vagueness-Confus...</td>\n",
       "      <td>train</td>\n",
       "      <td>[Še posebej direktorja, tam na mojem koncu, ko...</td>\n",
       "      <td>[golobisti, janšistov, janšisti, janšistov, go...</td>\n",
       "      <td>...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[False]</td>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41/v001...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "      <td>{\"description\": null, \"verdict\": false}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1781</th>\n",
       "      <td>20240704_URW_BG_30.txt</td>\n",
       "      <td>2946</td>\n",
       "      <td>2988</td>\n",
       "      <td>BG</td>\n",
       "      <td>Нинова, за процедура.\\n\\nИзчакайте, господи</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>train</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[False]</td>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41/v001...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "      <td>{\"description\": null, \"verdict\": false}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1782</th>\n",
       "      <td>20231208_URW_BG_72.txt</td>\n",
       "      <td>1795</td>\n",
       "      <td>2118</td>\n",
       "      <td>BG</td>\n",
       "      <td>Говорите, че машините, които гласувахме – „Стр...</td>\n",
       "      <td>True</td>\n",
       "      <td>[Questioning_the_Reputation, Doubt]</td>\n",
       "      <td>train</td>\n",
       "      <td>[Ако за Вас 1956 г. е същата като 2001 г., за ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[False]</td>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41/v001...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "      <td>{\"description\": null, \"verdict\": true}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1783</th>\n",
       "      <td>20240229_URW_BG_67.txt</td>\n",
       "      <td>2786</td>\n",
       "      <td>4165</td>\n",
       "      <td>BG</td>\n",
       "      <td>И да Ви кажа, уважаеми български граждани, че ...</td>\n",
       "      <td>True</td>\n",
       "      <td>[Appeal_to_Hypocrisy, Questioning_the_Reputati...</td>\n",
       "      <td>train</td>\n",
       "      <td>[И да Ви кажа, уважаеми български граждани, че...</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[False]</td>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41/v001...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "      <td>{\"description\": null, \"verdict\": true}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1814</th>\n",
       "      <td>20240704_URW_BG_25.txt</td>\n",
       "      <td>4080</td>\n",
       "      <td>4133</td>\n",
       "      <td>BG</td>\n",
       "      <td>оспожо Председател.\\n\\nЩе направя процедурно п...</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>train</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[False]</td>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41/v001...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "      <td>{\"description\": null, \"verdict\": false}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1821</th>\n",
       "      <td>trail_raw_BG_13.txt</td>\n",
       "      <td>3446</td>\n",
       "      <td>4689</td>\n",
       "      <td>BG</td>\n",
       "      <td>да се случи, когато се обърне колелото на ист...</td>\n",
       "      <td>True</td>\n",
       "      <td>[Conversation_Killer, Loaded_Language, Slogans...</td>\n",
       "      <td>train</td>\n",
       "      <td>[Вие не сте даже и такива, за които членувате ...</td>\n",
       "      <td>[руски агенти, руски агенти, гешефтари]</td>\n",
       "      <td>...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[False]</td>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41/v001...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "      <td>{\"description\": null, \"verdict\": true}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>241 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              filename  start   end text_lang  \\\n",
       "90      pl_abortion_11_04_2024_n03.txt   4168  5204        PL   \n",
       "201   SI_interpelation_interior_12.txt   4448  7979        SI   \n",
       "209    SI_interpelation_interior_7.txt   2598  5288        SI   \n",
       "227    SI_interpelation_interior_7.txt    839  2596        SI   \n",
       "234    SI_interpelation_interior_6.txt    270  7305        SI   \n",
       "...                                ...    ...   ...       ...   \n",
       "1781            20240704_URW_BG_30.txt   2946  2988        BG   \n",
       "1782            20231208_URW_BG_72.txt   1795  2118        BG   \n",
       "1783            20240229_URW_BG_67.txt   2786  4165        BG   \n",
       "1814            20240704_URW_BG_25.txt   4080  4133        BG   \n",
       "1821               trail_raw_BG_13.txt   3446  4689        BG   \n",
       "\n",
       "                                                   text  label_bin  \\\n",
       "90    W latach 90., które już bardzo dobrze pamiętam...       True   \n",
       "201   Najlepša hvala za besedo. Najprej hvala gospod...       True   \n",
       "209   Policisti prav tako dobijo navodila, naj ne sp...       True   \n",
       "227   Naslednji primer: žena pomočnika generalnega d...       True   \n",
       "234   Na eni izmed sej Odbora za notranje zadeve mi ...       True   \n",
       "...                                                 ...        ...   \n",
       "1781        Нинова, за процедура.\\n\\nИзчакайте, господи      False   \n",
       "1782  Говорите, че машините, които гласувахме – „Стр...       True   \n",
       "1783  И да Ви кажа, уважаеми български граждани, че ...       True   \n",
       "1814  оспожо Председател.\\n\\nЩе направя процедурно п...      False   \n",
       "1821   да се случи, когато се обърне колелото на ист...       True   \n",
       "\n",
       "                                            label_multi base_split  \\\n",
       "90    [Appeal_to_Hypocrisy, Loaded_Language, Questio...      train   \n",
       "201   [Consequential_Oversimplification, Exaggeratio...      train   \n",
       "209   [Consequential_Oversimplification, Exaggeratio...      train   \n",
       "227   [Causal_Oversimplification, Exaggeration-Minim...      train   \n",
       "234   [Loaded_Language, Obfuscation-Vagueness-Confus...      train   \n",
       "...                                                 ...        ...   \n",
       "1781                                                 []      train   \n",
       "1782                [Questioning_the_Reputation, Doubt]      train   \n",
       "1783  [Appeal_to_Hypocrisy, Questioning_the_Reputati...      train   \n",
       "1814                                                 []      train   \n",
       "1821  [Conversation_Killer, Loaded_Language, Slogans...      train   \n",
       "\n",
       "                             Questioning_the_Reputation  \\\n",
       "90    [ustawa była początkiem wymazywania kobiet z d...   \n",
       "201   [tisti, ki vam je pisal odgovore na našo inter...   \n",
       "209   [Taka navodila policistom seveda preprečujejo ...   \n",
       "227   [mora po navodilu pomočnika generalnega direkt...   \n",
       "234   [Še posebej direktorja, tam na mojem koncu, ko...   \n",
       "...                                                 ...   \n",
       "1781                                                 []   \n",
       "1782  [Ако за Вас 1956 г. е същата като 2001 г., за ...   \n",
       "1783  [И да Ви кажа, уважаеми български граждани, че...   \n",
       "1814                                                 []   \n",
       "1821  [Вие не сте даже и такива, за които членувате ...   \n",
       "\n",
       "                                  Name_Calling-Labeling  ... extra_content  \\\n",
       "90                                                   []  ...        [None]   \n",
       "201                                                  []  ...        [None]   \n",
       "209                                                  []  ...        [None]   \n",
       "227                                        [golobistov]  ...        [None]   \n",
       "234   [golobisti, janšistov, janšisti, janšistov, go...  ...        [None]   \n",
       "...                                                 ...  ...           ...   \n",
       "1781                                                 []  ...        [None]   \n",
       "1782                                                 []  ...        [None]   \n",
       "1783                                                 []  ...        [None]   \n",
       "1814                                                 []  ...        [None]   \n",
       "1821            [руски агенти, руски агенти, гешефтари]  ...        [None]   \n",
       "\n",
       "     explanation illegal_value think_content is_valid  \\\n",
       "90        [None]        [None]        [None]  [False]   \n",
       "201       [None]        [None]        [None]  [False]   \n",
       "209       [None]        [None]        [None]  [False]   \n",
       "227       [None]        [None]        [None]  [False]   \n",
       "234       [None]        [None]        [None]  [False]   \n",
       "...          ...           ...           ...      ...   \n",
       "1781      [None]        [None]        [None]  [False]   \n",
       "1782      [None]        [None]        [None]  [False]   \n",
       "1783      [None]        [None]        [None]  [False]   \n",
       "1814      [None]        [None]        [None]  [False]   \n",
       "1821      [None]        [None]        [None]  [False]   \n",
       "\n",
       "                                            source_file error status  split  \\\n",
       "90    data/llm_output/persuasion/explain/GPT_41/v001...   NaN    NaN  train   \n",
       "201   data/llm_output/persuasion/explain/GPT_41/v001...   NaN    NaN  train   \n",
       "209   data/llm_output/persuasion/explain/GPT_41/v001...   NaN    NaN  train   \n",
       "227   data/llm_output/persuasion/explain/GPT_41/v001...   NaN    NaN  train   \n",
       "234   data/llm_output/persuasion/explain/GPT_41/v001...   NaN    NaN  train   \n",
       "...                                                 ...   ...    ...    ...   \n",
       "1781  data/llm_output/persuasion/explain/GPT_41/v001...   NaN    NaN  train   \n",
       "1782  data/llm_output/persuasion/explain/GPT_41/v001...   NaN    NaN  train   \n",
       "1783  data/llm_output/persuasion/explain/GPT_41/v001...   NaN    NaN  train   \n",
       "1814  data/llm_output/persuasion/explain/GPT_41/v001...   NaN    NaN  train   \n",
       "1821  data/llm_output/persuasion/explain/GPT_41/v001...   NaN    NaN  train   \n",
       "\n",
       "                              expected_output  \n",
       "90     {\"description\": null, \"verdict\": true}  \n",
       "201    {\"description\": null, \"verdict\": true}  \n",
       "209    {\"description\": null, \"verdict\": true}  \n",
       "227    {\"description\": null, \"verdict\": true}  \n",
       "234   {\"description\": null, \"verdict\": false}  \n",
       "...                                       ...  \n",
       "1781  {\"description\": null, \"verdict\": false}  \n",
       "1782   {\"description\": null, \"verdict\": true}  \n",
       "1783   {\"description\": null, \"verdict\": true}  \n",
       "1814  {\"description\": null, \"verdict\": false}  \n",
       "1821   {\"description\": null, \"verdict\": true}  \n",
       "\n",
       "[241 rows x 60 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"is_valid\"].apply(\n",
    "    lambda x: isinstance(x, (list, np.ndarray)) and list(x) == [False]\n",
    ")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "26cfc4e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "filename",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "start",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "end",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "text_lang",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "text",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "label_bin",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "label_multi",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "base_split",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Questioning_the_Reputation",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Name_Calling-Labeling",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Appeal_to_Hypocrisy",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Conversation_Killer",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Loaded_Language",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Repetition",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Appeal_to_Popularity",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Doubt",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Red_Herring",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Flag_Waving",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Exaggeration-Minimisation",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Consequential_Oversimplification",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Appeal_to_Pity",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Appeal_to_Time",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Appeal_to_Values",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Obfuscation-Vagueness-Confusion",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Straw_Man",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Slogans",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Appeal_to_Fear-Prejudice",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Causal_Oversimplification",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Appeal_to_Authority",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "False_Dilemma-No_Choice",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Whataboutism",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "False_Equivalence",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Guilt_by_Association",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "alt_split",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "output_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "prompt_name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "prompt_version",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "job",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "step",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "max_iterations",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "temperature",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "model_provider",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "model_name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "model_mode",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "gold",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "gold_text",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "spans",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "raw",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "updated_definition",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "extra_properties",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "extra_content",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "explanation",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "illegal_value",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "think_content",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "is_valid",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "source_file",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "error",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "status",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "split",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "expected_output",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "2ae6f1bf-f20d-436a-b2ee-244337cc4058",
       "rows": [
        [
         "48",
         "pl_abortion_11_04_2024_n08.txt",
         "290",
         "1251",
         "PL",
         "Poseł Roman Fritz:\nGrupa feministek pomagająca mordować\nnienarodzone dzieci, Aborcyjny Dream Team, pochwaliła\nsię mniej więcej 2 lata temu, że pomogła zabić\ndziecko gotowe do porodu. Jego matka była w 37. tygodniu\nciąży. Feministki przyznają, że pomaganie w\naborcjach jest ich życiową pasją i misją, a za cel obrały\nsobie promowanie pozytywnego przekazu\ndotyczącego aborcji. Za pośrednictwem mediów\nspołecznościowych co jakiś czas Aborcyjny Dream Team chwali się\nswoimi morderczymi osiągnięciami. Uruchomiona\nprzez nich infolinia umożliwia konsultacje aborcyjne\ni zamawianie tabletek poronnych oraz umawianie\nwyjazdów na zabicie dziecka za granicami Polski.\nAborcjonistki przyznały również, że preferowaną metodą\nzabicia dziecka w tak zaawansowanym stadium\nrozwoju jest rozszerzenie szyjki macicy umożliwiające\nwydobycie go narzędziami, a wcześniej podanie\nbezbronnemu dziecku morderczego zastrzyku, który\nzatrzymuje akcję serca.\n(Poseł Krzysztof Bosak: Hańba!)",
         "True",
         "['Loaded_Language' 'Slogans' 'Questioning_the_Reputation'\n 'Name_Calling-Labeling' 'Appeal_to_Fear-Prejudice']",
         "train",
         "['Grupa feministek pomagająca mordować nienarodzone dzieci, Aborcyjny Dream Team, pochwaliła się mniej więcej 2 lata temu, że pomogła zabić dziecko gotowe do porodu'\n 'Feministki przyznają, że pomaganie w aborcjach jest ich życiową pasją i misją, a za cel obrały sobie promowanie pozytywnego przekazu dotyczącego aborcji'\n 'Aborcyjny Dream Team chwali się swoimi morderczymi osiągnięciami']",
         "['Aborcyjny Dream Team' 'Aborcyjny Dream Team' 'morderczymi']",
         "[]",
         "[]",
         "['pomagająca mordować nienarodzone dzieci' 'pomogła zabić dziecko'\n 'jest ich życiową pasją i misją' 'zabicie dziecka' 'zabicia'\n 'morderczego']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Hańba!)']",
         "['preferowaną metodą zabicia dziecka w tak zaawansowanym stadium rozwoju jest rozszerzenie szyjki macicy umożliwiające wydobycie go narzędziami, a wcześniej podanie bezbronnemu dziecku morderczego zastrzyku, który zatrzymuje akcję serca']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Hypocrisy",
         "Appeal_to_Hypocrisy",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Appeal to Hypocrisy technique is not used in the input.",
         "\"\"",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[ True]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/pl/train-pl-part_0002.parquet",
         "[{'code': 'content_filter', 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': True, 'severity': 'high'}, 'jailbreak': {'detected': False, 'filtered': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}, 'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'param': 'prompt', 'status': 400.0, 'type': None}]",
         "['no validation']",
         "train",
         "{\"description\": null, \"verdict\": false}"
        ],
        [
         "90",
         "pl_abortion_11_04_2024_n03.txt",
         "4168",
         "5204",
         "PL",
         "W latach 90., które już bardzo dobrze pamiętam,\nmiały miejsce kolejne próby zaostrzenia prawa\naborcyjnego. Najpierw efektem tego było prawo aborcyjne\noparte na czterech przesłankach, w tym przesłance\nekonomiczno-społecznej, a finalnie, po wyroku\nTrybunału Konstytucyjnego w 1997 r. zakończyło się to\nwprowadzeniem zakazu aborcji opartego na trzech\nwąskich przesłankach, dla niepoznaki i czystych\nsumień konserwatywnych polityków i duchownych\nKościoła katolickiego zwanego kompromisem aborcyjnym.\nNikt nie pytał wtedy kobiet o zdanie w sprawie\nplanowania rodziny, ochrony płodu ludzkiego i\nwarunków dopuszczalności przerywania ciąży – tak\nnazywała się ta ustawa. Nie pytano kobiet, bo ta ustawa\nbyła początkiem wymazywania kobiet z debaty o aborcji.\nCzęść polityków miała czyste ręce i czyste sumienia.\nPrawo zabraniało kobiecie przerywania ciąży,\nlekarze przestali wykonywać aborcję, ale tylko w\npublicznych szpitalach. Według rządowych statystyk\nciążę przerywało 600–1000 kobiet rocznie, a w rze-\nczywistości miała ją co trzecia Polka.",
         "True",
         "['Appeal_to_Hypocrisy' 'Loaded_Language' 'Questioning_the_Reputation'\n 'Appeal_to_Popularity' 'Repetition']",
         "train",
         "['ustawa była początkiem wymazywania kobiet z debaty o aborcji'\n 'Część polityków miała czyste ręce i czyste sumienia']",
         "[]",
         "['zakazu aborcji opartego na trzech wąskich przesłankach, dla niepoznaki i czystych sumień konserwatywnych polityków i duchownych Kościoła katolickiego zwanego kompromisem aborcyjnym']",
         "[]",
         "['wymazywania kobiet' 'wymazywania']",
         "['Nikt nie pytał wtedy kobiet' 'Nie pytano kobiet']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Hypocrisy",
         "Appeal_to_Hypocrisy",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "1",
         "Yes, the Appeal to Hypocrisy technique is used in the input.",
         "\"zakazu aborcji opartego na trzech wąskich przesłankach, dla niepoznaki i czystych sumień konserwatywnych polityków i duchownych Kościoła katolickiego zwanego kompromisem aborcyjnym\"",
         "['{\\n  \"explanation\": \"The Appeal to Hypocrisy technique is used in the input text by highlighting the inconsistency of conservative politicians and Catholic clergy who, while advocating for strict abortion laws, are described as having \\'czyste sumienia\\' (clean consciences). This implies that they are hypocritical for imposing restrictions on women\\'s rights while not considering their opinions, thus attacking their reputation by pointing out this hypocrisy.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[False]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/pl/train-pl-part_0000.parquet",
         null,
         null,
         "train",
         "{\"description\": null, \"verdict\": true}"
        ],
        [
         "172",
         "RU_migrants_5.txt",
         "354",
         "574",
         "RU",
         "йчас Каменск-Уральск во всех сводках новостей. Группа парней похитила двух девушек, привезли их на автомойку избивали, обливали пеной и ледяной водой, унижали. Как я понимаю, жертвы - русские девочки, истязатели - нет.\n\n",
         "True",
         "['Appeal_to_Fear-Prejudice']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Как я понимаю, жертвы - русские девочки, истязатели - нет']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Hypocrisy",
         "Appeal_to_Hypocrisy",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Appeal to Hypocrisy technique is not used in the input.",
         "\"\"",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[ True]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/ru/train-ru-part_0004.parquet",
         "[{'code': 'content_filter', 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'detected': False, 'filtered': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}, 'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'param': 'prompt', 'status': 400.0, 'type': None}]",
         "['no validation']",
         "train",
         "{\"description\": null, \"verdict\": false}"
        ],
        [
         "194",
         "RU_discrediting_the_west_7.txt",
         "700",
         "1046",
         "RU",
         "Затем 22 марта был теракт в концертном зале \"Крокус сити холл\", где в результате стрельбы и пожара погибли 144 человека, а пострадало более 500. Терроризм радикального ислама, казалось, был уже забыт в России, но в этот раз без помощи Украины не обошлось. Стоит отметить оперативность турецкой стороны, которая арестовала часть преступной группы.",
         "True",
         "['Guilt_by_Association' 'Appeal_to_Fear-Prejudice']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Затем 22 марта был теракт в концертном зале \"Крокус сити холл\", где в результате стрельбы и пожара погибли 144 человека, а пострадало более 500. Терроризм радикального ислама, казалось, был уже забыт в России, но в этот раз без помощи Украины не обошлось']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Терроризм радикального ислама, казалось, был уже забыт в России, но в этот раз без помощи Украины не обошлось']",
         "train",
         "GPT_41/v001/Appeal_to_Hypocrisy",
         "Appeal_to_Hypocrisy",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Appeal to Hypocrisy technique is not used in the input.",
         "\"\"",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[ True]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/ru/train-ru-part_0007.parquet",
         "[{'code': 'content_filter', 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'detected': False, 'filtered': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}, 'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'param': 'prompt', 'status': 400.0, 'type': None}]",
         "['no validation']",
         "train",
         "{\"description\": null, \"verdict\": false}"
        ],
        [
         "201",
         "SI_interpelation_interior_12.txt",
         "4448",
         "7979",
         "SI",
         "Najlepša hvala za besedo. Najprej hvala gospod minister za odgovor. Vi in vaši sodelavci ste se potrudili. Je pa res, da niste postregli s številkami, ki bi demantirale številke, ki smo jih predstavili poslanke in poslanci, ki smo se podpisali pod interpelacijo. V tem delu imate problem. Ampak pojdimo k številkam, kot sem rekla, ki ne lažejo. Brez patetike, brez in sumi insinuacij, kot je bilo danes rečeno, ampak prva trditev, gospod minister, policija dela dobro. Da, strinjam se z vami. Policistke in policisti na terenu delajo dobro, človek bi rekel, presenetljivo dobro glede na vodstvo policije, ki že dve leti to policijo razkraja. Hvaležna sem jim kot Novomeščanka, kajti ko je kjerkoli kaj narobe, posebno seveda v romskem naselju, o katerem bom govorila kasneje, so prvi na kraju policistke in policisti. Vendar, se opravičujem, še enkrat, bom prebrala najbolj pomembne številke, ki kažejo, gospod minister, da statistika, ki je popolnoma sveža letošnja in zajema tudi lansko obdobje kaže, da je v vašem obdobju se je zmanjšalo število odkritih kaznivih dejanj za 43,5 procentov. Torej vi ne morete vplivati verjetno ne na število kriminalcev, ki hodijo po naši državi, lahko pa vplivate na število odkritih kaznivih dejanj, torej z dobrim, učinkovitim vodenjem in s preventivnim delovanjem policije. Povečalo se je število kaznivih dejanj gospodarske kriminalitete za 18 procentov in mladoletniške za. 9,4, in tisto kar nas res boli in so nekateri, ki so ime, ki so pisali odzive poslanskih skupin slabo prebrali, našo interpelacijo, je porast kriminalitete v družinah, na področju nasilja v družini se je ta povečala za 18 procentov in pri odvzetih mladoletniških osebah, kar spet mislim na moje dolenjske mladoletne Rome, se je povečala za 65,7 procenta, ta kriminaliteta. Torej Slovenija je varna država, vendar je delo policije neučinkovito in če bo to delo trajalo še dolgo, hvala bogu, da ta Vlada ne bo zelo dolgo, bomo prišli res na zaskrbljujoče številke in nekaj o mladoletnikih, kar nas dejansko tudi skrbi, posebno v Novi Sloveniji in na kar smo dejansko opozarjali, da se je povečalo število nasilništva med mladoletniki. In ko smo vas prosili, spoštovana in draga koalicija, da ukrepate v zvezi z romsko problematiko, ste samo obljubljali, nekateri z gnusom zavrnili naše zakone in številke so vas vzele, izdale. Niste učinkoviti in nikoli ne boste vedeli kako učinkoviti bi bili, če bi pred enim letom in pol sprejeli zakone, ki so jih napisali župani. Takrat ste rekli, prav ena poslanka iz Svobode, da Vida Čadonič Špelič, njen župan in tudi ostali župani Dolenjske lažejo in zavajajo, številke govorijo drugače. Torej, spoštovani gospod minister, tisti, ki vam je pisal odgovore na našo interpelacijo je spregledal te številke. Drugo, rekli ste, da policija dela dobro, vendar ste v isti sapi povedali, da niste zadovoljni z delom CVZ. Spoštovani minister, saj vi ja dobro veste, da je CVZ del policije. In zdaj, ko se pogovarjamo o CVZ je prav, da povemo nekaj, česar se verjetno poslanke in poslanci ne zavedamo. Tudi policistke in policisti, ki so del naše službe, našega varovanja tukaj, ki nas tako prijetno pozdravijo, ko vstopimo v ta Državni zbor in najbolj prijetno je, ko zvečer pozno odhajajo, nam pomahajo v slovo in zaželijo srečno pot. Tudi oni so del CVZ, ne, oni ne delajo slabo, vsi ne delajo slabo. Dela pa slabo očitno vodstvo CVZ, ki ga vaš direktor, zdaj že bivši, ki je častno odstopil, ni uspel urediti. Šele danes ali včeraj, kdaj je to bilo, je tudi CVZ dobila novo vodstvo.",
         "True",
         "['Consequential_Oversimplification' 'Exaggeration-Minimisation'\n 'Loaded_Language' 'Appeal_to_Hypocrisy' 'Appeal_to_Pity'\n 'Appeal_to_Authority' 'Questioning_the_Reputation'\n 'False_Dilemma-No_Choice' 'Red_Herring' 'Repetition' 'Doubt'\n 'Appeal_to_Fear-Prejudice']",
         "train",
         "['tisti, ki vam je pisal odgovore na našo interpelacijo je spregledal te številke']",
         "[]",
         "['Drugo, rekli ste, da policija dela dobro, vendar ste v isti sapi povedali, da niste zadovoljni z delom CVZ']",
         "[]",
         "['posebno seveda v romskem naselju'\n 'kriminalcev, ki hodijo po naši državi' 'moje dolenjske mladoletne Rome'\n 'gnusom']",
         "['k številkam, kot sem rekla, ki ne lažejo' 'številke' 'številke'\n 'vsi ne delajo slabo']",
         "[]",
         "['Policistke in policisti na terenu delajo dobro, človek bi rekel, presenetljivo dobro glede na vodstvo policije, ki že dve leti to policijo razkraja'\n 'Niste učinkoviti in nikoli ne boste vedeli kako učinkoviti bi bili, če bi pred enim letom in pol sprejeli zakone, ki so jih napisali župani']",
         "['kot Novomeščanka'\n 'Tudi policistke in policisti, ki so del naše službe, našega varovanja tukaj, ki nas tako prijetno pozdravijo, ko vstopimo v ta Državni zbor in najbolj prijetno je, ko zvečer pozno odhajajo, nam pomahajo v slovo in zaželijo srečno pot']",
         "[]",
         "['Niste učinkoviti in nikoli ne boste vedeli kako učinkoviti bi bili']",
         "['vendar je delo policije neučinkovito in če bo to delo trajalo še dolgo, hvala bogu, da ta Vlada ne bo zelo dolgo, bomo prišli res na zaskrbljujoče številke']",
         "['Hvaležna sem jim kot Novomeščanka'\n 'Tudi policistke in policisti, ki so del naše službe, našega varovanja tukaj, ki nas tako prijetno pozdravijo, ko vstopimo v ta Državni zbor in najbolj prijetno je, ko zvečer pozno odhajajo, nam pomahajo v slovo in zaželijo srečno pot']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Povečalo se je število kaznivih dejanj gospodarske kriminalitete za 18 procentov in mladoletniške za. 9,4, in tisto kar nas res boli in so nekateri, ki so ime, ki so pisali odzive poslanskih skupin slabo prebrali, našo interpelacijo, je porast kriminalitete v družinah, na področju nasilja v družini se je ta povečala za 18 procentov in pri odvzetih mladoletniških osebah, kar spet mislim na moje dolenjske mladoletne Rome, se je povečala za 65,7 procenta, ta kriminaliteta'\n 'Torej Slovenija je varna država, vendar je delo policije neučinkovito in če bo to delo trajalo še dolgo, hvala bogu, da ta Vlada ne bo zelo dolgo, bomo prišli res na zaskrbljujoče številke in nekaj o mladoletnikih, kar nas dejansko tudi skrbi, posebno v Novi Sloveniji in na kar smo dejansko opozarjali, da se je povečalo število nasilništva med mladoletniki']",
         "[]",
         "['k številkam, kot sem rekla, ki ne lažejo'\n 'Hvaležna sem jim kot Novomeščanka, kajti ko je kjerkoli kaj narobe, posebno seveda v romskem naselju, o katerem bom govorila kasneje, so prvi na kraju policistke in policisti'\n 'številke so vas vzele, izdale']",
         "['Niste učinkoviti in nikoli ne boste vedeli kako učinkoviti bi bili, če bi pred enim letom in pol sprejeli zakone, ki so jih napisali župani']",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Hypocrisy",
         "Appeal_to_Hypocrisy",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "1",
         "Yes, the Appeal to Hypocrisy technique is used in the input.",
         "\"Drugo, rekli ste, da policija dela dobro, vendar ste v isti sapi povedali, da niste zadovoljni z delom CVZ\"",
         "['{\\n  \"explanation\": \"The Appeal to Hypocrisy technique is used in the input text when the speaker points out the contradiction in the minister\\'s statements. The minister claims that the police are doing well, yet simultaneously expresses dissatisfaction with the work of CVZ, which is part of the police. This highlights the inconsistency in the minister\\'s position, effectively attacking his credibility by showing hypocrisy.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[False]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/si/train-si-part_0004.parquet",
         null,
         null,
         "train",
         "{\"description\": null, \"verdict\": true}"
        ],
        [
         "209",
         "SI_interpelation_interior_7.txt",
         "2598",
         "5288",
         "SI",
         "Policisti prav tako dobijo navodila, naj ne spoštujejo zakonov, kajti policisti, ko primejo osebo, ki je ilegalno vstopila v Slovenijo, so dolžni preveriti vse okoliščine takega dejanja in morajo osebi zavrniti vstop v državo, če za to obstajajo zakoniti razlogi. Če je dejansko nesporno, da je oseba ilegalno vstopila v Slovenijo iz Hrvaške, ki je varna država, mora policist tako osebo vrniti v državo iz katere je prišla, torej s sosednjo Hrvaško. Tega policisti več ne preverjajo, kot so to prej, ampak postanejo le še zgolj taksisti, ki na državne stroške ilegalne migrante prevažajo v azilni dom v Ljubljano. Ti po nekaj dnevih azilni dom zapustijo, in če jih policisti na poti proti Avstriji ali Italiji ustavijo, imajo nalogo, da jim ponudijo ponovno možnost podajo vloge za azil ali mednarodno zaščito in ponovno nastanitev v azilnem domu, česar pa prej ni bilo. Taka navodila policistom seveda preprečujejo ostalo zakonodajo, delati ostalo zakonodajo, kar prav tako doprinaša k razpadanju sistema delovanja policije. V času bivanja v Sloveniji, se nekateri ilegalni migranti prosto gibajo po glavnem mestu in povzročajo številna kazniva dejanja, kradejo, napadajo policiste in paznike, ki jih pri tem zalotijo, posiljujejo, prekupčujejo z drogo in se pretepajo. Včasih katerega najdejo tudi utopljenega v Ljubljanici, med tem policija zadevo prikriva. Namesto ustreznega ukrepanja policija na podhodu železniške postaje v Ljubljani namesti nalepke z napisom: Če ste sami žrtev spolnega napada ali veste za ta primer, ga takoj prijavite policiji in ljudem svetuje, seveda mora biti žrtev posilstva, naj poskušajo s storilcem, naj se poskušajo s storilcem pogovoriti in vzbuditi občutek razumevanja ter sočutja. Zelo zanimivo. Ljudi, predvsem pa žensk, je ponoči strah hoditi po Ljubljani. Prodaja solzivcev se v Ljubljani poveča za kar 1000 odstotkov. Katastrofalne postanejo razmere tudi v centru za varnost in zaščito. Na to javnost opozori tožilka Mateja Gončin, ki se izpove o številnih nepravilnostih, zlorabah in celo naklepnih kaznivih dejanjih varnostnikov, zlasti pa vodstva omenjenega centra pri njenem varovanju. Prav tako naj bi varnostniki celo zbirali podatke o naši predsednici Državnega zbora zaradi morebitne kasnejše diskreditacije, iz Civilne centra za varstvo in zaščito naj bi informacije tudi odtekale kriminalcem. Čeprav je z nepravilnostmi večkrat seznanila tako nezakonitega generalnega direktorja policije Jušića, kot notranjega ministra Poklukarja, se na tem področju ni zgodilo nič. V CVZ se tudi nadpovprečno obremenjuje varnostnike, ki tudi več dni zaporedoma nimajo zagotovljenega minimalnega dnevnega počitka, nepravilno se obračunavajo delovne ure.",
         "True",
         "['Consequential_Oversimplification' 'Exaggeration-Minimisation'\n 'Loaded_Language' 'Appeal_to_Hypocrisy' 'Appeal_to_Pity'\n 'Questioning_the_Reputation' 'Appeal_to_Authority' 'Red_Herring' 'Doubt'\n 'Appeal_to_Fear-Prejudice']",
         "train",
         "['Taka navodila policistom seveda preprečujejo ostalo zakonodajo, delati ostalo zakonodajo, kar prav tako doprinaša k razpadanju sistema delovanja policije']",
         "[]",
         "['Čeprav je z nepravilnostmi večkrat seznanila tako nezakonitega generalnega direktorja policije Jušića, kot notranjega ministra Poklukarja, se na tem področju ni zgodilo nič']",
         "[]",
         "['le še zgolj taksisti' 'državne stroške']",
         "[]",
         "[]",
         "['Policisti prav tako dobijo navodila, naj ne spoštujejo zakonov'\n 'Včasih katerega najdejo tudi utopljenega v Ljubljanici, med tem policija zadevo prikriva']",
         "['V CVZ se tudi nadpovprečno obremenjuje varnostnike, ki tudi več dni zaporedoma nimajo zagotovljenega minimalnega dnevnega počitka, nepravilno se obračunavajo delovne ure']",
         "[]",
         "['številna kazniva dejanja'\n 'Katastrofalne postanejo razmere tudi v centru za varnost in zaščito']",
         "['Namesto ustreznega ukrepanja policija na podhodu železniške postaje v Ljubljani namesti nalepke z napisom: Če ste sami žrtev spolnega napada ali veste za ta primer, ga takoj prijavite policiji in ljudem svetuje, seveda mora biti žrtev posilstva, naj poskušajo s storilcem, naj se poskušajo s storilcem pogovoriti in vzbuditi občutek razumevanja ter sočutja'\n 'Prodaja solzivcev se v Ljubljani poveča za kar 1000 odstotkov']",
         "['nadpovprečno obremenjuje varnostnike, ki tudi več dni zaporedoma nimajo zagotovljenega minimalnega dnevnega počitka']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['V času bivanja v Sloveniji, se nekateri ilegalni migranti prosto gibajo po glavnem mestu in povzročajo številna kazniva dejanja, kradejo, napadajo policiste in paznike, ki jih pri tem zalotijo, posiljujejo, prekupčujejo z drogo in se pretepajo'\n 'Ljudi, predvsem pa žensk, je ponoči strah hoditi po Ljubljani'\n 'Prav tako naj bi varnostniki celo zbirali podatke o naši predsednici Državnega zbora zaradi morebitne kasnejše diskreditacije, iz Civilne centra za varstvo in zaščito naj bi informacije tudi odtekale kriminalcem']",
         "[]",
         "['tožilka Mateja Gončin']",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Hypocrisy",
         "Appeal_to_Hypocrisy",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "1",
         "Yes, the Appeal to Hypocrisy technique is used in the input.",
         "\"Čeprav je z nepravilnostmi večkrat seznanila tako nezakonitega generalnega direktorja policije Jušića, kot notranjega ministra Poklukarja, se na tem področju ni zgodilo nič\"",
         "['{\\n  \"explanation\": \"The Appeal to Hypocrisy technique is used in the input text by highlighting the inaction of the general director of police and the interior minister despite being informed of irregularities. This implies hypocrisy, as they are expected to uphold the law and address issues but fail to do so, thus attacking their reputation for inconsistency.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[False]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/si/train-si-part_0004.parquet",
         null,
         null,
         "train",
         "{\"description\": null, \"verdict\": true}"
        ],
        [
         "227",
         "SI_interpelation_interior_7.txt",
         "839",
         "2596",
         "SI",
         "Naslednji primer: žena pomočnika generalnega direktorja policije, ki na policiji opravlja piar službo, se prevaža s protokolarnim vozilom, ki je namenjeno za prevoze varovanih oseb in ne uslužbencev policije. Ko policijska voznica v poročilu navede, koga je prevažala, mora po navodilu pomočnika generalnega direktorja policije, ki je mož te osebe, poročilo popraviti. Prav tako je kasneje s strani vodstva šikanirana. Namestnik generalnega direktorja policije, torej mož piarovke, si za službeno vozilo prilasti novo toyoto, ostalim pa v uporabo nameni stara vozila. Zoper svetovalca generalnega direktorja, zdaj že bivšega generalnega direktorja za področje gospodarske in korupcijske kriminalitete, bi pa naj bilo podanih kar več kaznivih ovadb. Da je stanje v policiji slabo, dokazuje tudi poročilo iz prvega polletja leta 2023, iz katerega je razvidno, da se je število kaznivih dejanj znatno povečalo, število preiskanosti in odkritosti z lastno dejavnostjo pa znatno zmanjšalo. Povečala se je uporaba prisilnih sredstev in izdanih plačilnih nalogov, število opozoril se je zmanjšalo, prav tako se v deželici z imenom Slovenija v časih golobistov prične na meji odstranjevati ograja. S tem se ilegalnim migrantom sporoči, da je prehod preko Slovenije lažji, zato se prične znatno povečevati število ilegalnih prehodov meje. Migranti se tako množično gibajo po naseljih ob hrvaški meji, kar povzročajo, povzroča strah in nelagodje tamkajšnjim prebivalcem. Število je že tako veliko, da kapacitete v azilnih domovih več ne zadoščajo, zato vlada sklene, da bo v Obrežju in v Središču ob Dravi uredila izpostave azilnega doma, ne da bi se o tem predhodno posvetovala z lokalno skupnostjo. To seveda povzroči nestrinjanje in upor tamkajšnjega prebivalstva.",
         "True",
         "['Causal_Oversimplification' 'Exaggeration-Minimisation'\n 'Appeal_to_Hypocrisy' 'Loaded_Language' 'Appeal_to_Pity'\n 'Obfuscation-Vagueness-Confusion' 'Questioning_the_Reputation'\n 'Name_Calling-Labeling' 'Doubt' 'Repetition' 'Appeal_to_Fear-Prejudice']",
         "train",
         "['mora po navodilu pomočnika generalnega direktorja policije, ki je mož te osebe, poročilo popraviti']",
         "['golobistov']",
         "['žena pomočnika generalnega direktorja policije, ki na policiji opravlja piar službo, se prevaža s protokolarnim vozilom, ki je namenjeno za prevoze varovanih oseb in ne uslužbencev policije'\n 'Namestnik generalnega direktorja policije, torej mož piarovke, si za službeno vozilo prilasti novo toyoto, ostalim pa v uporabo nameni stara vozila'\n 'Zoper svetovalca generalnega direktorja, zdaj že bivšega generalnega direktorja za področje gospodarske in korupcijske kriminalitete, bi pa naj bilo podanih kar več kaznivih ovadb']",
         "[]",
         "['šikanirana' 'ilegalnim migrantom']",
         "['golobistov']",
         "[]",
         "['s strani vodstva šikanirana']",
         "[]",
         "[]",
         "['stara vozila' 'množično gibajo po naseljih ob hrvaški meji']",
         "[]",
         "['s strani vodstva šikanirana']",
         "[]",
         "[]",
         "['prisilnih sredstev']",
         "[]",
         "[]",
         "['zato se prične znatno povečevati število ilegalnih prehodov meje'\n 'Migranti se tako množično gibajo po naseljih ob hrvaški meji, kar povzročajo, povzroča strah in nelagodje tamkajšnjim prebivalcem']",
         "['S tem se ilegalnim migrantom sporoči, da je prehod preko Slovenije lažji, zato se prične znatno povečevati število ilegalnih prehodov meje']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Hypocrisy",
         "Appeal_to_Hypocrisy",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "1",
         "Yes, the Appeal to Hypocrisy technique is used in the input.",
         "\"žena pomočnika generalnega direktorja policije, ki na policiji opravlja piar službo, se prevaža s protokolarnim vozilom, ki je namenjeno za prevoze varovanih oseb in ne uslužbencev policije Namestnik generalnega direktorja policije, torej mož piarovke, si za službeno vozilo prilasti novo toyoto, ostalim pa v uporabo nameni stara vozila Zoper svetovalca generalnega direktorja, zdaj že bivšega generalnega direktorja za področje gospodarske in korupcijske kriminalitete, bi pa naj bilo podanih kar več kaznivih ovadb\"",
         "['{\\n  \"explanation\": \"The Appeal to Hypocrisy technique is used in the input text by highlighting the inconsistency in the actions of the deputy director of the police and his wife, who is in a public relations role. The text points out that while she uses a vehicle meant for protected individuals, her husband, the deputy director, appropriates a new vehicle for himself while providing older vehicles to others. This contradiction illustrates hypocrisy in their actions, as they are in positions of authority yet act in self-serving ways, which undermines their credibility.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[False]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/si/train-si-part_0006.parquet",
         null,
         null,
         "train",
         "{\"description\": null, \"verdict\": true}"
        ],
        [
         "234",
         "SI_interpelation_interior_6.txt",
         "270",
         "7305",
         "SI",
         "Na eni izmed sej Odbora za notranje zadeve mi je predsednica odbora dejala, da sem pravljičar, zato mi spoštovani kolegi in kolegice dovolite, da vam v imenu Poslanske skupine Slovenske demokratske stranke povem zgodbo, ki morda ni pravljica in se glasi takole. Tam, na sončni strani Alp, so v deželici z imenom Slovenija nedolgo nazaj vladali janšisti. Prišel je čas volitev in oblast so prevzeli golobisti. Tik pred prevzemom oblasti njihov vodja k sebi pokliče novo ministrico za notranje zadeve in novega vršilca dolžnosti generalnega direktorja policije in jima naroči: Imata eno samo nalogo in to je, da policijo očistita janšistov. Oba vestno pričneta z opravljanjem ukazane naloge in na vodilnih položajih policije zamenjujeta osebe, ki naj bi bili janšisti. Še posebej direktorja, tam na mojem koncu, kot je dejal njihov vodja, in direktor Nacionalnega preiskovalnega urada, kajti prav ta urad preiskuje vodjo golobistov, zaradi ukradene identitete v Romuniji in kup denarja na tamkajšnjem računu, nakazila novinarki Vesni Vuković za neznane usluge in balkanskim poslovanjem denarja. Pri svojem delu pa naletita na težavo, kdo je janšist in kdo ne, saj so določene osebe, menita, da zamenjava ni potrebna. To povzroči nezadovoljstvo pri vodji in zato vršilca dolžnosti generalnega direktorja policije vrže čez ramo in ga noče imenovati za generalnega direktorja policije. Temu se ministrica upre in odstopi. Praznino v vodenju notranjega ministrstva izkoristi človek iz ozadja, ki sicer deluje na drugem ministrstvu in vodji predlaga osebo, ki bo pa poslušna. In tako minister za notranje zadeve postane Boštjan Poklukar. No, in novi minister Boštjan Poklukar prične z delom, seveda s poslušnim delom. Najprej o tem, kako naj bi delovalo policija in ministrstvo sicer ne posvetuje z ustreznimi strokovnjaki, ampak pogovor opravi z Jašo Jenulom, torej osebo, ki je bila v času vodenja janšistov večkrat kaznovana, ker je pozival k neprijavljenim protestom. Nato kljub temu, da je znotraj policije na desetine visoko izobraženih ter usposobljenih kadrov, na željo vodje golobistov za vršilca dolžnosti generalnega direktorja policije imenuje Senada Jušića, ki seveda nima vodstvenih izkušenj, saj je v preteklosti deloval zgolj kot pomočnik vodje na lokalnem nivoju. Imenovanje za vršilca dolžnosti generalnega direktorja policije pa naj bi bilo celo nezakonito, saj se ob njegovi premestitvi ne bi opravilo varnostno preverjanje, kar je sicer vedno obvezno o premestitvi na višje delovno mesto. Senad Jušić je tako nezakonito imenovan kasneje za generalnega direktorja Policije, saj Uradniški svet pri sklepu o izpolnitvi pogojev upošteva neke interne akte policije in za to poda tudi pomanjkljivo obrazložitev, ker seveda nimajo kaj obrazložiti. Ker bivši vršilec dolžnosti generalnega direktorja policije to ve, poda tožbo na Upravno sodišče, ki seveda razsodi, da je sklep natečajne komisije nezakonit, tako da je tudi imenovanje Senada Jušića za generalnega direktorja Policije nezakonito. Vodja golobistov, generalni direktor Policije, kakor tudi minister Poklukar se sprenevedajo, zanemarjajo sistem pravne države in ne spoštujejo sodbe. Jušića varujejo pred očitki, tako daleč, da se mora v to dogajanje vključiti sam striček iz ozadja in po 83 dneh Senad Jušić odstopi. Seveda v času vodenja policije s strani Senada Jušića postajajo razmere na policiji iz dneva v dan bolj kritične in dosežejo najnižjo točko v sistem delovanja policije v zgodovini Slovenije. Nestrokovni vodje svojo nestrokovnost prenašajo na policiste in policiste. Na njih izvajajo pritiske. Policisti in policistke več ne vedo kako naj delajo, kako naj postopajo, da bo prav in da zoper njih ne bodo uvedene sankcije. Strah jih je, delajo več nadur in tako dalje. Tako se policisti raje umaknejo, kot bi posredovali v eni izmed garažnih hiš v Ljubljani, kjer so policijsko patruljo ob posredovanju obkrožili zbrani mladostniki in preprečevali vožnjo. Policista se z vozilom umakneta. Prav tako se v Ljubljani zbere množica ljudi, ki z avtomobili hupa, drifta s strelnim orožjem strelja v zrak in na eno izmed policijskih vozil celo namesti albansko zastavo. Na jugovzhodnem delu te deželice se pojavijo težave, saj policija ni več kos kaznivim dejanjem, tamkajšnjim živečim Romom, ki kršijo prometne predpise, izvajajo tatvine, ustrahujejo, pretepajo, uporabljajo strelno orožje in tako dalje. Slovenija postane tudi raj za hudodelske združbe, ki med sabo obračunavajo kar sredi dneva, izvajajo likvidacije, umore, in to kar pred očmi otrok. Prav tako umorijo skesanca, ki ga policija ne zaščiti kljub opozorilom o njegovi likvidaciji. V priljubljenem velenjskem lokalu ob pretepu poseduje lastnik tega lokala, ki pa je med najbolj iskanimi osebami v Evropi na Interpolovi tiralici, zaradi sodelovanja v kriminalni združbi v Bosni in Hercegovini. Kljub obsodbi na leto in pol zapora brez težav torej opravlja ta lokal, se svobodno giba po Sloveniji, saj ga policija ne aretira. Varnost v državi se iz leta v leto slabša, kar dokazuje podatek globalnega indeksa miru, ker je Slovenija iz četrtega mesta v letu 2020 v lanskem letu 2024 zdrsnila na deveto mesto. Policisti in policistke tako množično zapuščajo policijske vrste: bodisi se upokojijo ali pa si poiščejo boljšo zaposlitev in podajo odpoved. Novih zaposlitev ni. Zdesetkana, policija ne zmore več opravljati nalog, ki jih je dolžna izvajati. V času janšistov, torej v letu 2020 in 2021 je bilo kar 164 odstotkov več prihodov kot odhodov. V času golobistov, v letu 2022 in vaju 24 je pa bilo 60 odstotkov več. Torej, manj prihodov kot odhodov. Od tega v času ministrovanja Boštjana Poklukarja, torej v letu 23 in 24 za 51 odstotkov manj prihodov kot odhodov. Kljub temu, da je denarja v davčni blagajni rekordno veliko se za promocijo poklica policist, policijska ne namenjajo namenska finančna sredstva, ki bi imela v proračunu svojo postavko, kot jo ima to na primer vojska. Poslabšanje organizacijske klime v policiji dokazuje tudi raziskava odbora za integriteto in etiko v policiji, saj so se rezultati pod vodstvom Boštjana Poklukarja znatno poslabšali. Medtem se v vodstvenih vrstah izvajajo različne mahinacije, kot so naslednji; minister Poklukar podpiše novo sistemizacijo delovnih mest na Policijski upravi Maribor, kjer se omogoči zaposlitev izbrane osebe za pomočnika direktorja Policijske uprave. Njihovo namero na žalost tik pred iztekom roka razpise prekine poslanec iz naše poslanske skupine, ki na to temo poda pisno poslansko vprašanje. Tako v istem dnevu razpis prekličejo, zamenjajo priloge te sistemizacije in razpišejo novo delovno mesto, in sicer za policijskega svetnika na Policijski upravi. Ta oseba se na ta razpis prijavi in se tudi zaposli. V odgovoru na pisno poslansko vprašanje poslanca naše poslanske skupine se pa minister zlaže, da je zaposlitev policijskega svetnika na PU Maribor potrebna zaradi povečanega števila kaznivih dejanj Romov iz Hrvaške na območju Policijske postaje Ormož in Gorišnica in zaradi povečanega števila migracij na tem območju.",
         "True",
         "['Loaded_Language' 'Obfuscation-Vagueness-Confusion'\n 'Name_Calling-Labeling' 'Red_Herring' 'Guilt_by_Association' 'Doubt'\n 'Causal_Oversimplification' 'Exaggeration-Minimisation'\n 'Questioning_the_Reputation' 'Appeal_to_Authority' 'Appeal_to_Values'\n 'False_Dilemma-No_Choice' 'Repetition' 'Appeal_to_Fear-Prejudice']",
         "train",
         "['Še posebej direktorja, tam na mojem koncu, kot je dejal njihov vodja, in direktor Nacionalnega preiskovalnega urada, kajti prav ta urad preiskuje vodjo golobistov, zaradi ukradene identitete v Romuniji in kup denarja na tamkajšnjem računu, nakazila novinarki Vesni Vuković za neznane usluge in balkanskim poslovanjem denarja'\n 'Praznino v vodenju notranjega ministrstva izkoristi človek iz ozadja, ki sicer deluje na drugem ministrstvu in vodji predlaga osebo, ki bo pa poslušna'\n 'minister zlaže']",
         "['golobisti' 'janšistov' 'janšisti' 'janšistov' 'golobistov' 'golobistov'\n 'janšistov' 'golobistov']",
         "[]",
         "[]",
         "['janšisti' 'golobisti' 'janšist' 'vrže čez ramo' 'striček iz ozadja'\n 'deželice' 'hudodelske združbe' 'Zdesetkana' 'mahinacije']",
         "['janšisti' 'janšist' 'janšistov' 'golobistov' 'nezakonito' 'golobistov'\n 'janšistov' 'golobistov']",
         "[]",
         "['seveda s poslušnim delom'\n 'Nato kljub temu, da je znotraj policije na desetine visoko izobraženih ter usposobljenih kadrov, na željo vodje golobistov za vršilca dolžnosti generalnega direktorja policije imenuje Senada Jušića, ki seveda nima vodstvenih izkušenj, saj je v preteklosti deloval zgolj kot pomočnik vodje na lokalnem nivoju'\n 'Senad Jušić je tako nezakonito imenovan kasneje za generalnega direktorja Policije']",
         "['Na eni izmed sej Odbora za notranje zadeve mi je predsednica odbora dejala, da sem pravljičar, zato mi spoštovani kolegi in kolegice dovolite, da vam v imenu Poslanske skupine Slovenske demokratske stranke povem zgodbo, ki morda ni pravljica in se glasi takole'\n 'Tam, na sončni strani Alp, so v deželici z imenom Slovenija nedolgo nazaj vladali janšisti. Prišel je čas volitev in oblast so prevzeli golobisti. Tik pred prevzemom oblasti njihov vodja k sebi pokliče novo ministrico za notranje zadeve in novega vršilca dolžnosti generalnega direktorja policije in jima naroči: Imata eno samo nalogo in to je, da policijo očistita janšistov'\n 'Oba vestno pričneta z opravljanjem ukazane naloge in na vodilnih položajih policije zamenjujeta osebe, ki naj bi bili janšisti. Še posebej direktorja, tam na mojem koncu, kot je dejal njihov vodja, in direktor Nacionalnega preiskovalnega urada, kajti prav ta urad preiskuje vodjo golobistov, zaradi ukradene identitete v Romuniji in kup denarja na tamkajšnjem računu, nakazila novinarki Vesni Vuković za neznane usluge in balkanskim poslovanjem denarja. Pri svojem delu pa naletita na težavo, kdo je janšist in kdo ne, saj so določene osebe, menita, da zamenjava ni potrebna. To povzroči nezadovoljstvo pri vodji in zato vršilca dolžnosti generalnega direktorja policije vrže čez ramo in ga noče imenovati za generalnega direktorja policije. Temu se ministrica upre in odstopi. Praznino v vodenju notranjega ministrstva izkoristi človek iz ozadja, ki sicer deluje na drugem ministrstvu in vodji predlaga osebo, ki bo pa poslušna']",
         "[]",
         "['eno samo nalogo' 'zgolj kot pomočnik vodje na lokalnem nivoju'\n 'iz dneva v dan bolj kritične in dosežejo najnižjo točko v sistem delovanja policije v zgodovini Slovenije'\n 'Slovenija postane tudi raj za hudodelske združbe, ki med sabo obračunavajo kar sredi dneva, izvajajo likvidacije, umore, in to kar pred očmi otrok'\n 'najbolj iskanimi osebami v Evropi na Interpolovi tiralici' 'množično'\n 'V času janšistov, torej v letu 2020 in 2021 je bilo kar 164 odstotkov več prihodov kot odhodov'\n 'rekordno veliko' 'znatno poslabšali']",
         "[]",
         "[]",
         "[]",
         "['nezakonito' 'nezakonito'\n 'Vodja golobistov, generalni direktor Policije, kakor tudi minister Poklukar se sprenevedajo, zanemarjajo sistem pravne države in ne spoštujejo sodbe'\n 'Nestrokovni vodje svojo nestrokovnost prenašajo na policiste in policiste']",
         "['človek iz ozadja' 'neke interne akte policije' 'uvedene sankcije']",
         "[]",
         "[]",
         "['očistita janšistov'\n 'Nestrokovni vodje svojo nestrokovnost prenašajo na policiste in policiste. Na njih izvajajo pritiske'\n 'Policisti in policistke več ne vedo kako naj delajo, kako naj postopajo, da bo prav in da zoper njih ne bodo uvedene sankcije. Strah jih je, delajo več nadur in tako dalje'\n 'Prav tako se v Ljubljani zbere množica ljudi, ki z avtomobili hupa, drifta s strelnim orožjem strelja v zrak in na eno izmed policijskih vozil celo namesti albansko zastavo'\n 'Na jugovzhodnem delu te deželice se pojavijo težave, saj policija ni več kos kaznivim dejanjem, tamkajšnjim živečim Romom, ki kršijo prometne predpise, izvajajo tatvine, ustrahujejo, pretepajo, uporabljajo strelno orožje in tako dalje'\n 'Slovenija postane tudi raj za hudodelske združbe, ki med sabo obračunavajo kar sredi dneva, izvajajo likvidacije, umore, in to kar pred očmi otrok'\n 'Prav tako umorijo skesanca, ki ga policija ne zaščiti kljub opozorilom o njegovi likvidaciji'\n 'V priljubljenem velenjskem lokalu ob pretepu poseduje lastnik tega lokala, ki pa je med najbolj iskanimi osebami v Evropi na Interpolovi tiralici, zaradi sodelovanja v kriminalni združbi v Bosni in Hercegovini'\n 'Kljub obsodbi na leto in pol zapora brez težav torej opravlja ta lokal, se svobodno giba po Sloveniji, saj ga policija ne aretira'\n 'povečanega števila kaznivih dejanj Romov']",
         "['Varnost v državi se iz leta v leto slabša, kar dokazuje podatek globalnega indeksa miru, ker je Slovenija iz četrtega mesta v letu 2020 v lanskem letu 2024 zdrsnila na deveto mesto'\n 'Od tega v času ministrovanja Boštjana Poklukarja, torej v letu 23 in 24 za 51 odstotkov manj prihodov kot odhodov']",
         "['Nato kljub temu, da je znotraj policije na desetine visoko izobraženih ter usposobljenih kadrov'\n 'odbora za integriteto in etiko v policiji']",
         "['bodisi se upokojijo ali pa si poiščejo boljšo zaposlitev in podajo odpoved']",
         "[]",
         "[]",
         "['sicer ne posvetuje z ustreznimi strokovnjaki, ampak pogovor opravi z Jašo Jenulom, torej osebo, ki je bila v času vodenja janšistov večkrat kaznovana, ker je pozival k neprijavljenim protestom']",
         "train",
         "GPT_41/v001/Appeal_to_Hypocrisy",
         "Appeal_to_Hypocrisy",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Appeal to Hypocrisy technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not contain any explicit or implicit attacks on the reputation of a target by charging them with hypocrisy or inconsistency. There are no instances where the speaker calls out hypocrisy directly or highlights contradictions between different positions or actions. Therefore, the Appeal to Hypocrisy technique is not used.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[False]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/si/train-si-part_0006.parquet",
         null,
         null,
         "train",
         "{\"description\": null, \"verdict\": false}"
        ],
        [
         "256",
         "SI_interpelation_interior_11.txt",
         "2427",
         "2780",
         "SI",
         "Vse te stvari bomo uredili s sprejetjem novele Zakona o nalogah in pooblastilih policije, ki bo bolje urejala ukrep prepovedi približevanja. To so in bi morale biti družbene prioritete, ki bi si zaslužile obravnavo na sejah teles parlamenta, ne pa razne tendencioznosti, temelječe na napihovanju bojda slabe varnostne situacije, kot sem opisala uvodoma.",
         "True",
         "['Consequential_Oversimplification' 'Loaded_Language' 'Appeal_to_Values'\n 'Red_Herring']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "['tendencioznosti, temelječe na napihovanju bojda slabe varnostne situacije']",
         "[]",
         "[]",
         "[]",
         "['Vse te stvari bomo uredili s sprejetjem novele Zakona o nalogah in pooblastilih policije, ki bo bolje urejala ukrep prepovedi približevanja']",
         "[]",
         "[]",
         "['Vse te stvari bomo uredili s sprejetjem novele Zakona o nalogah in pooblastilih policije, ki bo bolje urejala ukrep prepovedi približevanja']",
         "[]",
         "[]",
         "['To so in bi morale biti družbene prioritete']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Hypocrisy",
         "Appeal_to_Hypocrisy",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Appeal to Hypocrisy technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. There are no explicit or implicit references to contradictions between positions or actions, which is essential for the Appeal to Hypocrisy technique.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[False]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/si/train-si-part_0000.parquet",
         null,
         null,
         "train",
         "{\"description\": null, \"verdict\": false}"
        ],
        [
         "259",
         "SI_interpelation_interior_1.txt",
         "0",
         "1089",
         "SI",
         "Tožilka se je zaradi nezaupanja v policijo varovanju odpovedala, saj je posumila, da je prišlo do nezakonitega vpogleda v nadzorno kamero, nameščeno na njeni hiši. Naj spomnim na znameniti stavek predsednika Vlade: \"Namesto, da bi bila varovana, je bila nadzorovana.\" Javno je priznal napake generalnega direktorja policije in ministra Poklukarja, toda ni ukrepal. In pri odstopu gospoda Jušića sta oba, tako predsednik vlade kot minister Poklukar, rekla, da je Jušić delal dobro in da je njegov odstop časten. Kaj je častnega v takšnem delu, kot sem ga zdaj predstavila? Na SVZ so razmere še zdaj nerešene in pred kratkim smo slišali, da mnenje, ali je potrebno ali ni potrebno varovanje tožilke in ostalih, ki delajo v pravnem sistemu, menjajo na SVZ hitreje kot mnenja, mnenje predsednik Vlade oziroma stališče o recimo omrežninah. Saj veste, v parih urah so rekli, da, potem pa ne. In kaj smo danes slišali? Da je bila v obdobju, ko SVZ ni varoval tožilke Gončinove, velika verjetnost, da je bil v Sloveniji morilec Satka Zovka, tako imenovani Cezar. In hvala bogu, tožilka je še živa.",
         "True",
         "['Appeal_to_Hypocrisy' 'Questioning_the_Reputation'\n 'Appeal_to_Fear-Prejudice']",
         "train",
         "['Kaj je častnega v takšnem delu, kot sem ga zdaj predstavila?']",
         "[]",
         "['Javno je priznal napake generalnega direktorja policije in ministra Poklukarja, toda ni ukrepal']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Da je bila v obdobju, ko SVZ ni varoval tožilke Gončinove, velika verjetnost, da je bil v Sloveniji morilec Satka Zovka, tako imenovani Cezar']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Hypocrisy",
         "Appeal_to_Hypocrisy",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "1",
         "Yes, the Appeal to Hypocrisy technique is used in the input.",
         "\"Javno je priznal napake generalnega direktorja policije in ministra Poklukarja, toda ni ukrepal\"",
         "['{\\n  \"explanation\": \"The Appeal to Hypocrisy technique is used in the input text by highlighting the inconsistency of the Prime Minister\\'s public acknowledgment of mistakes made by the police leadership while failing to take any action. This contradiction points to hypocrisy, as the Prime Minister criticizes the situation but does not follow through with necessary measures, thus undermining his credibility.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[False]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/si/train-si-part_0000.parquet",
         null,
         null,
         "train",
         "{\"description\": null, \"verdict\": true}"
        ],
        [
         "260",
         "SI_interpelation_interior_0.txt",
         "1825",
         "2018",
         "SI",
         "Glasujemo. Ravno sem bila obveščena, da je očitno prišlo do tehničnih težav s sistemom in da bi bilo treba za 15 minut prekiniti sejo, da bomo te tehnične težave rešili. Se iskreno opravičujem.",
         "False",
         "[]",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Hypocrisy",
         "Appeal_to_Hypocrisy",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Appeal to Hypocrisy technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. There are no explicit or implicit references to contradictions or past actions that would qualify as an Appeal to Hypocrisy.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[False]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/si/train-si-part_0000.parquet",
         null,
         null,
         "train",
         "{\"description\": null, \"verdict\": false}"
        ],
        [
         "263",
         "SI_interpelation_interior_0.txt",
         "3170",
         "3956",
         "SI",
         "Danes bomo govorili o delu ministra za notranje zadeve in o razlogih za njegovo razrešitev, v resnici pa bomo predstavljali tudi bistvo zgrešenih potez predsednika Vlade. On je namreč obljubljal eno, delal je popolnoma drugače. In kaj je pravzaprav največja napaka predsednika vlade? Da napak ne priznava. Dela in odloča se po navdihu. Kljub temu, da tako predsednik vlade kot v Svobodi ne priznavajo napak, sem prepričana, da globoko v sebi vedo, da je bila odstranitev Tatjane Bobnar in Boštjana Lindava napaka. Zaradi te napake je posledično prišlo do politizacije policije, krize vodenja razkroja institucij in zaradi velike ubogljivosti in želje ugajati šefu je stanje na področju varnosti slabo. Tako čutijo ljudje, tako govorijo ankete in tako vam bom zdaj dokazala s številkami.",
         "True",
         "['Consequential_Oversimplification' 'Appeal_to_Hypocrisy'\n 'Appeal_to_Popularity']",
         "train",
         "[]",
         "[]",
         "['Danes bomo govorili o delu ministra za notranje zadeve in o razlogih za njegovo razrešitev, v resnici pa bomo predstavljali tudi bistvo zgrešenih potez predsednika Vlade'\n 'On je namreč obljubljal eno, delal je popolnoma drugače'\n 'Kljub temu, da tako predsednik vlade kot v Svobodi ne priznavajo napak, sem prepričana, da globoko v sebi vedo, da je bila odstranitev Tatjane Bobnar in Boštjana Lindava napaka']",
         "[]",
         "[]",
         "[]",
         "['Tako čutijo ljudje, tako govorijo ankete']",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Zaradi te napake je posledično prišlo do politizacije policije, krize vodenja razkroja institucij in zaradi velike ubogljivosti in želje ugajati šefu je stanje na področju varnosti slabo']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Hypocrisy",
         "Appeal_to_Hypocrisy",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "1",
         "Yes, the Appeal to Hypocrisy technique is used in the input.",
         "\"Danes bomo govorili o delu ministra za notranje zadeve in o razlogih za njegovo razrešitev, v resnici pa bomo predstavljali tudi bistvo zgrešenih potez predsednika Vlade On je namreč obljubljal eno, delal je popolnoma drugače Kljub temu, da tako predsednik vlade kot v Svobodi ne priznavajo napak, sem prepričana, da globoko v sebi vedo, da je bila odstranitev Tatjane Bobnar in Boštjana Lindava napaka\"",
         "['{\\n  \"explanation\": \"The Appeal to Hypocrisy technique is used in the input text by highlighting the inconsistency between the Prime Minister\\'s promises and his actions. The speaker points out that the Prime Minister promised one thing but acted in a completely different manner, which directly attacks his credibility and reputation. This aligns with the definition of the technique, as it calls out the hypocrisy of the Prime Minister not acknowledging his mistakes while implying that he is aware of them.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[False]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/si/train-si-part_0000.parquet",
         null,
         null,
         "train",
         "{\"description\": null, \"verdict\": true}"
        ],
        [
         "265",
         "SI_interpelation_interior_2.txt",
         "3786",
         "5640",
         "SI",
         "Dovolite, da se referiram še na eno vašo značajsko lastnost, ki jo izpostavljate v odgovoru na interpelacijo. Zapišete: Visoka stopnja politične kulture bo vedno eno izmed mojih temeljnih vodil pri opravljanju funkcije. Pa se zato za zaključek dotaknimo še nezakonitega imenovanja direktorja policije. V odgovoru na interpelacijo zapišete: Nezakonitosti imenovanja magistra senata Jušića za generalnega direktorja policije. Posledično Upravno sodišče torej sploh ni moglo ugotoviti in je tudi ni ugotovilo. O nezakonitem imenovanju zato ne moremo in ne smemo govoriti. Spoštovani minister, pravnik doktor Pirnat, si je vendarle drznil govoriti. Rekel je: Če je akt posebne natečajne komisije uradniškega sveta nezakonit, potem je gotovo nezakonito tudi imenovanje generalnega direktorja. Tako nazadnje veleva tudi zdrav razum. Na dan sodbe Upravnega sodišča je potekel rok za odstop generalnega direktorja policije. Kajti, gospod Poklukar, če ste res pošten in iskren politik, potem se morava strinjati, da za nezakonito imenovan direktor ne more opravljati svoje funkcije niti en dan. Kakšen vtis v javnosti pa daje policija, če jo vodi nezakonito imenovan direktor, medtem ko v vseh ostalih zahteva zakonitost delovanja? In naprej, z vsakim dnem, ko je po odločitvi sodišča generalni direktor Policije vztrajal na svojem mestu, vi, gospod Poklukar, pa ga niste pozvali k odstopu, je minil dan strmoglavljenja politične kulture te vlade. In vi ste več kot dva meseca branili to stanje. Če ste torej pošten in iskren politik, katerega, kot sami pravite, visoka stopnja politične kulture bo vedno eno izmed temeljnih vodil pri opravljanju funkcije ministra, potem preprosto morate odstopiti, ker ste predolgo tolerirali nekaj, kar ni moč tolerirati, sploh ne na vrhu represivnega organa, ki bi moral biti vsem državljankam in državljanom za vzgled. Hvala.",
         "True",
         "['Exaggeration-Minimisation' 'Loaded_Language' 'Appeal_to_Hypocrisy'\n 'Appeal_to_Authority' 'Appeal_to_Values' 'Repetition']",
         "train",
         "[]",
         "[]",
         "['Kakšen vtis v javnosti pa daje policija, če jo vodi nezakonito imenovan direktor, medtem ko v vseh ostalih zahteva zakonitost delovanja?']",
         "[]",
         "['drznil govoriti']",
         "['pošten in iskren politik' 'pošten in iskren politik']",
         "[]",
         "[]",
         "[]",
         "[]",
         "['je minil dan strmoglavljenja politične kulture te vlade']",
         "[]",
         "[]",
         "[]",
         "['Če ste torej pošten in iskren politik, katerega, kot sami pravite, visoka stopnja politične kulture bo vedno eno izmed temeljnih vodil pri opravljanju funkcije ministra, potem preprosto morate odstopiti, ker ste predolgo tolerirali nekaj, kar ni moč tolerirati, sploh ne na vrhu represivnega organa, ki bi moral biti vsem državljankam in državljanom za vzgled']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['pravnik doktor Pirnat']",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Hypocrisy",
         "Appeal_to_Hypocrisy",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "1",
         "Yes, the Appeal to Hypocrisy technique is used in the input.",
         "\"Kakšen vtis v javnosti pa daje policija, če jo vodi nezakonito imenovan direktor, medtem ko v vseh ostalih zahteva zakonitost delovanja?\"",
         "['{\\n  \"explanation\": \"The Appeal to Hypocrisy technique is used in the input text by highlighting the inconsistency in the minister\\'s stance on legality. The speaker points out that while the minister demands legality in other areas, he tolerates an illegally appointed police director, thus attacking the minister\\'s reputation for being a principled politician. This aligns with the definition, as it calls out the hypocrisy of the minister\\'s actions compared to his stated values.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[False]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/si/train-si-part_0000.parquet",
         null,
         null,
         "train",
         "{\"description\": null, \"verdict\": true}"
        ],
        [
         "266",
         "SI_interpelation_interior_9.txt",
         "3480",
         "4437",
         "SI",
         "Spoštovani minister Poklukar! Državljanov ne zanimajo obljube o reorganizaciji, zanima jih, kdo in zakaj se je spravil na tožilko v zadevi Kavaški klan, kdaj bodo spisane in vložene ovadbe, kdaj se bodo začeli kazenski in predkazenski postopki glede tega, to nas zanima. Že 15 mesecev je minilo, odkar je tožilka vse odgovorne seznanila z nepravilnostmi, ko je šlo za varovanje predsednika vlade Goloba, se je zadeva rešila v treh mesecih. ko je šlo za varovanje predsednika vlade Goloba, se je zadeva rešila v treh mesecih. Ali vam je, minister Poklukar, pomembno samo varovanje predsednika vlade, za druge se pa ne sekirate, tudi za tiste, ki preganjajo mafijone, za predsednika vlade posebno varnostno službo, za ostale pa, kaj? Ne varnostno službo? Še veliko tega imam za povedati, ampak tudi kolegice in kolegi iz Poslanske skupine Nove Slovenije bodo kasneje v razpravi, kot tudi predlagateljica, ki je odlično uvedla zadevo, bodo kasneje še povedali.",
         "True",
         "['Appeal_to_Hypocrisy' 'Questioning_the_Reputation'\n 'Name_Calling-Labeling' 'Appeal_to_Popularity' 'Repetition']",
         "train",
         "['Ali vam je, minister Poklukar, pomembno samo varovanje predsednika vlade, za druge se pa ne sekirate, tudi za tiste, ki preganjajo mafijone, za predsednika vlade posebno varnostno službo, za ostale pa, kaj? Ne varnostno službo?']",
         "['mafijone']",
         "['Že 15 mesecev je minilo, odkar je tožilka vse odgovorne seznanila z nepravilnostmi, ko je šlo za varovanje predsednika vlade Goloba, se je zadeva rešila v treh mesecih. ko je šlo za varovanje predsednika vlade Goloba, se je zadeva rešila v treh mesecih']",
         "[]",
         "[]",
         "['to nas zanima'\n 'ko je šlo za varovanje predsednika vlade Goloba, se je zadeva rešila v treh mesecih']",
         "['Državljanov ne zanimajo obljube o reorganizaciji, zanima jih, kdo in zakaj se je spravil na tožilko v zadevi Kavaški klan, kdaj bodo spisane in vložene ovadbe, kdaj se bodo začeli kazenski in predkazenski postopki glede tega, to nas zanima']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Hypocrisy",
         "Appeal_to_Hypocrisy",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "1",
         "Yes, the Appeal to Hypocrisy technique is used in the input.",
         "\"Že 15 mesecev je minilo, odkar je tožilka vse odgovorne seznanila z nepravilnostmi, ko je šlo za varovanje predsednika vlade Goloba, se je zadeva rešila v treh mesecih. ko je šlo za varovanje predsednika vlade Goloba, se je zadeva rešila v treh mesecih\"",
         "['{\\n  \"explanation\": \"The Appeal to Hypocrisy technique is used in the input text by highlighting the inconsistency in the minister\\'s actions regarding the protection of the Prime Minister compared to the lack of action for others. The speaker points out that while issues concerning the Prime Minister were resolved quickly, similar issues affecting others have not been addressed, thus calling out the hypocrisy in prioritizing one over the other.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[False]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/si/train-si-part_0001.parquet",
         null,
         null,
         "train",
         "{\"description\": null, \"verdict\": true}"
        ],
        [
         "271",
         "SI_interpelation_interior_2.txt",
         "5869",
         "5947",
         "SI",
         "Spoštovana gospa predsednica Državnega zbora! Spoštovane poslanke in poslanci!",
         "False",
         "[]",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Hypocrisy",
         "Appeal_to_Hypocrisy",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Appeal to Hypocrisy technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. There are no explicit or implicit references to contradictions or past actions that would qualify as an Appeal to Hypocrisy.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[False]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/si/train-si-part_0001.parquet",
         null,
         null,
         "train",
         "{\"description\": null, \"verdict\": false}"
        ],
        [
         "272",
         "SI_interpelation_interior_4.txt",
         "3163",
         "7586",
         "SI",
         "V javnosti najodmevnejši očitek, ki so ga seveda prevzeli tudi predlagatelji, je očitek glede delovanja Centra za varovanje in zaščito. Situacija v zvezi z delovanjem in organizacijo Centra za varovanje in zaščito je bistveno bolj kompleksna, kot jo sicer nekateri radi prikazujejo in je trenutno v fazi preiskave morebitnih sumov storitve kaznivih dejanj pripadnikov te enote, ki jo vodi specializirano državno tožilstvo. Naj povem, da je Center za varovanje in zaščito vseeno zelo profesionalna enota policije z dolgoletno tradicijo in je sposobna brezhibno izvesti tudi najzahtevnejša varovanja, vključno z zagotavljanjem najvišje stopnje varovanja svetovnim voditeljem, ki so izpostavljeni visokim varnostnim tveganjem in grožnjam. Pri osebnem varovanju je ključno vzpostaviti zaupanje med varnostniki in varovano osebo. Iz lastnih izkušenj že drugič kot varovana oseba lahko potrdim, da policisti varnostniki svoje naloge opravljajo profesionalno in dosledno. Naj pa jasno povem, da je bil zadnji izredni nadzor nad Centrom za varovanje in zaščito uveden leta 2010 s strani takratne ministrice za notranje zadeve, zaradi tako imenovane afere katarske ure, in ponovni nadzor nad enoto leta 2012 s strani takratnega notranjega ministra. Dejstvo je tudi, da v vsem tem času direktorat za policijo in druge varnostne naloge ministrstva v obravnavo ni prejel nobene pritožbe zoper dela policistov varnostnikov centra za varovanje in zaščito. Nekdanji generalni direktor Policije magister Senad Jušić je takoj po nastopu funkcije leta 2023 aktivno pričel z različnimi aktivnostmi in ukrepi za izboljšanje stanja v Centru za varovanje in zaščito. Zaradi določenih nepravilnosti in napak v enoti je večkrat odredil notranje varnostne postopke, ki pa so v izključni pristojnosti generalnega direktorja policije in ne ministra za notranje zadeve. Kot minister za notranje zadeve sem na podlagi nekaterih medijskih objav o nepravilnostih v Centru za varovanje in zaščito 28. februarja lani v skladu s svojo zakonsko pristojnostjo direktoratu za policijo in druge varnostne naloge Ministrstva za notranje zadeve odredil izredni strokovni nadzor nad izvajanjem policijskih nalog in pooblastil v Centru za varovanje in zaščito, ki sta ga izvedla nadzornika direktorata. Po zaključnem nadzoru sta nadzornika direktorata konec avgusta leta 2024 zaključila poročilo o izrednem nadzoru v centru za varovanje in zaščito, ki je pod oznako stopnje zaupnosti interno. V samem izrednem strokovnem nadzoru so bile ugotovljene nepravilnosti in napake, ki so zapisane v poročilu izrednega nadzora. Na podlagi teh ugotovitev sem generalnemu direktorju policije z usmeritvami in obveznimi navodili ministra naložil ukrepe za izboljšanje stanja v Centru za varovanje in zaščito. Policija je takoj pristopila k odpravljanju nepravilnosti in pripravila načrt za odpravo ugotovljenih nepravilnosti in pomanjkljivosti na podlagi mojih usmeritev in obveznih navodil in ga začela tudi izvajati. V oddaji TV Slovenija Tarča lani decembra, so bile razkrite operativne informacije o varovanju varovanih oseb, izpostavljene so bile nepravilnosti in podani morebitni sumi storitve kaznivih dejanj v Centru za varovanje in zaščito na podlagi razkritih odklonov sem naslednji dan generalnemu direktorju policije izdal usmeritev in obvezno navodilo za reorganizacijo centra za varovanje in zaščito do 1. aprila letos. Prav tako sem zaradi javnega dvoma v zakonitost in transparentnost postopka javnega naročanja izdal sklep o izvedbi notranje revizije uporabe nastanitvenih kapacitet za potrebe Centra za varovanje in zaščito. Na podlagi medijskih očitkov in nekaterih neresničnih informacij ter predvsem zaradi velikega interesa javnosti, je bila delno umaknjena stopnja zaupnosti sporočila izrednega nadzora, ki ga je na tiskovni konferenci predstavil direktor direktorata za policijo in druge varnostne naloge, prav tako pa so ga prejeli nekateri mediji po dostopu do informacij javnega značaja in ga tudi javno objavili. Prav tako sem z elektronskim sporočilom zaprosil generalno državno tožilko, da v skladu s svojimi pristojnostmi naredi vse, da se čim prej preiščejo sumi morebitnih kaznivih dejanj v Centru za varovanje in zaščito. Njen odgovor je bil, da je preiskava že uvedena po uradni dolžnosti. Naj še dodam, da je Specializirano državno tožilstvo zahtevalo celotno poročilo o izrednem nadzoru, ki ga je Ministrstvo za notranje zadeve tudi predal.",
         "True",
         "['Exaggeration-Minimisation' 'Loaded_Language'\n 'Obfuscation-Vagueness-Confusion' 'Appeal_to_Authority'\n 'Appeal_to_Values' 'Appeal_to_Popularity' 'Doubt']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "['seveda'\n 'vseeno zelo profesionalna enota policije z dolgoletno tradicijo'\n 'brezhibno izvesti tudi najzahtevnejša varovanja, vključno z zagotavljanjem najvišje stopnje varovanja'\n 'operativne informacije']",
         "[]",
         "['ni prejel nobene pritožbe']",
         "['nekaterih neresničnih informacij']",
         "[]",
         "[]",
         "['V javnosti najodmevnejši očitek' 'aktivno pričel']",
         "[]",
         "[]",
         "[]",
         "['javnega dvoma v zakonitost in transparentnost postopka javnega naročanja']",
         "['bolj kompleksna, kot jo sicer nekateri radi prikazujejo'\n 'različnimi aktivnostmi in ukrepi' 'določenih nepravilnosti in napak'\n 'operativne informacije' 'nepravilnosti'\n 'morebitni sumi storitve kaznivih dejanj' 'javnega dvoma']",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Naj povem, da je Center za varovanje in zaščito vseeno zelo profesionalna enota policije z dolgoletno tradicijo in je sposobna brezhibno izvesti tudi najzahtevnejša varovanja, vključno z zagotavljanjem najvišje stopnje varovanja svetovnim voditeljem, ki so izpostavljeni visokim varnostnim tveganjem in grožnjam'\n 'kot varovana oseba lahko potrdim' 'Kot minister za notranje zadeve'\n 'v skladu s svojo zakonsko pristojnostjo' 'nadzornika direktorata'\n 'izrednem strokovnem nadzoru']",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Hypocrisy",
         "Appeal_to_Hypocrisy",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Appeal to Hypocrisy technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not contain any instances of the Appeal to Hypocrisy technique, as it does not attack the reputation of any individual by charging them with hypocrisy or inconsistency. The text focuses on the operations and oversight of the Center for Protection and Security without making any comparisons to past actions or positions that would indicate hypocrisy.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[False]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/si/train-si-part_0001.parquet",
         null,
         null,
         "train",
         "{\"description\": null, \"verdict\": false}"
        ],
        [
         "275",
         "SI_interpelation_interior_10.txt",
         "554",
         "2314",
         "SI",
         "Na tem mestu Socialni demokrati opozarjamo, da se je v razmerju do vodstvenih kadrov v policiji doslej že bistveno prevečkrat pozabljalo na potrebo po ohranjanju zakonskih določb, gospod Jušić je položaj obdržal kljub ugotovitvam upravnega sodišča in po zaslugi intervenciji politike, zato zahtevamo, da minister in koalicija opravita nujen razmislek o spremembi načina imenovanja generalnega direktorja policije na način, ki v največji možni meri politično izključi iz postopkov imenovanja in izbire. Pred navedenim pa so se odprli tudi očitki zoper strokovnost ministra, ki izhaja iz katastrofalnega stanja v Centru za varovanje in zaščito. Specializirana tožilka, gospa Gončin, je pričala o napakah v okviru njenega varovanja in CVZ očita, da naj bi nepooblaščeno zbirali njene zasebne podatke. Sama je celo izjavila, da je izgubila zaupanje v policijo. Sporne okoliščine se pojavljajo tudi v razmerju zaposlitve člana osebnega varovanja tožilke. Specializirana tožilka Gončin je proti zaposlenemu v centru spisala tudi kazensko ovadbo, in sicer zaradi nepooblaščenega vstopa v videonadzorni sistem, ki je namenjen njenemu varovanju. Članu njenega varovanja očitno kaznivo dejanje zlorabe pooblastil. Kljub navedenemu pa je pod ministrom in nekdanjim generalnim direktorjem v okviru CVZ celo napredoval. Dejstvo je, da je stanje na CVZ odgovornost ministra za notranje zadeve, saj ima na podlagi določb Zakona o organiziranosti in delu v policiji vsa pooblastila, ki mu preko podajanja usmeritev omogočajo, da stanje posredno z intervencijo v vodstvo policije odpravi. Zato je nesprejemljivo, da takšno stanje na CVZ vlada že kar 14 mesecev. Navsezadnje pa gre za odgovornost ministra tudi zato, ker je na vodilno mesto v policiji imenovan neprimeren kader.",
         "True",
         "['Loaded_Language' 'Appeal_to_Hypocrisy' 'Questioning_the_Reputation'\n 'Appeal_to_Authority' 'Doubt' 'Appeal_to_Fear-Prejudice']",
         "train",
         "['opozarjamo, da se je v razmerju do vodstvenih kadrov v policiji doslej že bistveno prevečkrat pozabljalo na potrebo po ohranjanju zakonskih določb, gospod Jušić je položaj obdržal kljub ugotovitvam upravnega sodišča in po zaslugi intervenciji politike'\n 'očitki zoper strokovnost ministra'\n 'Kljub navedenemu pa je pod ministrom in nekdanjim generalnim direktorjem v okviru CVZ celo napredoval']",
         "[]",
         "['Kljub navedenemu pa je pod ministrom in nekdanjim generalnim direktorjem v okviru CVZ celo napredoval']",
         "[]",
         "['katastrofalnega stanja']",
         "[]",
         "[]",
         "['Navsezadnje pa gre za odgovornost ministra tudi zato, ker je na vodilno mesto v policiji imenovan neprimeren kader']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['zaradi nepooblaščenega vstopa v videonadzorni sistem, ki je namenjen njenemu varovanju']",
         "[]",
         "['Sama je celo izjavila, da je izgubila zaupanje v policijo']",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Hypocrisy",
         "Appeal_to_Hypocrisy",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "1",
         "Yes, the Appeal to Hypocrisy technique is used in the input.",
         "\"Kljub navedenemu pa je pod ministrom in nekdanjim generalnim direktorjem v okviru CVZ celo napredoval\"",
         "['{\\n  \"explanation\": \"The Appeal to Hypocrisy technique is used in the input text by highlighting the inconsistency in the minister\\'s actions. The excerpt points out that despite the problematic situation in the CVZ, a member of the security team has advanced under the minister\\'s leadership, suggesting hypocrisy in the minister\\'s ability to manage the situation while allowing such advancements.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[False]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/si/train-si-part_0001.parquet",
         null,
         null,
         "train",
         "{\"description\": null, \"verdict\": true}"
        ],
        [
         "286",
         "20231208_URW_BG_72.txt",
         "3279",
         "3627",
         "BG",
         "Аз обаче не взех репликата за това, а взех репликата, господин Гуцанов, за да Ви кажа, че не само лъжете в това Ваше изказване, но и от 29 септември, когато излязохте на тази трибуна да ни кажете, че бензинът става 4 лв., измина доста време, а вече той е със 17 стотинки надолу от деня, в който Вие го казахте, и нямат нищо общо с 4 лв. Благодаря. ",
         "True",
         "['Appeal_to_Hypocrisy' 'Red_Herring']",
         "train",
         "[]",
         "[]",
         "['Аз обаче не взех репликата за това, а взех репликата, господин Гуцанов, за да Ви кажа, че не само лъжете в това Ваше изказване, но и от 29 септември, когато излязохте на тази трибуна да ни кажете, че бензинът става 4 лв., измина доста време, а вече той е със 17 стотинки надолу от деня, в който Вие го казахте, и нямат нищо общо с 4 лв']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Аз обаче не взех репликата за това, а взех репликата, господин Гуцанов, за да Ви кажа, че не само лъжете в това Ваше изказване, но и от 29 септември, когато излязохте на тази трибуна да ни кажете, че бензинът става 4 лв., измина доста време, а вече той е със 17 стотинки надолу от деня, в който Вие го казахте, и нямат нищо общо с 4 лв']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Hypocrisy",
         "Appeal_to_Hypocrisy",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "1",
         "Yes, the Appeal to Hypocrisy technique is used in the input.",
         "\"Аз обаче не взех репликата за това, а взех репликата, господин Гуцанов, за да Ви кажа, че не само лъжете в това Ваше изказване, но и от 29 септември, когато излязохте на тази трибуна да ни кажете, че бензинът става 4 лв., измина доста време, а вече той е със 17 стотинки надолу от деня, в който Вие го казахте, и нямат нищо общо с 4 лв\"",
         "['{\\n  \"explanation\": \"The Appeal to Hypocrisy technique is used in the input text as the speaker accuses Mr. Gutsanov of lying about the price of gasoline, highlighting the inconsistency between his previous statement and the current price. This directly attacks Gutsanov\\'s credibility by pointing out his past claim that gasoline would rise to 4 BGN, which is now proven false.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[False]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/bg/train-bg-part_0009.parquet",
         "[None]",
         "[None]",
         "train",
         "{\"description\": null, \"verdict\": true}"
        ],
        [
         "294",
         "20231208_URW_BG_76.txt",
         "5170",
         "5523",
         "BG",
         "Това, което всъщност в момента даваме тук, е разрешение да унищожим Българската армия, да изпразним складовете, да оголим българския резерв, ако въобще такъв е останал след престъпниците, които управляват Армията и управляват Министерството на отбраната най-вече, защото в Армията все пак, за разлика от Министерството на отбраната, има професионалисти.",
         "True",
         "['Consequential_Oversimplification' 'Loaded_Language'\n 'Questioning_the_Reputation' 'Straw_Man']",
         "train",
         "['след престъпниците, които управляват Армията и управляват Министерството на отбраната най-вече, защото в Армията все пак, за разлика от Министерството на отбраната, има професионалисти']",
         "[]",
         "[]",
         "[]",
         "['унищожим']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Това, което всъщност в момента даваме тук, е разрешение да унищожим Българската армия, да изпразним складовете, да оголим българския резерв']",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Това, което всъщност в момента даваме тук, е разрешение да унищожим Българската армия, да изпразним складовете, да оголим българския резерв, ако въобще такъв е останал след престъпниците, които управляват Армията и управляват Министерството на отбраната най-вече, защото в Армията все пак, за разлика от Министерството на отбраната, има професионалисти']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Hypocrisy",
         "Appeal_to_Hypocrisy",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Appeal to Hypocrisy technique is not used in the input.",
         "\"\"",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[ True]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/bg/train-bg-part_0009.parquet",
         "[{'code': 'content_filter', 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'detected': False, 'filtered': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}, 'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'param': 'prompt', 'status': 400.0, 'type': None}]",
         "['no validation']",
         "train",
         "{\"description\": null, \"verdict\": false}"
        ],
        [
         "332",
         "20231208_URW_BG_73.txt",
         "5323",
         "5459",
         "BG",
         "КОСТАДИН КОСТАДИНОВ (ВЪЗРАЖДАНЕ, от място): А докато беше в БСП до миналата година, дали беше проруска партия?! (Реплики от ВЪЗРАЖДАНЕ.)",
         "True",
         "['Appeal_to_Hypocrisy']",
         "train",
         "[]",
         "[]",
         "['А докато беше в БСП до миналата година, дали беше проруска партия?!']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Hypocrisy",
         "Appeal_to_Hypocrisy",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "1",
         "Yes, the Appeal to Hypocrisy technique is used in the input.",
         "\"А докато беше в БСП до миналата година, дали беше проруска партия?!\"",
         "['{\\n  \"explanation\": \"The Appeal to Hypocrisy technique is used in the input text as it directly calls out the hypocrisy of the target by questioning their past affiliation with the BСП (Bulgarian Socialist Party) and implying that they were a pro-Russian party at that time. This highlights a contradiction between their past actions and their current stance.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[False]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/bg/train-bg-part_0002.parquet",
         null,
         null,
         "train",
         "{\"description\": null, \"verdict\": true}"
        ],
        [
         "358",
         "20231208_URW_BG_75.txt",
         "5280",
         "5654",
         "BG",
         "Така че не е непредизвикана агресията, убити са хиляди хора. Лошото е, че сега ние се приближаваме – само тук по този въпрос бяхте прав, тъй като привършва живият материал от наши събратя и от двете страни – над 500 хиляди ковчега, има нови ковчези, които трябва да бъдат пълнени. С кого? Новите еничари ще закарат и българите там, след като оголваме цялата Българска армия.",
         "True",
         "['Loaded_Language' 'Appeal_to_Pity' 'Name_Calling-Labeling'\n 'Appeal_to_Fear-Prejudice']",
         "train",
         "[]",
         "['Новите еничари']",
         "[]",
         "[]",
         "['ковчега, има нови ковчези, които трябва да бъдат пълнени']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Така че не е непредизвикана агресията, убити са хиляди хора']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Лошото е, че сега ние се приближаваме – само тук по този въпрос бяхте прав, тъй като привършва живият материал от наши събратя и от двете страни – над 500 хиляди ковчега, има нови ковчези, които трябва да бъдат пълнени'\n 'Новите еничари ще закарат и българите там, след като оголваме цялата Българска армия']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Hypocrisy",
         "Appeal_to_Hypocrisy",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Appeal to Hypocrisy technique is not used in the input.",
         "\"\"",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[ True]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/bg/train-bg-part_0004.parquet",
         "[{'code': 'content_filter', 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'detected': False, 'filtered': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}, 'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'param': 'prompt', 'status': 400.0, 'type': None}]",
         "['no validation']",
         "train",
         "{\"description\": null, \"verdict\": false}"
        ],
        [
         "376",
         "pl_eu_12_06_2024_n01.txt",
         "0",
         "135",
         "PL",
         "Wicemarszałek Włodzimierz Czarzasty:\nBardzo proszę panią poseł Danutę Jazłowiecką\no przedstawienie sprawozdania komisji.\nBardzo proszę.",
         "False",
         "[]",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Questioning_the_Reputation",
         "Questioning_the_Reputation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Questioning the Reputation technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not contain any elements that attack or undermine the reputation of any individual. It is a straightforward request for a report without any negative claims or implications about the character or moral stature of the individuals involved.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[False]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/pl/train-pl-part_0005.parquet",
         null,
         null,
         "train",
         "{\"description\": null, \"verdict\": false}"
        ],
        [
         "379",
         "pl_abortion_11_04_2024_n08.txt",
         "2952",
         "3136",
         "PL",
         "Czy czas najwyższy, by w końcu dopuścić\ndekryminalizację kradzieży i pomocnictwa w kradzieżach\nz włamaniem? Dlaczego tak nie lubicie dzieci?\nDlaczego chcecie pozwolić na ich zabijanie?",
         "True",
         "['False_Equivalence' 'Loaded_Language' 'Whataboutism' 'Straw_Man']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "['zabijanie?']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Czy czas najwyższy, by w końcu dopuścić dekryminalizację kradzieży i pomocnictwa w kradzieżach z włamaniem?']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Dlaczego tak nie lubicie dzieci?']",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Questioning_the_Reputation",
         "Questioning_the_Reputation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Questioning the Reputation technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not contain any explicit attacks on the reputation or character of a target. It poses questions about policies and expresses concern for children, but does not undermine anyone\\'s moral stature or credibility, which is essential for the Questioning the Reputation technique.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[False]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/pl/train-pl-part_0005.parquet",
         null,
         null,
         "train",
         "{\"description\": null, \"verdict\": false}"
        ],
        [
         "381",
         "pl_abortion_11_04_2024_n06.txt",
         "1965",
         "2258",
         "PL",
         "Wicemarszałek Włodzimierz Czarzasty:\nPrzepraszam, pani posłanko, przepraszam bardzo.\n(Poseł Krystyna Skowrońska: Proszę zwrócić uwagę.)\nAle zaraz, proszę państwa, proszę państwa…\n(Wypowiedź poza mikrofonem)\n(Poseł Krystyna Skowrońska: Ale nie zagłusza…)\n(Poseł Mariusz Krystian: A wy możecie?)",
         "False",
         "[]",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Questioning_the_Reputation",
         "Questioning_the_Reputation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Questioning the Reputation technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not contain any elements that attack the reputation of a target or make negative claims about their character or moral stature. There are no instances of undermining reputation or credibility, which aligns with the expert\\'s verdict that the Questioning the Reputation technique is not used.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[False]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/pl/train-pl-part_0005.parquet",
         null,
         null,
         "train",
         "{\"description\": null, \"verdict\": false}"
        ],
        [
         "383",
         "pl_abortion_11_04_2024_n03.txt",
         "10068",
         "10611",
         "PL",
         "Państwo polskie zaoszczędziło na zdrowiu i życiu\nPolek 49 mln przez ostatnie 8 lat. Na aborcje\nwykonywane u kobiet z Polski składają się wszystkie inne\npaństwa, takie jak Holandia, Francja czy Belgia, ale\nteż prywatni darczyńcy. Każdego dnia dzięki pieniądzom\notrzymanym z organizacji kobiecych około\nsiedmiu kobiet wyjeżdża do Holandii na zabieg\naborcji w drugim trymestrze ciąży. Wiele z nich\npotrzebuje wsparcia finansowego. To są często ciąże chciane,\nto są często ciąże wyczekane, ale te kobiety nie\nmogą otrzymać pomocy w swoim państwie.",
         "True",
         "['Flag_Waving' 'Questioning_the_Reputation' 'Appeal_to_Popularity']",
         "train",
         "['Państwo polskie zaoszczędziło na zdrowiu i życiu Polek 49 mln przez ostatnie 8 lat']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Na aborcje wykonywane u kobiet z Polski składają się wszystkie inne państwa, takie jak Holandia, Francja czy Belgia, ale też prywatni darczyńcy. Każdego dnia dzięki pieniądzom otrzymanym z organizacji kobiecych około siedmiu kobiet wyjeżdża do Holandii na zabieg aborcji w drugim trymestrze ciąży']",
         "[]",
         "[]",
         "['te kobiety nie mogą otrzymać pomocy w swoim państwie']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Questioning_the_Reputation",
         "Questioning_the_Reputation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "1",
         "Yes, the Questioning the Reputation technique is used in the input.",
         "\"Państwo polskie zaoszczędziło na zdrowiu i życiu Polek 49 mln przez ostatnie 8 lat\"",
         "['{\\n  \"explanation\": \"The technique of Questioning the Reputation is explicitly used in the input text by making a strong negative claim about the Polish state, stating that it has \\'saved\\' money at the expense of the health and lives of women. This undermines the reputation and moral standing of the state, suggesting negligence or a lack of care for its citizens, which aligns with the definition of the technique.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[False]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/pl/train-pl-part_0005.parquet",
         null,
         null,
         "train",
         "{\"description\": null, \"verdict\": true}"
        ],
        [
         "384",
         "pl_defence_22_05_2024_n01.txt",
         "3494",
         "3606",
         "PL",
         "A więc trzeba za to wszystko przeprosić i potem\nrealizować program Prawa i Sprawiedliwości, bo to\ndobry program.",
         "True",
         "['Slogans' 'False_Dilemma-No_Choice']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['bo to dobry program']",
         "[]",
         "[]",
         "[]",
         "['A więc trzeba za to wszystko przeprosić i potem realizować program Prawa i Sprawiedliwości, bo to dobry program']",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Questioning_the_Reputation",
         "Questioning_the_Reputation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Questioning the Reputation technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not contain any elements that attack the reputation of a target or make negative claims about it. It focuses on the need to apologize and implement a program, which does not align with the definition of Questioning the Reputation.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[False]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/pl/train-pl-part_0005.parquet",
         null,
         null,
         "train",
         "{\"description\": null, \"verdict\": false}"
        ],
        [
         "385",
         "pl_abortion_11_04_2024_n03.txt",
         "6145",
         "6687",
         "PL",
         "W szpitalach na Podlasiu i Podkarpaciu nawet ten\npseudokompromis nie działał, bo żadna, ale to żadna,\nkobieta od lat, nawet w przypadku zagrożenia\nzdrowia i życia, nie mogła tam otrzymać pomocy i była\nodsyłana z kwitkiem, chociaż w zasadzie raczej bez\nkwitka, bo lekarze odmawiali aborcji, zasłaniając się\nklauzulą sumienia. I chociaż łamali w ten sposób prawo,\nnie wyznaczali podmiotu leczniczego, w którym\nkobieta mogłaby przerwać ciążę, i nie dokumentowali\ntej odmowy na piśmie. Łamanie praw pacjentek?\nKto by tam się przejmował kobietami.",
         "True",
         "['Loaded_Language' 'Appeal_to_Hypocrisy' 'Questioning_the_Reputation'\n 'Appeal_to_Values' 'Repetition']",
         "train",
         "['I chociaż łamali w ten sposób prawo, nie wyznaczali podmiotu leczniczego, w którym kobieta mogłaby przerwać ciążę, i nie dokumentowali tej odmowy na piśmie']",
         "[]",
         "['lekarze odmawiali aborcji, zasłaniając się klauzulą sumienia']",
         "[]",
         "['pseudokompromis' 'była odsyłana z kwitkiem' 'Kto by tam się przejmował']",
         "['żadna' 'żadna']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['bo lekarze odmawiali aborcji, zasłaniając się klauzulą sumienia'\n 'Łamanie praw pacjentek? Kto by tam się przejmował kobietami']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Questioning_the_Reputation",
         "Questioning_the_Reputation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "1",
         "Yes, the Questioning the Reputation technique is used in the input.",
         "\"I chociaż łamali w ten sposób prawo, nie wyznaczali podmiotu leczniczego, w którym kobieta mogłaby przerwać ciążę, i nie dokumentowali tej odmowy na piśmie\"",
         "['{\\n  \"explanation\": \"The Questioning the Reputation technique is used in the input text by making strong negative claims about the behavior of doctors who refuse to provide necessary medical assistance, thereby undermining their moral stature and credibility. The excerpt highlights their illegal actions and lack of accountability, which attacks their reputation as healthcare providers.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[False]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/pl/train-pl-part_0005.parquet",
         null,
         null,
         "train",
         "{\"description\": null, \"verdict\": true}"
        ],
        [
         "386",
         "pl_abortion_11_04_2024_n06.txt",
         "3465",
         "3708",
         "PL",
         "Poseł Monika Rosa:\nPanie Pośle! Pan nigdy nie był w ciąży i pan nie\nwie, co to znaczy nosić dziecko i się bać. A więc proszę\nnie wychodzić mi z jakimiś moralnymi według pana\ni etycznymi komentarzami. (Oklaski)\n(Poseł Piotr Kaleta: Ojej, ojej…)",
         "True",
         "['Loaded_Language' 'Questioning_the_Reputation' 'Straw_Man']",
         "train",
         "['Pan nigdy nie był w ciąży i pan nie wie, co to znaczy nosić dziecko i się bać. A więc proszę nie wychodzić mi z jakimiś moralnymi według pana i etycznymi komentarzami']",
         "[]",
         "[]",
         "[]",
         "['nie wychodzić mi']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Pan nigdy nie był w ciąży i pan nie wie, co to znaczy nosić dziecko i się bać. A więc proszę nie wychodzić mi z jakimiś moralnymi według pana i etycznymi komentarzami']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Questioning_the_Reputation",
         "Questioning_the_Reputation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "1",
         "Yes, the Questioning the Reputation technique is used in the input.",
         "\"Pan nigdy nie był w ciąży i pan nie wie, co to znaczy nosić dziecko i się bać. A więc proszę nie wychodzić mi z jakimiś moralnymi według pana i etycznymi komentarzami\"",
         "['{\\n  \"explanation\": \"The Questioning the Reputation technique is explicitly used in the input text as the speaker attacks the reputation of the opponent by stating that he has never been pregnant and therefore cannot understand the associated fears. This undermines his moral authority to make ethical comments on the subject, aligning with the technique\\'s definition of attacking character and moral stature.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[False]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/pl/train-pl-part_0004.parquet",
         null,
         null,
         "train",
         "{\"description\": null, \"verdict\": true}"
        ],
        [
         "387",
         "pl_abortion_11_04_2024_n01.txt",
         "4660",
         "5608",
         "PL",
         "Musimy się zgodzić na to, żeby ta pomoc nie groziła\ntym, że rozdziela się rodziny, rozdziela się ojców i\ndzieci, rozdziela się babcie oraz ciocie czy też przyjaciółki\nrodziny. Ogólnodostępne dane zawierające informacje\no treści wyroków polskich sądów pokazują, że w\nostatnich latach za pomoc kobiecie w aborcji zostali skazani\nm.in.: ojciec, który przekazał córce pieniądze na\npokrycie kosztów jej zabiegu aborcji w klinice w Holandii;\nmatka, która pomogła córce wyjechać na zabieg aborcji\ndo kliniki w Holandii i która opłaciła córce koszty\nprzejazdu i samego zabiegu; kolejna matka, matka kobiety,\nżyjącej kobiety, która zorganizowała swojej córce\nwyjazd na zabieg aborcji i również opłaciła jej środek\ntransportu; następna matka – to samo, dokładnie taki\nsam przypadek. Tych wyroków jest w Polsce dużo.\nPaństwo może sobie nie zdają z tego sprawy, bo być może\nto jest takie podejście: nie interesujemy się, niech sobie\nkobiety to załatwiają same.",
         "True",
         "['Appeal_to_Pity' 'Appeal_to_Values' 'False_Dilemma-No_Choice' 'Doubt']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['bo być może to jest takie podejście: nie interesujemy się, niech sobie kobiety to załatwiają same']",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Ogólnodostępne dane zawierające informacje o treści wyroków polskich sądów pokazują, że w ostatnich latach za pomoc kobiecie w aborcji zostali skazani m.in.: ojciec, który przekazał córce pieniądze na pokrycie kosztów jej zabiegu aborcji w klinice w Holandii; matka, która pomogła córce wyjechać na zabieg aborcji do kliniki w Holandii i która opłaciła córce koszty przejazdu i samego zabiegu; kolejna matka, matka kobiety, żyjącej kobiety, która zorganizowała swojej córce wyjazd na zabieg aborcji i również opłaciła jej środek transportu; następna matka – to samo, dokładnie taki sam przypadek']",
         "[]",
         "['Musimy się zgodzić na to, żeby ta pomoc nie groziła tym, że rozdziela się rodziny, rozdziela się ojców i dzieci, rozdziela się babcie oraz ciocie czy też przyjaciółki rodziny']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Musimy się zgodzić na to, żeby ta pomoc nie groziła tym, że rozdziela się rodziny, rozdziela się ojców i dzieci, rozdziela się babcie oraz ciocie czy też przyjaciółki rodziny']",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Questioning_the_Reputation",
         "Questioning_the_Reputation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Questioning the Reputation technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not contain any strong negative claims aimed at undermining the reputation or moral stature of any individual or group. It discusses the consequences of legal actions related to abortion without attacking the character of those involved. Therefore, the Questioning the Reputation technique is not used.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[False]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/pl/train-pl-part_0004.parquet",
         null,
         null,
         "train",
         "{\"description\": null, \"verdict\": false}"
        ],
        [
         "388",
         "pl_eu_12_06_2024_n02.txt",
         "2901",
         "3285",
         "PL",
         "Niewątpliwie priorytetem będzie kwestia poprawy obronności. Cieszę się, że rząd Donalda Tuska po\nzmianie, po 15 października przejął stery naszej dyplomacji, bo to jest gwarancja tego, że wykorzystamy\nten czas jak najlepiej (Dzwonek) dla zapewnienia i realizacji interesów Polski, m.in. poprzez poprawę bezpieczeństwa i zaangażowania w tę kwestię członków\nUnii Europejskiej. Dziękuję.",
         "True",
         "['Consequential_Oversimplification' 'Flag_Waving']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['dla zapewnienia i realizacji interesów Polski']",
         "[]",
         "['rząd Donalda Tuska po zmianie, po 15 października przejął stery naszej dyplomacji, bo to jest gwarancja tego, że wykorzystamy ten czas jak najlepiej']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Questioning_the_Reputation",
         "Questioning_the_Reputation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Questioning the Reputation technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not contain any elements that attack or undermine the reputation of any individual or group. It focuses on positive statements regarding the government\\'s actions and priorities without making negative claims about any opponents or their character.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[False]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/pl/train-pl-part_0004.parquet",
         null,
         null,
         "train",
         "{\"description\": null, \"verdict\": false}"
        ],
        [
         "392",
         "pl_abortion_11_04_2024_n04.txt",
         "7452",
         "7724",
         "PL",
         "Wicemarszałek Włodzimierz Czarzasty:\nDziękuję bardzo.\nZanim poproszę panią poseł, chcę przeprosić, bo\nnie wiem, czy jeszcze jest grupa młodzieży z Jędrzejowa.\nJesteście jeszcze państwo? Są, jesteście.\nWitam was serdecznie. (Oklaski)\n(Poseł Urszula Pasławska: Pozdrawiamy.)",
         "False",
         "[]",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Questioning_the_Reputation",
         "Questioning_the_Reputation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Questioning the Reputation technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not contain any elements that attack or undermine the reputation of any individual. It is a polite greeting and does not include any negative claims or implications about character or moral stature, which are essential for the use of the Questioning the Reputation technique.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[False]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/pl/train-pl-part_0004.parquet",
         null,
         null,
         "train",
         "{\"description\": null, \"verdict\": false}"
        ],
        [
         "394",
         "pl_defence_22_05_2024_n02.txt",
         "3985",
         "4869",
         "PL",
         "Trzeba zwiększyć polskie zdolności produkcyjne,\nzamawiać dużo sprzętu w polskich firmach, zarówno\nprywatnych, jak i publicznych, trzeba też im płacić\nza utrzymanie zdolności produkcyjnych na czas\nwojny oraz wycofać się z konwencji ottawskiej o zakazie\nużywania min przeciwpiechotnych. Nie są stroną tej\nkonwencji Rosja, Stany Zjednoczone, Chiny, Indie,\nIzrael, Egipt. Ukraina, gdyby nie miny\nprzeciwpiechotne, nie broniłaby się skutecznie przed Rosją.\nMusimy jak najszybciej wypowiedzieć tę konwencję.\nNie jesteśmy w tym momencie gotowi do wojny.\nJedni i drudzy rządziliście Polską od 20 lat i nie\nprzygotowaliście nas do obrony na czas wojny. PiS\nprzygotowywał się tylko do wojny z Platformą, Platforma\nprzygotowywała się do wojny z PiS-em, a Polska nie\njest gotowa. Nasze Siły Zbrojne pod kątem liczby\nrezerw, liczby czołgów czy też liczby\nsprzętu są najsłabsze od 80 lat. (Oklaski)",
         "True",
         "['Causal_Oversimplification' 'Exaggeration-Minimisation' 'Appeal_to_Time'\n 'Questioning_the_Reputation' 'Whataboutism' 'Doubt'\n 'Appeal_to_Fear-Prejudice']",
         "train",
         "['Jedni i drudzy rządziliście Polską od 20 lat i nie przygotowaliście nas do obrony na czas wojny']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Nasze Siły Zbrojne pod kątem liczby rezerw, liczby czołgów czy też liczby sprzętu są najsłabsze od 80 lat']",
         "[]",
         "[]",
         "['PiS przygotowywał się tylko do wojny z Platformą, Platforma przygotowywała się do wojny z PiS-em, a Polska nie jest gotowa']",
         "[]",
         "[]",
         "['Musimy jak najszybciej wypowiedzieć tę konwencję']",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Nie jesteśmy w tym momencie gotowi do wojny'\n 'Jedni i drudzy rządziliście Polską od 20 lat i nie przygotowaliście nas do obrony na czas wojny']",
         "['Ukraina, gdyby nie miny przeciwpiechotne, nie broniłaby się skutecznie przed Rosją']",
         "[]",
         "[]",
         "['PiS przygotowywał się tylko do wojny z Platformą, Platforma przygotowywała się do wojny z PiS-em, a Polska nie jest gotowa']",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Questioning_the_Reputation",
         "Questioning_the_Reputation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "1",
         "Yes, the Questioning the Reputation technique is used in the input.",
         "\"Jedni i drudzy rządziliście Polską od 20 lat i nie przygotowaliście nas do obrony na czas wojny\"",
         "['{\\n  \"explanation\": \"The Questioning the Reputation technique is explicitly used in the input text through the statement that criticizes both political parties for their failure to prepare Poland for defense over the past 20 years. This attack on their competence and moral responsibility undermines their reputation, aligning with the technique\\'s definition of making strong negative claims to damage the target\\'s character and moral stature.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[False]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/pl/train-pl-part_0004.parquet",
         null,
         null,
         "train",
         "{\"description\": null, \"verdict\": true}"
        ],
        [
         "395",
         "pl_abortion_11_04_2024_n02.txt",
         "2916",
         "3709",
         "PL",
         "Ale to nie koniec. Art. 152, jak wiemy, jest\nprzyczyną tragedii także w polskich szpitalach, bo od\n30 lat aborcja jest traktowana nie jak zabieg\nmedyczny, tylko jak przestępstwo. To sprawia, że lekarze nie\nuczą się o tym, jak przeprowadzać aborcję, nie mają\npraktyki, nie wiedzą, jak to się robi, i kiedy stają\nwobec takiej sytuacji, że mają przerwać ciążę, to się\nboją, próbują tego uniknąć. Nawet wtedy, kiedy ta\ndecyzja zagraża życiu i zdrowiu pacjentki.\nBo brakuje im kompetencji, bo boją się o swoją karierę.\nI właśnie to spychanie aborcji do sfery świata\nkryminalnego doprowadziło do śmierci Izy z Pszczyny,\ndoprowadziło do śmierci Doroty z Nowego Targu i innych\nmłodych kobiet, które miały przed sobą całe życie,\nktóre miały małe dzieci, które mogły dalej\nżyć i wychowywać swoje dzieci.",
         "True",
         "['Causal_Oversimplification' 'Loaded_Language'\n 'Questioning_the_Reputation' 'Appeal_to_Values' 'Doubt']",
         "train",
         "['bo boją się o swoją karierę']",
         "[]",
         "[]",
         "[]",
         "['spychanie aborcji do sfery świata kryminalnego']",
         "[]",
         "[]",
         "['Art. 152, jak wiemy, jest przyczyną tragedii także w polskich szpitalach, bo od 30 lat aborcja jest traktowana nie jak zabieg medyczny, tylko jak przestępstwo'\n 'Bo brakuje im kompetencji']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Nawet wtedy, kiedy ta decyzja zagraża życiu i zdrowiu pacjentki'\n 'które miały przed sobą całe życie, które miały małe dzieci, które mogły dalej żyć i wychowywać swoje dzieci']",
         "[]",
         "[]",
         "[]",
         "[]",
         "['To sprawia, że lekarze nie uczą się o tym, jak przeprowadzać aborcję, nie mają praktyki, nie wiedzą, jak to się robi, i kiedy stają wobec takiej sytuacji, że mają przerwać ciążę, to się boją, próbują tego uniknąć'\n 'I właśnie to spychanie aborcji do sfery świata kryminalnego doprowadziło do śmierci Izy z Pszczyny, doprowadziło do śmierci Doroty z Nowego Targu i innych młodych kobiet, które miały przed sobą całe życie, które miały małe dzieci, które mogły dalej żyć i wychowywać swoje dzieci']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Questioning_the_Reputation",
         "Questioning_the_Reputation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "1",
         "Yes, the Questioning the Reputation technique is used in the input.",
         "\"bo boją się o swoją karierę\"",
         "['{\\n  \"explanation\": \"The Questioning the Reputation technique is used in the input text by implying that doctors are fearful of their careers due to the criminalization of abortion, which undermines their professional integrity and moral character. This suggests that their reputation is at risk, thus attacking their credibility and moral stature in the context of performing abortions.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[False]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/pl/train-pl-part_0004.parquet",
         null,
         null,
         "train",
         "{\"description\": null, \"verdict\": true}"
        ],
        [
         "397",
         "pl_abortion_11_04_2024_n03.txt",
         "9280",
         "9741",
         "PL",
         "Zakaz aborcji zabija i nie likwiduje aborcji. Zakaz\naborcji powoduje, że w polskich szpitalach nie ma\ndzisiaj bezpiecznej aborcji. Ale od 30 lat te aborcje się\ndzieją tylko dlatego, że poszczególne osoby znajdują\nsposób na to, żeby je zrobić. Ostatnie lata to zasługa\ngrup nieformalnych i aktywistek działających\nw Polsce – to Aborcyjny Dream Team czy Aborcja bez Granic.\nWiem, że jesteście, pozdrawiam was bardzo serdecznie\ni dziękuję za waszą pracę. (Oklaski)",
         "True",
         "['Consequential_Oversimplification' 'Causal_Oversimplification'\n 'Loaded_Language' 'Flag_Waving' 'Appeal_to_Popularity' 'Doubt'\n 'Appeal_to_Fear-Prejudice']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "['zabija']",
         "[]",
         "['Ostatnie lata to zasługa grup nieformalnych i aktywistek działających w Polsce – to Aborcyjny Dream Team czy Aborcja bez Granic']",
         "['Zakaz aborcji zabija i nie likwiduje aborcji']",
         "[]",
         "['Wiem, że jesteście, pozdrawiam']",
         "[]",
         "['Zakaz aborcji zabija i nie likwiduje aborcji']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Zakaz aborcji zabija']",
         "['Zakaz aborcji powoduje, że w polskich szpitalach nie ma dzisiaj bezpiecznej aborcji']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Questioning_the_Reputation",
         "Questioning_the_Reputation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Questioning the Reputation technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not contain any elements that attack the reputation of a target or make strong negative claims about it. It focuses on discussing the issue of abortion and acknowledges the efforts of certain groups without undermining their character or moral stature.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[False]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/pl/train-pl-part_0006.parquet",
         null,
         null,
         "train",
         "{\"description\": null, \"verdict\": false}"
        ],
        [
         "398",
         "pl_abortion_11_04_2024_n04.txt",
         "7809",
         "7883",
         "PL",
         "Bardzo proszę panią poseł Urszulę Pasławską o zabranie głosu.\nProszę, Ula.",
         "False",
         "[]",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Questioning_the_Reputation",
         "Questioning_the_Reputation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Questioning the Reputation technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not contain any elements that attack or undermine the reputation of an individual. It simply requests a member of parliament to speak, without making any negative claims about her character or moral stature.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[False]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/pl/train-pl-part_0006.parquet",
         null,
         null,
         "train",
         "{\"description\": null, \"verdict\": false}"
        ],
        [
         "401",
         "pl_eu_12_06_2024_n01.txt",
         "3163",
         "3547",
         "PL",
         "Po rozpatrzeniu całości projektu ustawy członkowie obu komisji, 51 posłanek i posłów, 32 głosami za,\n2 przeciw i 17 wstrzymującymi przyjęli projekt ustawy o szczególnych rozwiązaniach w związku z przygotowywaniem i sprawowaniem przez Rzeczpospolitą Polską przewodnictwa w Radzie Unii Europejskiej\nw I połowie 2025 roku, druk nr 347, rekomendując\ngo Wysokiej Izbie. Dziękuję. (Oklaski)",
         "False",
         "[]",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Questioning_the_Reputation",
         "Questioning_the_Reputation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Questioning the Reputation technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not contain any elements that attack the reputation of a target or make negative claims about it. It simply discusses the approval of a legislative project without undermining anyone\\'s character or moral stature.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[False]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/pl/train-pl-part_0006.parquet",
         null,
         null,
         "train",
         "{\"description\": null, \"verdict\": false}"
        ],
        [
         "402",
         "pl_eu_12_06_2024_n02.txt",
         "5845",
         "5961",
         "PL",
         "Wicemarszałek Włodzimierz Czarzasty:\nDziękuję.\nPan poseł Janusz Kowalski, Klub Parlamentarny\nPrawo i Sprawiedliwość.",
         "False",
         "[]",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Questioning_the_Reputation",
         "Questioning_the_Reputation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Questioning the Reputation technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not contain any elements that attack or undermine the reputation of any individual. There are no strong negative claims made about anyone\\'s character or moral stature, which aligns with the expert\\'s verdict that the Questioning the Reputation technique is not used.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[False]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/pl/train-pl-part_0006.parquet",
         null,
         null,
         "train",
         "{\"description\": null, \"verdict\": false}"
        ],
        [
         "403",
         "pl_abortion_11_04_2024_n01.txt",
         "268",
         "371",
         "PL",
         "Panowie, halo, szanujmy wszystkich gości.\nDziękujemy wam bardzo za przybycie.\nSuper, bardzo dziękujemy.",
         "False",
         "[]",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Questioning_the_Reputation",
         "Questioning_the_Reputation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Questioning the Reputation technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not contain any elements that attack or undermine the reputation of any individual or group. It is a polite acknowledgment of guests and does not make any negative claims about anyone\\'s character or moral stature.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[False]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/pl/train-pl-part_0006.parquet",
         null,
         null,
         "train",
         "{\"description\": null, \"verdict\": false}"
        ],
        [
         "404",
         "pl_abortion_11_04_2024_n03.txt",
         "0",
         "175",
         "PL",
         "Wicemarszałek Włodzimierz Czarzasty:\nDziękuję serdecznie.\nBardzo proszę panią posłankę Katarzynę Kotulę\no przedstawienie uzasadnienia projektu ustawy\nzawartego w druku nr 177.",
         "False",
         "[]",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Questioning_the_Reputation",
         "Questioning_the_Reputation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Questioning the Reputation technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not contain any elements that attack the reputation of an individual or make negative claims about their character or moral stature. It is a straightforward request for justification of a legislative proposal, lacking any derogatory or reputational questioning.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[False]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/pl/train-pl-part_0006.parquet",
         null,
         null,
         "train",
         "{\"description\": null, \"verdict\": false}"
        ],
        [
         "405",
         "pl_defence_22_05_2024_n02.txt",
         "807",
         "993",
         "PL",
         "Ustawa o ochronie Ojczyzny obowiązuje już od\nponad 2 lat, a do tej pory nie ma do niej wydanych\n12 niezbędnych rozporządzeń, w wyniku czego\nWojsko Polskie nawet nie może się mobilizować.",
         "False",
         "[]",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Questioning_the_Reputation",
         "Questioning_the_Reputation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Questioning the Reputation technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text discusses the lack of necessary regulations related to the law on the protection of the homeland and its impact on the Polish Army\\'s mobilization. It does not make any negative claims about the character or moral stature of any individual or group, which is required for the Questioning the Reputation technique. Therefore, the technique is not used.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[False]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/pl/train-pl-part_0006.parquet",
         null,
         null,
         "train",
         "{\"description\": null, \"verdict\": false}"
        ],
        [
         "407",
         "pl_abortion_11_04_2024_n08.txt",
         "3138",
         "3188",
         "PL",
         "(Poseł Joanna Scheuring-Wielgus: Zejdź z mównicy.)",
         "True",
         "['Loaded_Language']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Zejdź z mównicy']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Questioning_the_Reputation",
         "Questioning_the_Reputation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Questioning the Reputation technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not contain any elements that attack the reputation of a target or make negative claims about their character or moral stature. Therefore, the Questioning the Reputation technique is not used.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[False]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/pl/train-pl-part_0007.parquet",
         null,
         null,
         "train",
         "{\"description\": null, \"verdict\": false}"
        ],
        [
         "409",
         "pl_eu_12_06_2024_n02.txt",
         "5000",
         "5586",
         "PL",
         "Poseł Marcin Porzucek:\nPanie Marszałku! Wysoka Izbo! Szanowni Państwo! W okresie COVID-u, gdy sytuacje pandemiczne\npojawiały się w ciągu nie roku, nie miesięcy, nie tygodnia, ale wręcz dni, i podejmowaliśmy stosowne\ndziałania, państwo nas krytykowaliście. Gdy Rosja\nnapadała pełnoskalowo na Ukrainę, było podobnie.\nSytuacja wojny hybrydowej na granicy polsko-białoruskiej, podobnie. A dzisiaj państwo macie jeszcze\ntyle czasu, chociaż zmarnowaliście ostatnie pół roku,\nproponujecie rozwiązania ekstraordynaryjne, choć\nmożna to w wielu aspektach zrobić tradycyjnie. To\njest jedna sprawa.",
         "True",
         "['Questioning_the_Reputation']",
         "train",
         "['podejmowaliśmy stosowne działania, państwo nas krytykowaliście'\n 'Gdy Rosja napadała pełnoskalowo na Ukrainę, było podobnie. Sytuacja wojny hybrydowej na granicy polsko-białoruskiej, podobnie'\n 'zmarnowaliście ostatnie pół roku']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Questioning_the_Reputation",
         "Questioning_the_Reputation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "1",
         "Yes, the Questioning the Reputation technique is used in the input.",
         "\"podejmowaliśmy stosowne działania, państwo nas krytykowaliście Gdy Rosja napadała pełnoskalowo na Ukrainę, było podobnie. Sytuacja wojny hybrydowej na granicy polsko-białoruskiej, podobnie zmarnowaliście ostatnie pół roku\"",
         "['{\\n  \"explanation\": \"The input text uses the Questioning the Reputation technique by criticizing the actions of the opposing party during critical situations, such as the COVID pandemic and the war in Ukraine. The speaker implies that the opposition has failed to act appropriately (\\'państwo nas krytykowaliście\\' and \\'zmarnowaliście ostatnie pół roku\\'), which attacks their reputation and moral standing rather than addressing the topic directly.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[False]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/pl/train-pl-part_0007.parquet",
         null,
         null,
         "train",
         "{\"description\": null, \"verdict\": true}"
        ],
        [
         "411",
         "pl_abortion_11_04_2024_n05.txt",
         "9681",
         "10556",
         "PL",
         "Dziś jesteśmy w demograficznym kryzysie. Polki\nnie chcą rodzić dzieci w Polsce, która nie jest dla nich\nbezpieczna pod żadnym względem. Mówią: boję się\nbyć w ciąży, bo dziewczyny w moim wieku umierają.\nUmarły pan Iza, pani Agnieszka, pani Marta, pani\nDorota. Dlatego Koalicja Obywatelska przygotowała\ni przedstawia projekt ustawy o świadomym rodzicielstwie.\nZakaz aborcji w Polsce to restrykcyjne prawo,\nktóre zagraża zdrowiu, życiu i bezpieczeństwu kobiet,\na nasz projekt, projekt Koalicji Obywatelskiej,\nprzywraca kobietom wolność wyboru, przywraca kobietom\ngodność, przywraca kobietom podmiotowość. Zakłada\nmożliwość bezpiecznego i bezpłatnego przerywania\nciąży do 12 tygodnia jej trwania oraz po 12 tygodniu\nw określonych okolicznościach. Aborcja musi być\nbezpieczna, aborcja musi być legalna. Aborcja musi być\ndostępna, a kobieta musi być bezpieczna.\nDziękuję. (Oklaski)",
         "True",
         "['Conversation_Killer' 'Causal_Oversimplification' 'Slogans'\n 'Whataboutism' 'Appeal_to_Values' 'Repetition' 'Appeal_to_Fear-Prejudice']",
         "train",
         "[]",
         "[]",
         "[]",
         "['aborcja musi być legalna' 'Aborcja musi być dostępna']",
         "[]",
         "['przywraca kobietom wolność wyboru' 'przywraca kobietom godność'\n 'przywraca kobietom podmiotowość']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['zagraża zdrowiu, życiu i bezpieczeństwu kobiet']",
         "[]",
         "[]",
         "['Aborcja musi być bezpieczna, aborcja musi być legalna'\n 'Aborcja musi być dostępna, a kobieta musi być bezpieczna']",
         "['Mówią: boję się być w ciąży, bo dziewczyny w moim wieku umierają. Umarły pan Iza, pani Agnieszka, pani Marta, pani Dorota'\n 'Zakaz aborcji w Polsce to restrykcyjne prawo, które zagraża zdrowiu, życiu i bezpieczeństwu kobiet']",
         "['Polki nie chcą rodzić dzieci w Polsce, która nie jest dla nich bezpieczna pod żadnym względem']",
         "[]",
         "[]",
         "['Dziś jesteśmy w demograficznym kryzysie']",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Questioning_the_Reputation",
         "Questioning_the_Reputation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Questioning the Reputation technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not contain any elements that attack the reputation of a target or make strong negative claims about it. It focuses on discussing the issue of abortion and women\\'s rights without undermining the character or moral stature of any individual or group. Therefore, the Questioning the Reputation technique is not used.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[False]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/pl/train-pl-part_0007.parquet",
         null,
         null,
         "train",
         "{\"description\": null, \"verdict\": false}"
        ],
        [
         "416",
         "pl_abortion_11_04_2024_n08.txt",
         "150",
         "288",
         "PL",
         "Wicemarszałek Monika Wielichowska:\nSam pan wywołał reakcję pań, które znajdują się na\ngalerii. Proszę kontynuować. (Gwar na sali, dzwonek)",
         "True",
         "['Questioning_the_Reputation']",
         "train",
         "['Sam pan wywołał reakcję pań, które znajdują się na galerii']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Questioning_the_Reputation",
         "Questioning_the_Reputation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "1",
         "Yes, the Questioning the Reputation technique is used in the input.",
         "\"Sam pan wywołał reakcję pań, które znajdują się na galerii\"",
         "['{\\n  \"explanation\": \"The technique of Questioning the Reputation is used in the input text as the speaker, Wicemarszałek Monika Wielichowska, implies that the person addressed has provoked a negative reaction from the women in the gallery. This statement attacks the character of the individual by suggesting they are responsible for inciting a disturbance, thereby undermining their reputation without addressing the actual topic at hand.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[False]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/pl/train-pl-part_0002.parquet",
         "[None]",
         "[None]",
         "train",
         "{\"description\": null, \"verdict\": true}"
        ],
        [
         "418",
         "pl_defence_22_05_2024_n01.txt",
         "8339",
         "10002",
         "PL",
         "Proszę państwa, jeśli chodzi o te zakupy, to one\nwszystkie były konsultowane, były wynikiem naszych rozmów w Radzie Modernizacji Technicznej\nz przeważającym, decydującym głosem Sztabu Generalnego Wojska Polskiego. Zmieniłem sposób zamawiania sprzętu wojskowego dla polskiego wojska,\nbo on był sprzeczny wewnętrznie. To była sytuacja,\nw której nie można było pójść naprzód, więc udrożniłem te procesy. Potem, kiedy przyszedł rok 2022,\nkiedy po raz kolejny Rosja napadła na Ukrainę, nawiązałem relacje z Koreą Południową. Dlaczego to\nzrobiłem? Dlatego że Korea Południowa posiada olbrzymi potencjał produkcyjny, jeśli chodzi o przemysł\nzbrojeniowy. Uważam za jeden z naszych sukcesów\nto, że w tak krótkim czasie doprowadziliśmy do tego,\nże w Wojsku Polskim już są czołgi K2, że obok\nHIMARS-ów, o których powiedziałem, są Chunmoo,\nczyli artyleria rakietowa o zasięgu do 300 km, że są\nsamoloty szkolno-bojowe FA-50. Pan powiedział, że\npiloci tak dużo zarabiają. Trzeba szkolić pilotów.\nFA-50 zostały zaprojektowane przez Lockheed Martin, a więc są taką mniejszą, to prawda, wersją\nF-16. W Wojsku Polskim, kiedy przyszliśmy do\nwładzy, w zasadzie tylko F-16 stanowiły jakąś siłę\nbojową. Pozostały sprzęt wojskowy był postsowiecki,\nbył zużyty. To był obraz nędzy i rozpaczy, a my doprowadziliśmy do tego, że dziś Wojsko Polskie liczy\nponad 200 tys. żołnierzy. Tylko jeszcze cele… Też\npan o tym nie wspomniał. Co najmniej 300 tys. żołnierzy. Można powiedzieć, że 300 tys. żołnierzy wojsk\noperacyjnych i 50 tys. żołnierzy Wojsk Obrony Terytorialnej – to powinien być nasz wspólny cel, mówię\no państwie polskim (Oklaski), bo w ten sposób możemy realnie odstraszyć agresora.",
         "True",
         "['Loaded_Language' 'Flag_Waving' 'Obfuscation-Vagueness-Confusion'\n 'Appeal_to_Authority' 'Name_Calling-Labeling' 'Red_Herring'\n 'Appeal_to_Fear-Prejudice']",
         "train",
         "[]",
         "['postsowiecki']",
         "[]",
         "[]",
         "['obraz nędzy i rozpaczy']",
         "[]",
         "[]",
         "[]",
         "['Pan powiedział, że piloci tak dużo zarabiają']",
         "['mówię o państwie polskim']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['To była sytuacja, w której nie można było pójść naprzód, więc udrożniłem te procesy']",
         "[]",
         "[]",
         "['realnie odstraszyć agresora']",
         "[]",
         "['jeśli chodzi o te zakupy, to one wszystkie były konsultowane, były wynikiem naszych rozmów w Radzie Modernizacji Technicznej z przeważającym, decydującym głosem Sztabu Generalnego Wojska Polskiego']",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Questioning_the_Reputation",
         "Questioning_the_Reputation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Questioning the Reputation technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not contain any elements that attack the reputation of a target or make strong negative claims about it. The speaker focuses on achievements and improvements in the military rather than undermining anyone\\'s character or moral stature.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[False]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/pl/train-pl-part_0002.parquet",
         "[None]",
         "[None]",
         "train",
         "{\"description\": null, \"verdict\": false}"
        ],
        [
         "421",
         "pl_abortion_11_04_2024_n07.txt",
         "7843",
         "8354",
         "PL",
         "Tytuł projektu Lewicy sugeruje, że aborcja może być\nbezpieczna, tymczasem sami projektodawcy w\nuzasadnieniu projektu podają, że od dnia wydania wyroku\nTrybunału Konstytucyjnego w 2020 r. tylko jedna z\norganizacji proaborcyjnych pomagała w aborcji w\nprzypadku 125 tys. kobiet, co oznacza, że co najmniej tyle\nsamo dzieci w wyniku aborcji straciło życie.\nProjektowane przepisy uderzają w podstawowe prawo każdego\nczłowieka, są całkowicie nieakceptowalne i powinny\nbyć odrzucone już w pierwszym czytaniu. (Oklaski)",
         "True",
         "['Conversation_Killer' 'Appeal_to_Hypocrisy' 'Appeal_to_Values']",
         "train",
         "[]",
         "[]",
         "['Tytuł projektu Lewicy sugeruje, że aborcja może być bezpieczna, tymczasem sami projektodawcy w uzasadnieniu projektu podają, że od dnia wydania wyroku Trybunału Konstytucyjnego w 2020 r. tylko jedna z organizacji proaborcyjnych pomagała w aborcji w przypadku 125 tys. kobiet, co oznacza, że co najmniej tyle samo dzieci w wyniku aborcji straciło życie']",
         "['są całkowicie nieakceptowalne i powinny być odrzucone już w pierwszym czytaniu']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Projektowane przepisy uderzają w podstawowe prawo każdego człowieka']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Questioning_the_Reputation",
         "Questioning_the_Reputation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Questioning the Reputation technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not contain any explicit attacks on the reputation or moral character of the project proponents. It focuses on presenting factual information and expressing opposition to the proposed legislation without undermining the character of the individuals involved.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[False]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/pl/train-pl-part_0002.parquet",
         "[None]",
         "[None]",
         "train",
         "{\"description\": null, \"verdict\": false}"
        ],
        [
         "423",
         "pl_current_affairs_09_01_2025_n01.txt",
         "4848",
         "5376",
         "PL",
         "Dzięki zastosowaniu automatycznego programowania od startu programu do końca grudnia 2024 r.\nrozpatrzono ponad 80% wniosków złożonych w tym\nokresie, pomimo że w październiku, co było naturalne, doszło do spiętrzenia wpływu wniosków z uwagi\nna to, że złożyli je rodzice dzieci z trzech roczników:\n2021–2023. W okresie od 1 października do 31 grudnia ZUS wypłacił łącznie 558 685 świadczeń na kwotę 670 279 596,83 zł. Nadal trwa rozpatrywanie wniosków z okresu, w którym konieczne jest przeprowadzenie postępowania wyjaśniającego.",
         "False",
         "[]",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Questioning_the_Reputation",
         "Questioning_the_Reputation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Questioning the Reputation technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not contain any elements that attack or undermine the reputation of any individual or entity. It focuses on factual information regarding the processing of applications and financial disbursements without making negative claims about anyone\\'s character or moral stature.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[False]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/pl/train-pl-part_0002.parquet",
         "[None]",
         "[None]",
         "train",
         "{\"description\": null, \"verdict\": false}"
        ],
        [
         "424",
         "pl_abortion_11_04_2024_n08.txt",
         "290",
         "1251",
         "PL",
         "Poseł Roman Fritz:\nGrupa feministek pomagająca mordować\nnienarodzone dzieci, Aborcyjny Dream Team, pochwaliła\nsię mniej więcej 2 lata temu, że pomogła zabić\ndziecko gotowe do porodu. Jego matka była w 37. tygodniu\nciąży. Feministki przyznają, że pomaganie w\naborcjach jest ich życiową pasją i misją, a za cel obrały\nsobie promowanie pozytywnego przekazu\ndotyczącego aborcji. Za pośrednictwem mediów\nspołecznościowych co jakiś czas Aborcyjny Dream Team chwali się\nswoimi morderczymi osiągnięciami. Uruchomiona\nprzez nich infolinia umożliwia konsultacje aborcyjne\ni zamawianie tabletek poronnych oraz umawianie\nwyjazdów na zabicie dziecka za granicami Polski.\nAborcjonistki przyznały również, że preferowaną metodą\nzabicia dziecka w tak zaawansowanym stadium\nrozwoju jest rozszerzenie szyjki macicy umożliwiające\nwydobycie go narzędziami, a wcześniej podanie\nbezbronnemu dziecku morderczego zastrzyku, który\nzatrzymuje akcję serca.\n(Poseł Krzysztof Bosak: Hańba!)",
         "True",
         "['Loaded_Language' 'Slogans' 'Questioning_the_Reputation'\n 'Name_Calling-Labeling' 'Appeal_to_Fear-Prejudice']",
         "train",
         "['Grupa feministek pomagająca mordować nienarodzone dzieci, Aborcyjny Dream Team, pochwaliła się mniej więcej 2 lata temu, że pomogła zabić dziecko gotowe do porodu'\n 'Feministki przyznają, że pomaganie w aborcjach jest ich życiową pasją i misją, a za cel obrały sobie promowanie pozytywnego przekazu dotyczącego aborcji'\n 'Aborcyjny Dream Team chwali się swoimi morderczymi osiągnięciami']",
         "['Aborcyjny Dream Team' 'Aborcyjny Dream Team' 'morderczymi']",
         "[]",
         "[]",
         "['pomagająca mordować nienarodzone dzieci' 'pomogła zabić dziecko'\n 'jest ich życiową pasją i misją' 'zabicie dziecka' 'zabicia'\n 'morderczego']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Hańba!)']",
         "['preferowaną metodą zabicia dziecka w tak zaawansowanym stadium rozwoju jest rozszerzenie szyjki macicy umożliwiające wydobycie go narzędziami, a wcześniej podanie bezbronnemu dziecku morderczego zastrzyku, który zatrzymuje akcję serca']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Questioning_the_Reputation",
         "Questioning_the_Reputation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "1",
         "Yes, the Questioning the Reputation technique is used in the input.",
         "\"Grupa feministek pomagająca mordować nienarodzone dzieci, Aborcyjny Dream Team, pochwaliła się mniej więcej 2 lata temu, że pomogła zabić dziecko gotowe do porodu Feministki przyznają, że pomaganie w aborcjach jest ich życiową pasją i misją, a za cel obrały sobie promowanie pozytywnego przekazu dotyczącego aborcji Aborcyjny Dream Team chwali się swoimi morderczymi osiągnięciami\"",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[ True]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/pl/train-pl-part_0002.parquet",
         "[{'code': 'content_filter', 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': True, 'severity': 'high'}, 'jailbreak': {'detected': False, 'filtered': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}, 'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'param': 'prompt', 'status': 400.0, 'type': None}]",
         "['no validation']",
         "train",
         "{\"description\": null, \"verdict\": true}"
        ],
        [
         "426",
         "pl_current_affairs_09_01_2025_n03.txt",
         "3170",
         "3937",
         "PL",
         "Przypomnę również rok 2020. Powstało coś takiego jak specustawa suszowa, projekt. To kolejny projekt ministra odpowiedzialnego za gospodarkę wodną, w tym za zabezpieczenie przeciwsuszowe i przeciwpowodziowe w Polsce przez 8 lat. Projekt powstał\n4 lata po gigantycznej suszy, która nawiedziła Polskę\nw 2015 r., 2016 r. Dopiero 4 lata po niej. Zawierał\ngłównie plan budowy ok. 500 budowli hydrotechnicznych, z których wiele, podobnie jak w przypadku\nplanu zapory w Siarzewie, nie gwarantowało zabezpieczenia przeciwpowodziowego i przeciwsuszowego.\nByło to tylko de facto przykrywką dla zupełnie innych planów, planów żeglugowych. I z tego znany był\nwtedy wasz minister za to odpowiadający.\n(Poseł Anna Gembicka: No to chyba dobrze, że\nchciał, żeby można było żeglować?)",
         "True",
         "['Appeal_to_Hypocrisy' 'Questioning_the_Reputation' 'Red_Herring' 'Doubt']",
         "train",
         "['I z tego znany był wtedy wasz minister za to odpowiadający']",
         "[]",
         "['Było to tylko de facto przykrywką dla zupełnie innych planów, planów żeglugowych']",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Powstało coś takiego jak specustawa suszowa, projekt. To kolejny projekt ministra odpowiedzialnego za gospodarkę wodną, w tym za zabezpieczenie przeciwsuszowe i przeciwpowodziowe w Polsce przez 8 lat. Projekt powstał 4 lata po gigantycznej suszy, która nawiedziła Polskę w 2015 r., 2016 r. Dopiero 4 lata po niej. Zawierał głównie plan budowy ok. 500 budowli hydrotechnicznych, z których wiele, podobnie jak w przypadku planu zapory w Siarzewie, nie gwarantowało zabezpieczenia przeciwpowodziowego i przeciwsuszowego. Było to tylko de facto przykrywką dla zupełnie innych planów, planów żeglugowych. I z tego znany był wtedy wasz minister za to odpowiadający']",
         "['No to chyba dobrze, że chciał, żeby można było żeglować?)']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Questioning_the_Reputation",
         "Questioning_the_Reputation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "1",
         "Yes, the Questioning the Reputation technique is used in the input.",
         "\"I z tego znany był wtedy wasz minister za to odpowiadający\"",
         "['{\\n  \"explanation\": \"The Questioning the Reputation technique is explicitly used in the input text by making a strong negative claim about the minister\\'s reputation. The excerpt \\'I z tego znany był wtedy wasz minister za to odpowiadający\\' implies that the minister is known for something negative, which undermines his character and moral stature, aligning with the definition of the technique.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[False]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/pl/train-pl-part_0003.parquet",
         null,
         null,
         "train",
         "{\"description\": null, \"verdict\": true}"
        ],
        [
         "430",
         "pl_current_affairs_09_01_2025_n02.txt",
         "9440",
         "9898",
         "PL",
         "Wreszcie raport nie zawierał analizy wpływu na\njakość wód. Nie przeprowadzono dokładnej oceny, jak\nbudowa stopnia wodnego wpłynie na jakość wody\nw Wiśle, w jej dopływach czy na wyznaczone dla niej\ncele środowiskowe. Warto podkreślić, że inwestor\nw całym tym bardzo długim procesie od 2017 r. był\nwielokrotnie wzywany do przedłożenia i uzupełnienia raportu w zakresie braków ustawowych, które\nw tym raporcie były, jednak nie uzupełnił go zgodnie\nz wezwaniami.",
         "True",
         "['Doubt']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Warto podkreślić, że inwestor w całym tym bardzo długim procesie od 2017 r. był wielokrotnie wzywany do przedłożenia i uzupełnienia raportu w zakresie braków ustawowych, które w tym raporcie były, jednak nie uzupełnił go zgodnie z wezwaniami']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Questioning_the_Reputation",
         "Questioning_the_Reputation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Questioning the Reputation technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not contain any strong negative claims aimed at undermining the reputation or moral stature of any individual or entity. It focuses on the lack of analysis in a report and the investor\\'s failure to comply with requests, which does not align with the definition of Questioning the Reputation.\",\\n  \"updated_definition\": null\\n}']",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[False]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/pl/train-pl-part_0003.parquet",
         null,
         null,
         "train",
         "{\"description\": null, \"verdict\": false}"
        ]
       ],
       "shape": {
        "columns": 60,
        "rows": 273
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>text_lang</th>\n",
       "      <th>text</th>\n",
       "      <th>label_bin</th>\n",
       "      <th>label_multi</th>\n",
       "      <th>base_split</th>\n",
       "      <th>Questioning_the_Reputation</th>\n",
       "      <th>Name_Calling-Labeling</th>\n",
       "      <th>...</th>\n",
       "      <th>extra_content</th>\n",
       "      <th>explanation</th>\n",
       "      <th>illegal_value</th>\n",
       "      <th>think_content</th>\n",
       "      <th>is_valid</th>\n",
       "      <th>source_file</th>\n",
       "      <th>error</th>\n",
       "      <th>status</th>\n",
       "      <th>split</th>\n",
       "      <th>expected_output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>pl_abortion_11_04_2024_n08.txt</td>\n",
       "      <td>290</td>\n",
       "      <td>1251</td>\n",
       "      <td>PL</td>\n",
       "      <td>Poseł Roman Fritz:\\nGrupa feministek pomagając...</td>\n",
       "      <td>True</td>\n",
       "      <td>[Loaded_Language, Slogans, Questioning_the_Rep...</td>\n",
       "      <td>train</td>\n",
       "      <td>[Grupa feministek pomagająca mordować nienarod...</td>\n",
       "      <td>[Aborcyjny Dream Team, Aborcyjny Dream Team, m...</td>\n",
       "      <td>...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[True]</td>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41/v001...</td>\n",
       "      <td>[{'code': 'content_filter', 'innererror': {'co...</td>\n",
       "      <td>[no validation]</td>\n",
       "      <td>train</td>\n",
       "      <td>{\"description\": null, \"verdict\": false}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>pl_abortion_11_04_2024_n03.txt</td>\n",
       "      <td>4168</td>\n",
       "      <td>5204</td>\n",
       "      <td>PL</td>\n",
       "      <td>W latach 90., które już bardzo dobrze pamiętam...</td>\n",
       "      <td>True</td>\n",
       "      <td>[Appeal_to_Hypocrisy, Loaded_Language, Questio...</td>\n",
       "      <td>train</td>\n",
       "      <td>[ustawa była początkiem wymazywania kobiet z d...</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[False]</td>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41/v001...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "      <td>{\"description\": null, \"verdict\": true}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>RU_migrants_5.txt</td>\n",
       "      <td>354</td>\n",
       "      <td>574</td>\n",
       "      <td>RU</td>\n",
       "      <td>йчас Каменск-Уральск во всех сводках новостей....</td>\n",
       "      <td>True</td>\n",
       "      <td>[Appeal_to_Fear-Prejudice]</td>\n",
       "      <td>train</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[True]</td>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41/v001...</td>\n",
       "      <td>[{'code': 'content_filter', 'innererror': {'co...</td>\n",
       "      <td>[no validation]</td>\n",
       "      <td>train</td>\n",
       "      <td>{\"description\": null, \"verdict\": false}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>RU_discrediting_the_west_7.txt</td>\n",
       "      <td>700</td>\n",
       "      <td>1046</td>\n",
       "      <td>RU</td>\n",
       "      <td>Затем 22 марта был теракт в концертном зале \"К...</td>\n",
       "      <td>True</td>\n",
       "      <td>[Guilt_by_Association, Appeal_to_Fear-Prejudice]</td>\n",
       "      <td>train</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[True]</td>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41/v001...</td>\n",
       "      <td>[{'code': 'content_filter', 'innererror': {'co...</td>\n",
       "      <td>[no validation]</td>\n",
       "      <td>train</td>\n",
       "      <td>{\"description\": null, \"verdict\": false}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>SI_interpelation_interior_12.txt</td>\n",
       "      <td>4448</td>\n",
       "      <td>7979</td>\n",
       "      <td>SI</td>\n",
       "      <td>Najlepša hvala za besedo. Najprej hvala gospod...</td>\n",
       "      <td>True</td>\n",
       "      <td>[Consequential_Oversimplification, Exaggeratio...</td>\n",
       "      <td>train</td>\n",
       "      <td>[tisti, ki vam je pisal odgovore na našo inter...</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[False]</td>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41/v001...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "      <td>{\"description\": null, \"verdict\": true}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1783</th>\n",
       "      <td>20240229_URW_BG_67.txt</td>\n",
       "      <td>2786</td>\n",
       "      <td>4165</td>\n",
       "      <td>BG</td>\n",
       "      <td>И да Ви кажа, уважаеми български граждани, че ...</td>\n",
       "      <td>True</td>\n",
       "      <td>[Appeal_to_Hypocrisy, Questioning_the_Reputati...</td>\n",
       "      <td>train</td>\n",
       "      <td>[И да Ви кажа, уважаеми български граждани, че...</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[False]</td>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41/v001...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "      <td>{\"description\": null, \"verdict\": true}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1798</th>\n",
       "      <td>20231208_URW_BG_76.txt</td>\n",
       "      <td>5170</td>\n",
       "      <td>5523</td>\n",
       "      <td>BG</td>\n",
       "      <td>Това, което всъщност в момента даваме тук, е р...</td>\n",
       "      <td>True</td>\n",
       "      <td>[Consequential_Oversimplification, Loaded_Lang...</td>\n",
       "      <td>train</td>\n",
       "      <td>[след престъпниците, които управляват Армията ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[True]</td>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41/v001...</td>\n",
       "      <td>[{'code': 'content_filter', 'innererror': {'co...</td>\n",
       "      <td>[no validation]</td>\n",
       "      <td>train</td>\n",
       "      <td>{\"description\": null, \"verdict\": false}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1814</th>\n",
       "      <td>20240704_URW_BG_25.txt</td>\n",
       "      <td>4080</td>\n",
       "      <td>4133</td>\n",
       "      <td>BG</td>\n",
       "      <td>оспожо Председател.\\n\\nЩе направя процедурно п...</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>train</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[False]</td>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41/v001...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "      <td>{\"description\": null, \"verdict\": false}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1821</th>\n",
       "      <td>trail_raw_BG_13.txt</td>\n",
       "      <td>3446</td>\n",
       "      <td>4689</td>\n",
       "      <td>BG</td>\n",
       "      <td>да се случи, когато се обърне колелото на ист...</td>\n",
       "      <td>True</td>\n",
       "      <td>[Conversation_Killer, Loaded_Language, Slogans...</td>\n",
       "      <td>train</td>\n",
       "      <td>[Вие не сте даже и такива, за които членувате ...</td>\n",
       "      <td>[руски агенти, руски агенти, гешефтари]</td>\n",
       "      <td>...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[False]</td>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41/v001...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "      <td>{\"description\": null, \"verdict\": true}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1862</th>\n",
       "      <td>20231208_URW_BG_75.txt</td>\n",
       "      <td>5280</td>\n",
       "      <td>5654</td>\n",
       "      <td>BG</td>\n",
       "      <td>Така че не е непредизвикана агресията, убити с...</td>\n",
       "      <td>True</td>\n",
       "      <td>[Loaded_Language, Appeal_to_Pity, Name_Calling...</td>\n",
       "      <td>train</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Новите еничари]</td>\n",
       "      <td>...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[True]</td>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41/v001...</td>\n",
       "      <td>[{'code': 'content_filter', 'innererror': {'co...</td>\n",
       "      <td>[no validation]</td>\n",
       "      <td>train</td>\n",
       "      <td>{\"description\": null, \"verdict\": false}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>273 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              filename  start   end text_lang  \\\n",
       "48      pl_abortion_11_04_2024_n08.txt    290  1251        PL   \n",
       "90      pl_abortion_11_04_2024_n03.txt   4168  5204        PL   \n",
       "172                  RU_migrants_5.txt    354   574        RU   \n",
       "194     RU_discrediting_the_west_7.txt    700  1046        RU   \n",
       "201   SI_interpelation_interior_12.txt   4448  7979        SI   \n",
       "...                                ...    ...   ...       ...   \n",
       "1783            20240229_URW_BG_67.txt   2786  4165        BG   \n",
       "1798            20231208_URW_BG_76.txt   5170  5523        BG   \n",
       "1814            20240704_URW_BG_25.txt   4080  4133        BG   \n",
       "1821               trail_raw_BG_13.txt   3446  4689        BG   \n",
       "1862            20231208_URW_BG_75.txt   5280  5654        BG   \n",
       "\n",
       "                                                   text  label_bin  \\\n",
       "48    Poseł Roman Fritz:\\nGrupa feministek pomagając...       True   \n",
       "90    W latach 90., które już bardzo dobrze pamiętam...       True   \n",
       "172   йчас Каменск-Уральск во всех сводках новостей....       True   \n",
       "194   Затем 22 марта был теракт в концертном зале \"К...       True   \n",
       "201   Najlepša hvala za besedo. Najprej hvala gospod...       True   \n",
       "...                                                 ...        ...   \n",
       "1783  И да Ви кажа, уважаеми български граждани, че ...       True   \n",
       "1798  Това, което всъщност в момента даваме тук, е р...       True   \n",
       "1814  оспожо Председател.\\n\\nЩе направя процедурно п...      False   \n",
       "1821   да се случи, когато се обърне колелото на ист...       True   \n",
       "1862  Така че не е непредизвикана агресията, убити с...       True   \n",
       "\n",
       "                                            label_multi base_split  \\\n",
       "48    [Loaded_Language, Slogans, Questioning_the_Rep...      train   \n",
       "90    [Appeal_to_Hypocrisy, Loaded_Language, Questio...      train   \n",
       "172                          [Appeal_to_Fear-Prejudice]      train   \n",
       "194    [Guilt_by_Association, Appeal_to_Fear-Prejudice]      train   \n",
       "201   [Consequential_Oversimplification, Exaggeratio...      train   \n",
       "...                                                 ...        ...   \n",
       "1783  [Appeal_to_Hypocrisy, Questioning_the_Reputati...      train   \n",
       "1798  [Consequential_Oversimplification, Loaded_Lang...      train   \n",
       "1814                                                 []      train   \n",
       "1821  [Conversation_Killer, Loaded_Language, Slogans...      train   \n",
       "1862  [Loaded_Language, Appeal_to_Pity, Name_Calling...      train   \n",
       "\n",
       "                             Questioning_the_Reputation  \\\n",
       "48    [Grupa feministek pomagająca mordować nienarod...   \n",
       "90    [ustawa była początkiem wymazywania kobiet z d...   \n",
       "172                                                  []   \n",
       "194                                                  []   \n",
       "201   [tisti, ki vam je pisal odgovore na našo inter...   \n",
       "...                                                 ...   \n",
       "1783  [И да Ви кажа, уважаеми български граждани, че...   \n",
       "1798  [след престъпниците, които управляват Армията ...   \n",
       "1814                                                 []   \n",
       "1821  [Вие не сте даже и такива, за които членувате ...   \n",
       "1862                                                 []   \n",
       "\n",
       "                                  Name_Calling-Labeling  ... extra_content  \\\n",
       "48    [Aborcyjny Dream Team, Aborcyjny Dream Team, m...  ...        [None]   \n",
       "90                                                   []  ...        [None]   \n",
       "172                                                  []  ...        [None]   \n",
       "194                                                  []  ...        [None]   \n",
       "201                                                  []  ...        [None]   \n",
       "...                                                 ...  ...           ...   \n",
       "1783                                                 []  ...        [None]   \n",
       "1798                                                 []  ...        [None]   \n",
       "1814                                                 []  ...        [None]   \n",
       "1821            [руски агенти, руски агенти, гешефтари]  ...        [None]   \n",
       "1862                                   [Новите еничари]  ...        [None]   \n",
       "\n",
       "     explanation illegal_value think_content is_valid  \\\n",
       "48        [None]        [None]        [None]   [True]   \n",
       "90        [None]        [None]        [None]  [False]   \n",
       "172       [None]        [None]        [None]   [True]   \n",
       "194       [None]        [None]        [None]   [True]   \n",
       "201       [None]        [None]        [None]  [False]   \n",
       "...          ...           ...           ...      ...   \n",
       "1783      [None]        [None]        [None]  [False]   \n",
       "1798      [None]        [None]        [None]   [True]   \n",
       "1814      [None]        [None]        [None]  [False]   \n",
       "1821      [None]        [None]        [None]  [False]   \n",
       "1862      [None]        [None]        [None]   [True]   \n",
       "\n",
       "                                            source_file  \\\n",
       "48    data/llm_output/persuasion/explain/GPT_41/v001...   \n",
       "90    data/llm_output/persuasion/explain/GPT_41/v001...   \n",
       "172   data/llm_output/persuasion/explain/GPT_41/v001...   \n",
       "194   data/llm_output/persuasion/explain/GPT_41/v001...   \n",
       "201   data/llm_output/persuasion/explain/GPT_41/v001...   \n",
       "...                                                 ...   \n",
       "1783  data/llm_output/persuasion/explain/GPT_41/v001...   \n",
       "1798  data/llm_output/persuasion/explain/GPT_41/v001...   \n",
       "1814  data/llm_output/persuasion/explain/GPT_41/v001...   \n",
       "1821  data/llm_output/persuasion/explain/GPT_41/v001...   \n",
       "1862  data/llm_output/persuasion/explain/GPT_41/v001...   \n",
       "\n",
       "                                                  error           status  \\\n",
       "48    [{'code': 'content_filter', 'innererror': {'co...  [no validation]   \n",
       "90                                                  NaN              NaN   \n",
       "172   [{'code': 'content_filter', 'innererror': {'co...  [no validation]   \n",
       "194   [{'code': 'content_filter', 'innererror': {'co...  [no validation]   \n",
       "201                                                 NaN              NaN   \n",
       "...                                                 ...              ...   \n",
       "1783                                                NaN              NaN   \n",
       "1798  [{'code': 'content_filter', 'innererror': {'co...  [no validation]   \n",
       "1814                                                NaN              NaN   \n",
       "1821                                                NaN              NaN   \n",
       "1862  [{'code': 'content_filter', 'innererror': {'co...  [no validation]   \n",
       "\n",
       "      split                          expected_output  \n",
       "48    train  {\"description\": null, \"verdict\": false}  \n",
       "90    train   {\"description\": null, \"verdict\": true}  \n",
       "172   train  {\"description\": null, \"verdict\": false}  \n",
       "194   train  {\"description\": null, \"verdict\": false}  \n",
       "201   train   {\"description\": null, \"verdict\": true}  \n",
       "...     ...                                      ...  \n",
       "1783  train   {\"description\": null, \"verdict\": true}  \n",
       "1798  train  {\"description\": null, \"verdict\": false}  \n",
       "1814  train  {\"description\": null, \"verdict\": false}  \n",
       "1821  train   {\"description\": null, \"verdict\": true}  \n",
       "1862  train  {\"description\": null, \"verdict\": false}  \n",
       "\n",
       "[273 rows x 60 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"explanation\"].apply(\n",
    "    lambda x: isinstance(x, (list, np.ndarray)) and list(x) == [None]\n",
    ")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "075abb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PART_NAME = \"system\"\n",
    "USER_PART_NAME = \"user\"\n",
    "\n",
    "def build_messages(text,expected_output,job=\"persuasion\", step=\"detect\", prompt_name=\"Name_Calling-Labeling\", prompt_version=\"v001\"):\n",
    "    prompt_layout, prompt_content = load_template_parts(\n",
    "        job=\"persuasion\", step=\"detect\", prompt_name=\"Name_Calling-Labeling\", prompt_version=\"v001\"\n",
    "    )\n",
    "\n",
    "    json_line = {\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": prompt_layout[SYSTEM_PART_NAME].format(technique_name=prompt_content['technique_name'],\n",
    "                                                                                     technique_desc=prompt_content['technique_desc'],\n",
    "                                                                                     input_example = prompt_content['input_example'],\n",
    "                                                                                     output_example = prompt_content['output_example'])},\n",
    "                {\"role\": \"user\", \"content\": prompt_layout[USER_PART_NAME].format(text = text)},\n",
    "                {\"role\": \"assistant\", \"content\": expected_output}\n",
    "            ]\n",
    "        }\n",
    "    return json_line\n",
    "    # return(json.dumps(json_line, ensure_ascii=False) + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45e322b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_layout, prompt_content = load_template_parts(\n",
    "        job=\"persuasion\", step=\"detect\", prompt_name=\"Name_Calling-Labeling\", prompt_version=\"v001\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a76222a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write DataFrame to JSONL\n",
    "with open(\"data/finetuning/explain2detect_pers_v1.jsonl\", \"w\", encoding=\"utf-8\") as file:\n",
    "    for _, row in df[df.error.isna()].iterrows():\n",
    "        json_line = build_messages(text = row['text'],expected_output = row['expected_output'])\n",
    "        file.write(json.dumps(json_line, ensure_ascii=False) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7133e54a",
   "metadata": {},
   "source": [
    "# errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff84010",
   "metadata": {},
   "source": [
    "Unhandled exception during LLM call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "eb9a5425",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "filename",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "start",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "end",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "text_lang",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "text",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "label_bin",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "label_multi",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "base_split",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Questioning_the_Reputation",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Name_Calling-Labeling",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Appeal_to_Hypocrisy",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Conversation_Killer",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Loaded_Language",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Repetition",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Appeal_to_Popularity",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Doubt",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Red_Herring",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Flag_Waving",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Exaggeration-Minimisation",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Consequential_Oversimplification",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Appeal_to_Pity",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Appeal_to_Time",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Appeal_to_Values",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Obfuscation-Vagueness-Confusion",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Straw_Man",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Slogans",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Appeal_to_Fear-Prejudice",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Causal_Oversimplification",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Appeal_to_Authority",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "False_Dilemma-No_Choice",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Whataboutism",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "False_Equivalence",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Guilt_by_Association",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "alt_split",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "output_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "prompt_name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "prompt_version",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "job",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "step",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "max_iterations",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "temperature",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "model_provider",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "model_name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "model_mode",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "gold",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "gold_text",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "spans",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "raw",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "updated_definition",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "extra_properties",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "extra_content",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "explanation",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "illegal_value",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "think_content",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "is_valid",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "source_file",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "error",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "status",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "split",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "expected_output",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "7df8dc76-b83f-4df1-b181-a5ee01c29a80",
       "rows": [],
       "shape": {
        "columns": 60,
        "rows": 0
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>text_lang</th>\n",
       "      <th>text</th>\n",
       "      <th>label_bin</th>\n",
       "      <th>label_multi</th>\n",
       "      <th>base_split</th>\n",
       "      <th>Questioning_the_Reputation</th>\n",
       "      <th>Name_Calling-Labeling</th>\n",
       "      <th>...</th>\n",
       "      <th>extra_content</th>\n",
       "      <th>explanation</th>\n",
       "      <th>illegal_value</th>\n",
       "      <th>think_content</th>\n",
       "      <th>is_valid</th>\n",
       "      <th>source_file</th>\n",
       "      <th>error</th>\n",
       "      <th>status</th>\n",
       "      <th>split</th>\n",
       "      <th>expected_output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [filename, start, end, text_lang, text, label_bin, label_multi, base_split, Questioning_the_Reputation, Name_Calling-Labeling, Appeal_to_Hypocrisy, Conversation_Killer, Loaded_Language, Repetition, Appeal_to_Popularity, Doubt, Red_Herring, Flag_Waving, Exaggeration-Minimisation, Consequential_Oversimplification, Appeal_to_Pity, Appeal_to_Time, Appeal_to_Values, Obfuscation-Vagueness-Confusion, Straw_Man, Slogans, Appeal_to_Fear-Prejudice, Causal_Oversimplification, Appeal_to_Authority, False_Dilemma-No_Choice, Whataboutism, False_Equivalence, Guilt_by_Association, alt_split, output_id, prompt_name, prompt_version, job, step, max_iterations, temperature, model_provider, model_name, model_mode, gold, gold_text, spans, raw, updated_definition, extra_properties, extra_content, explanation, illegal_value, think_content, is_valid, source_file, error, status, split, expected_output]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 60 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errs_to_delete = df[df['error'].apply(lambda x: isinstance(x, np.ndarray) and 'Unhandled exception during LLM call' in x)]\n",
    "errs_to_delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a1a7c2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# List of file paths\n",
    "files_to_delete = errs_to_delete['source_file'].dropna().unique().tolist()\n",
    "\n",
    "# Delete each file safely\n",
    "for path in files_to_delete:\n",
    "    if os.path.isfile(path):\n",
    "        try:\n",
    "            # os.remove(path)\n",
    "            print(f\"Deleted: {path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error deleting {path}: {e}\")\n",
    "    else:\n",
    "        print(f\"File not found: {path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "53751190",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "filename",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "start",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "end",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "text_lang",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "text",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "label_bin",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "label_multi",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "base_split",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Questioning_the_Reputation",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Name_Calling-Labeling",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Appeal_to_Hypocrisy",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Conversation_Killer",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Loaded_Language",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Repetition",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Appeal_to_Popularity",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Doubt",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Red_Herring",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Flag_Waving",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Exaggeration-Minimisation",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Consequential_Oversimplification",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Appeal_to_Pity",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Appeal_to_Time",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Appeal_to_Values",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Obfuscation-Vagueness-Confusion",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Straw_Man",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Slogans",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Appeal_to_Fear-Prejudice",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Causal_Oversimplification",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Appeal_to_Authority",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "False_Dilemma-No_Choice",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Whataboutism",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "False_Equivalence",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Guilt_by_Association",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "alt_split",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "output_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "prompt_name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "prompt_version",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "job",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "step",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "max_iterations",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "temperature",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "model_provider",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "model_name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "model_mode",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "gold",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "gold_text",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "spans",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "raw",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "updated_definition",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "extra_properties",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "extra_content",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "explanation",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "illegal_value",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "think_content",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "is_valid",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "source_file",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "error",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "status",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "split",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "expected_output",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "4de9cad2-4e51-4dfc-89d0-68a03e9ac386",
       "rows": [
        [
         "30",
         "pl_abortion_11_04_2024_n08.txt",
         "150",
         "288",
         "PL",
         "Wicemarszałek Monika Wielichowska:\nSam pan wywołał reakcję pań, które znajdują się na\ngalerii. Proszę kontynuować. (Gwar na sali, dzwonek)",
         "True",
         "['Questioning_the_Reputation']",
         "train",
         "['Sam pan wywołał reakcję pań, które znajdują się na galerii']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Hypocrisy",
         "Appeal_to_Hypocrisy",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Appeal to Hypocrisy technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. There are no explicit or implicit references to contradictions or past actions that would qualify as an Appeal to Hypocrisy.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "['The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. There are no explicit or implicit references to contradictions or past actions that would qualify as an Appeal to Hypocrisy.']",
         "[None]",
         "[None]",
         "[ True]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/pl/train-pl-part_0002.parquet",
         "[None]",
         "[None]",
         "train",
         "{\"description\": \"The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. There are no explicit or implicit references to contradictions or past actions that would qualify as an Appeal to Hypocrisy.\", \"verdict\": false}"
        ],
        [
         "31",
         "pl_abortion_11_04_2024_n04.txt",
         "1320",
         "1701",
         "PL",
         "Zakaz aborcji w Polsce nie działa i wiedzą o tym\ndoskonale pomagające w aborcjach aktywistki i\nprzedstawicielki organizacji pozarządowych, które są tutaj\ndziś z nami. Nie wiem, czy wszystkie, bo nie wszystkie\notrzymały dziś rano zgodę od marszałka Hołowni\nna wejście na galerię. Podobno powodem są jakieś\nlimity, limity w otwartości i w uśmiechu.\nPierwsze słyszę, ale się zdarzyło.",
         "True",
         "['Conversation_Killer' 'Appeal_to_Pity' 'Repetition']",
         "train",
         "[]",
         "[]",
         "[]",
         "['Zakaz aborcji w Polsce nie działa']",
         "[]",
         "['Zakaz aborcji w Polsce nie działa']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Podobno powodem są jakieś limity, limity w otwartości i w uśmiechu']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Hypocrisy",
         "Appeal_to_Hypocrisy",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Appeal to Hypocrisy technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. There are no explicit or implicit references to contradictions between positions or actions that would qualify as an Appeal to Hypocrisy.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "['The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. There are no explicit or implicit references to contradictions between positions or actions that would qualify as an Appeal to Hypocrisy.']",
         "[None]",
         "[None]",
         "[ True]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/pl/train-pl-part_0002.parquet",
         "[None]",
         "[None]",
         "train",
         "{\"description\": \"The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. There are no explicit or implicit references to contradictions between positions or actions that would qualify as an Appeal to Hypocrisy.\", \"verdict\": false}"
        ],
        [
         "32",
         "pl_defence_22_05_2024_n01.txt",
         "8339",
         "10002",
         "PL",
         "Proszę państwa, jeśli chodzi o te zakupy, to one\nwszystkie były konsultowane, były wynikiem naszych rozmów w Radzie Modernizacji Technicznej\nz przeważającym, decydującym głosem Sztabu Generalnego Wojska Polskiego. Zmieniłem sposób zamawiania sprzętu wojskowego dla polskiego wojska,\nbo on był sprzeczny wewnętrznie. To była sytuacja,\nw której nie można było pójść naprzód, więc udrożniłem te procesy. Potem, kiedy przyszedł rok 2022,\nkiedy po raz kolejny Rosja napadła na Ukrainę, nawiązałem relacje z Koreą Południową. Dlaczego to\nzrobiłem? Dlatego że Korea Południowa posiada olbrzymi potencjał produkcyjny, jeśli chodzi o przemysł\nzbrojeniowy. Uważam za jeden z naszych sukcesów\nto, że w tak krótkim czasie doprowadziliśmy do tego,\nże w Wojsku Polskim już są czołgi K2, że obok\nHIMARS-ów, o których powiedziałem, są Chunmoo,\nczyli artyleria rakietowa o zasięgu do 300 km, że są\nsamoloty szkolno-bojowe FA-50. Pan powiedział, że\npiloci tak dużo zarabiają. Trzeba szkolić pilotów.\nFA-50 zostały zaprojektowane przez Lockheed Martin, a więc są taką mniejszą, to prawda, wersją\nF-16. W Wojsku Polskim, kiedy przyszliśmy do\nwładzy, w zasadzie tylko F-16 stanowiły jakąś siłę\nbojową. Pozostały sprzęt wojskowy był postsowiecki,\nbył zużyty. To był obraz nędzy i rozpaczy, a my doprowadziliśmy do tego, że dziś Wojsko Polskie liczy\nponad 200 tys. żołnierzy. Tylko jeszcze cele… Też\npan o tym nie wspomniał. Co najmniej 300 tys. żołnierzy. Można powiedzieć, że 300 tys. żołnierzy wojsk\noperacyjnych i 50 tys. żołnierzy Wojsk Obrony Terytorialnej – to powinien być nasz wspólny cel, mówię\no państwie polskim (Oklaski), bo w ten sposób możemy realnie odstraszyć agresora.",
         "True",
         "['Loaded_Language' 'Flag_Waving' 'Obfuscation-Vagueness-Confusion'\n 'Appeal_to_Authority' 'Name_Calling-Labeling' 'Red_Herring'\n 'Appeal_to_Fear-Prejudice']",
         "train",
         "[]",
         "['postsowiecki']",
         "[]",
         "[]",
         "['obraz nędzy i rozpaczy']",
         "[]",
         "[]",
         "[]",
         "['Pan powiedział, że piloci tak dużo zarabiają']",
         "['mówię o państwie polskim']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['To była sytuacja, w której nie można było pójść naprzód, więc udrożniłem te procesy']",
         "[]",
         "[]",
         "['realnie odstraszyć agresora']",
         "[]",
         "['jeśli chodzi o te zakupy, to one wszystkie były konsultowane, były wynikiem naszych rozmów w Radzie Modernizacji Technicznej z przeważającym, decydującym głosem Sztabu Generalnego Wojska Polskiego']",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Hypocrisy",
         "Appeal_to_Hypocrisy",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Appeal to Hypocrisy technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not contain any instances of attacking the reputation of a target by charging them with hypocrisy or inconsistency. There are no explicit or implicit references to contradictions in positions or actions that would qualify as an Appeal to Hypocrisy.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "['The input text does not contain any instances of attacking the reputation of a target by charging them with hypocrisy or inconsistency. There are no explicit or implicit references to contradictions in positions or actions that would qualify as an Appeal to Hypocrisy.']",
         "[None]",
         "[None]",
         "[ True]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/pl/train-pl-part_0002.parquet",
         "[None]",
         "[None]",
         "train",
         "{\"description\": \"The input text does not contain any instances of attacking the reputation of a target by charging them with hypocrisy or inconsistency. There are no explicit or implicit references to contradictions in positions or actions that would qualify as an Appeal to Hypocrisy.\", \"verdict\": false}"
        ],
        [
         "33",
         "pl_abortion_11_04_2024_n03.txt",
         "1839",
         "2256",
         "PL",
         "Mam dzisiaj zaszczyt i przyjemność jako posłanka\nklubu parlamentarnego Lewicy i wnioskodawczyni\nprojektu o bezpiecznym przerywaniu ciąży\nprzedstawić państwu projekt, który jest oparty na trosce i\nempatii w stosunku do kobiet, które po 30 latach\nobowiązywania zakazu aborcji muszą w końcu odzyskać\nodebrane im wiele lat temu prawo do podejmowania\nsamodzielnych decyzji w sprawie macierzyństwa,\nswojego zdrowia i życia.",
         "True",
         "['Appeal_to_Time' 'Appeal_to_Pity' 'Appeal_to_Values']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['po 30 latach obowiązywania zakazu aborcji muszą w końcu odzyskać odebrane im wiele lat temu prawo do podejmowania samodzielnych decyzji w sprawie macierzyństwa, swojego zdrowia i życia']",
         "['po 30 latach obowiązywania zakazu aborcji muszą w końcu odzyskać odebrane im wiele lat temu prawo']",
         "['który jest oparty na trosce i empatii w stosunku do kobiet'\n 'muszą w końcu odzyskać odebrane im wiele lat temu prawo do podejmowania samodzielnych decyzji w sprawie macierzyństwa, swojego zdrowia i życia']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Hypocrisy",
         "Appeal_to_Hypocrisy",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Appeal to Hypocrisy technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. It focuses on advocating for women\\'s rights without referencing any contradictions or past actions of others.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "[\"The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. It focuses on advocating for women's rights without referencing any contradictions or past actions of others.\"]",
         "[None]",
         "[None]",
         "[ True]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/pl/train-pl-part_0002.parquet",
         "[None]",
         "[None]",
         "train",
         "{\"description\": \"The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. It focuses on advocating for women's rights without referencing any contradictions or past actions of others.\", \"verdict\": false}"
        ],
        [
         "34",
         "pl_current_affairs_09_01_2025_n01.txt",
         "1187",
         "2227",
         "PL",
         "Poseł Maria Koc:\nDziękuję, panie marszałku.\nSzanowny Panie Marszałku! Szanowna Pani Minister! Wysoka Izbo! Jedną ze sztandarowych obietnic złożonych w trakcie kampanii wyborczej w 2023 r.\nprzez Koalicję Obywatelską, przez pana Donalda\nTuska była obietnica wprowadzenia w ciągu pierwszych 100 dni rządów tzw. świadczenia babciowego.\nTo pieniądze dla rodziców na zapewnienie opieki nad\nmałymi dziećmi, po to aby ci rodzice mogli wrócić na\nrynek pracy. Nie udało się koalicji rządzącej wprowadzić tego świadczenia w życie w ciągu pierwszych\n100 dni rządów, ale jesienią ta ustawa weszła w życie.\nOd 1 października 2024 r. rodzice mogli już składać\nwnioski do ZUS-u i wielu rodziców takie wnioski złożyło. Były opóźnienia w wypłatach, rodzice komunikowali się z ZUS-em, ZUS zapewniał, że wszystkie\nświadczenia, łącznie z wyrównaniami od 1 października, zostaną wypłacone rodzicom do dnia 20 grudnia. Niestety mamy rok 2025 i media ogólnopolskie\ndonoszą, że wielu rodziców nadal nie otrzymało tego\nświadczenia, mimo że składali wnioski w 2024 r.",
         "True",
         "['Doubt']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Niestety mamy rok 2025 i media ogólnopolskie donoszą, że wielu rodziców nadal nie otrzymało tego świadczenia, mimo że składali wnioski w 2024 r']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Hypocrisy",
         "Appeal_to_Hypocrisy",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Appeal to Hypocrisy technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. There are no explicit or implicit references to contradictions between past actions or positions held by the individuals mentioned. Therefore, the Appeal to Hypocrisy technique is not used.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "['The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. There are no explicit or implicit references to contradictions between past actions or positions held by the individuals mentioned. Therefore, the Appeal to Hypocrisy technique is not used.']",
         "[None]",
         "[None]",
         "[ True]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/pl/train-pl-part_0002.parquet",
         "[None]",
         "[None]",
         "train",
         "{\"description\": \"The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. There are no explicit or implicit references to contradictions between past actions or positions held by the individuals mentioned. Therefore, the Appeal to Hypocrisy technique is not used.\", \"verdict\": false}"
        ],
        [
         "35",
         "pl_abortion_11_04_2024_n07.txt",
         "7843",
         "8354",
         "PL",
         "Tytuł projektu Lewicy sugeruje, że aborcja może być\nbezpieczna, tymczasem sami projektodawcy w\nuzasadnieniu projektu podają, że od dnia wydania wyroku\nTrybunału Konstytucyjnego w 2020 r. tylko jedna z\norganizacji proaborcyjnych pomagała w aborcji w\nprzypadku 125 tys. kobiet, co oznacza, że co najmniej tyle\nsamo dzieci w wyniku aborcji straciło życie.\nProjektowane przepisy uderzają w podstawowe prawo każdego\nczłowieka, są całkowicie nieakceptowalne i powinny\nbyć odrzucone już w pierwszym czytaniu. (Oklaski)",
         "True",
         "['Conversation_Killer' 'Appeal_to_Hypocrisy' 'Appeal_to_Values']",
         "train",
         "[]",
         "[]",
         "['Tytuł projektu Lewicy sugeruje, że aborcja może być bezpieczna, tymczasem sami projektodawcy w uzasadnieniu projektu podają, że od dnia wydania wyroku Trybunału Konstytucyjnego w 2020 r. tylko jedna z organizacji proaborcyjnych pomagała w aborcji w przypadku 125 tys. kobiet, co oznacza, że co najmniej tyle samo dzieci w wyniku aborcji straciło życie']",
         "['są całkowicie nieakceptowalne i powinny być odrzucone już w pierwszym czytaniu']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Projektowane przepisy uderzają w podstawowe prawo każdego człowieka']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Hypocrisy",
         "Appeal_to_Hypocrisy",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "1",
         "Yes, the Appeal to Hypocrisy technique is used in the input.",
         "\"Tytuł projektu Lewicy sugeruje, że aborcja może być bezpieczna, tymczasem sami projektodawcy w uzasadnieniu projektu podają, że od dnia wydania wyroku Trybunału Konstytucyjnego w 2020 r. tylko jedna z organizacji proaborcyjnych pomagała w aborcji w przypadku 125 tys. kobiet, co oznacza, że co najmniej tyle samo dzieci w wyniku aborcji straciło życie\"",
         "['{\\n  \"explanation\": \"The Appeal to Hypocrisy technique is used in the input text by highlighting the inconsistency between the claim that abortion can be safe and the evidence presented that only one organization has helped a limited number of women, implying that the proponents of the project are not acting in accordance with their stated beliefs. This directly points out the hypocrisy in their position.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "['The Appeal to Hypocrisy technique is used in the input text by highlighting the inconsistency between the claim that abortion can be safe and the evidence presented that only one organization has helped a limited number of women, implying that the proponents of the project are not acting in accordance with their stated beliefs. This directly points out the hypocrisy in their position.']",
         "[None]",
         "[None]",
         "[ True]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/pl/train-pl-part_0002.parquet",
         "[None]",
         "[None]",
         "train",
         "{\"description\": \"The Appeal to Hypocrisy technique is used in the input text by highlighting the inconsistency between the claim that abortion can be safe and the evidence presented that only one organization has helped a limited number of women, implying that the proponents of the project are not acting in accordance with their stated beliefs. This directly points out the hypocrisy in their position.\", \"verdict\": true}"
        ],
        [
         "36",
         "pl_abortion_11_04_2024_n06.txt",
         "7874",
         "8360",
         "PL",
         "Jeszcze żaden zakaz aborcji nie zlikwidował aborcji.\nTa debata, szanowni państwo, nie jest o waszych\nsumieniach, jest o nas, o kobietach, o naszym zdrowiu,\no naszym życiu, o naszej godności. Więc proszę\nwas, abyście nie kazali nam być zakładnikami waszej\nwiary albo jej braku, waszych sumień i waszych poglądów.\nProszę was o to, abyście nam, kobietom, po\nprostu zaufali. Uwierzcie, że jesteśmy mądre, że\nmożemy podejmować decyzje i że te decyzje są najlepsze dla nas. Dziękuję. (Oklaski",
         "True",
         "['Conversation_Killer' 'Flag_Waving' 'Appeal_to_Pity']",
         "train",
         "[]",
         "[]",
         "[]",
         "['Jeszcze żaden zakaz aborcji nie zlikwidował aborcji']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Ta debata, szanowni państwo, nie jest o waszych sumieniach, jest o nas, o kobietach, o naszym zdrowiu, o naszym życiu, o naszej godności'\n 'Proszę was o to, abyście nam, kobietom, po prostu zaufali. Uwierzcie, że jesteśmy mądre, że możemy podejmować decyzje i że te decyzje są najlepsze dla nas']",
         "[]",
         "[]",
         "['Więc proszę was, abyście nie kazali nam być zakładnikami waszej wiary albo jej braku, waszych sumień i waszych poglądów']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Hypocrisy",
         "Appeal_to_Hypocrisy",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Appeal to Hypocrisy technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not contain any elements that attack the reputation of the audience by charging them with hypocrisy or inconsistency. It focuses on advocating for women\\'s rights and autonomy without referencing any past actions or positions of the audience that would imply hypocrisy.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "[\"The input text does not contain any elements that attack the reputation of the audience by charging them with hypocrisy or inconsistency. It focuses on advocating for women's rights and autonomy without referencing any past actions or positions of the audience that would imply hypocrisy.\"]",
         "[None]",
         "[None]",
         "[ True]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/pl/train-pl-part_0002.parquet",
         "[None]",
         "[None]",
         "train",
         "{\"description\": \"The input text does not contain any elements that attack the reputation of the audience by charging them with hypocrisy or inconsistency. It focuses on advocating for women's rights and autonomy without referencing any past actions or positions of the audience that would imply hypocrisy.\", \"verdict\": false}"
        ],
        [
         "37",
         "pl_current_affairs_09_01_2025_n01.txt",
         "4848",
         "5376",
         "PL",
         "Dzięki zastosowaniu automatycznego programowania od startu programu do końca grudnia 2024 r.\nrozpatrzono ponad 80% wniosków złożonych w tym\nokresie, pomimo że w październiku, co było naturalne, doszło do spiętrzenia wpływu wniosków z uwagi\nna to, że złożyli je rodzice dzieci z trzech roczników:\n2021–2023. W okresie od 1 października do 31 grudnia ZUS wypłacił łącznie 558 685 świadczeń na kwotę 670 279 596,83 zł. Nadal trwa rozpatrywanie wniosków z okresu, w którym konieczne jest przeprowadzenie postępowania wyjaśniającego.",
         "False",
         "[]",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Hypocrisy",
         "Appeal_to_Hypocrisy",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Appeal to Hypocrisy technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. There are no explicit or implicit references to contradictions between positions or actions, nor is there any mention of someone criticizing another for actions they themselves have taken in the past.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "['The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. There are no explicit or implicit references to contradictions between positions or actions, nor is there any mention of someone criticizing another for actions they themselves have taken in the past.']",
         "[None]",
         "[None]",
         "[ True]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/pl/train-pl-part_0002.parquet",
         "[None]",
         "[None]",
         "train",
         "{\"description\": \"The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. There are no explicit or implicit references to contradictions between positions or actions, nor is there any mention of someone criticizing another for actions they themselves have taken in the past.\", \"verdict\": false}"
        ],
        [
         "38",
         "pl_abortion_11_04_2024_n08.txt",
         "290",
         "1251",
         "PL",
         "Poseł Roman Fritz:\nGrupa feministek pomagająca mordować\nnienarodzone dzieci, Aborcyjny Dream Team, pochwaliła\nsię mniej więcej 2 lata temu, że pomogła zabić\ndziecko gotowe do porodu. Jego matka była w 37. tygodniu\nciąży. Feministki przyznają, że pomaganie w\naborcjach jest ich życiową pasją i misją, a za cel obrały\nsobie promowanie pozytywnego przekazu\ndotyczącego aborcji. Za pośrednictwem mediów\nspołecznościowych co jakiś czas Aborcyjny Dream Team chwali się\nswoimi morderczymi osiągnięciami. Uruchomiona\nprzez nich infolinia umożliwia konsultacje aborcyjne\ni zamawianie tabletek poronnych oraz umawianie\nwyjazdów na zabicie dziecka za granicami Polski.\nAborcjonistki przyznały również, że preferowaną metodą\nzabicia dziecka w tak zaawansowanym stadium\nrozwoju jest rozszerzenie szyjki macicy umożliwiające\nwydobycie go narzędziami, a wcześniej podanie\nbezbronnemu dziecku morderczego zastrzyku, który\nzatrzymuje akcję serca.\n(Poseł Krzysztof Bosak: Hańba!)",
         "True",
         "['Loaded_Language' 'Slogans' 'Questioning_the_Reputation'\n 'Name_Calling-Labeling' 'Appeal_to_Fear-Prejudice']",
         "train",
         "['Grupa feministek pomagająca mordować nienarodzone dzieci, Aborcyjny Dream Team, pochwaliła się mniej więcej 2 lata temu, że pomogła zabić dziecko gotowe do porodu'\n 'Feministki przyznają, że pomaganie w aborcjach jest ich życiową pasją i misją, a za cel obrały sobie promowanie pozytywnego przekazu dotyczącego aborcji'\n 'Aborcyjny Dream Team chwali się swoimi morderczymi osiągnięciami']",
         "['Aborcyjny Dream Team' 'Aborcyjny Dream Team' 'morderczymi']",
         "[]",
         "[]",
         "['pomagająca mordować nienarodzone dzieci' 'pomogła zabić dziecko'\n 'jest ich życiową pasją i misją' 'zabicie dziecka' 'zabicia'\n 'morderczego']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Hańba!)']",
         "['preferowaną metodą zabicia dziecka w tak zaawansowanym stadium rozwoju jest rozszerzenie szyjki macicy umożliwiające wydobycie go narzędziami, a wcześniej podanie bezbronnemu dziecku morderczego zastrzyku, który zatrzymuje akcję serca']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Hypocrisy",
         "Appeal_to_Hypocrisy",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Appeal to Hypocrisy technique is not used in the input.",
         "\"\"",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[ True]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/pl/train-pl-part_0002.parquet",
         "[{'code': 'content_filter', 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': True, 'severity': 'high'}, 'jailbreak': {'detected': False, 'filtered': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}, 'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'param': 'prompt', 'status': 400.0, 'type': None}]",
         "['no validation']",
         "train",
         "{\"description\": null, \"verdict\": false}"
        ],
        [
         "39",
         "pl_defence_22_05_2024_n02.txt",
         "1681",
         "1905",
         "PL",
         "Nie mamy też rezerw. Armia polska jest\nmobilizowana na czas wojny. Niestety nie mamy kogo\nmobilizować. Przeciętny wiek polskiego rezerwisty wynosi 50 lat.\nZanim pośle się żołnierza do wojny...\n(Poseł Piotr Kaleta: Na wojnę.)",
         "True",
         "['Doubt']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Nie mamy też rezerw. Armia polska jest mobilizowana na czas wojny. Niestety nie mamy kogo mobilizować. Przeciętny wiek polskiego rezerwisty wynosi 50 lat']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Hypocrisy",
         "Appeal_to_Hypocrisy",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Appeal to Hypocrisy technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. There are no explicit or implicit references to contradictions between positions or actions, nor is there any mention of someone criticizing another for a past action they themselves have done.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "['The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. There are no explicit or implicit references to contradictions between positions or actions, nor is there any mention of someone criticizing another for a past action they themselves have done.']",
         "[None]",
         "[None]",
         "[ True]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/pl/train-pl-part_0002.parquet",
         "[None]",
         "[None]",
         "train",
         "{\"description\": \"The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. There are no explicit or implicit references to contradictions between positions or actions, nor is there any mention of someone criticizing another for a past action they themselves have done.\", \"verdict\": false}"
        ],
        [
         "130",
         "RU_migrants_2.txt",
         "0",
         "65",
         "RU",
         "МИГРАЦИОННОЕ ЦУНАМИ УГРОЖАЕТ УТОПИТЬ АНГЛОГОВОРЯЩИЕ СТРАНЫ ЗАПАДА",
         "True",
         "['Exaggeration-Minimisation']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['МИГРАЦИОННОЕ ЦУНАМИ УГРОЖАЕТ УТОПИТЬ АНГЛОГОВОРЯЩИЕ СТРАНЫ ЗАПАДА']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Hypocrisy",
         "Appeal_to_Hypocrisy",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Appeal to Hypocrisy technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. There are no explicit or implicit references to contradictions between positions or actions, nor is there any mention of someone criticizing another for actions they themselves have taken.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "['The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. There are no explicit or implicit references to contradictions between positions or actions, nor is there any mention of someone criticizing another for actions they themselves have taken.']",
         "[None]",
         "[None]",
         "[ True]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/ru/train-ru-part_0007.parquet",
         "[None]",
         "[None]",
         "train",
         "{\"description\": \"The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. There are no explicit or implicit references to contradictions between positions or actions, nor is there any mention of someone criticizing another for actions they themselves have taken.\", \"verdict\": false}"
        ],
        [
         "131",
         "RU_discrediting_the_west_19.txt",
         "205",
         "556",
         "RU",
         "Вице-президент США Вэнс в своём откровенно жёстком выступлении прямо указал, что сегодняшняя Европа далеко ушла и от реальной демократии (пример обнулённой победы румынского кандидата, представителя национальных элит), и от традиционных ценностей, внедряет антихристианскую толерантность и другие, в том числе \"зелёные\" вопросы глобалистской повестки.",
         "True",
         "['Straw_Man']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Вице-президент США Вэнс в своём откровенно жёстком выступлении прямо указал, что сегодняшняя Европа далеко ушла и от реальной демократии (пример обнулённой победы румынского кандидата, представителя национальных элит), и от традиционных ценностей, внедряет антихристианскую толерантность и другие, в том числе \"зелёные\" вопросы глобалистской повестки']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Hypocrisy",
         "Appeal_to_Hypocrisy",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Appeal to Hypocrisy technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. It discusses the state of democracy and values in Europe without making any comparisons to past actions or positions of the critics.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "['The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. It discusses the state of democracy and values in Europe without making any comparisons to past actions or positions of the critics.']",
         "[None]",
         "[None]",
         "[ True]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/ru/train-ru-part_0007.parquet",
         "[None]",
         "[None]",
         "train",
         "{\"description\": \"The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. It discusses the state of democracy and values in Europe without making any comparisons to past actions or positions of the critics.\", \"verdict\": false}"
        ],
        [
         "132",
         "RU_demography_3.txt",
         "1885",
         "2142",
         "RU",
         "Также рассматривается возможность ограничения круга лиц, которым будет доступна сельская ипотека. Например, дешёвые жилищные кредиты могут оставить только для специалистов агропромышленного сектора и социально значимых работников (врачей, учителей и т. д.).",
         "False",
         "[]",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Hypocrisy",
         "Appeal_to_Hypocrisy",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Appeal to Hypocrisy technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text discusses the potential limitation of access to rural mortgages without attacking anyone\\'s reputation or calling out hypocrisy. There are no contradictions or past actions mentioned that would indicate the use of the Appeal to Hypocrisy technique.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "[\"The input text discusses the potential limitation of access to rural mortgages without attacking anyone's reputation or calling out hypocrisy. There are no contradictions or past actions mentioned that would indicate the use of the Appeal to Hypocrisy technique.\"]",
         "[None]",
         "[None]",
         "[ True]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/ru/train-ru-part_0007.parquet",
         "[None]",
         "[None]",
         "train",
         "{\"description\": \"The input text discusses the potential limitation of access to rural mortgages without attacking anyone's reputation or calling out hypocrisy. There are no contradictions or past actions mentioned that would indicate the use of the Appeal to Hypocrisy technique.\", \"verdict\": false}"
        ],
        [
         "133",
         "RU_discrediting_the_west_21.txt",
         "1417",
         "1655",
         "RU",
         "olihull, United Kingdom\nСтоит ли за этим пожаром Россия? Абсолютно во всех бедах, которые случаются с этой страной, виновата Россия, верно? Начиная с резиновых лодок и заканчивая тем, что Стармер стал премьер-министром.\n\n\nlondonvir, Londo",
         "True",
         "['Causal_Oversimplification']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Абсолютно во всех бедах, которые случаются с этой страной, виновата Россия, верно? Начиная с резиновых лодок и заканчивая тем, что Стармер стал премьер-министром']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Hypocrisy",
         "Appeal_to_Hypocrisy",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Appeal to Hypocrisy technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not contain any explicit or implicit accusations of hypocrisy or inconsistency directed at a target. It discusses blame attributed to Russia without referencing any contradictions in positions or actions, which is necessary for the Appeal to Hypocrisy technique to be applicable.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "['The input text does not contain any explicit or implicit accusations of hypocrisy or inconsistency directed at a target. It discusses blame attributed to Russia without referencing any contradictions in positions or actions, which is necessary for the Appeal to Hypocrisy technique to be applicable.']",
         "[None]",
         "[None]",
         "[ True]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/ru/train-ru-part_0007.parquet",
         "[None]",
         "[None]",
         "train",
         "{\"description\": \"The input text does not contain any explicit or implicit accusations of hypocrisy or inconsistency directed at a target. It discusses blame attributed to Russia without referencing any contradictions in positions or actions, which is necessary for the Appeal to Hypocrisy technique to be applicable.\", \"verdict\": false}"
        ],
        [
         "134",
         "RU_discrediting_the_west_7.txt",
         "700",
         "1046",
         "RU",
         "Затем 22 марта был теракт в концертном зале \"Крокус сити холл\", где в результате стрельбы и пожара погибли 144 человека, а пострадало более 500. Терроризм радикального ислама, казалось, был уже забыт в России, но в этот раз без помощи Украины не обошлось. Стоит отметить оперативность турецкой стороны, которая арестовала часть преступной группы.",
         "True",
         "['Guilt_by_Association' 'Appeal_to_Fear-Prejudice']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Затем 22 марта был теракт в концертном зале \"Крокус сити холл\", где в результате стрельбы и пожара погибли 144 человека, а пострадало более 500. Терроризм радикального ислама, казалось, был уже забыт в России, но в этот раз без помощи Украины не обошлось']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Терроризм радикального ислама, казалось, был уже забыт в России, но в этот раз без помощи Украины не обошлось']",
         "train",
         "GPT_41/v001/Appeal_to_Hypocrisy",
         "Appeal_to_Hypocrisy",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Appeal to Hypocrisy technique is not used in the input.",
         "\"\"",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[ True]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/ru/train-ru-part_0007.parquet",
         "[{'code': 'content_filter', 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'detected': False, 'filtered': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}, 'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'param': 'prompt', 'status': 400.0, 'type': None}]",
         "['no validation']",
         "train",
         "{\"description\": null, \"verdict\": false}"
        ],
        [
         "135",
         "RU_discrediting_the_west_1.txt",
         "952",
         "1002",
         "RU",
         "Одиноким намного легче манипулировать и управлять.",
         "False",
         "[]",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Hypocrisy",
         "Appeal_to_Hypocrisy",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Appeal to Hypocrisy technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not contain any elements that attack a target\\'s reputation by charging them with hypocrisy or inconsistency. There are no explicit or implicit references to contradictions or past actions that would qualify as an Appeal to Hypocrisy.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "[\"The input text does not contain any elements that attack a target's reputation by charging them with hypocrisy or inconsistency. There are no explicit or implicit references to contradictions or past actions that would qualify as an Appeal to Hypocrisy.\"]",
         "[None]",
         "[None]",
         "[ True]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/ru/train-ru-part_0007.parquet",
         "[None]",
         "[None]",
         "train",
         "{\"description\": \"The input text does not contain any elements that attack a target's reputation by charging them with hypocrisy or inconsistency. There are no explicit or implicit references to contradictions or past actions that would qualify as an Appeal to Hypocrisy.\", \"verdict\": false}"
        ],
        [
         "136",
         "RU_Trump_1.txt",
         "1222",
         "1298",
         "RU",
         " на встрече Зеленский в агрессивно-закрытой позе, как неврастеник.\n\nСейчас у",
         "False",
         "[]",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Hypocrisy",
         "Appeal_to_Hypocrisy",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Appeal to Hypocrisy technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. There are no explicit or implicit references to contradictions between positions or actions, nor is there any mention of someone criticizing another for something they themselves have done.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "['The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. There are no explicit or implicit references to contradictions between positions or actions, nor is there any mention of someone criticizing another for something they themselves have done.']",
         "[None]",
         "[None]",
         "[ True]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/ru/train-ru-part_0007.parquet",
         "[None]",
         "[None]",
         "train",
         "{\"description\": \"The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. There are no explicit or implicit references to contradictions between positions or actions, nor is there any mention of someone criticizing another for something they themselves have done.\", \"verdict\": false}"
        ],
        [
         "137",
         "RU_discrediting_the_west_3.txt",
         "1162",
         "1376",
         "RU",
         "4. Культура и традиции.\nРазрушается институт семьи. Крупнейшие украинские компании и официальные государственные ресурсы активно участвуют в так называемом «месяце прайда»: «украшают» свои страницы ЛГБТ-символикой.",
         "True",
         "['Appeal_to_Values']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Культура и традиции. Разрушается институт семьи. Крупнейшие украинские компании и официальные государственные ресурсы активно участвуют в так называемом «месяце прайда»: «украшают» свои страницы ЛГБТ-символикой']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Hypocrisy",
         "Appeal_to_Hypocrisy",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Appeal to Hypocrisy technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text discusses the involvement of Ukrainian companies and state resources in the \\'month of pride\\' but does not attack anyone\\'s reputation by charging them with hypocrisy or inconsistency. There are no explicit or implicit calls to hypocrisy present in the text.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "[\"The input text discusses the involvement of Ukrainian companies and state resources in the 'month of pride' but does not attack anyone's reputation by charging them with hypocrisy or inconsistency. There are no explicit or implicit calls to hypocrisy present in the text.\"]",
         "[None]",
         "[None]",
         "[ True]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/ru/train-ru-part_0007.parquet",
         "[None]",
         "[None]",
         "train",
         "{\"description\": \"The input text discusses the involvement of Ukrainian companies and state resources in the 'month of pride' but does not attack anyone's reputation by charging them with hypocrisy or inconsistency. There are no explicit or implicit calls to hypocrisy present in the text.\", \"verdict\": false}"
        ],
        [
         "138",
         "RU_URW_2.txt",
         "724",
         "855",
         "RU",
         "Православная церковь всегда вместе с русским воинством стояла на страже нашего государства и на защите народа от иноземных нападок.",
         "False",
         "[]",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Hypocrisy",
         "Appeal_to_Hypocrisy",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Appeal to Hypocrisy technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. It simply states the role of the Orthodox Church in defending the state and the people, without referencing any contradictions or past actions.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "['The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. It simply states the role of the Orthodox Church in defending the state and the people, without referencing any contradictions or past actions.']",
         "[None]",
         "[None]",
         "[ True]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/ru/train-ru-part_0007.parquet",
         "[None]",
         "[None]",
         "train",
         "{\"description\": \"The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. It simply states the role of the Orthodox Church in defending the state and the people, without referencing any contradictions or past actions.\", \"verdict\": false}"
        ],
        [
         "139",
         "RU_Trump_1.txt",
         "95",
         "309",
         "RU",
         "Трамп, конечно, король сейчас. Он разыграл партию так, что любое решение Зеленского будет выгодно США. Война дальше - продолжение ослабления России. Прекращение войны - экономический захват Украины. Везде профит.\n\n",
         "True",
         "['Causal_Oversimplification' 'Loaded_Language']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "['А Трамп, конечно, король сейчас']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Война дальше - продолжение ослабления России. Прекращение войны - экономический захват Украины. Везде профит']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Hypocrisy",
         "Appeal_to_Hypocrisy",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Appeal to Hypocrisy technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. There are no explicit or implicit references to contradictions in positions or actions that would qualify as an Appeal to Hypocrisy.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "['The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. There are no explicit or implicit references to contradictions in positions or actions that would qualify as an Appeal to Hypocrisy.']",
         "[None]",
         "[None]",
         "[ True]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/ru/train-ru-part_0007.parquet",
         "[None]",
         "[None]",
         "train",
         "{\"description\": \"The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. There are no explicit or implicit references to contradictions in positions or actions that would qualify as an Appeal to Hypocrisy.\", \"verdict\": false}"
        ],
        [
         "196",
         "20240111_SHG_BG_61.txt",
         "4984",
         "5168",
         "BG",
         "3. В срок до 30 септември 2018 г. Министерският съвет да представи пред Народното събрание предложение на България за реформа на така наречената Дъблинска система за прием на бежанци.“",
         "False",
         "[]",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Hypocrisy",
         "Appeal_to_Hypocrisy",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Appeal to Hypocrisy technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. There are no explicit or implicit references to contradictions or past actions that would qualify as an Appeal to Hypocrisy.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "['The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. There are no explicit or implicit references to contradictions or past actions that would qualify as an Appeal to Hypocrisy.']",
         "[None]",
         "[None]",
         "[ True]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/bg/train-bg-part_0004.parquet",
         "[None]",
         "[None]",
         "train",
         "{\"description\": \"The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. There are no explicit or implicit references to contradictions or past actions that would qualify as an Appeal to Hypocrisy.\", \"verdict\": false}"
        ],
        [
         "197",
         "20240704_URW_BG_28.txt",
         "7144",
         "7442",
         "BG",
         "шения за предстоящата Среща на върха във Вашингтон за подпомагане на Украйна, както и важността на координиране на усилията между НАТО и Европейския съюз с цел постигане на синергичен ефект на различни инструменти за помощ и да се избегне всякакво дублиране.\n\nИзвън официалната програма на срещата ",
         "False",
         "[]",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Hypocrisy",
         "Appeal_to_Hypocrisy",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Appeal to Hypocrisy technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. There are no explicit or implicit references to contradictions or past actions that would qualify as an Appeal to Hypocrisy.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "['The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. There are no explicit or implicit references to contradictions or past actions that would qualify as an Appeal to Hypocrisy.']",
         "[None]",
         "[None]",
         "[ True]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/bg/train-bg-part_0004.parquet",
         "[None]",
         "[None]",
         "train",
         "{\"description\": \"The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. There are no explicit or implicit references to contradictions or past actions that would qualify as an Appeal to Hypocrisy.\", \"verdict\": false}"
        ],
        [
         "198",
         "20231208_URW_BG_75.txt",
         "5280",
         "5654",
         "BG",
         "Така че не е непредизвикана агресията, убити са хиляди хора. Лошото е, че сега ние се приближаваме – само тук по този въпрос бяхте прав, тъй като привършва живият материал от наши събратя и от двете страни – над 500 хиляди ковчега, има нови ковчези, които трябва да бъдат пълнени. С кого? Новите еничари ще закарат и българите там, след като оголваме цялата Българска армия.",
         "True",
         "['Loaded_Language' 'Appeal_to_Pity' 'Name_Calling-Labeling'\n 'Appeal_to_Fear-Prejudice']",
         "train",
         "[]",
         "['Новите еничари']",
         "[]",
         "[]",
         "['ковчега, има нови ковчези, които трябва да бъдат пълнени']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Така че не е непредизвикана агресията, убити са хиляди хора']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Лошото е, че сега ние се приближаваме – само тук по този въпрос бяхте прав, тъй като привършва живият материал от наши събратя и от двете страни – над 500 хиляди ковчега, има нови ковчези, които трябва да бъдат пълнени'\n 'Новите еничари ще закарат и българите там, след като оголваме цялата Българска армия']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Hypocrisy",
         "Appeal_to_Hypocrisy",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Appeal to Hypocrisy technique is not used in the input.",
         "\"\"",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[ True]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/bg/train-bg-part_0004.parquet",
         "[{'code': 'content_filter', 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'detected': False, 'filtered': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}, 'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'param': 'prompt', 'status': 400.0, 'type': None}]",
         "['no validation']",
         "train",
         "{\"description\": null, \"verdict\": false}"
        ],
        [
         "199",
         "20240704_URW_BG_28.txt",
         "8169",
         "8224",
         "BG",
         ".\n\nВИКТОРИЯ ВАСИЛЕВА (ВЕЛИЧИЕ): Благодаря Ви, госпожо П",
         "False",
         "[]",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Hypocrisy",
         "Appeal_to_Hypocrisy",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Appeal to Hypocrisy technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. There are no explicit or implicit references to contradictions or past actions that would qualify as an Appeal to Hypocrisy.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "['The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. There are no explicit or implicit references to contradictions or past actions that would qualify as an Appeal to Hypocrisy.']",
         "[None]",
         "[None]",
         "[ True]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/bg/train-bg-part_0004.parquet",
         "[None]",
         "[None]",
         "train",
         "{\"description\": \"The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. There are no explicit or implicit references to contradictions or past actions that would qualify as an Appeal to Hypocrisy.\", \"verdict\": false}"
        ],
        [
         "200",
         "20240704_URW_BG_29.txt",
         "3835",
         "4157",
         "BG",
         "тическата подкрепа за Украйна остава приоритет за България. Със седем решения на Народното събрание предоставяме широк спектър от мерки за подпомагане на Украйна – политически, военни, хуманитарни и възстановителни. Помощта се предоставя, без да бъдат нарушавани отбранителните способности на България.\n\nСред най-важните р",
         "False",
         "[]",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Hypocrisy",
         "Appeal_to_Hypocrisy",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Appeal to Hypocrisy technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text discusses Bulgaria\\'s support for Ukraine without attacking anyone\\'s reputation or calling out hypocrisy. It focuses on the measures taken to assist Ukraine and does not reference any contradictions or past actions of critics.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "[\"The input text discusses Bulgaria's support for Ukraine without attacking anyone's reputation or calling out hypocrisy. It focuses on the measures taken to assist Ukraine and does not reference any contradictions or past actions of critics.\"]",
         "[None]",
         "[None]",
         "[ True]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/bg/train-bg-part_0004.parquet",
         "[None]",
         "[None]",
         "train",
         "{\"description\": \"The input text discusses Bulgaria's support for Ukraine without attacking anyone's reputation or calling out hypocrisy. It focuses on the measures taken to assist Ukraine and does not reference any contradictions or past actions of critics.\", \"verdict\": false}"
        ],
        [
         "201",
         "trail_raw_BG_7.txt",
         "2179",
         "2221",
         "BG",
         "АНЕ, от място): Я пак!\n\nИСКРЕН МИТЕВ: Това",
         "False",
         "[]",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Hypocrisy",
         "Appeal_to_Hypocrisy",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Appeal to Hypocrisy technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. There are no explicit or implicit references to contradictions or past actions that would qualify as an Appeal to Hypocrisy.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "['The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. There are no explicit or implicit references to contradictions or past actions that would qualify as an Appeal to Hypocrisy.']",
         "[None]",
         "[None]",
         "[ True]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/bg/train-bg-part_0004.parquet",
         "[None]",
         "[None]",
         "train",
         "{\"description\": \"The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. There are no explicit or implicit references to contradictions or past actions that would qualify as an Appeal to Hypocrisy.\", \"verdict\": false}"
        ],
        [
         "202",
         "20240704_URW_BG_30.txt",
         "5823",
         "6119",
         "BG",
         "заседанието, което ще бъде абсолютно безсмислено, защото тази позиция трябва да се чуе от българския народ. Коментирайки я на закрито заседание, ще засилим подозрения, страхове, че нещо тук се прави, че ще вкарате България във война и така нататък.\n\nПравя цялото това изложение с абсолютната добр",
         "True",
         "['Consequential_Oversimplification' 'Exaggeration-Minimisation'\n 'Name_Calling-Labeling' 'Appeal_to_Fear-Prejudice']",
         "train",
         "[]",
         "['абсолютно безсмислено']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['абсолютно безсмислено']",
         "['Коментирайки я на закрито заседание, ще засилим подозрения, страхове, че нещо тук се прави, че ще вкарате България във война и така нататък']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['ще засилим подозрения, страхове, че нещо тук се прави, че ще вкарате България във война и така нататък']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Hypocrisy",
         "Appeal_to_Hypocrisy",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Appeal to Hypocrisy technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. There are no explicit or implicit references to contradictions between positions or actions, which is essential for the Appeal to Hypocrisy technique to be applicable.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "['The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. There are no explicit or implicit references to contradictions between positions or actions, which is essential for the Appeal to Hypocrisy technique to be applicable.']",
         "[None]",
         "[None]",
         "[ True]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/bg/train-bg-part_0004.parquet",
         "[None]",
         "[None]",
         "train",
         "{\"description\": \"The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. There are no explicit or implicit references to contradictions between positions or actions, which is essential for the Appeal to Hypocrisy technique to be applicable.\", \"verdict\": false}"
        ],
        [
         "203",
         "trail_raw_BG_7.txt",
         "2225",
         "2773",
         "BG",
         "итат от Мария Захарова, която е директно представител на руската държава. Това не е просто проруска партия, това са директно думите на Кремъл, изречени от тази трибуна. Това правят ВЪЗРАЖДАНЕ, господин Божанков. Така че, когато кажете проруска партия, това не е достатъчно ясно. Това са буквално представители – явно платени или по някакъв начин накарани да идват и да изразяват позицията на руската държава и на Кремъл от трибуната, така че, моля Ви се, когато ги адресирате, адресирайте ги правилно. (Реплики от ВЪЗРАЖДАНЕ.)\n\nПРЕДСЕДАТЕЛ РОСЕН ЖЕ",
         "True",
         "['Exaggeration-Minimisation' 'Name_Calling-Labeling'\n 'Guilt_by_Association']",
         "train",
         "[]",
         "['проруска партия' 'проруска партия']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['това са директно думите на Кремъл, изречени от тази трибуна'\n 'буквално представители – явно платени или по някакъв начин накарани да идват и да изразяват позицията на руската държава и на Кремъл от трибуната']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Това не е просто проруска партия, това са директно думите на Кремъл, изречени от тази трибуна'\n 'буквално представители – явно платени или по някакъв начин накарани да идват и да изразяват позицията на руската държава и на Кремъл от трибуната']",
         "train",
         "GPT_41/v001/Appeal_to_Hypocrisy",
         "Appeal_to_Hypocrisy",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Appeal to Hypocrisy technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. There are no explicit or implicit references to contradictions between different positions or actions held by the individuals mentioned. Therefore, the Appeal to Hypocrisy technique is not used.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "['The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. There are no explicit or implicit references to contradictions between different positions or actions held by the individuals mentioned. Therefore, the Appeal to Hypocrisy technique is not used.']",
         "[None]",
         "[None]",
         "[ True]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/bg/train-bg-part_0004.parquet",
         "[None]",
         "[None]",
         "train",
         "{\"description\": \"The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. There are no explicit or implicit references to contradictions between different positions or actions held by the individuals mentioned. Therefore, the Appeal to Hypocrisy technique is not used.\", \"verdict\": false}"
        ],
        [
         "204",
         "20240229_URW_BG_67.txt",
         "4167",
         "4219",
         "BG",
         "ПРЕДСЕДАТЕЛ РОСЕН ЖЕЛЯЗКОВ: Времето, госпожо Нинова.",
         "False",
         "[]",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Hypocrisy",
         "Appeal_to_Hypocrisy",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Appeal to Hypocrisy technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. There are no explicit or implicit references to contradictions or past actions that would qualify as an Appeal to Hypocrisy.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "['The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. There are no explicit or implicit references to contradictions or past actions that would qualify as an Appeal to Hypocrisy.']",
         "[None]",
         "[None]",
         "[ True]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/bg/train-bg-part_0004.parquet",
         "[None]",
         "[None]",
         "train",
         "{\"description\": \"The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. There are no explicit or implicit references to contradictions or past actions that would qualify as an Appeal to Hypocrisy.\", \"verdict\": false}"
        ],
        [
         "205",
         "20240229_URW_BG_67.txt",
         "766",
         "1302",
         "BG",
         "Запитан дали изпращането на западни войски в Украйна е вариант, Макрон отговаря, че въпросът е бил обсъден на конференцията. Драматизмът на тези съобщения беше засилен от министър-председателя Роберт Фицо, който заяви официално: „Няколко държави от НАТО и Европейския съюз обмислят възможността да изпратят войници в Украйна на двустранна основа.“ Цитирам само официални източници, за да няма двусмислие, да няма обвинения, че Българската социалистическа партия злоупотребяваме със страхове и използваме страховете на българския народ. ",
         "True",
         "['Appeal_to_Authority']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Цитирам само официални източници, за да няма двусмислие, да няма обвинения']",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Hypocrisy",
         "Appeal_to_Hypocrisy",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Appeal to Hypocrisy technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. There are no explicit or implicit references to contradictions between positions or actions, nor is there any mention of someone criticizing another for actions they themselves have taken. Therefore, the Appeal to Hypocrisy technique is not used.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "['The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. There are no explicit or implicit references to contradictions between positions or actions, nor is there any mention of someone criticizing another for actions they themselves have taken. Therefore, the Appeal to Hypocrisy technique is not used.']",
         "[None]",
         "[None]",
         "[ True]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/bg/train-bg-part_0004.parquet",
         "[None]",
         "[None]",
         "train",
         "{\"description\": \"The input text does not contain any elements that attack the reputation of a target by charging them with hypocrisy or inconsistency. There are no explicit or implicit references to contradictions between positions or actions, nor is there any mention of someone criticizing another for actions they themselves have taken. Therefore, the Appeal to Hypocrisy technique is not used.\", \"verdict\": false}"
        ],
        [
         "216",
         "RU_discrediting_the_west_12.txt",
         "2311",
         "2457",
         "RU",
         "чные случаи. Сверху рисуют план по набору на контракт, регионы берут под козырек и привлекают людей выплатами, мошенники зарабатывают.\n\nПрофит у в",
         "True",
         "['Causal_Oversimplification' 'Exaggeration-Minimisation']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Это не единичные случаи']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Сверху рисуют план по набору на контракт, регионы берут под козырек и привлекают людей выплатами, мошенники зарабатывают']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Questioning_the_Reputation",
         "Questioning_the_Reputation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Questioning the Reputation technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not contain any explicit negative claims aimed at undermining the reputation or moral stature of a specific target. Therefore, the Questioning the Reputation technique is not used.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "['The input text does not contain any explicit negative claims aimed at undermining the reputation or moral stature of a specific target. Therefore, the Questioning the Reputation technique is not used.']",
         "[None]",
         "[None]",
         "[ True]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/ru/train-ru-part_0000.parquet",
         "[None]",
         "[None]",
         "train",
         "{\"description\": \"The input text does not contain any explicit negative claims aimed at undermining the reputation or moral stature of a specific target. Therefore, the Questioning the Reputation technique is not used.\", \"verdict\": false}"
        ],
        [
         "217",
         "RU_URW_4.txt",
         "507",
         "751",
         "RU",
         "Собственно, данная тактика себя оправдала во время \"Минского формата\", когда подписанное обязана была соблюдать только Россия, которая тогда вообще не была стороной конфликта, но все равно оставалась виноватой. Так зачем ломать \"рабочую\" схему.",
         "True",
         "['Causal_Oversimplification']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Собственно, данная тактика себя оправдала во время \"Минского формата\", когда подписанное обязана была соблюдать только Россия, которая тогда вообще не была стороной конфликта, но все равно оставалась виноватой']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Questioning_the_Reputation",
         "Questioning_the_Reputation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Questioning the Reputation technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not contain any explicit negative claims about the reputation or moral character of a target. It discusses a tactical situation without attacking anyone\\'s character or credibility, which aligns with the expert\\'s verdict that the Questioning the Reputation technique is not used.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "[\"The input text does not contain any explicit negative claims about the reputation or moral character of a target. It discusses a tactical situation without attacking anyone's character or credibility, which aligns with the expert's verdict that the Questioning the Reputation technique is not used.\"]",
         "[None]",
         "[None]",
         "[ True]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/ru/train-ru-part_0000.parquet",
         "[None]",
         "[None]",
         "train",
         "{\"description\": \"The input text does not contain any explicit negative claims about the reputation or moral character of a target. It discusses a tactical situation without attacking anyone's character or credibility, which aligns with the expert's verdict that the Questioning the Reputation technique is not used.\", \"verdict\": false}"
        ],
        [
         "218",
         "RU_migrants_4.txt",
         "1955",
         "2137",
         "RU",
         "Будем надеяться, что ужесточение законодательства ударит и по адептам нетрадиционного Ислама и религиозного экстремизма, а также по распространителям наркотиков на территории России.",
         "True",
         "['Straw_Man']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Будем надеяться, что ужесточение законодательства ударит и по адептам нетрадиционного Ислама и религиозного экстремизма, а также по распространителям наркотиков на территории России']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Questioning_the_Reputation",
         "Questioning_the_Reputation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Questioning the Reputation technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not contain any explicit attacks on the reputation of a specific target. It discusses the hope that legislation will impact certain groups but does not make strong negative claims about their character or moral stature.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "['The input text does not contain any explicit attacks on the reputation of a specific target. It discusses the hope that legislation will impact certain groups but does not make strong negative claims about their character or moral stature.']",
         "[None]",
         "[None]",
         "[ True]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/ru/train-ru-part_0000.parquet",
         "[None]",
         "[None]",
         "train",
         "{\"description\": \"The input text does not contain any explicit attacks on the reputation of a specific target. It discusses the hope that legislation will impact certain groups but does not make strong negative claims about their character or moral stature.\", \"verdict\": false}"
        ],
        [
         "219",
         "RU_demography_1.txt",
         "1283",
         "1609",
         "RU",
         "Русские, как народ, нация, культура, могут исчезнуть. Если русские утратят волю к жизни, инстинкт самосохранения и продолжения рода, так и будет. И случится всё вполне в течение текущего столетия. Во второй его половине. Просто в силу сокращения, размывания новых поколений русских, их вытеснения и замещения другими народами.",
         "True",
         "['Appeal_to_Fear-Prejudice']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Русские, как народ, нация, культура, могут исчезнуть. Если русские утратят волю к жизни, инстинкт самосохранения и продолжения рода, так и будет']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Questioning_the_Reputation",
         "Questioning_the_Reputation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Questioning the Reputation technique is not used in the input.",
         "\"\"",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[ True]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/ru/train-ru-part_0000.parquet",
         "[{'code': 'content_filter', 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': True, 'severity': 'medium'}, 'jailbreak': {'detected': False, 'filtered': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}, 'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'param': 'prompt', 'status': 400.0, 'type': None}]",
         "['no validation']",
         "train",
         "{\"description\": null, \"verdict\": false}"
        ],
        [
         "220",
         "RU_discrediting_the_west_12.txt",
         "717",
         "969",
         "RU",
         "имер, родная для меня Самарская область отличилась. Выплаты за подписание контракта подняли до 4 млн, тысяч 30 выплачивают по акции \"приведи друга\", и в целом, стахановскими темпами идёт вербовка контрактников, молодцы! Ещё бы на качество смотрели.\n\nНе",
         "True",
         "['Doubt']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Например, родная для меня Самарская область отличилась. Выплаты за подписание контракта подняли до 4 млн, тысяч 30 выплачивают по акции \"приведи друга\", и в целом, стахановскими темпами идёт вербовка контрактников, молодцы!']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Questioning_the_Reputation",
         "Questioning_the_Reputation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Questioning the Reputation technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not contain any elements that attack the reputation of a target or make strong negative claims about it. It discusses contract signing and recruitment without undermining anyone\\'s character or moral stature, which aligns with the expert\\'s verdict that the technique was not used.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "[\"The input text does not contain any elements that attack the reputation of a target or make strong negative claims about it. It discusses contract signing and recruitment without undermining anyone's character or moral stature, which aligns with the expert's verdict that the technique was not used.\"]",
         "[None]",
         "[None]",
         "[ True]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/ru/train-ru-part_0000.parquet",
         "[None]",
         "[None]",
         "train",
         "{\"description\": \"The input text does not contain any elements that attack the reputation of a target or make strong negative claims about it. It discusses contract signing and recruitment without undermining anyone's character or moral stature, which aligns with the expert's verdict that the technique was not used.\", \"verdict\": false}"
        ],
        [
         "221",
         "RU_Trump_1.txt",
         "1302",
         "1987",
         "RU",
         "мпа стратегия «only business», то есть экономическая выгода для США, у Путина стратегия «realpolitik» - прагматизм в интересах общества, но с элементами нравственности. А вот стратегия Зеленского - сохранить не Украину, а себя. У него цугцванг- любой ход ведет к проигрышу. Сделка - продажа Украины, отказ от сделки - разрушение государства. А договориться он не смог, так как человек недалекий. И, вероятно, Зеленский не думал, что будут вопросы к нему по поводу махинаций с выделяемыми средствами из бюджета США, что сумеет проскочить и Трампу он выгоден, но Трамп хочет полного контроля над ресурсами Украины и полного подчинения Зеленского - такова цена военной помощи.\n\nЛишившись ",
         "True",
         "['False_Dilemma-No_Choice' 'Name_Calling-Labeling' 'Straw_Man' 'Doubt']",
         "train",
         "[]",
         "['так как человек недалекий']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['А вот стратегия Зеленского - сохранить не Украину, а себя. У него цугцванг- любой ход ведет к проигрышу']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['И, вероятно, Зеленский не думал, что будут вопросы к нему по поводу махинаций с выделяемыми средствами из бюджета США, что сумеет проскочить и Трампу он выгоден, но Трамп хочет полного контроля над ресурсами Украины и полного подчинения Зеленского - такова цена военной помощи']",
         "[]",
         "[]",
         "[]",
         "[]",
         "['А вот стратегия Зеленского - сохранить не Украину, а себя'\n 'Сделка - продажа Украины, отказ от сделки - разрушение государства']",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Questioning_the_Reputation",
         "Questioning_the_Reputation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Questioning the Reputation technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not contain any explicit attacks on the reputation of the target, nor does it make strong negative claims aimed at undermining the character or moral stature of any individual. The statements made about Zelensky do not constitute a direct questioning of his overall reputation but rather critique his actions and decisions in a specific context. Therefore, the Questioning the Reputation technique is not used.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "['The input text does not contain any explicit attacks on the reputation of the target, nor does it make strong negative claims aimed at undermining the character or moral stature of any individual. The statements made about Zelensky do not constitute a direct questioning of his overall reputation but rather critique his actions and decisions in a specific context. Therefore, the Questioning the Reputation technique is not used.']",
         "[None]",
         "[None]",
         "[ True]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/ru/train-ru-part_0000.parquet",
         "[None]",
         "[None]",
         "train",
         "{\"description\": \"The input text does not contain any explicit attacks on the reputation of the target, nor does it make strong negative claims aimed at undermining the character or moral stature of any individual. The statements made about Zelensky do not constitute a direct questioning of his overall reputation but rather critique his actions and decisions in a specific context. Therefore, the Questioning the Reputation technique is not used.\", \"verdict\": false}"
        ],
        [
         "222",
         "RU_discrediting_the_west_6.txt",
         "1132",
         "1580",
         "RU",
         "За два с половиной года нет ни одной публичной адекватной версии произошедшего. Три отдельных расследования диверсии были инициированы и прекращены, а европейцев кормят сказками об украинском водолазе «Володимире З.», который чуть ли не в одиночку спустил несколько тонн оборудования и взорвал защищённую энергоинфраструктуру на дне Балтийского моря. Хотя разрушительную террористическую сущность «Володимиров З.» не стоит недооценивать, но всё же.",
         "True",
         "['Causal_Oversimplification' 'Loaded_Language']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Три отдельных расследования диверсии были инициированы и прекращены, а европейцев кормят сказками об украинском водолазе «Володимире З.», который чуть ли не в одиночку спустил несколько тонн оборудования и взорвал защищённую энергоинфраструктуру на дне Балтийского моря'\n 'кормят сказками']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['За два с половиной года нет ни одной публичной адекватной версии произошедшего']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Questioning_the_Reputation",
         "Questioning_the_Reputation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Questioning the Reputation technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not contain any explicit attacks on the reputation or character of a specific individual or group. Instead, it discusses the lack of credible information regarding an event and mentions a character named \\'Володимир З.\\' in a critical context, but does not undermine his overall reputation or moral qualities in a way that fits the definition of Questioning the Reputation.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "[\"The input text does not contain any explicit attacks on the reputation or character of a specific individual or group. Instead, it discusses the lack of credible information regarding an event and mentions a character named 'Володимир З.' in a critical context, but does not undermine his overall reputation or moral qualities in a way that fits the definition of Questioning the Reputation.\"]",
         "[None]",
         "[None]",
         "[ True]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/ru/train-ru-part_0000.parquet",
         "[None]",
         "[None]",
         "train",
         "{\"description\": \"The input text does not contain any explicit attacks on the reputation or character of a specific individual or group. Instead, it discusses the lack of credible information regarding an event and mentions a character named '\\u0412\\u043e\\u043b\\u043e\\u0434\\u0438\\u043c\\u0438\\u0440 \\u0417.' in a critical context, but does not undermine his overall reputation or moral qualities in a way that fits the definition of Questioning the Reputation.\", \"verdict\": false}"
        ],
        [
         "223",
         "RU_discrediting_the_west_2.txt",
         "1414",
         "1566",
         "RU",
         "Всё из-за политики Вашингтона, в основе которой принцип собственной исключительности, превосходства американцев над другими, а также двойных стандартов.",
         "True",
         "['Appeal_to_Hypocrisy']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Questioning_the_Reputation",
         "Questioning_the_Reputation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Questioning the Reputation technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text discusses the policies of Washington and implies a negative view of American exceptionalism and double standards, but it does not explicitly attack the reputation or moral character of a specific individual or group. Therefore, the Questioning the Reputation technique is not used.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "['The input text discusses the policies of Washington and implies a negative view of American exceptionalism and double standards, but it does not explicitly attack the reputation or moral character of a specific individual or group. Therefore, the Questioning the Reputation technique is not used.']",
         "[None]",
         "[None]",
         "[ True]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/ru/train-ru-part_0000.parquet",
         "[None]",
         "[None]",
         "train",
         "{\"description\": \"The input text discusses the policies of Washington and implies a negative view of American exceptionalism and double standards, but it does not explicitly attack the reputation or moral character of a specific individual or group. Therefore, the Questioning the Reputation technique is not used.\", \"verdict\": false}"
        ],
        [
         "224",
         "RU_discrediting_the_west_6.txt",
         "1060",
         "1130",
         "RU",
         "Что это за надругательство над здравым смыслом уходящей администрации?",
         "True",
         "['Conversation_Killer' 'Loaded_Language']",
         "train",
         "[]",
         "[]",
         "[]",
         "['Что это за надругательство над здравым смыслом уходящей администрации?']",
         "['надругательство над здравым смыслом']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Questioning_the_Reputation",
         "Questioning_the_Reputation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Questioning the Reputation technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not contain any explicit negative claims about the reputation or moral character of a specific target. It questions the actions of the administration but does not attack its overall reputation or character, which is necessary for the use of the Questioning the Reputation technique.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "['The input text does not contain any explicit negative claims about the reputation or moral character of a specific target. It questions the actions of the administration but does not attack its overall reputation or character, which is necessary for the use of the Questioning the Reputation technique.']",
         "[None]",
         "[None]",
         "[ True]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/ru/train-ru-part_0000.parquet",
         "[None]",
         "[None]",
         "train",
         "{\"description\": \"The input text does not contain any explicit negative claims about the reputation or moral character of a specific target. It questions the actions of the administration but does not attack its overall reputation or character, which is necessary for the use of the Questioning the Reputation technique.\", \"verdict\": false}"
        ],
        [
         "225",
         "RU_URW_4.txt",
         "753",
         "934",
         "RU",
         "Как видим, от администрации Трампа тоже не слышно слов возмущения по поводу атаки на нашу нефтебазу, молчит Европа, молчат все. Но как только Россия ответит, то молчание закончится.",
         "True",
         "['Causal_Oversimplification' 'Appeal_to_Authority']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Как видим, от администрации Трампа тоже не слышно слов возмущения по поводу атаки на нашу нефтебазу, молчит Европа, молчат все']",
         "['Но как только Россия ответит, то молчание закончится']",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Questioning_the_Reputation",
         "Questioning_the_Reputation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Questioning the Reputation technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not contain any explicit attacks on the reputation of a target or strong negative claims aimed at undermining character or moral stature. It discusses the silence of various parties in response to an attack without questioning their reputation.\",\\n  \"updated_definition\": \"This technique is used to attack the reputation of the target by making strong negative claims about it, focusing especially on undermining its character and moral stature rather than relying on an argument about the topic. Whether the claims are true or false is irrelevant for the effective use of this technique. Smears can be used at any point in a discussion. One particular way of using this technique is to preemptively call into question the reputation/credibility of an opponent, before he had any chance to express himself, therefore biasing the audience perception. The main difference between Casting Doubt and Questioning the Reputation technique is that the former focuses on questioning the capacity, the capabilities, and the credibility of the target, while the latter targets undermining the overall reputation, moral qualities, behavior, etc. The technique is characterized by explicit negative assertions about the target\\'s character or integrity.\"\\n}']",
         "[\"This technique is used to attack the reputation of the target by making strong negative claims about it, focusing especially on undermining its character and moral stature rather than relying on an argument about the topic. Whether the claims are true or false is irrelevant for the effective use of this technique. Smears can be used at any point in a discussion. One particular way of using this technique is to preemptively call into question the reputation/credibility of an opponent, before he had any chance to express himself, therefore biasing the audience perception. The main difference between Casting Doubt and Questioning the Reputation technique is that the former focuses on questioning the capacity, the capabilities, and the credibility of the target, while the latter targets undermining the overall reputation, moral qualities, behavior, etc. The technique is characterized by explicit negative assertions about the target's character or integrity.\"]",
         "[None]",
         "[None]",
         "['The input text does not contain any explicit attacks on the reputation of a target or strong negative claims aimed at undermining character or moral stature. It discusses the silence of various parties in response to an attack without questioning their reputation.']",
         "[None]",
         "[None]",
         "[ True]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/ru/train-ru-part_0000.parquet",
         "[None]",
         "[None]",
         "train",
         "{\"description\": \"The input text does not contain any explicit attacks on the reputation of a target or strong negative claims aimed at undermining character or moral stature. It discusses the silence of various parties in response to an attack without questioning their reputation.\", \"verdict\": false}"
        ],
        [
         "226",
         "RU_migrants_2.txt",
         "0",
         "65",
         "RU",
         "МИГРАЦИОННОЕ ЦУНАМИ УГРОЖАЕТ УТОПИТЬ АНГЛОГОВОРЯЩИЕ СТРАНЫ ЗАПАДА",
         "True",
         "['Exaggeration-Minimisation']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['МИГРАЦИОННОЕ ЦУНАМИ УГРОЖАЕТ УТОПИТЬ АНГЛОГОВОРЯЩИЕ СТРАНЫ ЗАПАДА']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Questioning_the_Reputation",
         "Questioning_the_Reputation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Questioning the Reputation technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not contain any elements that attack the reputation of a target or undermine its character or moral stature. It focuses on a general claim about a threat without making negative assertions about any specific individual or group.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "['The input text does not contain any elements that attack the reputation of a target or undermine its character or moral stature. It focuses on a general claim about a threat without making negative assertions about any specific individual or group.']",
         "[None]",
         "[None]",
         "[ True]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/ru/train-ru-part_0007.parquet",
         "[None]",
         "[None]",
         "train",
         "{\"description\": \"The input text does not contain any elements that attack the reputation of a target or undermine its character or moral stature. It focuses on a general claim about a threat without making negative assertions about any specific individual or group.\", \"verdict\": false}"
        ],
        [
         "227",
         "RU_discrediting_the_west_19.txt",
         "205",
         "556",
         "RU",
         "Вице-президент США Вэнс в своём откровенно жёстком выступлении прямо указал, что сегодняшняя Европа далеко ушла и от реальной демократии (пример обнулённой победы румынского кандидата, представителя национальных элит), и от традиционных ценностей, внедряет антихристианскую толерантность и другие, в том числе \"зелёные\" вопросы глобалистской повестки.",
         "True",
         "['Straw_Man']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Вице-президент США Вэнс в своём откровенно жёстком выступлении прямо указал, что сегодняшняя Европа далеко ушла и от реальной демократии (пример обнулённой победы румынского кандидата, представителя национальных элит), и от традиционных ценностей, внедряет антихристианскую толерантность и другие, в том числе \"зелёные\" вопросы глобалистской повестки']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Questioning_the_Reputation",
         "Questioning_the_Reputation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Questioning the Reputation technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not contain any explicit attacks on the reputation or moral character of a specific target. Instead, it discusses the state of democracy and values in Europe without making strong negative claims about an individual or group. Therefore, the Questioning the Reputation technique is not used.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "['The input text does not contain any explicit attacks on the reputation or moral character of a specific target. Instead, it discusses the state of democracy and values in Europe without making strong negative claims about an individual or group. Therefore, the Questioning the Reputation technique is not used.']",
         "[None]",
         "[None]",
         "[ True]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/ru/train-ru-part_0007.parquet",
         "[None]",
         "[None]",
         "train",
         "{\"description\": \"The input text does not contain any explicit attacks on the reputation or moral character of a specific target. Instead, it discusses the state of democracy and values in Europe without making strong negative claims about an individual or group. Therefore, the Questioning the Reputation technique is not used.\", \"verdict\": false}"
        ],
        [
         "228",
         "RU_demography_3.txt",
         "1885",
         "2142",
         "RU",
         "Также рассматривается возможность ограничения круга лиц, которым будет доступна сельская ипотека. Например, дешёвые жилищные кредиты могут оставить только для специалистов агропромышленного сектора и социально значимых работников (врачей, учителей и т. д.).",
         "False",
         "[]",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Questioning_the_Reputation",
         "Questioning_the_Reputation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Questioning the Reputation technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not contain any elements that attack the reputation of a target or make negative claims about individuals or groups. It discusses the potential limitation of access to rural mortgages without undermining anyone\\'s character or moral stature.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "[\"The input text does not contain any elements that attack the reputation of a target or make negative claims about individuals or groups. It discusses the potential limitation of access to rural mortgages without undermining anyone's character or moral stature.\"]",
         "[None]",
         "[None]",
         "[ True]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/ru/train-ru-part_0007.parquet",
         "[None]",
         "[None]",
         "train",
         "{\"description\": \"The input text does not contain any elements that attack the reputation of a target or make negative claims about individuals or groups. It discusses the potential limitation of access to rural mortgages without undermining anyone's character or moral stature.\", \"verdict\": false}"
        ],
        [
         "229",
         "RU_discrediting_the_west_21.txt",
         "1417",
         "1655",
         "RU",
         "olihull, United Kingdom\nСтоит ли за этим пожаром Россия? Абсолютно во всех бедах, которые случаются с этой страной, виновата Россия, верно? Начиная с резиновых лодок и заканчивая тем, что Стармер стал премьер-министром.\n\n\nlondonvir, Londo",
         "True",
         "['Causal_Oversimplification']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Абсолютно во всех бедах, которые случаются с этой страной, виновата Россия, верно? Начиная с резиновых лодок и заканчивая тем, что Стармер стал премьер-министром']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Questioning_the_Reputation",
         "Questioning_the_Reputation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Questioning the Reputation technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not contain any explicit attacks on the reputation or character of a specific target. Instead, it makes a general statement about blaming Russia for various issues without providing strong negative claims about its moral stature or character. Therefore, the Questioning the Reputation technique is not used.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "['The input text does not contain any explicit attacks on the reputation or character of a specific target. Instead, it makes a general statement about blaming Russia for various issues without providing strong negative claims about its moral stature or character. Therefore, the Questioning the Reputation technique is not used.']",
         "[None]",
         "[None]",
         "[ True]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/ru/train-ru-part_0007.parquet",
         "[None]",
         "[None]",
         "train",
         "{\"description\": \"The input text does not contain any explicit attacks on the reputation or character of a specific target. Instead, it makes a general statement about blaming Russia for various issues without providing strong negative claims about its moral stature or character. Therefore, the Questioning the Reputation technique is not used.\", \"verdict\": false}"
        ],
        [
         "230",
         "RU_discrediting_the_west_7.txt",
         "700",
         "1046",
         "RU",
         "Затем 22 марта был теракт в концертном зале \"Крокус сити холл\", где в результате стрельбы и пожара погибли 144 человека, а пострадало более 500. Терроризм радикального ислама, казалось, был уже забыт в России, но в этот раз без помощи Украины не обошлось. Стоит отметить оперативность турецкой стороны, которая арестовала часть преступной группы.",
         "True",
         "['Guilt_by_Association' 'Appeal_to_Fear-Prejudice']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Затем 22 марта был теракт в концертном зале \"Крокус сити холл\", где в результате стрельбы и пожара погибли 144 человека, а пострадало более 500. Терроризм радикального ислама, казалось, был уже забыт в России, но в этот раз без помощи Украины не обошлось']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Терроризм радикального ислама, казалось, был уже забыт в России, но в этот раз без помощи Украины не обошлось']",
         "train",
         "GPT_41/v001/Questioning_the_Reputation",
         "Questioning_the_Reputation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Questioning the Reputation technique is not used in the input.",
         "\"\"",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[ True]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/ru/train-ru-part_0007.parquet",
         "[{'code': 'content_filter', 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'detected': False, 'filtered': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}, 'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'param': 'prompt', 'status': 400.0, 'type': None}]",
         "['no validation']",
         "train",
         "{\"description\": null, \"verdict\": false}"
        ],
        [
         "231",
         "RU_discrediting_the_west_1.txt",
         "952",
         "1002",
         "RU",
         "Одиноким намного легче манипулировать и управлять.",
         "False",
         "[]",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Questioning_the_Reputation",
         "Questioning_the_Reputation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Questioning the Reputation technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not contain any elements that attack the reputation or moral stature of a target. It simply makes a statement about the ease of manipulation of lonely individuals, which does not align with the definition of Questioning the Reputation.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "['The input text does not contain any elements that attack the reputation or moral stature of a target. It simply makes a statement about the ease of manipulation of lonely individuals, which does not align with the definition of Questioning the Reputation.']",
         "[None]",
         "[None]",
         "[ True]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/ru/train-ru-part_0007.parquet",
         "[None]",
         "[None]",
         "train",
         "{\"description\": \"The input text does not contain any elements that attack the reputation or moral stature of a target. It simply makes a statement about the ease of manipulation of lonely individuals, which does not align with the definition of Questioning the Reputation.\", \"verdict\": false}"
        ],
        [
         "232",
         "RU_Trump_1.txt",
         "1222",
         "1298",
         "RU",
         " на встрече Зеленский в агрессивно-закрытой позе, как неврастеник.\n\nСейчас у",
         "False",
         "[]",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Questioning_the_Reputation",
         "Questioning_the_Reputation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Questioning the Reputation technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not contain any strong negative claims aimed at undermining the character or moral stature of the target. The description of Zelensky\\'s posture does not constitute an attack on his reputation, as it does not focus on his overall moral qualities or behavior.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "[\"The input text does not contain any strong negative claims aimed at undermining the character or moral stature of the target. The description of Zelensky's posture does not constitute an attack on his reputation, as it does not focus on his overall moral qualities or behavior.\"]",
         "[None]",
         "[None]",
         "[ True]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/ru/train-ru-part_0007.parquet",
         "[None]",
         "[None]",
         "train",
         "{\"description\": \"The input text does not contain any strong negative claims aimed at undermining the character or moral stature of the target. The description of Zelensky's posture does not constitute an attack on his reputation, as it does not focus on his overall moral qualities or behavior.\", \"verdict\": false}"
        ],
        [
         "233",
         "RU_discrediting_the_west_3.txt",
         "1162",
         "1376",
         "RU",
         "4. Культура и традиции.\nРазрушается институт семьи. Крупнейшие украинские компании и официальные государственные ресурсы активно участвуют в так называемом «месяце прайда»: «украшают» свои страницы ЛГБТ-символикой.",
         "True",
         "['Appeal_to_Values']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Культура и традиции. Разрушается институт семьи. Крупнейшие украинские компании и официальные государственные ресурсы активно участвуют в так называемом «месяце прайда»: «украшают» свои страницы ЛГБТ-символикой']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Questioning_the_Reputation",
         "Questioning_the_Reputation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Questioning the Reputation technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text discusses the involvement of Ukrainian companies and state resources in LGBTQ+ events without making strong negative claims about their character or moral stature. It does not attack the reputation of any specific target, which aligns with the expert\\'s verdict that the Questioning the Reputation technique is not used.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "[\"The input text discusses the involvement of Ukrainian companies and state resources in LGBTQ+ events without making strong negative claims about their character or moral stature. It does not attack the reputation of any specific target, which aligns with the expert's verdict that the Questioning the Reputation technique is not used.\"]",
         "[None]",
         "[None]",
         "[ True]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/ru/train-ru-part_0007.parquet",
         "[None]",
         "[None]",
         "train",
         "{\"description\": \"The input text discusses the involvement of Ukrainian companies and state resources in LGBTQ+ events without making strong negative claims about their character or moral stature. It does not attack the reputation of any specific target, which aligns with the expert's verdict that the Questioning the Reputation technique is not used.\", \"verdict\": false}"
        ],
        [
         "234",
         "RU_URW_2.txt",
         "724",
         "855",
         "RU",
         "Православная церковь всегда вместе с русским воинством стояла на страже нашего государства и на защите народа от иноземных нападок.",
         "False",
         "[]",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Questioning_the_Reputation",
         "Questioning_the_Reputation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Questioning the Reputation technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not contain any elements that attack or undermine the reputation of a target. It instead presents a positive statement about the Orthodox Church\\'s role in protecting the state and the people, which does not align with the definition of Questioning the Reputation.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "[\"The input text does not contain any elements that attack or undermine the reputation of a target. It instead presents a positive statement about the Orthodox Church's role in protecting the state and the people, which does not align with the definition of Questioning the Reputation.\"]",
         "[None]",
         "[None]",
         "[ True]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/ru/train-ru-part_0007.parquet",
         "[None]",
         "[None]",
         "train",
         "{\"description\": \"The input text does not contain any elements that attack or undermine the reputation of a target. It instead presents a positive statement about the Orthodox Church's role in protecting the state and the people, which does not align with the definition of Questioning the Reputation.\", \"verdict\": false}"
        ],
        [
         "235",
         "RU_Trump_1.txt",
         "95",
         "309",
         "RU",
         "Трамп, конечно, король сейчас. Он разыграл партию так, что любое решение Зеленского будет выгодно США. Война дальше - продолжение ослабления России. Прекращение войны - экономический захват Украины. Везде профит.\n\n",
         "True",
         "['Causal_Oversimplification' 'Loaded_Language']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "['А Трамп, конечно, король сейчас']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Война дальше - продолжение ослабления России. Прекращение войны - экономический захват Украины. Везде профит']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Questioning_the_Reputation",
         "Questioning_the_Reputation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Questioning the Reputation technique is not used in the input.",
         "\"\"",
         "['{\\n  \"explanation\": \"The input text does not contain any strong negative claims aimed at undermining the character or moral stature of a specific target. Instead, it discusses political strategies and outcomes without attacking anyone\\'s reputation.\",\\n  \"updated_definition\": \"\"\\n}']",
         "['']",
         "[None]",
         "[None]",
         "[\"The input text does not contain any strong negative claims aimed at undermining the character or moral stature of a specific target. Instead, it discusses political strategies and outcomes without attacking anyone's reputation.\"]",
         "[None]",
         "[None]",
         "[ True]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/ru/train-ru-part_0007.parquet",
         "[None]",
         "[None]",
         "train",
         "{\"description\": \"The input text does not contain any strong negative claims aimed at undermining the character or moral stature of a specific target. Instead, it discusses political strategies and outcomes without attacking anyone's reputation.\", \"verdict\": false}"
        ]
       ],
       "shape": {
        "columns": 60,
        "rows": 190
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>text_lang</th>\n",
       "      <th>text</th>\n",
       "      <th>label_bin</th>\n",
       "      <th>label_multi</th>\n",
       "      <th>base_split</th>\n",
       "      <th>Questioning_the_Reputation</th>\n",
       "      <th>Name_Calling-Labeling</th>\n",
       "      <th>...</th>\n",
       "      <th>extra_content</th>\n",
       "      <th>explanation</th>\n",
       "      <th>illegal_value</th>\n",
       "      <th>think_content</th>\n",
       "      <th>is_valid</th>\n",
       "      <th>source_file</th>\n",
       "      <th>error</th>\n",
       "      <th>status</th>\n",
       "      <th>split</th>\n",
       "      <th>expected_output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>pl_abortion_11_04_2024_n08.txt</td>\n",
       "      <td>150</td>\n",
       "      <td>288</td>\n",
       "      <td>PL</td>\n",
       "      <td>Wicemarszałek Monika Wielichowska:\\nSam pan wy...</td>\n",
       "      <td>True</td>\n",
       "      <td>[Questioning_the_Reputation]</td>\n",
       "      <td>train</td>\n",
       "      <td>[Sam pan wywołał reakcję pań, które znajdują s...</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[The input text does not contain any elements ...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[True]</td>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41/v001...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>train</td>\n",
       "      <td>{\"description\": \"The input text does not conta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>pl_abortion_11_04_2024_n04.txt</td>\n",
       "      <td>1320</td>\n",
       "      <td>1701</td>\n",
       "      <td>PL</td>\n",
       "      <td>Zakaz aborcji w Polsce nie działa i wiedzą o t...</td>\n",
       "      <td>True</td>\n",
       "      <td>[Conversation_Killer, Appeal_to_Pity, Repetition]</td>\n",
       "      <td>train</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[The input text does not contain any elements ...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[True]</td>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41/v001...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>train</td>\n",
       "      <td>{\"description\": \"The input text does not conta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>pl_defence_22_05_2024_n01.txt</td>\n",
       "      <td>8339</td>\n",
       "      <td>10002</td>\n",
       "      <td>PL</td>\n",
       "      <td>Proszę państwa, jeśli chodzi o te zakupy, to o...</td>\n",
       "      <td>True</td>\n",
       "      <td>[Loaded_Language, Flag_Waving, Obfuscation-Vag...</td>\n",
       "      <td>train</td>\n",
       "      <td>[]</td>\n",
       "      <td>[postsowiecki]</td>\n",
       "      <td>...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[The input text does not contain any instances...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[True]</td>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41/v001...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>train</td>\n",
       "      <td>{\"description\": \"The input text does not conta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>pl_abortion_11_04_2024_n03.txt</td>\n",
       "      <td>1839</td>\n",
       "      <td>2256</td>\n",
       "      <td>PL</td>\n",
       "      <td>Mam dzisiaj zaszczyt i przyjemność jako posłan...</td>\n",
       "      <td>True</td>\n",
       "      <td>[Appeal_to_Time, Appeal_to_Pity, Appeal_to_Val...</td>\n",
       "      <td>train</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[The input text does not contain any elements ...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[True]</td>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41/v001...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>train</td>\n",
       "      <td>{\"description\": \"The input text does not conta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>pl_current_affairs_09_01_2025_n01.txt</td>\n",
       "      <td>1187</td>\n",
       "      <td>2227</td>\n",
       "      <td>PL</td>\n",
       "      <td>Poseł Maria Koc:\\nDziękuję, panie marszałku.\\n...</td>\n",
       "      <td>True</td>\n",
       "      <td>[Doubt]</td>\n",
       "      <td>train</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[The input text does not contain any elements ...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[True]</td>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41/v001...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>train</td>\n",
       "      <td>{\"description\": \"The input text does not conta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>929</th>\n",
       "      <td>20240704_URW_BG_26.txt</td>\n",
       "      <td>6397</td>\n",
       "      <td>6449</td>\n",
       "      <td>BG</td>\n",
       "      <td>ажаеми господин Министър-председател, господин...</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>train</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[The input text does not contain any elements ...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[True]</td>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41/v001...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>train</td>\n",
       "      <td>{\"description\": \"The input text does not conta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>930</th>\n",
       "      <td>20240704_URW_BG_26.txt</td>\n",
       "      <td>2223</td>\n",
       "      <td>2390</td>\n",
       "      <td>BG</td>\n",
       "      <td>о искам да задам, пък вече Вие ще прецените да...</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>train</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[The input text does not contain any elements ...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[True]</td>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41/v001...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>train</td>\n",
       "      <td>{\"description\": \"The input text does not conta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>931</th>\n",
       "      <td>20240704_URW_BG_29.txt</td>\n",
       "      <td>2821</td>\n",
       "      <td>3126</td>\n",
       "      <td>BG</td>\n",
       "      <td>о държавни и правителствени ръководители на НА...</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>train</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[The input text does not contain any elements ...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[True]</td>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41/v001...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>train</td>\n",
       "      <td>{\"description\": \"The input text does not conta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>932</th>\n",
       "      <td>20231208_URW_BG_76.txt</td>\n",
       "      <td>5170</td>\n",
       "      <td>5523</td>\n",
       "      <td>BG</td>\n",
       "      <td>Това, което всъщност в момента даваме тук, е р...</td>\n",
       "      <td>True</td>\n",
       "      <td>[Consequential_Oversimplification, Loaded_Lang...</td>\n",
       "      <td>train</td>\n",
       "      <td>[след престъпниците, които управляват Армията ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[True]</td>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41/v001...</td>\n",
       "      <td>[{'code': 'content_filter', 'innererror': {'co...</td>\n",
       "      <td>[no validation]</td>\n",
       "      <td>train</td>\n",
       "      <td>{\"description\": null, \"verdict\": false}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>933</th>\n",
       "      <td>20240704_URW_BG_26.txt</td>\n",
       "      <td>259</td>\n",
       "      <td>314</td>\n",
       "      <td>BG</td>\n",
       "      <td>ТЕЛ РАЯ НАЗАРЯН: Заповядайте, госпожо Василева...</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>train</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[The input text does not contain any elements ...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[True]</td>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41/v001...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>train</td>\n",
       "      <td>{\"description\": \"The input text does not conta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>190 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  filename  start    end text_lang  \\\n",
       "30          pl_abortion_11_04_2024_n08.txt    150    288        PL   \n",
       "31          pl_abortion_11_04_2024_n04.txt   1320   1701        PL   \n",
       "32           pl_defence_22_05_2024_n01.txt   8339  10002        PL   \n",
       "33          pl_abortion_11_04_2024_n03.txt   1839   2256        PL   \n",
       "34   pl_current_affairs_09_01_2025_n01.txt   1187   2227        PL   \n",
       "..                                     ...    ...    ...       ...   \n",
       "929                 20240704_URW_BG_26.txt   6397   6449        BG   \n",
       "930                 20240704_URW_BG_26.txt   2223   2390        BG   \n",
       "931                 20240704_URW_BG_29.txt   2821   3126        BG   \n",
       "932                 20231208_URW_BG_76.txt   5170   5523        BG   \n",
       "933                 20240704_URW_BG_26.txt    259    314        BG   \n",
       "\n",
       "                                                  text  label_bin  \\\n",
       "30   Wicemarszałek Monika Wielichowska:\\nSam pan wy...       True   \n",
       "31   Zakaz aborcji w Polsce nie działa i wiedzą o t...       True   \n",
       "32   Proszę państwa, jeśli chodzi o te zakupy, to o...       True   \n",
       "33   Mam dzisiaj zaszczyt i przyjemność jako posłan...       True   \n",
       "34   Poseł Maria Koc:\\nDziękuję, panie marszałku.\\n...       True   \n",
       "..                                                 ...        ...   \n",
       "929  ажаеми господин Министър-председател, господин...      False   \n",
       "930  о искам да задам, пък вече Вие ще прецените да...      False   \n",
       "931  о държавни и правителствени ръководители на НА...      False   \n",
       "932  Това, което всъщност в момента даваме тук, е р...       True   \n",
       "933  ТЕЛ РАЯ НАЗАРЯН: Заповядайте, госпожо Василева...      False   \n",
       "\n",
       "                                           label_multi base_split  \\\n",
       "30                        [Questioning_the_Reputation]      train   \n",
       "31   [Conversation_Killer, Appeal_to_Pity, Repetition]      train   \n",
       "32   [Loaded_Language, Flag_Waving, Obfuscation-Vag...      train   \n",
       "33   [Appeal_to_Time, Appeal_to_Pity, Appeal_to_Val...      train   \n",
       "34                                             [Doubt]      train   \n",
       "..                                                 ...        ...   \n",
       "929                                                 []      train   \n",
       "930                                                 []      train   \n",
       "931                                                 []      train   \n",
       "932  [Consequential_Oversimplification, Loaded_Lang...      train   \n",
       "933                                                 []      train   \n",
       "\n",
       "                            Questioning_the_Reputation Name_Calling-Labeling  \\\n",
       "30   [Sam pan wywołał reakcję pań, które znajdują s...                    []   \n",
       "31                                                  []                    []   \n",
       "32                                                  []        [postsowiecki]   \n",
       "33                                                  []                    []   \n",
       "34                                                  []                    []   \n",
       "..                                                 ...                   ...   \n",
       "929                                                 []                    []   \n",
       "930                                                 []                    []   \n",
       "931                                                 []                    []   \n",
       "932  [след престъпниците, които управляват Армията ...                    []   \n",
       "933                                                 []                    []   \n",
       "\n",
       "     ... extra_content                                        explanation  \\\n",
       "30   ...        [None]  [The input text does not contain any elements ...   \n",
       "31   ...        [None]  [The input text does not contain any elements ...   \n",
       "32   ...        [None]  [The input text does not contain any instances...   \n",
       "33   ...        [None]  [The input text does not contain any elements ...   \n",
       "34   ...        [None]  [The input text does not contain any elements ...   \n",
       "..   ...           ...                                                ...   \n",
       "929  ...        [None]  [The input text does not contain any elements ...   \n",
       "930  ...        [None]  [The input text does not contain any elements ...   \n",
       "931  ...        [None]  [The input text does not contain any elements ...   \n",
       "932  ...        [None]                                             [None]   \n",
       "933  ...        [None]  [The input text does not contain any elements ...   \n",
       "\n",
       "    illegal_value think_content is_valid  \\\n",
       "30         [None]        [None]   [True]   \n",
       "31         [None]        [None]   [True]   \n",
       "32         [None]        [None]   [True]   \n",
       "33         [None]        [None]   [True]   \n",
       "34         [None]        [None]   [True]   \n",
       "..            ...           ...      ...   \n",
       "929        [None]        [None]   [True]   \n",
       "930        [None]        [None]   [True]   \n",
       "931        [None]        [None]   [True]   \n",
       "932        [None]        [None]   [True]   \n",
       "933        [None]        [None]   [True]   \n",
       "\n",
       "                                           source_file  \\\n",
       "30   data/llm_output/persuasion/explain/GPT_41/v001...   \n",
       "31   data/llm_output/persuasion/explain/GPT_41/v001...   \n",
       "32   data/llm_output/persuasion/explain/GPT_41/v001...   \n",
       "33   data/llm_output/persuasion/explain/GPT_41/v001...   \n",
       "34   data/llm_output/persuasion/explain/GPT_41/v001...   \n",
       "..                                                 ...   \n",
       "929  data/llm_output/persuasion/explain/GPT_41/v001...   \n",
       "930  data/llm_output/persuasion/explain/GPT_41/v001...   \n",
       "931  data/llm_output/persuasion/explain/GPT_41/v001...   \n",
       "932  data/llm_output/persuasion/explain/GPT_41/v001...   \n",
       "933  data/llm_output/persuasion/explain/GPT_41/v001...   \n",
       "\n",
       "                                                 error           status  \\\n",
       "30                                              [None]           [None]   \n",
       "31                                              [None]           [None]   \n",
       "32                                              [None]           [None]   \n",
       "33                                              [None]           [None]   \n",
       "34                                              [None]           [None]   \n",
       "..                                                 ...              ...   \n",
       "929                                             [None]           [None]   \n",
       "930                                             [None]           [None]   \n",
       "931                                             [None]           [None]   \n",
       "932  [{'code': 'content_filter', 'innererror': {'co...  [no validation]   \n",
       "933                                             [None]           [None]   \n",
       "\n",
       "     split                                    expected_output  \n",
       "30   train  {\"description\": \"The input text does not conta...  \n",
       "31   train  {\"description\": \"The input text does not conta...  \n",
       "32   train  {\"description\": \"The input text does not conta...  \n",
       "33   train  {\"description\": \"The input text does not conta...  \n",
       "34   train  {\"description\": \"The input text does not conta...  \n",
       "..     ...                                                ...  \n",
       "929  train  {\"description\": \"The input text does not conta...  \n",
       "930  train  {\"description\": \"The input text does not conta...  \n",
       "931  train  {\"description\": \"The input text does not conta...  \n",
       "932  train            {\"description\": null, \"verdict\": false}  \n",
       "933  train  {\"description\": \"The input text does not conta...  \n",
       "\n",
       "[190 rows x 60 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[~df.error.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "32362a41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "filename",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "start",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "end",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "text_lang",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "text",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "label_bin",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "label_multi",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "base_split",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Questioning_the_Reputation",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Name_Calling-Labeling",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Appeal_to_Hypocrisy",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Conversation_Killer",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Loaded_Language",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Repetition",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Appeal_to_Popularity",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Doubt",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Red_Herring",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Flag_Waving",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Exaggeration-Minimisation",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Consequential_Oversimplification",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Appeal_to_Pity",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Appeal_to_Time",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Appeal_to_Values",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Obfuscation-Vagueness-Confusion",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Straw_Man",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Slogans",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Appeal_to_Fear-Prejudice",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Causal_Oversimplification",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Appeal_to_Authority",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "False_Dilemma-No_Choice",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Whataboutism",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "False_Equivalence",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Guilt_by_Association",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "alt_split",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "output_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "prompt_name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "prompt_version",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "job",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "step",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "max_iterations",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "temperature",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "model_provider",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "model_name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "model_mode",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "gold",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "gold_text",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "spans",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "raw",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "updated_definition",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "extra_properties",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "extra_content",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "explanation",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "illegal_value",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "think_content",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "is_valid",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "source_file",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "error",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "status",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "split",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "expected_output",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "b5cdf0fd-5c89-421b-8b00-e21dfed7664a",
       "rows": [
        [
         "38",
         "pl_abortion_11_04_2024_n08.txt",
         "290",
         "1251",
         "PL",
         "Poseł Roman Fritz:\nGrupa feministek pomagająca mordować\nnienarodzone dzieci, Aborcyjny Dream Team, pochwaliła\nsię mniej więcej 2 lata temu, że pomogła zabić\ndziecko gotowe do porodu. Jego matka była w 37. tygodniu\nciąży. Feministki przyznają, że pomaganie w\naborcjach jest ich życiową pasją i misją, a za cel obrały\nsobie promowanie pozytywnego przekazu\ndotyczącego aborcji. Za pośrednictwem mediów\nspołecznościowych co jakiś czas Aborcyjny Dream Team chwali się\nswoimi morderczymi osiągnięciami. Uruchomiona\nprzez nich infolinia umożliwia konsultacje aborcyjne\ni zamawianie tabletek poronnych oraz umawianie\nwyjazdów na zabicie dziecka za granicami Polski.\nAborcjonistki przyznały również, że preferowaną metodą\nzabicia dziecka w tak zaawansowanym stadium\nrozwoju jest rozszerzenie szyjki macicy umożliwiające\nwydobycie go narzędziami, a wcześniej podanie\nbezbronnemu dziecku morderczego zastrzyku, który\nzatrzymuje akcję serca.\n(Poseł Krzysztof Bosak: Hańba!)",
         "True",
         "['Loaded_Language' 'Slogans' 'Questioning_the_Reputation'\n 'Name_Calling-Labeling' 'Appeal_to_Fear-Prejudice']",
         "train",
         "['Grupa feministek pomagająca mordować nienarodzone dzieci, Aborcyjny Dream Team, pochwaliła się mniej więcej 2 lata temu, że pomogła zabić dziecko gotowe do porodu'\n 'Feministki przyznają, że pomaganie w aborcjach jest ich życiową pasją i misją, a za cel obrały sobie promowanie pozytywnego przekazu dotyczącego aborcji'\n 'Aborcyjny Dream Team chwali się swoimi morderczymi osiągnięciami']",
         "['Aborcyjny Dream Team' 'Aborcyjny Dream Team' 'morderczymi']",
         "[]",
         "[]",
         "['pomagająca mordować nienarodzone dzieci' 'pomogła zabić dziecko'\n 'jest ich życiową pasją i misją' 'zabicie dziecka' 'zabicia'\n 'morderczego']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Hańba!)']",
         "['preferowaną metodą zabicia dziecka w tak zaawansowanym stadium rozwoju jest rozszerzenie szyjki macicy umożliwiające wydobycie go narzędziami, a wcześniej podanie bezbronnemu dziecku morderczego zastrzyku, który zatrzymuje akcję serca']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Hypocrisy",
         "Appeal_to_Hypocrisy",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Appeal to Hypocrisy technique is not used in the input.",
         "\"\"",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[ True]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/pl/train-pl-part_0002.parquet",
         "[{'code': 'content_filter', 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': True, 'severity': 'high'}, 'jailbreak': {'detected': False, 'filtered': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}, 'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'param': 'prompt', 'status': 400.0, 'type': None}]",
         "['no validation']",
         "train",
         "{\"description\": null, \"verdict\": false}"
        ],
        [
         "134",
         "RU_discrediting_the_west_7.txt",
         "700",
         "1046",
         "RU",
         "Затем 22 марта был теракт в концертном зале \"Крокус сити холл\", где в результате стрельбы и пожара погибли 144 человека, а пострадало более 500. Терроризм радикального ислама, казалось, был уже забыт в России, но в этот раз без помощи Украины не обошлось. Стоит отметить оперативность турецкой стороны, которая арестовала часть преступной группы.",
         "True",
         "['Guilt_by_Association' 'Appeal_to_Fear-Prejudice']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Затем 22 марта был теракт в концертном зале \"Крокус сити холл\", где в результате стрельбы и пожара погибли 144 человека, а пострадало более 500. Терроризм радикального ислама, казалось, был уже забыт в России, но в этот раз без помощи Украины не обошлось']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Терроризм радикального ислама, казалось, был уже забыт в России, но в этот раз без помощи Украины не обошлось']",
         "train",
         "GPT_41/v001/Appeal_to_Hypocrisy",
         "Appeal_to_Hypocrisy",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Appeal to Hypocrisy technique is not used in the input.",
         "\"\"",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[ True]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/ru/train-ru-part_0007.parquet",
         "[{'code': 'content_filter', 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'detected': False, 'filtered': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}, 'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'param': 'prompt', 'status': 400.0, 'type': None}]",
         "['no validation']",
         "train",
         "{\"description\": null, \"verdict\": false}"
        ],
        [
         "198",
         "20231208_URW_BG_75.txt",
         "5280",
         "5654",
         "BG",
         "Така че не е непредизвикана агресията, убити са хиляди хора. Лошото е, че сега ние се приближаваме – само тук по този въпрос бяхте прав, тъй като привършва живият материал от наши събратя и от двете страни – над 500 хиляди ковчега, има нови ковчези, които трябва да бъдат пълнени. С кого? Новите еничари ще закарат и българите там, след като оголваме цялата Българска армия.",
         "True",
         "['Loaded_Language' 'Appeal_to_Pity' 'Name_Calling-Labeling'\n 'Appeal_to_Fear-Prejudice']",
         "train",
         "[]",
         "['Новите еничари']",
         "[]",
         "[]",
         "['ковчега, има нови ковчези, които трябва да бъдат пълнени']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Така че не е непредизвикана агресията, убити са хиляди хора']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Лошото е, че сега ние се приближаваме – само тук по този въпрос бяхте прав, тъй като привършва живият материал от наши събратя и от двете страни – над 500 хиляди ковчега, има нови ковчези, които трябва да бъдат пълнени'\n 'Новите еничари ще закарат и българите там, след като оголваме цялата Българска армия']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Appeal_to_Hypocrisy",
         "Appeal_to_Hypocrisy",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Appeal to Hypocrisy technique is not used in the input.",
         "\"\"",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[ True]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/bg/train-bg-part_0004.parquet",
         "[{'code': 'content_filter', 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'detected': False, 'filtered': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}, 'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'param': 'prompt', 'status': 400.0, 'type': None}]",
         "['no validation']",
         "train",
         "{\"description\": null, \"verdict\": false}"
        ],
        [
         "219",
         "RU_demography_1.txt",
         "1283",
         "1609",
         "RU",
         "Русские, как народ, нация, культура, могут исчезнуть. Если русские утратят волю к жизни, инстинкт самосохранения и продолжения рода, так и будет. И случится всё вполне в течение текущего столетия. Во второй его половине. Просто в силу сокращения, размывания новых поколений русских, их вытеснения и замещения другими народами.",
         "True",
         "['Appeal_to_Fear-Prejudice']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Русские, как народ, нация, культура, могут исчезнуть. Если русские утратят волю к жизни, инстинкт самосохранения и продолжения рода, так и будет']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Questioning_the_Reputation",
         "Questioning_the_Reputation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Questioning the Reputation technique is not used in the input.",
         "\"\"",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[ True]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/ru/train-ru-part_0000.parquet",
         "[{'code': 'content_filter', 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': True, 'severity': 'medium'}, 'jailbreak': {'detected': False, 'filtered': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}, 'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'param': 'prompt', 'status': 400.0, 'type': None}]",
         "['no validation']",
         "train",
         "{\"description\": null, \"verdict\": false}"
        ],
        [
         "230",
         "RU_discrediting_the_west_7.txt",
         "700",
         "1046",
         "RU",
         "Затем 22 марта был теракт в концертном зале \"Крокус сити холл\", где в результате стрельбы и пожара погибли 144 человека, а пострадало более 500. Терроризм радикального ислама, казалось, был уже забыт в России, но в этот раз без помощи Украины не обошлось. Стоит отметить оперативность турецкой стороны, которая арестовала часть преступной группы.",
         "True",
         "['Guilt_by_Association' 'Appeal_to_Fear-Prejudice']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Затем 22 марта был теракт в концертном зале \"Крокус сити холл\", где в результате стрельбы и пожара погибли 144 человека, а пострадало более 500. Терроризм радикального ислама, казалось, был уже забыт в России, но в этот раз без помощи Украины не обошлось']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Терроризм радикального ислама, казалось, был уже забыт в России, но в этот раз без помощи Украины не обошлось']",
         "train",
         "GPT_41/v001/Questioning_the_Reputation",
         "Questioning_the_Reputation",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Questioning the Reputation technique is not used in the input.",
         "\"\"",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[ True]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/ru/train-ru-part_0007.parquet",
         "[{'code': 'content_filter', 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'detected': False, 'filtered': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}, 'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'param': 'prompt', 'status': 400.0, 'type': None}]",
         "['no validation']",
         "train",
         "{\"description\": null, \"verdict\": false}"
        ],
        [
         "274",
         "pl_abortion_11_04_2024_n08.txt",
         "290",
         "1251",
         "PL",
         "Poseł Roman Fritz:\nGrupa feministek pomagająca mordować\nnienarodzone dzieci, Aborcyjny Dream Team, pochwaliła\nsię mniej więcej 2 lata temu, że pomogła zabić\ndziecko gotowe do porodu. Jego matka była w 37. tygodniu\nciąży. Feministki przyznają, że pomaganie w\naborcjach jest ich życiową pasją i misją, a za cel obrały\nsobie promowanie pozytywnego przekazu\ndotyczącego aborcji. Za pośrednictwem mediów\nspołecznościowych co jakiś czas Aborcyjny Dream Team chwali się\nswoimi morderczymi osiągnięciami. Uruchomiona\nprzez nich infolinia umożliwia konsultacje aborcyjne\ni zamawianie tabletek poronnych oraz umawianie\nwyjazdów na zabicie dziecka za granicami Polski.\nAborcjonistki przyznały również, że preferowaną metodą\nzabicia dziecka w tak zaawansowanym stadium\nrozwoju jest rozszerzenie szyjki macicy umożliwiające\nwydobycie go narzędziami, a wcześniej podanie\nbezbronnemu dziecku morderczego zastrzyku, który\nzatrzymuje akcję serca.\n(Poseł Krzysztof Bosak: Hańba!)",
         "True",
         "['Loaded_Language' 'Slogans' 'Questioning_the_Reputation'\n 'Name_Calling-Labeling' 'Appeal_to_Fear-Prejudice']",
         "train",
         "['Grupa feministek pomagająca mordować nienarodzone dzieci, Aborcyjny Dream Team, pochwaliła się mniej więcej 2 lata temu, że pomogła zabić dziecko gotowe do porodu'\n 'Feministki przyznają, że pomaganie w aborcjach jest ich życiową pasją i misją, a za cel obrały sobie promowanie pozytywnego przekazu dotyczącego aborcji'\n 'Aborcyjny Dream Team chwali się swoimi morderczymi osiągnięciami']",
         "['Aborcyjny Dream Team' 'Aborcyjny Dream Team' 'morderczymi']",
         "[]",
         "[]",
         "['pomagająca mordować nienarodzone dzieci' 'pomogła zabić dziecko'\n 'jest ich życiową pasją i misją' 'zabicie dziecka' 'zabicia'\n 'morderczego']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Hańba!)']",
         "['preferowaną metodą zabicia dziecka w tak zaawansowanym stadium rozwoju jest rozszerzenie szyjki macicy umożliwiające wydobycie go narzędziami, a wcześniej podanie bezbronnemu dziecku morderczego zastrzyku, który zatrzymuje akcję serca']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Guilt_by_Association",
         "Guilt_by_Association",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Guilt by Association technique is not used in the input.",
         "\"\"",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[ True]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Guilt_by_Association/train/pl/train-pl-part_0002.parquet",
         "[{'code': 'content_filter', 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': True, 'severity': 'high'}, 'jailbreak': {'detected': False, 'filtered': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}, 'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'param': 'prompt', 'status': 400.0, 'type': None}]",
         "['no validation']",
         "train",
         "{\"description\": null, \"verdict\": false}"
        ],
        [
         "369",
         "RU_demography_1.txt",
         "1283",
         "1609",
         "RU",
         "Русские, как народ, нация, культура, могут исчезнуть. Если русские утратят волю к жизни, инстинкт самосохранения и продолжения рода, так и будет. И случится всё вполне в течение текущего столетия. Во второй его половине. Просто в силу сокращения, размывания новых поколений русских, их вытеснения и замещения другими народами.",
         "True",
         "['Appeal_to_Fear-Prejudice']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Русские, как народ, нация, культура, могут исчезнуть. Если русские утратят волю к жизни, инстинкт самосохранения и продолжения рода, так и будет']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Guilt_by_Association",
         "Guilt_by_Association",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Guilt by Association technique is not used in the input.",
         "\"\"",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[ True]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Guilt_by_Association/train/ru/train-ru-part_0000.parquet",
         "[{'code': 'content_filter', 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': True, 'severity': 'medium'}, 'jailbreak': {'detected': False, 'filtered': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}, 'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'param': 'prompt', 'status': 400.0, 'type': None}]",
         "['no validation']",
         "train",
         "{\"description\": null, \"verdict\": false}"
        ],
        [
         "470",
         "20231208_URW_BG_76.txt",
         "5170",
         "5523",
         "BG",
         "Това, което всъщност в момента даваме тук, е разрешение да унищожим Българската армия, да изпразним складовете, да оголим българския резерв, ако въобще такъв е останал след престъпниците, които управляват Армията и управляват Министерството на отбраната най-вече, защото в Армията все пак, за разлика от Министерството на отбраната, има професионалисти.",
         "True",
         "['Consequential_Oversimplification' 'Loaded_Language'\n 'Questioning_the_Reputation' 'Straw_Man']",
         "train",
         "['след престъпниците, които управляват Армията и управляват Министерството на отбраната най-вече, защото в Армията все пак, за разлика от Министерството на отбраната, има професионалисти']",
         "[]",
         "[]",
         "[]",
         "['унищожим']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Това, което всъщност в момента даваме тук, е разрешение да унищожим Българската армия, да изпразним складовете, да оголим българския резерв']",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Това, което всъщност в момента даваме тук, е разрешение да унищожим Българската армия, да изпразним складовете, да оголим българския резерв, ако въобще такъв е останал след престъпниците, които управляват Армията и управляват Министерството на отбраната най-вече, защото в Армията все пак, за разлика от Министерството на отбраната, има професионалисти']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Guilt_by_Association",
         "Guilt_by_Association",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Guilt by Association technique is not used in the input.",
         "\"\"",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[ True]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Guilt_by_Association/train/bg/train-bg-part_0009.parquet",
         "[{'code': 'content_filter', 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'low'}, 'jailbreak': {'detected': False, 'filtered': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}, 'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'param': 'prompt', 'status': 400.0, 'type': None}]",
         "['no validation']",
         "train",
         "{\"description\": null, \"verdict\": false}"
        ],
        [
         "570",
         "pl_abortion_11_04_2024_n08.txt",
         "290",
         "1251",
         "PL",
         "Poseł Roman Fritz:\nGrupa feministek pomagająca mordować\nnienarodzone dzieci, Aborcyjny Dream Team, pochwaliła\nsię mniej więcej 2 lata temu, że pomogła zabić\ndziecko gotowe do porodu. Jego matka była w 37. tygodniu\nciąży. Feministki przyznają, że pomaganie w\naborcjach jest ich życiową pasją i misją, a za cel obrały\nsobie promowanie pozytywnego przekazu\ndotyczącego aborcji. Za pośrednictwem mediów\nspołecznościowych co jakiś czas Aborcyjny Dream Team chwali się\nswoimi morderczymi osiągnięciami. Uruchomiona\nprzez nich infolinia umożliwia konsultacje aborcyjne\ni zamawianie tabletek poronnych oraz umawianie\nwyjazdów na zabicie dziecka za granicami Polski.\nAborcjonistki przyznały również, że preferowaną metodą\nzabicia dziecka w tak zaawansowanym stadium\nrozwoju jest rozszerzenie szyjki macicy umożliwiające\nwydobycie go narzędziami, a wcześniej podanie\nbezbronnemu dziecku morderczego zastrzyku, który\nzatrzymuje akcję serca.\n(Poseł Krzysztof Bosak: Hańba!)",
         "True",
         "['Loaded_Language' 'Slogans' 'Questioning_the_Reputation'\n 'Name_Calling-Labeling' 'Appeal_to_Fear-Prejudice']",
         "train",
         "['Grupa feministek pomagająca mordować nienarodzone dzieci, Aborcyjny Dream Team, pochwaliła się mniej więcej 2 lata temu, że pomogła zabić dziecko gotowe do porodu'\n 'Feministki przyznają, że pomaganie w aborcjach jest ich życiową pasją i misją, a za cel obrały sobie promowanie pozytywnego przekazu dotyczącego aborcji'\n 'Aborcyjny Dream Team chwali się swoimi morderczymi osiągnięciami']",
         "['Aborcyjny Dream Team' 'Aborcyjny Dream Team' 'morderczymi']",
         "[]",
         "[]",
         "['pomagająca mordować nienarodzone dzieci' 'pomogła zabić dziecko'\n 'jest ich życiową pasją i misją' 'zabicie dziecka' 'zabicia'\n 'morderczego']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Hańba!)']",
         "['preferowaną metodą zabicia dziecka w tak zaawansowanym stadium rozwoju jest rozszerzenie szyjki macicy umożliwiające wydobycie go narzędziami, a wcześniej podanie bezbronnemu dziecku morderczego zastrzyku, który zatrzymuje akcję serca']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Name_Calling-Labeling",
         "Name_Calling-Labeling",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "1",
         "Yes, the Name Calling-Labeling technique is used in the input.",
         "\"Aborcyjny Dream Team Aborcyjny Dream Team morderczymi\"",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[ True]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Name_Calling-Labeling/train/pl/train-pl-part_0002.parquet",
         "[{'code': 'content_filter', 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': True, 'severity': 'high'}, 'jailbreak': {'detected': False, 'filtered': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}, 'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'param': 'prompt', 'status': 400.0, 'type': None}]",
         "['no validation']",
         "train",
         "{\"description\": null, \"verdict\": true}"
        ],
        [
         "625",
         "RU_demography_1.txt",
         "1283",
         "1609",
         "RU",
         "Русские, как народ, нация, культура, могут исчезнуть. Если русские утратят волю к жизни, инстинкт самосохранения и продолжения рода, так и будет. И случится всё вполне в течение текущего столетия. Во второй его половине. Просто в силу сокращения, размывания новых поколений русских, их вытеснения и замещения другими народами.",
         "True",
         "['Appeal_to_Fear-Prejudice']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Русские, как народ, нация, культура, могут исчезнуть. Если русские утратят волю к жизни, инстинкт самосохранения и продолжения рода, так и будет']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Name_Calling-Labeling",
         "Name_Calling-Labeling",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Name Calling-Labeling technique is not used in the input.",
         "\"\"",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[ True]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Name_Calling-Labeling/train/ru/train-ru-part_0000.parquet",
         "[{'code': 'content_filter', 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': True, 'severity': 'medium'}, 'jailbreak': {'detected': False, 'filtered': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}, 'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'param': 'prompt', 'status': 400.0, 'type': None}]",
         "['no validation']",
         "train",
         "{\"description\": null, \"verdict\": false}"
        ],
        [
         "634",
         "RU_migrants_5.txt",
         "354",
         "574",
         "RU",
         "йчас Каменск-Уральск во всех сводках новостей. Группа парней похитила двух девушек, привезли их на автомойку избивали, обливали пеной и ледяной водой, унижали. Как я понимаю, жертвы - русские девочки, истязатели - нет.\n\n",
         "True",
         "['Appeal_to_Fear-Prejudice']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Как я понимаю, жертвы - русские девочки, истязатели - нет']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Name_Calling-Labeling",
         "Name_Calling-Labeling",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Name Calling-Labeling technique is not used in the input.",
         "\"\"",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[ True]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Name_Calling-Labeling/train/ru/train-ru-part_0004.parquet",
         "[{'code': 'content_filter', 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'detected': False, 'filtered': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}, 'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'param': 'prompt', 'status': 400.0, 'type': None}]",
         "['no validation']",
         "train",
         "{\"description\": null, \"verdict\": false}"
        ],
        [
         "646",
         "RU_discrediting_the_west_7.txt",
         "700",
         "1046",
         "RU",
         "Затем 22 марта был теракт в концертном зале \"Крокус сити холл\", где в результате стрельбы и пожара погибли 144 человека, а пострадало более 500. Терроризм радикального ислама, казалось, был уже забыт в России, но в этот раз без помощи Украины не обошлось. Стоит отметить оперативность турецкой стороны, которая арестовала часть преступной группы.",
         "True",
         "['Guilt_by_Association' 'Appeal_to_Fear-Prejudice']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Затем 22 марта был теракт в концертном зале \"Крокус сити холл\", где в результате стрельбы и пожара погибли 144 человека, а пострадало более 500. Терроризм радикального ислама, казалось, был уже забыт в России, но в этот раз без помощи Украины не обошлось']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Терроризм радикального ислама, казалось, был уже забыт в России, но в этот раз без помощи Украины не обошлось']",
         "train",
         "GPT_41/v001/Name_Calling-Labeling",
         "Name_Calling-Labeling",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Name Calling-Labeling technique is not used in the input.",
         "\"\"",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[ True]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Name_Calling-Labeling/train/ru/train-ru-part_0007.parquet",
         "[{'code': 'content_filter', 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'detected': False, 'filtered': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}, 'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'param': 'prompt', 'status': 400.0, 'type': None}]",
         "['no validation']",
         "train",
         "{\"description\": null, \"verdict\": false}"
        ],
        [
         "716",
         "20231208_URW_BG_76.txt",
         "5170",
         "5523",
         "BG",
         "Това, което всъщност в момента даваме тук, е разрешение да унищожим Българската армия, да изпразним складовете, да оголим българския резерв, ако въобще такъв е останал след престъпниците, които управляват Армията и управляват Министерството на отбраната най-вече, защото в Армията все пак, за разлика от Министерството на отбраната, има професионалисти.",
         "True",
         "['Consequential_Oversimplification' 'Loaded_Language'\n 'Questioning_the_Reputation' 'Straw_Man']",
         "train",
         "['след престъпниците, които управляват Армията и управляват Министерството на отбраната най-вече, защото в Армията все пак, за разлика от Министерството на отбраната, има професионалисти']",
         "[]",
         "[]",
         "[]",
         "['унищожим']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Това, което всъщност в момента даваме тук, е разрешение да унищожим Българската армия, да изпразним складовете, да оголим българския резерв']",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Това, което всъщност в момента даваме тук, е разрешение да унищожим Българската армия, да изпразним складовете, да оголим българския резерв, ако въобще такъв е останал след престъпниците, които управляват Армията и управляват Министерството на отбраната най-вече, защото в Армията все пак, за разлика от Министерството на отбраната, има професионалисти']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Name_Calling-Labeling",
         "Name_Calling-Labeling",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Name Calling-Labeling technique is not used in the input.",
         "\"\"",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[ True]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Name_Calling-Labeling/train/bg/train-bg-part_0009.parquet",
         "[{'code': 'content_filter', 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'low'}, 'jailbreak': {'detected': False, 'filtered': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}, 'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'param': 'prompt', 'status': 400.0, 'type': None}]",
         "['no validation']",
         "train",
         "{\"description\": null, \"verdict\": false}"
        ],
        [
         "796",
         "pl_abortion_11_04_2024_n08.txt",
         "290",
         "1251",
         "PL",
         "Poseł Roman Fritz:\nGrupa feministek pomagająca mordować\nnienarodzone dzieci, Aborcyjny Dream Team, pochwaliła\nsię mniej więcej 2 lata temu, że pomogła zabić\ndziecko gotowe do porodu. Jego matka była w 37. tygodniu\nciąży. Feministki przyznają, że pomaganie w\naborcjach jest ich życiową pasją i misją, a za cel obrały\nsobie promowanie pozytywnego przekazu\ndotyczącego aborcji. Za pośrednictwem mediów\nspołecznościowych co jakiś czas Aborcyjny Dream Team chwali się\nswoimi morderczymi osiągnięciami. Uruchomiona\nprzez nich infolinia umożliwia konsultacje aborcyjne\ni zamawianie tabletek poronnych oraz umawianie\nwyjazdów na zabicie dziecka za granicami Polski.\nAborcjonistki przyznały również, że preferowaną metodą\nzabicia dziecka w tak zaawansowanym stadium\nrozwoju jest rozszerzenie szyjki macicy umożliwiające\nwydobycie go narzędziami, a wcześniej podanie\nbezbronnemu dziecku morderczego zastrzyku, który\nzatrzymuje akcję serca.\n(Poseł Krzysztof Bosak: Hańba!)",
         "True",
         "['Loaded_Language' 'Slogans' 'Questioning_the_Reputation'\n 'Name_Calling-Labeling' 'Appeal_to_Fear-Prejudice']",
         "train",
         "['Grupa feministek pomagająca mordować nienarodzone dzieci, Aborcyjny Dream Team, pochwaliła się mniej więcej 2 lata temu, że pomogła zabić dziecko gotowe do porodu'\n 'Feministki przyznają, że pomaganie w aborcjach jest ich życiową pasją i misją, a za cel obrały sobie promowanie pozytywnego przekazu dotyczącego aborcji'\n 'Aborcyjny Dream Team chwali się swoimi morderczymi osiągnięciami']",
         "['Aborcyjny Dream Team' 'Aborcyjny Dream Team' 'morderczymi']",
         "[]",
         "[]",
         "['pomagająca mordować nienarodzone dzieci' 'pomogła zabić dziecko'\n 'jest ich życiową pasją i misją' 'zabicie dziecka' 'zabicia'\n 'morderczego']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Hańba!)']",
         "['preferowaną metodą zabicia dziecka w tak zaawansowanym stadium rozwoju jest rozszerzenie szyjki macicy umożliwiające wydobycie go narzędziami, a wcześniej podanie bezbronnemu dziecku morderczego zastrzyku, który zatrzymuje akcję serca']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Doubt",
         "Doubt",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Doubt technique is not used in the input.",
         "\"\"",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[ True]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Doubt/train/pl/train-pl-part_0002.parquet",
         "[{'code': 'content_filter', 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': True, 'severity': 'high'}, 'jailbreak': {'detected': False, 'filtered': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}, 'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'param': 'prompt', 'status': 400.0, 'type': None}]",
         "['no validation']",
         "train",
         "{\"description\": null, \"verdict\": false}"
        ],
        [
         "868",
         "RU_discrediting_the_west_5.txt",
         "949",
         "1079",
         "RU",
         "Не вызывало вопросов у Парижа и открытое поощрение в «Твиттере» русофобии, призывов убивать россиян и «отменять» русскую культуру.",
         "True",
         "['Appeal_to_Hypocrisy']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Doubt",
         "Doubt",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Doubt technique is not used in the input.",
         "\"\"",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[ True]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Doubt/train/ru/train-ru-part_0009.parquet",
         "[{'code': 'content_filter', 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': True, 'severity': 'medium'}, 'jailbreak': {'detected': False, 'filtered': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'low'}}}, 'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'param': 'prompt', 'status': 400.0, 'type': None}]",
         "['no validation']",
         "train",
         "{\"description\": null, \"verdict\": false}"
        ],
        [
         "881",
         "RU_demography_1.txt",
         "1283",
         "1609",
         "RU",
         "Русские, как народ, нация, культура, могут исчезнуть. Если русские утратят волю к жизни, инстинкт самосохранения и продолжения рода, так и будет. И случится всё вполне в течение текущего столетия. Во второй его половине. Просто в силу сокращения, размывания новых поколений русских, их вытеснения и замещения другими народами.",
         "True",
         "['Appeal_to_Fear-Prejudice']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Русские, как народ, нация, культура, могут исчезнуть. Если русские утратят волю к жизни, инстинкт самосохранения и продолжения рода, так и будет']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Doubt",
         "Doubt",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Doubt technique is not used in the input.",
         "\"\"",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[ True]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Doubt/train/ru/train-ru-part_0000.parquet",
         "[{'code': 'content_filter', 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': True, 'severity': 'medium'}, 'jailbreak': {'detected': False, 'filtered': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'low'}}}, 'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'param': 'prompt', 'status': 400.0, 'type': None}]",
         "['no validation']",
         "train",
         "{\"description\": null, \"verdict\": false}"
        ],
        [
         "890",
         "RU_migrants_5.txt",
         "354",
         "574",
         "RU",
         "йчас Каменск-Уральск во всех сводках новостей. Группа парней похитила двух девушек, привезли их на автомойку избивали, обливали пеной и ледяной водой, унижали. Как я понимаю, жертвы - русские девочки, истязатели - нет.\n\n",
         "True",
         "['Appeal_to_Fear-Prejudice']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Как я понимаю, жертвы - русские девочки, истязатели - нет']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Doubt",
         "Doubt",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Doubt technique is not used in the input.",
         "\"\"",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[ True]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Doubt/train/ru/train-ru-part_0004.parquet",
         "[{'code': 'content_filter', 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'detected': False, 'filtered': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}, 'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'param': 'prompt', 'status': 400.0, 'type': None}]",
         "['no validation']",
         "train",
         "{\"description\": null, \"verdict\": false}"
        ],
        [
         "902",
         "RU_discrediting_the_west_7.txt",
         "700",
         "1046",
         "RU",
         "Затем 22 марта был теракт в концертном зале \"Крокус сити холл\", где в результате стрельбы и пожара погибли 144 человека, а пострадало более 500. Терроризм радикального ислама, казалось, был уже забыт в России, но в этот раз без помощи Украины не обошлось. Стоит отметить оперативность турецкой стороны, которая арестовала часть преступной группы.",
         "True",
         "['Guilt_by_Association' 'Appeal_to_Fear-Prejudice']",
         "train",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Затем 22 марта был теракт в концертном зале \"Крокус сити холл\", где в результате стрельбы и пожара погибли 144 человека, а пострадало более 500. Терроризм радикального ислама, казалось, был уже забыт в России, но в этот раз без помощи Украины не обошлось']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Терроризм радикального ислама, казалось, был уже забыт в России, но в этот раз без помощи Украины не обошлось']",
         "train",
         "GPT_41/v001/Doubt",
         "Doubt",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Doubt technique is not used in the input.",
         "\"\"",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[ True]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Doubt/train/ru/train-ru-part_0007.parquet",
         "[{'code': 'content_filter', 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'detected': False, 'filtered': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}, 'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'param': 'prompt', 'status': 400.0, 'type': None}]",
         "['no validation']",
         "train",
         "{\"description\": null, \"verdict\": false}"
        ],
        [
         "932",
         "20231208_URW_BG_76.txt",
         "5170",
         "5523",
         "BG",
         "Това, което всъщност в момента даваме тук, е разрешение да унищожим Българската армия, да изпразним складовете, да оголим българския резерв, ако въобще такъв е останал след престъпниците, които управляват Армията и управляват Министерството на отбраната най-вече, защото в Армията все пак, за разлика от Министерството на отбраната, има професионалисти.",
         "True",
         "['Consequential_Oversimplification' 'Loaded_Language'\n 'Questioning_the_Reputation' 'Straw_Man']",
         "train",
         "['след престъпниците, които управляват Армията и управляват Министерството на отбраната най-вече, защото в Армията все пак, за разлика от Министерството на отбраната, има професионалисти']",
         "[]",
         "[]",
         "[]",
         "['унищожим']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Това, което всъщност в момента даваме тук, е разрешение да унищожим Българската армия, да изпразним складовете, да оголим българския резерв']",
         "[]",
         "[]",
         "[]",
         "[]",
         "['Това, което всъщност в момента даваме тук, е разрешение да унищожим Българската армия, да изпразним складовете, да оголим българския резерв, ако въобще такъв е останал след престъпниците, които управляват Армията и управляват Министерството на отбраната най-вече, защото в Армията все пак, за разлика от Министерството на отбраната, има професионалисти']",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "[]",
         "train",
         "GPT_41/v001/Doubt",
         "Doubt",
         "v001",
         "persuasion",
         "explain",
         "1",
         "0.0",
         "azure_openai",
         "gpt-4.1",
         "chat",
         "0",
         "No, the Doubt technique is not used in the input.",
         "\"\"",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[None]",
         "[ True]",
         "data/llm_output/persuasion/explain/GPT_41/v001/Doubt/train/bg/train-bg-part_0009.parquet",
         "[{'code': 'content_filter', 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'low'}, 'jailbreak': {'detected': False, 'filtered': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}, 'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'param': 'prompt', 'status': 400.0, 'type': None}]",
         "['no validation']",
         "train",
         "{\"description\": null, \"verdict\": false}"
        ]
       ],
       "shape": {
        "columns": 60,
        "rows": 19
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>text_lang</th>\n",
       "      <th>text</th>\n",
       "      <th>label_bin</th>\n",
       "      <th>label_multi</th>\n",
       "      <th>base_split</th>\n",
       "      <th>Questioning_the_Reputation</th>\n",
       "      <th>Name_Calling-Labeling</th>\n",
       "      <th>...</th>\n",
       "      <th>extra_content</th>\n",
       "      <th>explanation</th>\n",
       "      <th>illegal_value</th>\n",
       "      <th>think_content</th>\n",
       "      <th>is_valid</th>\n",
       "      <th>source_file</th>\n",
       "      <th>error</th>\n",
       "      <th>status</th>\n",
       "      <th>split</th>\n",
       "      <th>expected_output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>pl_abortion_11_04_2024_n08.txt</td>\n",
       "      <td>290</td>\n",
       "      <td>1251</td>\n",
       "      <td>PL</td>\n",
       "      <td>Poseł Roman Fritz:\\nGrupa feministek pomagając...</td>\n",
       "      <td>True</td>\n",
       "      <td>[Loaded_Language, Slogans, Questioning_the_Rep...</td>\n",
       "      <td>train</td>\n",
       "      <td>[Grupa feministek pomagająca mordować nienarod...</td>\n",
       "      <td>[Aborcyjny Dream Team, Aborcyjny Dream Team, m...</td>\n",
       "      <td>...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[True]</td>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41/v001...</td>\n",
       "      <td>[{'code': 'content_filter', 'innererror': {'co...</td>\n",
       "      <td>[no validation]</td>\n",
       "      <td>train</td>\n",
       "      <td>{\"description\": null, \"verdict\": false}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>RU_discrediting_the_west_7.txt</td>\n",
       "      <td>700</td>\n",
       "      <td>1046</td>\n",
       "      <td>RU</td>\n",
       "      <td>Затем 22 марта был теракт в концертном зале \"К...</td>\n",
       "      <td>True</td>\n",
       "      <td>[Guilt_by_Association, Appeal_to_Fear-Prejudice]</td>\n",
       "      <td>train</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[True]</td>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41/v001...</td>\n",
       "      <td>[{'code': 'content_filter', 'innererror': {'co...</td>\n",
       "      <td>[no validation]</td>\n",
       "      <td>train</td>\n",
       "      <td>{\"description\": null, \"verdict\": false}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>20231208_URW_BG_75.txt</td>\n",
       "      <td>5280</td>\n",
       "      <td>5654</td>\n",
       "      <td>BG</td>\n",
       "      <td>Така че не е непредизвикана агресията, убити с...</td>\n",
       "      <td>True</td>\n",
       "      <td>[Loaded_Language, Appeal_to_Pity, Name_Calling...</td>\n",
       "      <td>train</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Новите еничари]</td>\n",
       "      <td>...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[True]</td>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41/v001...</td>\n",
       "      <td>[{'code': 'content_filter', 'innererror': {'co...</td>\n",
       "      <td>[no validation]</td>\n",
       "      <td>train</td>\n",
       "      <td>{\"description\": null, \"verdict\": false}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>RU_demography_1.txt</td>\n",
       "      <td>1283</td>\n",
       "      <td>1609</td>\n",
       "      <td>RU</td>\n",
       "      <td>Русские, как народ, нация, культура, могут исч...</td>\n",
       "      <td>True</td>\n",
       "      <td>[Appeal_to_Fear-Prejudice]</td>\n",
       "      <td>train</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[True]</td>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41/v001...</td>\n",
       "      <td>[{'code': 'content_filter', 'innererror': {'co...</td>\n",
       "      <td>[no validation]</td>\n",
       "      <td>train</td>\n",
       "      <td>{\"description\": null, \"verdict\": false}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>RU_discrediting_the_west_7.txt</td>\n",
       "      <td>700</td>\n",
       "      <td>1046</td>\n",
       "      <td>RU</td>\n",
       "      <td>Затем 22 марта был теракт в концертном зале \"К...</td>\n",
       "      <td>True</td>\n",
       "      <td>[Guilt_by_Association, Appeal_to_Fear-Prejudice]</td>\n",
       "      <td>train</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[True]</td>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41/v001...</td>\n",
       "      <td>[{'code': 'content_filter', 'innererror': {'co...</td>\n",
       "      <td>[no validation]</td>\n",
       "      <td>train</td>\n",
       "      <td>{\"description\": null, \"verdict\": false}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>pl_abortion_11_04_2024_n08.txt</td>\n",
       "      <td>290</td>\n",
       "      <td>1251</td>\n",
       "      <td>PL</td>\n",
       "      <td>Poseł Roman Fritz:\\nGrupa feministek pomagając...</td>\n",
       "      <td>True</td>\n",
       "      <td>[Loaded_Language, Slogans, Questioning_the_Rep...</td>\n",
       "      <td>train</td>\n",
       "      <td>[Grupa feministek pomagająca mordować nienarod...</td>\n",
       "      <td>[Aborcyjny Dream Team, Aborcyjny Dream Team, m...</td>\n",
       "      <td>...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[True]</td>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41/v001...</td>\n",
       "      <td>[{'code': 'content_filter', 'innererror': {'co...</td>\n",
       "      <td>[no validation]</td>\n",
       "      <td>train</td>\n",
       "      <td>{\"description\": null, \"verdict\": false}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>RU_demography_1.txt</td>\n",
       "      <td>1283</td>\n",
       "      <td>1609</td>\n",
       "      <td>RU</td>\n",
       "      <td>Русские, как народ, нация, культура, могут исч...</td>\n",
       "      <td>True</td>\n",
       "      <td>[Appeal_to_Fear-Prejudice]</td>\n",
       "      <td>train</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[True]</td>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41/v001...</td>\n",
       "      <td>[{'code': 'content_filter', 'innererror': {'co...</td>\n",
       "      <td>[no validation]</td>\n",
       "      <td>train</td>\n",
       "      <td>{\"description\": null, \"verdict\": false}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>20231208_URW_BG_76.txt</td>\n",
       "      <td>5170</td>\n",
       "      <td>5523</td>\n",
       "      <td>BG</td>\n",
       "      <td>Това, което всъщност в момента даваме тук, е р...</td>\n",
       "      <td>True</td>\n",
       "      <td>[Consequential_Oversimplification, Loaded_Lang...</td>\n",
       "      <td>train</td>\n",
       "      <td>[след престъпниците, които управляват Армията ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[True]</td>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41/v001...</td>\n",
       "      <td>[{'code': 'content_filter', 'innererror': {'co...</td>\n",
       "      <td>[no validation]</td>\n",
       "      <td>train</td>\n",
       "      <td>{\"description\": null, \"verdict\": false}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570</th>\n",
       "      <td>pl_abortion_11_04_2024_n08.txt</td>\n",
       "      <td>290</td>\n",
       "      <td>1251</td>\n",
       "      <td>PL</td>\n",
       "      <td>Poseł Roman Fritz:\\nGrupa feministek pomagając...</td>\n",
       "      <td>True</td>\n",
       "      <td>[Loaded_Language, Slogans, Questioning_the_Rep...</td>\n",
       "      <td>train</td>\n",
       "      <td>[Grupa feministek pomagająca mordować nienarod...</td>\n",
       "      <td>[Aborcyjny Dream Team, Aborcyjny Dream Team, m...</td>\n",
       "      <td>...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[True]</td>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41/v001...</td>\n",
       "      <td>[{'code': 'content_filter', 'innererror': {'co...</td>\n",
       "      <td>[no validation]</td>\n",
       "      <td>train</td>\n",
       "      <td>{\"description\": null, \"verdict\": true}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625</th>\n",
       "      <td>RU_demography_1.txt</td>\n",
       "      <td>1283</td>\n",
       "      <td>1609</td>\n",
       "      <td>RU</td>\n",
       "      <td>Русские, как народ, нация, культура, могут исч...</td>\n",
       "      <td>True</td>\n",
       "      <td>[Appeal_to_Fear-Prejudice]</td>\n",
       "      <td>train</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[True]</td>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41/v001...</td>\n",
       "      <td>[{'code': 'content_filter', 'innererror': {'co...</td>\n",
       "      <td>[no validation]</td>\n",
       "      <td>train</td>\n",
       "      <td>{\"description\": null, \"verdict\": false}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>634</th>\n",
       "      <td>RU_migrants_5.txt</td>\n",
       "      <td>354</td>\n",
       "      <td>574</td>\n",
       "      <td>RU</td>\n",
       "      <td>йчас Каменск-Уральск во всех сводках новостей....</td>\n",
       "      <td>True</td>\n",
       "      <td>[Appeal_to_Fear-Prejudice]</td>\n",
       "      <td>train</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[True]</td>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41/v001...</td>\n",
       "      <td>[{'code': 'content_filter', 'innererror': {'co...</td>\n",
       "      <td>[no validation]</td>\n",
       "      <td>train</td>\n",
       "      <td>{\"description\": null, \"verdict\": false}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>RU_discrediting_the_west_7.txt</td>\n",
       "      <td>700</td>\n",
       "      <td>1046</td>\n",
       "      <td>RU</td>\n",
       "      <td>Затем 22 марта был теракт в концертном зале \"К...</td>\n",
       "      <td>True</td>\n",
       "      <td>[Guilt_by_Association, Appeal_to_Fear-Prejudice]</td>\n",
       "      <td>train</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[True]</td>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41/v001...</td>\n",
       "      <td>[{'code': 'content_filter', 'innererror': {'co...</td>\n",
       "      <td>[no validation]</td>\n",
       "      <td>train</td>\n",
       "      <td>{\"description\": null, \"verdict\": false}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>716</th>\n",
       "      <td>20231208_URW_BG_76.txt</td>\n",
       "      <td>5170</td>\n",
       "      <td>5523</td>\n",
       "      <td>BG</td>\n",
       "      <td>Това, което всъщност в момента даваме тук, е р...</td>\n",
       "      <td>True</td>\n",
       "      <td>[Consequential_Oversimplification, Loaded_Lang...</td>\n",
       "      <td>train</td>\n",
       "      <td>[след престъпниците, които управляват Армията ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[True]</td>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41/v001...</td>\n",
       "      <td>[{'code': 'content_filter', 'innererror': {'co...</td>\n",
       "      <td>[no validation]</td>\n",
       "      <td>train</td>\n",
       "      <td>{\"description\": null, \"verdict\": false}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>pl_abortion_11_04_2024_n08.txt</td>\n",
       "      <td>290</td>\n",
       "      <td>1251</td>\n",
       "      <td>PL</td>\n",
       "      <td>Poseł Roman Fritz:\\nGrupa feministek pomagając...</td>\n",
       "      <td>True</td>\n",
       "      <td>[Loaded_Language, Slogans, Questioning_the_Rep...</td>\n",
       "      <td>train</td>\n",
       "      <td>[Grupa feministek pomagająca mordować nienarod...</td>\n",
       "      <td>[Aborcyjny Dream Team, Aborcyjny Dream Team, m...</td>\n",
       "      <td>...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[True]</td>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41/v001...</td>\n",
       "      <td>[{'code': 'content_filter', 'innererror': {'co...</td>\n",
       "      <td>[no validation]</td>\n",
       "      <td>train</td>\n",
       "      <td>{\"description\": null, \"verdict\": false}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>RU_discrediting_the_west_5.txt</td>\n",
       "      <td>949</td>\n",
       "      <td>1079</td>\n",
       "      <td>RU</td>\n",
       "      <td>Не вызывало вопросов у Парижа и открытое поощр...</td>\n",
       "      <td>True</td>\n",
       "      <td>[Appeal_to_Hypocrisy]</td>\n",
       "      <td>train</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[True]</td>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41/v001...</td>\n",
       "      <td>[{'code': 'content_filter', 'innererror': {'co...</td>\n",
       "      <td>[no validation]</td>\n",
       "      <td>train</td>\n",
       "      <td>{\"description\": null, \"verdict\": false}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>881</th>\n",
       "      <td>RU_demography_1.txt</td>\n",
       "      <td>1283</td>\n",
       "      <td>1609</td>\n",
       "      <td>RU</td>\n",
       "      <td>Русские, как народ, нация, культура, могут исч...</td>\n",
       "      <td>True</td>\n",
       "      <td>[Appeal_to_Fear-Prejudice]</td>\n",
       "      <td>train</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[True]</td>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41/v001...</td>\n",
       "      <td>[{'code': 'content_filter', 'innererror': {'co...</td>\n",
       "      <td>[no validation]</td>\n",
       "      <td>train</td>\n",
       "      <td>{\"description\": null, \"verdict\": false}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>RU_migrants_5.txt</td>\n",
       "      <td>354</td>\n",
       "      <td>574</td>\n",
       "      <td>RU</td>\n",
       "      <td>йчас Каменск-Уральск во всех сводках новостей....</td>\n",
       "      <td>True</td>\n",
       "      <td>[Appeal_to_Fear-Prejudice]</td>\n",
       "      <td>train</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[True]</td>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41/v001...</td>\n",
       "      <td>[{'code': 'content_filter', 'innererror': {'co...</td>\n",
       "      <td>[no validation]</td>\n",
       "      <td>train</td>\n",
       "      <td>{\"description\": null, \"verdict\": false}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>902</th>\n",
       "      <td>RU_discrediting_the_west_7.txt</td>\n",
       "      <td>700</td>\n",
       "      <td>1046</td>\n",
       "      <td>RU</td>\n",
       "      <td>Затем 22 марта был теракт в концертном зале \"К...</td>\n",
       "      <td>True</td>\n",
       "      <td>[Guilt_by_Association, Appeal_to_Fear-Prejudice]</td>\n",
       "      <td>train</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[True]</td>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41/v001...</td>\n",
       "      <td>[{'code': 'content_filter', 'innererror': {'co...</td>\n",
       "      <td>[no validation]</td>\n",
       "      <td>train</td>\n",
       "      <td>{\"description\": null, \"verdict\": false}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>932</th>\n",
       "      <td>20231208_URW_BG_76.txt</td>\n",
       "      <td>5170</td>\n",
       "      <td>5523</td>\n",
       "      <td>BG</td>\n",
       "      <td>Това, което всъщност в момента даваме тук, е р...</td>\n",
       "      <td>True</td>\n",
       "      <td>[Consequential_Oversimplification, Loaded_Lang...</td>\n",
       "      <td>train</td>\n",
       "      <td>[след престъпниците, които управляват Армията ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[True]</td>\n",
       "      <td>data/llm_output/persuasion/explain/GPT_41/v001...</td>\n",
       "      <td>[{'code': 'content_filter', 'innererror': {'co...</td>\n",
       "      <td>[no validation]</td>\n",
       "      <td>train</td>\n",
       "      <td>{\"description\": null, \"verdict\": false}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           filename  start   end text_lang  \\\n",
       "38   pl_abortion_11_04_2024_n08.txt    290  1251        PL   \n",
       "134  RU_discrediting_the_west_7.txt    700  1046        RU   \n",
       "198          20231208_URW_BG_75.txt   5280  5654        BG   \n",
       "219             RU_demography_1.txt   1283  1609        RU   \n",
       "230  RU_discrediting_the_west_7.txt    700  1046        RU   \n",
       "274  pl_abortion_11_04_2024_n08.txt    290  1251        PL   \n",
       "369             RU_demography_1.txt   1283  1609        RU   \n",
       "470          20231208_URW_BG_76.txt   5170  5523        BG   \n",
       "570  pl_abortion_11_04_2024_n08.txt    290  1251        PL   \n",
       "625             RU_demography_1.txt   1283  1609        RU   \n",
       "634               RU_migrants_5.txt    354   574        RU   \n",
       "646  RU_discrediting_the_west_7.txt    700  1046        RU   \n",
       "716          20231208_URW_BG_76.txt   5170  5523        BG   \n",
       "796  pl_abortion_11_04_2024_n08.txt    290  1251        PL   \n",
       "868  RU_discrediting_the_west_5.txt    949  1079        RU   \n",
       "881             RU_demography_1.txt   1283  1609        RU   \n",
       "890               RU_migrants_5.txt    354   574        RU   \n",
       "902  RU_discrediting_the_west_7.txt    700  1046        RU   \n",
       "932          20231208_URW_BG_76.txt   5170  5523        BG   \n",
       "\n",
       "                                                  text  label_bin  \\\n",
       "38   Poseł Roman Fritz:\\nGrupa feministek pomagając...       True   \n",
       "134  Затем 22 марта был теракт в концертном зале \"К...       True   \n",
       "198  Така че не е непредизвикана агресията, убити с...       True   \n",
       "219  Русские, как народ, нация, культура, могут исч...       True   \n",
       "230  Затем 22 марта был теракт в концертном зале \"К...       True   \n",
       "274  Poseł Roman Fritz:\\nGrupa feministek pomagając...       True   \n",
       "369  Русские, как народ, нация, культура, могут исч...       True   \n",
       "470  Това, което всъщност в момента даваме тук, е р...       True   \n",
       "570  Poseł Roman Fritz:\\nGrupa feministek pomagając...       True   \n",
       "625  Русские, как народ, нация, культура, могут исч...       True   \n",
       "634  йчас Каменск-Уральск во всех сводках новостей....       True   \n",
       "646  Затем 22 марта был теракт в концертном зале \"К...       True   \n",
       "716  Това, което всъщност в момента даваме тук, е р...       True   \n",
       "796  Poseł Roman Fritz:\\nGrupa feministek pomagając...       True   \n",
       "868  Не вызывало вопросов у Парижа и открытое поощр...       True   \n",
       "881  Русские, как народ, нация, культура, могут исч...       True   \n",
       "890  йчас Каменск-Уральск во всех сводках новостей....       True   \n",
       "902  Затем 22 марта был теракт в концертном зале \"К...       True   \n",
       "932  Това, което всъщност в момента даваме тук, е р...       True   \n",
       "\n",
       "                                           label_multi base_split  \\\n",
       "38   [Loaded_Language, Slogans, Questioning_the_Rep...      train   \n",
       "134   [Guilt_by_Association, Appeal_to_Fear-Prejudice]      train   \n",
       "198  [Loaded_Language, Appeal_to_Pity, Name_Calling...      train   \n",
       "219                         [Appeal_to_Fear-Prejudice]      train   \n",
       "230   [Guilt_by_Association, Appeal_to_Fear-Prejudice]      train   \n",
       "274  [Loaded_Language, Slogans, Questioning_the_Rep...      train   \n",
       "369                         [Appeal_to_Fear-Prejudice]      train   \n",
       "470  [Consequential_Oversimplification, Loaded_Lang...      train   \n",
       "570  [Loaded_Language, Slogans, Questioning_the_Rep...      train   \n",
       "625                         [Appeal_to_Fear-Prejudice]      train   \n",
       "634                         [Appeal_to_Fear-Prejudice]      train   \n",
       "646   [Guilt_by_Association, Appeal_to_Fear-Prejudice]      train   \n",
       "716  [Consequential_Oversimplification, Loaded_Lang...      train   \n",
       "796  [Loaded_Language, Slogans, Questioning_the_Rep...      train   \n",
       "868                              [Appeal_to_Hypocrisy]      train   \n",
       "881                         [Appeal_to_Fear-Prejudice]      train   \n",
       "890                         [Appeal_to_Fear-Prejudice]      train   \n",
       "902   [Guilt_by_Association, Appeal_to_Fear-Prejudice]      train   \n",
       "932  [Consequential_Oversimplification, Loaded_Lang...      train   \n",
       "\n",
       "                            Questioning_the_Reputation  \\\n",
       "38   [Grupa feministek pomagająca mordować nienarod...   \n",
       "134                                                 []   \n",
       "198                                                 []   \n",
       "219                                                 []   \n",
       "230                                                 []   \n",
       "274  [Grupa feministek pomagająca mordować nienarod...   \n",
       "369                                                 []   \n",
       "470  [след престъпниците, които управляват Армията ...   \n",
       "570  [Grupa feministek pomagająca mordować nienarod...   \n",
       "625                                                 []   \n",
       "634                                                 []   \n",
       "646                                                 []   \n",
       "716  [след престъпниците, които управляват Армията ...   \n",
       "796  [Grupa feministek pomagająca mordować nienarod...   \n",
       "868                                                 []   \n",
       "881                                                 []   \n",
       "890                                                 []   \n",
       "902                                                 []   \n",
       "932  [след престъпниците, които управляват Армията ...   \n",
       "\n",
       "                                 Name_Calling-Labeling  ... extra_content  \\\n",
       "38   [Aborcyjny Dream Team, Aborcyjny Dream Team, m...  ...        [None]   \n",
       "134                                                 []  ...        [None]   \n",
       "198                                   [Новите еничари]  ...        [None]   \n",
       "219                                                 []  ...        [None]   \n",
       "230                                                 []  ...        [None]   \n",
       "274  [Aborcyjny Dream Team, Aborcyjny Dream Team, m...  ...        [None]   \n",
       "369                                                 []  ...        [None]   \n",
       "470                                                 []  ...        [None]   \n",
       "570  [Aborcyjny Dream Team, Aborcyjny Dream Team, m...  ...        [None]   \n",
       "625                                                 []  ...        [None]   \n",
       "634                                                 []  ...        [None]   \n",
       "646                                                 []  ...        [None]   \n",
       "716                                                 []  ...        [None]   \n",
       "796  [Aborcyjny Dream Team, Aborcyjny Dream Team, m...  ...        [None]   \n",
       "868                                                 []  ...        [None]   \n",
       "881                                                 []  ...        [None]   \n",
       "890                                                 []  ...        [None]   \n",
       "902                                                 []  ...        [None]   \n",
       "932                                                 []  ...        [None]   \n",
       "\n",
       "    explanation illegal_value think_content is_valid  \\\n",
       "38       [None]        [None]        [None]   [True]   \n",
       "134      [None]        [None]        [None]   [True]   \n",
       "198      [None]        [None]        [None]   [True]   \n",
       "219      [None]        [None]        [None]   [True]   \n",
       "230      [None]        [None]        [None]   [True]   \n",
       "274      [None]        [None]        [None]   [True]   \n",
       "369      [None]        [None]        [None]   [True]   \n",
       "470      [None]        [None]        [None]   [True]   \n",
       "570      [None]        [None]        [None]   [True]   \n",
       "625      [None]        [None]        [None]   [True]   \n",
       "634      [None]        [None]        [None]   [True]   \n",
       "646      [None]        [None]        [None]   [True]   \n",
       "716      [None]        [None]        [None]   [True]   \n",
       "796      [None]        [None]        [None]   [True]   \n",
       "868      [None]        [None]        [None]   [True]   \n",
       "881      [None]        [None]        [None]   [True]   \n",
       "890      [None]        [None]        [None]   [True]   \n",
       "902      [None]        [None]        [None]   [True]   \n",
       "932      [None]        [None]        [None]   [True]   \n",
       "\n",
       "                                           source_file  \\\n",
       "38   data/llm_output/persuasion/explain/GPT_41/v001...   \n",
       "134  data/llm_output/persuasion/explain/GPT_41/v001...   \n",
       "198  data/llm_output/persuasion/explain/GPT_41/v001...   \n",
       "219  data/llm_output/persuasion/explain/GPT_41/v001...   \n",
       "230  data/llm_output/persuasion/explain/GPT_41/v001...   \n",
       "274  data/llm_output/persuasion/explain/GPT_41/v001...   \n",
       "369  data/llm_output/persuasion/explain/GPT_41/v001...   \n",
       "470  data/llm_output/persuasion/explain/GPT_41/v001...   \n",
       "570  data/llm_output/persuasion/explain/GPT_41/v001...   \n",
       "625  data/llm_output/persuasion/explain/GPT_41/v001...   \n",
       "634  data/llm_output/persuasion/explain/GPT_41/v001...   \n",
       "646  data/llm_output/persuasion/explain/GPT_41/v001...   \n",
       "716  data/llm_output/persuasion/explain/GPT_41/v001...   \n",
       "796  data/llm_output/persuasion/explain/GPT_41/v001...   \n",
       "868  data/llm_output/persuasion/explain/GPT_41/v001...   \n",
       "881  data/llm_output/persuasion/explain/GPT_41/v001...   \n",
       "890  data/llm_output/persuasion/explain/GPT_41/v001...   \n",
       "902  data/llm_output/persuasion/explain/GPT_41/v001...   \n",
       "932  data/llm_output/persuasion/explain/GPT_41/v001...   \n",
       "\n",
       "                                                 error           status  \\\n",
       "38   [{'code': 'content_filter', 'innererror': {'co...  [no validation]   \n",
       "134  [{'code': 'content_filter', 'innererror': {'co...  [no validation]   \n",
       "198  [{'code': 'content_filter', 'innererror': {'co...  [no validation]   \n",
       "219  [{'code': 'content_filter', 'innererror': {'co...  [no validation]   \n",
       "230  [{'code': 'content_filter', 'innererror': {'co...  [no validation]   \n",
       "274  [{'code': 'content_filter', 'innererror': {'co...  [no validation]   \n",
       "369  [{'code': 'content_filter', 'innererror': {'co...  [no validation]   \n",
       "470  [{'code': 'content_filter', 'innererror': {'co...  [no validation]   \n",
       "570  [{'code': 'content_filter', 'innererror': {'co...  [no validation]   \n",
       "625  [{'code': 'content_filter', 'innererror': {'co...  [no validation]   \n",
       "634  [{'code': 'content_filter', 'innererror': {'co...  [no validation]   \n",
       "646  [{'code': 'content_filter', 'innererror': {'co...  [no validation]   \n",
       "716  [{'code': 'content_filter', 'innererror': {'co...  [no validation]   \n",
       "796  [{'code': 'content_filter', 'innererror': {'co...  [no validation]   \n",
       "868  [{'code': 'content_filter', 'innererror': {'co...  [no validation]   \n",
       "881  [{'code': 'content_filter', 'innererror': {'co...  [no validation]   \n",
       "890  [{'code': 'content_filter', 'innererror': {'co...  [no validation]   \n",
       "902  [{'code': 'content_filter', 'innererror': {'co...  [no validation]   \n",
       "932  [{'code': 'content_filter', 'innererror': {'co...  [no validation]   \n",
       "\n",
       "     split                          expected_output  \n",
       "38   train  {\"description\": null, \"verdict\": false}  \n",
       "134  train  {\"description\": null, \"verdict\": false}  \n",
       "198  train  {\"description\": null, \"verdict\": false}  \n",
       "219  train  {\"description\": null, \"verdict\": false}  \n",
       "230  train  {\"description\": null, \"verdict\": false}  \n",
       "274  train  {\"description\": null, \"verdict\": false}  \n",
       "369  train  {\"description\": null, \"verdict\": false}  \n",
       "470  train  {\"description\": null, \"verdict\": false}  \n",
       "570  train   {\"description\": null, \"verdict\": true}  \n",
       "625  train  {\"description\": null, \"verdict\": false}  \n",
       "634  train  {\"description\": null, \"verdict\": false}  \n",
       "646  train  {\"description\": null, \"verdict\": false}  \n",
       "716  train  {\"description\": null, \"verdict\": false}  \n",
       "796  train  {\"description\": null, \"verdict\": false}  \n",
       "868  train  {\"description\": null, \"verdict\": false}  \n",
       "881  train  {\"description\": null, \"verdict\": false}  \n",
       "890  train  {\"description\": null, \"verdict\": false}  \n",
       "902  train  {\"description\": null, \"verdict\": false}  \n",
       "932  train  {\"description\": null, \"verdict\": false}  \n",
       "\n",
       "[19 rows x 60 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['raw'].apply(lambda x: isinstance(x, np.ndarray) and None in x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895c8920",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "source_file\n",
       "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/bg/train-bg-part_0004.parquet           10\n",
       "data/llm_output/persuasion/explain/GPT_41/v001/Name_Calling-Labeling/train/ru/train-ru-part_0001.parquet         10\n",
       "data/llm_output/persuasion/explain/GPT_41/v001/Name_Calling-Labeling/train/bg/train-bg-part_0004.parquet         10\n",
       "data/llm_output/persuasion/explain/GPT_41/v001/Name_Calling-Labeling/train/bg/train-bg-part_0007.parquet         10\n",
       "data/llm_output/persuasion/explain/GPT_41/v001/Name_Calling-Labeling/train/bg/train-bg-part_0009.parquet         10\n",
       "data/llm_output/persuasion/explain/GPT_41/v001/Name_Calling-Labeling/train/pl/train-pl-part_0000.parquet         10\n",
       "data/llm_output/persuasion/explain/GPT_41/v001/Name_Calling-Labeling/train/pl/train-pl-part_0001.parquet         10\n",
       "data/llm_output/persuasion/explain/GPT_41/v001/Name_Calling-Labeling/train/pl/train-pl-part_0002.parquet         10\n",
       "data/llm_output/persuasion/explain/GPT_41/v001/Name_Calling-Labeling/train/pl/train-pl-part_0003.parquet         10\n",
       "data/llm_output/persuasion/explain/GPT_41/v001/Name_Calling-Labeling/train/ru/train-ru-part_0000.parquet         10\n",
       "data/llm_output/persuasion/explain/GPT_41/v001/Name_Calling-Labeling/train/ru/train-ru-part_0004.parquet         10\n",
       "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/pl/train-pl-part_0002.parquet           10\n",
       "data/llm_output/persuasion/explain/GPT_41/v001/Name_Calling-Labeling/train/ru/train-ru-part_0005.parquet         10\n",
       "data/llm_output/persuasion/explain/GPT_41/v001/Name_Calling-Labeling/train/ru/train-ru-part_0006.parquet         10\n",
       "data/llm_output/persuasion/explain/GPT_41/v001/Name_Calling-Labeling/train/ru/train-ru-part_0007.parquet         10\n",
       "data/llm_output/persuasion/explain/GPT_41/v001/Name_Calling-Labeling/train/ru/train-ru-part_0008.parquet         10\n",
       "data/llm_output/persuasion/explain/GPT_41/v001/Name_Calling-Labeling/train/ru/train-ru-part_0009.parquet         10\n",
       "data/llm_output/persuasion/explain/GPT_41/v001/Name_Calling-Labeling/train/si/train-si-part_0001.parquet         10\n",
       "data/llm_output/persuasion/explain/GPT_41/v001/Name_Calling-Labeling/train/si/train-si-part_0002.parquet         10\n",
       "data/llm_output/persuasion/explain/GPT_41/v001/Name_Calling-Labeling/train/si/train-si-part_0006.parquet         10\n",
       "data/llm_output/persuasion/explain/GPT_41/v001/Name_Calling-Labeling/train/bg/train-bg-part_0002.parquet         10\n",
       "data/llm_output/persuasion/explain/GPT_41/v001/Name_Calling-Labeling/train/bg/train-bg-part_0001.parquet         10\n",
       "data/llm_output/persuasion/explain/GPT_41/v001/Guilt_by_Association/train/si/train-si-part_0006.parquet          10\n",
       "data/llm_output/persuasion/explain/GPT_41/v001/Guilt_by_Association/train/si/train-si-part_0005.parquet          10\n",
       "data/llm_output/persuasion/explain/GPT_41/v001/Appeal_to_Hypocrisy/train/ru/train-ru-part_0007.parquet           10\n",
       "data/llm_output/persuasion/explain/GPT_41/v001/Doubt/train/bg/train-bg-part_0009.parquet                         10\n",
       "data/llm_output/persuasion/explain/GPT_41/v001/Doubt/train/pl/train-pl-part_0002.parquet                         10\n",
       "data/llm_output/persuasion/explain/GPT_41/v001/Doubt/train/ru/train-ru-part_0000.parquet                         10\n",
       "data/llm_output/persuasion/explain/GPT_41/v001/Doubt/train/ru/train-ru-part_0004.parquet                         10\n",
       "data/llm_output/persuasion/explain/GPT_41/v001/Doubt/train/ru/train-ru-part_0007.parquet                         10\n",
       "data/llm_output/persuasion/explain/GPT_41/v001/Doubt/train/ru/train-ru-part_0009.parquet                         10\n",
       "data/llm_output/persuasion/explain/GPT_41/v001/Guilt_by_Association/train/bg/train-bg-part_0004.parquet          10\n",
       "data/llm_output/persuasion/explain/GPT_41/v001/Guilt_by_Association/train/bg/train-bg-part_0005.parquet          10\n",
       "data/llm_output/persuasion/explain/GPT_41/v001/Guilt_by_Association/train/bg/train-bg-part_0008.parquet          10\n",
       "data/llm_output/persuasion/explain/GPT_41/v001/Guilt_by_Association/train/bg/train-bg-part_0009.parquet          10\n",
       "data/llm_output/persuasion/explain/GPT_41/v001/Guilt_by_Association/train/pl/train-pl-part_0002.parquet          10\n",
       "data/llm_output/persuasion/explain/GPT_41/v001/Guilt_by_Association/train/pl/train-pl-part_0007.parquet          10\n",
       "data/llm_output/persuasion/explain/GPT_41/v001/Guilt_by_Association/train/pl/train-pl-part_0008.parquet          10\n",
       "data/llm_output/persuasion/explain/GPT_41/v001/Guilt_by_Association/train/ru/train-ru-part_0000.parquet          10\n",
       "data/llm_output/persuasion/explain/GPT_41/v001/Guilt_by_Association/train/ru/train-ru-part_0004.parquet          10\n",
       "data/llm_output/persuasion/explain/GPT_41/v001/Guilt_by_Association/train/si/train-si-part_0001.parquet          10\n",
       "data/llm_output/persuasion/explain/GPT_41/v001/Questioning_the_Reputation/train/ru/train-ru-part_0000.parquet    10\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[~df.error.isna()].value_counts('source_file')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
